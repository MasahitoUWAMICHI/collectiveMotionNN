{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f855b76a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T12:17:27.035820Z",
     "start_time": "2022-10-27T12:17:27.031059Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install dgl-cu113 dglgo -f https://data.dgl.ai/wheels/repo.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7807020c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T12:17:27.049227Z",
     "start_time": "2022-10-27T12:17:27.044884Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['DGLBACKEND'] = 'pytorch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d12568c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T12:17:27.061719Z",
     "start_time": "2022-10-27T12:17:27.054111Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "\n",
    "import networkx as nx\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# デバイス設定\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "61e1f3ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T12:17:27.072110Z",
     "start_time": "2022-10-27T12:17:27.066927Z"
    }
   },
   "outputs": [],
   "source": [
    "def printNPZ(npz):\n",
    "    for kw in npz.files:\n",
    "        print(kw, npz[kw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0ba5ba52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T12:17:27.091630Z",
     "start_time": "2022-10-27T12:17:27.076327Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v0 1.0\n",
      "r 1.0\n",
      "D 0.1\n",
      "A 0.0\n",
      "L 20\n",
      "rho 1.0\n",
      "beta 1.0\n",
      "A_CFs [0.9 0.5]\n",
      "A_CIL 0.0\n",
      "cellType_ratio [0.7 0.3]\n",
      "quiv_colors ['k' 'r']\n",
      "kappa 0.5\n",
      "A_Macdonalds [0.5 0.5]\n",
      "batch_size 400\n",
      "state_size 3\n",
      "brownian_size 1\n",
      "periodic True\n",
      "t_max 1000\n",
      "methodSDE heun\n",
      "isIto False\n",
      "stepSDE 0.01\n"
     ]
    }
   ],
   "source": [
    "dirName = './HiraiwaModel_chem20220922_180005/'\n",
    "savedirName = dirName + 'ActiveNet_vp_rotsym_multiStep_transfer_batchNorm/'\n",
    "os.makedirs(savedirName, exist_ok=True)\n",
    "\n",
    "params = np.load(dirName+'params.npz')\n",
    "#traj = np.load(dirName+'result.npz')\n",
    "\n",
    "printNPZ(params)\n",
    "#printNPZ(traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c4e73591",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T12:17:27.104110Z",
     "start_time": "2022-10-27T12:17:27.095523Z"
    }
   },
   "outputs": [],
   "source": [
    "if params['periodic']:\n",
    "    L = torch.tensor(params['L'])\n",
    "    def calc_dr(r1, r2):\n",
    "        dr = torch.remainder((r1 - r2), L)\n",
    "        dr[dr > L/2] = dr[dr > L/2] - L\n",
    "        return dr\n",
    "else:\n",
    "    def calc_dr(r1, r2):\n",
    "        return r1 - r2\n",
    "    \n",
    "def makeGraph(x_data, r_thresh):\n",
    "        Ndata = x_data.size(0)\n",
    "        dx = calc_dr(torch.unsqueeze(x_data, 0), torch.unsqueeze(x_data, 1))\n",
    "        dx = torch.sum(dx**2, dim=2)\n",
    "        edges = torch.argwhere(dx < r_thresh/2)\n",
    "        return dgl.graph((edges[:,0], edges[:,1]), num_nodes=Ndata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e3e01d8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T12:17:27.113113Z",
     "start_time": "2022-10-27T12:17:27.106652Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./HiraiwaModel_chem20220922_180005/20221026_220625', './HiraiwaModel_chem20220922_180005/20221027_020808', './HiraiwaModel_chem20220922_180005/20221027_061543', './HiraiwaModel_chem20220922_180005/20221027_102254', './HiraiwaModel_chem20220922_180005/20221027_144800', './HiraiwaModel_chem20220922_180005/ActiveNet_vp_rotsym_batchNorm', './HiraiwaModel_chem20220922_180005/20221027_190650', './HiraiwaModel_chem20220922_180005/ActiveNet_vp_rotsym_multiStep_transfer_batchNorm']\n",
      "['./HiraiwaModel_chem20220922_180005/20221026_220625', './HiraiwaModel_chem20220922_180005/20221027_020808', './HiraiwaModel_chem20220922_180005/20221027_061543', './HiraiwaModel_chem20220922_180005/20221027_102254', './HiraiwaModel_chem20220922_180005/20221027_144800', './HiraiwaModel_chem20220922_180005/20221027_190650']\n"
     ]
    }
   ],
   "source": [
    "subdir_list = [f.path for f in os.scandir(dirName) if f.is_dir()]\n",
    "\n",
    "print(subdir_list)\n",
    "\n",
    "datadir_list = [f for f in subdir_list if 'result.npz' in [ff.name for ff in os.scandir(f)]]\n",
    "\n",
    "print(datadir_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3260481d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T12:17:27.127833Z",
     "start_time": "2022-10-27T12:17:27.116475Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], ['./HiraiwaModel_chem20220922_180005/ActiveNet_vp_rotsym_batchNorm/20221027_180328/20221027_180328_Model.pt'], [], [], [], []]\n",
      "['./HiraiwaModel_chem20220922_180005/ActiveNet_vp_rotsym_batchNorm/20221027_180328/20221027_180328_Model.pt']\n",
      "20221027_180328/20221027_180328\n"
     ]
    }
   ],
   "source": [
    "modeldirName = dirName + 'ActiveNet_vp_rotsym_batchNorm/'\n",
    "\n",
    "#datename = '20220921_160055'\n",
    "i_model = -1\n",
    "\n",
    "model_files_list = [[os.path.join(c, ff) for ff in f if ff.endswith('_Model.pt')]\n",
    "               for c, s, f in os.walk(modeldirName)]\n",
    "print(model_files_list)\n",
    "\n",
    "model_files = []\n",
    "for i in range(len(model_files_list)):\n",
    "    for j in range(len(model_files_list[i])):\n",
    "        model_files.append(model_files_list[i][j])\n",
    "print(model_files)\n",
    "\n",
    "model_dir = os.path.dirname(model_files[i_model])\n",
    "\n",
    "model_name = model_files[i_model].replace('_Model.pt', '').replace(modeldirName, '')\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "19f22447",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T12:17:27.138205Z",
     "start_time": "2022-10-27T12:17:27.130423Z"
    }
   },
   "outputs": [],
   "source": [
    "class myDataset(Dataset):\n",
    "    def __init__(self, data_x, celltype_List, t_yseq=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.data_x = data_x # List of tensors\n",
    "        #self.data_y = data_y\n",
    "        self.celltype_List = celltype_List\n",
    "        \n",
    "        self.data_len = np.array([xx.size(0) for xx in self.data_x])\n",
    "        self.t_yseq = t_yseq\n",
    "        \n",
    "        self.data_len_cumsum = np.cumsum(self.data_len - (self.t_yseq - 1))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.data_len - (self.t_yseq - 1)).sum()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        id_List = np.argwhere(index<self.data_len_cumsum)[0,0]\n",
    "        \n",
    "        if id_List:\n",
    "            id_tensor = index - self.data_len_cumsum[id_List-1]\n",
    "        else:\n",
    "            id_tensor = index\n",
    "        \n",
    "        return self.data_x[id_List][id_tensor], self.data_x[id_List][id_tensor:(id_tensor+self.t_yseq)], self.celltype_List[id_List]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "3e9e2f01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T12:17:27.531205Z",
     "start_time": "2022-10-27T12:17:27.140967Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "644"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dr_thresh = 7\n",
    "dt = 1\n",
    "batch_size = 8\n",
    "\n",
    "T_pred = 10\n",
    "\n",
    "N_data = len(datadir_list)\n",
    "\n",
    "#TR_VA_rate = np.array([0.6, 0.2])\n",
    "\n",
    "TR_last = 3\n",
    "VA_last = 4\n",
    "\n",
    "shuffle_inds = np.arange(N_data, dtype=int)\n",
    "np.random.shuffle(shuffle_inds)\n",
    "\n",
    "train_inds = shuffle_inds[:TR_last]\n",
    "valid_inds = shuffle_inds[TR_last:VA_last]\n",
    "test_inds = shuffle_inds[VA_last:]\n",
    "\n",
    "celltype_lst = []\n",
    "\n",
    "train_x = []\n",
    "valid_x = []\n",
    "test_x = []\n",
    "\n",
    "train_y = []\n",
    "valid_y = []\n",
    "test_y = []\n",
    "\n",
    "train_ct = []\n",
    "valid_ct = []\n",
    "test_ct = []\n",
    "\n",
    "for i_dir, subdirName in enumerate(datadir_list):\n",
    "    \n",
    "    traj = np.load(subdirName+'/result.npz')\n",
    "    \n",
    "    xy_t = torch.tensor(traj['xy'])#[:-1,:,:])\n",
    "    #v_t = calc_dr(torch.tensor(traj['xy'][1:,:,:]), torch.tensor(traj['xy'][:-1,:,:])) / dt\n",
    "    p_t = torch.unsqueeze(torch.tensor(traj['theta']), dim=2)#[:-1,:]), dim=2)\n",
    "    #w_t = torch.unsqueeze(torch.tensor((traj['theta'][1:,:]-traj['theta'][:-1,:])%(2*np.pi)/dt), dim=2)\n",
    "    \n",
    "    if i_dir in train_inds:\n",
    "        train_x.append(torch.concat((xy_t, p_t), -1))\n",
    "        #train_y.append(torch.concat((v_t, w_t), -1))\n",
    "        train_ct.append(torch.tensor(traj['celltype_label']).view(-1,1))\n",
    "\n",
    "    if i_dir in valid_inds:\n",
    "        valid_x.append(torch.concat((xy_t, p_t), -1))\n",
    "        #valid_y.append(torch.concat((v_t, w_t), -1))\n",
    "        valid_ct.append(torch.tensor(traj['celltype_label']).view(-1,1))\n",
    "        \n",
    "    if i_dir in test_inds:\n",
    "        test_x.append(torch.concat((xy_t, p_t), -1))\n",
    "        #test_y.append(torch.concat((v_t, w_t), -1))\n",
    "        test_ct.append(torch.tensor(traj['celltype_label']).view(-1,1))\n",
    "    \n",
    "train_dataset = myDataset(train_x, train_ct, t_yseq=T_pred)\n",
    "\n",
    "valid_dataset = myDataset(valid_x, valid_ct, t_yseq=T_pred)\n",
    "\n",
    "test_dataset = myDataset(test_x, test_ct, t_yseq=T_pred)\n",
    "\n",
    "\n",
    "train_data = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, pin_memory=True)\n",
    "valid_data = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, pin_memory=True)\n",
    "test_data = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, pin_memory=True)\n",
    "\n",
    "del train_x, train_ct, train_dataset\n",
    "del valid_x, valid_ct, valid_dataset\n",
    "del test_x, test_ct, test_dataset\n",
    "gc.collect()\n",
    "\n",
    "#print(data)\n",
    "#print(data.num_graphs)\n",
    "#print(data.x)\n",
    "#print(data.y)\n",
    "#print(data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1c0a633b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T12:17:27.535926Z",
     "start_time": "2022-10-27T12:17:27.532991Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 5 1]\n"
     ]
    }
   ],
   "source": [
    "print(train_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4f35452f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T12:17:27.550008Z",
     "start_time": "2022-10-27T12:17:27.540698Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_DataLoader__initialized',\n",
       " '_DataLoader__multiprocessing_context',\n",
       " '_IterableDataset_len_called',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__orig_bases__',\n",
       " '__parameters__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_auto_collation',\n",
       " '_dataset_kind',\n",
       " '_get_iterator',\n",
       " '_get_shared_seed',\n",
       " '_index_sampler',\n",
       " '_is_protocol',\n",
       " '_iterator',\n",
       " 'batch_sampler',\n",
       " 'batch_size',\n",
       " 'check_worker_number_rationality',\n",
       " 'collate_fn',\n",
       " 'dataset',\n",
       " 'drop_last',\n",
       " 'generator',\n",
       " 'multiprocessing_context',\n",
       " 'num_workers',\n",
       " 'persistent_workers',\n",
       " 'pin_memory',\n",
       " 'pin_memory_device',\n",
       " 'prefetch_factor',\n",
       " 'sampler',\n",
       " 'timeout',\n",
       " 'worker_init_fn']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e5e6c153",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T12:17:27.559063Z",
     "start_time": "2022-10-27T12:17:27.552543Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ca11fa4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T12:17:27.568104Z",
     "start_time": "2022-10-27T12:17:27.563752Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 992 1984 2976]\n"
     ]
    }
   ],
   "source": [
    "print(train_data.dataset.data_len_cumsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f94ee7f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T12:17:27.592517Z",
     "start_time": "2022-10-27T12:17:27.584198Z"
    }
   },
   "outputs": [],
   "source": [
    "def plotGraph(data):\n",
    "\n",
    "    # networkxのグラフに変換\n",
    "    nxg = dgl.to_networkx(data)\n",
    "\n",
    "    # 可視化のためのページランク計算\n",
    "    pr = nx.pagerank(nxg)\n",
    "    pr_max = np.array(list(pr.values())).max()\n",
    "\n",
    "    # 可視化する際のノード位置\n",
    "    draw_pos = nx.spring_layout(nxg, seed=0) \n",
    "\n",
    "    # ノードの色設定\n",
    "    cmap = plt.get_cmap('tab10')\n",
    "    labels = data.y.numpy()\n",
    "    colors = [cmap(l) for l in labels]\n",
    "\n",
    "    # 図のサイズ\n",
    "    fig0 = plt.figure(figsize=(10, 10))\n",
    "\n",
    "    # 描画\n",
    "    nx.draw_networkx_nodes(nxg, \n",
    "                          draw_pos,\n",
    "                          node_size=[v / pr_max * 1000 for v in pr.values()])#,\n",
    "                          #node_color=colors, alpha=0.5)\n",
    "    nx.draw_networkx_edges(nxg, draw_pos, arrowstyle='-', alpha=0.2)\n",
    "    nx.draw_networkx_labels(nxg, draw_pos, font_size=10)\n",
    "\n",
    "    #plt.title('KarateClub')\n",
    "    plt.show()\n",
    "\n",
    "    return fig0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "21e97796",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T12:17:27.617786Z",
     "start_time": "2022-10-27T12:17:27.595593Z"
    }
   },
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, Nchannels, dropout=0, batchN=False, flgBias=False):\n",
    "        super(NeuralNet, self).__init__()\n",
    "\n",
    "        if dropout:\n",
    "            self.dropout = nn.Dropout(p=dropout)\n",
    "        else:\n",
    "            self.dropout = 0\n",
    "            \n",
    "        if batchN:\n",
    "            self.bNorm1 = nn.BatchNorm1d(Nchannels)\n",
    "            self.bNorm2 = nn.BatchNorm1d(Nchannels)\n",
    "            self.bNorm3 = nn.BatchNorm1d(Nchannels)\n",
    "            \n",
    "        self.batchN=batchN\n",
    "        \n",
    "        self.layer1 = nn.Linear(in_channels, Nchannels, bias=flgBias)\n",
    "        self.layer2 = nn.Linear(Nchannels, Nchannels, bias=flgBias)\n",
    "        self.layer3 = nn.Linear(Nchannels, Nchannels, bias=flgBias)\n",
    "        self.layer4 = nn.Linear(Nchannels, out_channels, bias=flgBias)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.layer1.reset_parameters()\n",
    "        self.layer2.reset_parameters()\n",
    "        self.layer3.reset_parameters()\n",
    "        self.layer4.reset_parameters()\n",
    "        #nn.init.zeros_(self.layer1.weight)\n",
    "        #nn.init.zeros_(self.layer2.weight)\n",
    "        #nn.init.zeros_(self.layer3.weight)\n",
    "        #nn.init.zeros_(self.layer4.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.activation(self.layer1(x))\n",
    "        if self.batchN:\n",
    "            out = self.bNorm1(out)\n",
    "        if self.dropout:\n",
    "            out = self.dropout(out)\n",
    "        \n",
    "        out = self.activation(self.layer2(out))\n",
    "        if self.batchN:\n",
    "            out = self.bNorm2(out)\n",
    "        if self.dropout:\n",
    "            out = self.dropout(out)\n",
    "        \n",
    "        out = self.activation(self.layer3(out))\n",
    "        if self.batchN:\n",
    "            out = self.bNorm3(out)\n",
    "        if self.dropout:\n",
    "            out = self.dropout(out)\n",
    "        \n",
    "        out = self.layer4(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ActiveNet(nn.Module):\n",
    "    def __init__(self, xy_dim, r, dropout=0, batchN=False, bias=False, Nchannels=128):\n",
    "        super().__init__()\n",
    "\n",
    "        self.interactNN = NeuralNet(xy_dim*2 + 2, xy_dim, Nchannels, dropout, batchN, bias)\n",
    "\n",
    "        self.thetaDotNN = NeuralNet(xy_dim*2 + 2, 1, Nchannels, dropout, batchN, bias)\n",
    "        \n",
    "        self.selfpropel = nn.Parameter(torch.tensor(0.0, requires_grad=True, device=device))\n",
    "\n",
    "        #self.Normalizer = nn.Softmax(dim=1)\n",
    "\n",
    "        self.xy_dim = xy_dim\n",
    "        \n",
    "        self.r = r\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.interactNN.reset_parameters()\n",
    "\n",
    "        self.thetaDotNN.reset_parameters()\n",
    "        \n",
    "        nn.init.uniform_(self.selfpropel)\n",
    "\n",
    "        #self.bias.data.zero_()\n",
    "        \n",
    "    def load_celltypes(self, celltype):\n",
    "        self.celltype = celltype\n",
    "\n",
    "    def calc_message(self, edges):\n",
    "        dx = calc_dr(edges.dst['x'], edges.src['x'])\n",
    "\n",
    "        costheta = torch.cos(edges.dst['theta'])\n",
    "        sintheta = torch.sin(edges.dst['theta'])\n",
    "\n",
    "        dx_para = costheta * dx[..., :1] + sintheta * dx[..., 1:]\n",
    "        dx_perp = costheta * dx[..., 1:] - sintheta * dx[..., :1]\n",
    "\n",
    "        p_para_src = torch.cos(edges.src['theta'] - edges.dst['theta'])\n",
    "        p_perp_src = torch.sin(edges.src['theta'] - edges.dst['theta'])\n",
    "\n",
    "        rot_m_v = self.interactNN(torch.concat((dx_para, dx_perp, \n",
    "                                                p_para_src, p_perp_src,\n",
    "                                                edges.dst['type'], edges.src['type']), -1))\n",
    "\n",
    "        m_v = torch.concat((costheta * rot_m_v[..., :1] - sintheta * rot_m_v[..., 1:],\n",
    "                            costheta * rot_m_v[..., 1:] + sintheta * rot_m_v[..., :1]), -1)\n",
    "\n",
    "        m_theta = self.thetaDotNN(torch.concat((dx_para, dx_perp, \n",
    "                                                p_para_src, p_perp_src, \n",
    "                                                edges.dst['type'], edges.src['type']), -1))\n",
    "        \n",
    "        return {'m': torch.concat((m_v, m_theta), -1)}\n",
    "        \n",
    "    def forward(self, xv):\n",
    "        r_g = makeGraph(xv[..., :self.xy_dim], self.r/2)\n",
    "        r_g.ndata['x'] = xv[..., :self.xy_dim]\n",
    "        r_g.ndata['theta'] = xv[..., self.xy_dim:(self.xy_dim+1)]\n",
    "        r_g.ndata['type'] = self.celltype\n",
    "        r_g.update_all(self.calc_message, fn.sum('m', 'a'))\n",
    "        r_g.ndata['a'][..., :self.xy_dim] = r_g.ndata['a'][..., :self.xy_dim] + self.selfpropel * torch.concat((torch.cos(r_g.ndata['theta']), torch.sin(r_g.ndata['theta'])), -1)\n",
    "        \n",
    "        return r_g.ndata['a']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b52c1e60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T12:17:27.630376Z",
     "start_time": "2022-10-27T12:17:27.620432Z"
    }
   },
   "outputs": [],
   "source": [
    "def myLoss(out, target):\n",
    "    #dv = torch.sum(torch.square(out[..., :xy_dim] - target[..., :xy_dim]), dim=-1)\n",
    "    dv = torch.sum(torch.square(calc_dr(out[..., :xy_dim], target[..., :xy_dim])), dim=-1)\n",
    "    dcos = torch.cos(out[..., xy_dim] - target[..., xy_dim])\n",
    "    \n",
    "    wei_shape = np.ones([dv.dim()], dtype=int)\n",
    "    wei_shape[0] = T_pred\n",
    "    wei = torch.tensor(np.reshape(1/np.arange(1, T_pred+1), wei_shape)).to(dv.device)\n",
    "    wei = wei/wei.mean()\n",
    "    \n",
    "    return torch.mean(dv*wei), torch.mean((1-dcos)*wei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a8ed0774",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T12:17:27.691362Z",
     "start_time": "2022-10-27T12:17:27.639233Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dr_thresh 7\n",
      "batch_size 8\n",
      "train_inds [1 0 4]\n",
      "valid_inds [3]\n",
      "test_inds [2]\n",
      "val_loss_log [[0.09111871 0.44418126]\n",
      " [0.07597389 0.06489998]\n",
      " [0.04772207 0.05202916]\n",
      " [0.04632266 0.05390411]\n",
      " [0.04069772 0.06005173]\n",
      " [0.04226593 0.05445142]\n",
      " [0.03899791 0.05283115]\n",
      " [0.03684358 0.05249891]\n",
      " [0.03971675 0.05149936]\n",
      " [0.0371751  0.05173785]\n",
      " [0.03626863 0.05144568]\n",
      " [0.03588772 0.04907713]\n",
      " [0.03683211 0.04989376]\n",
      " [0.03551206 0.0517021 ]\n",
      " [0.03565202 0.05200741]\n",
      " [0.03540417 0.05068859]\n",
      " [0.03502168 0.05062947]\n",
      " [0.03597966 0.05099249]\n",
      " [0.03465882 0.04825766]\n",
      " [0.03467671 0.04826461]\n",
      " [0.03462716 0.04826995]\n",
      " [0.03459214 0.04826058]\n",
      " [0.0345862  0.04826218]\n",
      " [0.03456455 0.04825664]\n",
      " [0.03456592 0.04824945]\n",
      " [0.03452701 0.04825112]\n",
      " [0.03450526 0.04825334]\n",
      " [0.0344765  0.04823513]\n",
      " [0.03446846 0.0482363 ]\n",
      " [0.03445971 0.04822361]\n",
      " [0.03446096 0.0482255 ]\n",
      " [0.03444988 0.04822063]\n",
      " [0.03443012 0.04822293]\n",
      " [0.03442478 0.04821874]\n",
      " [0.03441511 0.04821655]\n",
      " [0.03440804 0.0482097 ]\n",
      " [0.03439086 0.04821148]\n",
      " [0.03438268 0.04819878]\n",
      " [0.03437518 0.04818629]\n",
      " [0.03435903 0.04819782]\n",
      " [0.0343461  0.04819283]\n",
      " [0.03434613 0.04818931]\n",
      " [0.03434084 0.04817795]\n",
      " [0.03433518 0.04817685]\n",
      " [0.03432674 0.04817877]\n",
      " [0.03432307 0.04817513]\n",
      " [0.03431909 0.0481764 ]\n",
      " [0.03431177 0.0481649 ]\n",
      " [0.03430995 0.04816829]\n",
      " [0.03430404 0.04816892]\n",
      " [0.03429045 0.04817629]\n",
      " [0.03428497 0.04817223]\n",
      " [0.03428277 0.04817101]\n",
      " [0.03427536 0.04817385]\n",
      " [0.03427932 0.04817846]\n",
      " [0.03427795 0.04818543]\n",
      " [0.03428046 0.04818673]\n",
      " [0.03427881 0.04817994]\n",
      " [0.03404322 0.04768482]\n",
      " [0.03404123 0.04768393]\n",
      " [0.03403925 0.04768388]\n",
      " [0.03403898 0.04768242]\n",
      " [0.0340353  0.04768307]\n",
      " [0.03403284 0.04768404]\n",
      " [0.0340328  0.04768114]\n",
      " [0.03403018 0.04768324]\n",
      " [0.03402929 0.04768493]\n",
      " [0.03402898 0.04768466]\n",
      " [0.03402729 0.04768391]\n",
      " [0.03394879 0.0473    ]\n",
      " [0.03394734 0.04730449]\n",
      " [0.03394717 0.0473075 ]\n",
      " [0.03394695 0.04731022]\n",
      " [0.03394657 0.04731296]\n",
      " [0.0339463  0.0473147 ]\n",
      " [0.03394595 0.04731678]\n",
      " [0.03390516 0.04720582]\n",
      " [0.03390459 0.04720603]\n",
      " [0.03390431 0.04720637]\n",
      " [0.03390414 0.04720673]\n",
      " [0.03390383 0.04720712]\n",
      " [0.03390372 0.04720743]\n",
      " [0.03390357 0.04720778]\n",
      " [0.0338827  0.04721145]\n",
      " [0.03388212 0.04721111]\n",
      " [0.03388177 0.04721114]\n",
      " [0.03388142 0.04721105]\n",
      " [0.03388115 0.04721099]\n",
      " [0.03388097 0.04721097]\n",
      " [0.03388099 0.04721081]\n",
      " [0.0338869  0.04724324]\n",
      " [0.03388632 0.04724314]\n",
      " [0.03388615 0.04724308]\n",
      " [0.03388605 0.04724304]\n",
      " [0.03388595 0.04724303]\n",
      " [0.03388589 0.04724293]\n",
      " [0.03391846 0.04726931]\n",
      " [0.03391769 0.04726926]\n",
      " [0.03391746 0.04726924]\n",
      " [0.03391734 0.04726953]\n",
      " [0.03391722 0.04726978]\n",
      " [0.03391715 0.04727006]\n",
      " [0.03394172 0.04727571]\n",
      " [0.03394116 0.04727584]\n",
      " [0.03394089 0.04727596]\n",
      " [0.03394081 0.04727598]\n",
      " [0.03394075 0.04727606]\n",
      " [0.03394072 0.04727612]\n",
      " [0.03394978 0.04727616]\n",
      " [0.03394976 0.04727625]\n",
      " [0.03394959 0.04727627]\n",
      " [0.03394949 0.04727628]\n",
      " [0.03394942 0.0472763 ]\n",
      " [0.03394937 0.04727638]\n",
      " [0.03395387 0.04727673]\n",
      " [0.03395427 0.04727687]\n",
      " [0.0339543  0.04727697]\n",
      " [0.03395425 0.04727698]\n",
      " [0.03395423 0.047277  ]\n",
      " [0.0339542  0.04727701]\n",
      " [0.03395716 0.04727704]\n",
      " [0.03395789 0.0472771 ]\n",
      " [0.03395814 0.04727717]\n",
      " [0.03395821 0.04727721]\n",
      " [0.03395824 0.04727726]\n",
      " [0.03395823 0.04727728]\n",
      " [0.03395945 0.04727723]\n",
      " [0.03395999 0.0472772 ]\n",
      " [0.03396033 0.04727722]\n",
      " [0.0339605  0.04727722]\n",
      " [0.03396059 0.04727721]\n",
      " [0.03396063 0.04727722]\n",
      " [0.033961   0.04727719]\n",
      " [0.03396127 0.04727719]\n",
      " [0.03396147 0.04727718]\n",
      " [0.03396163 0.04727719]\n",
      " [0.03396174 0.04727719]\n",
      " [0.0339618  0.04727719]\n",
      " [0.0339619  0.04727717]\n",
      " [0.033962   0.04727717]\n",
      " [0.0339621  0.04727716]\n",
      " [0.03396218 0.04727717]\n",
      " [0.03396224 0.04727716]\n",
      " [0.03396229 0.04727716]\n",
      " [0.03396235 0.04727715]\n",
      " [0.0339624  0.04727716]\n",
      " [0.03396244 0.04727714]\n",
      " [0.03396249 0.04727716]\n",
      " [0.03396251 0.04727715]\n",
      " [0.03396255 0.04727716]\n",
      " [0.03396257 0.04727714]\n",
      " [0.0339626  0.04727714]\n",
      " [0.03396263 0.04727715]\n",
      " [0.03396265 0.04727715]\n",
      " [0.03396265 0.04727715]\n",
      " [0.03396268 0.04727714]\n",
      " [0.03396269 0.04727714]\n",
      " [0.0339627  0.04727715]\n",
      " [0.03396271 0.04727713]\n",
      " [0.03396272 0.04727713]\n",
      " [0.03396273 0.04727715]\n",
      " [0.03396276 0.04727715]\n",
      " [0.03396276 0.04727714]\n",
      " [0.03396277 0.04727714]\n",
      " [0.03396277 0.04727715]\n",
      " [0.03396278 0.04727715]\n",
      " [0.03396278 0.04727714]\n",
      " [0.03396278 0.04727713]\n",
      " [0.03396278 0.04727714]\n",
      " [0.03396278 0.04727713]\n",
      " [0.03396278 0.04727714]\n",
      " [0.03396278 0.04727713]\n",
      " [0.03396279 0.04727713]\n",
      " [0.03396279 0.04727713]\n",
      " [0.03396279 0.04727713]\n",
      " [0.03396279 0.04727713]\n",
      " [0.03396279 0.04727713]\n",
      " [0.0339628  0.04727713]\n",
      " [0.0339628  0.04727714]\n",
      " [0.0339628  0.04727715]\n",
      " [0.0339628  0.04727715]\n",
      " [0.0339628  0.04727714]\n",
      " [0.0339628  0.04727713]\n",
      " [0.0339628  0.04727713]\n",
      " [0.0339628  0.04727713]\n",
      " [0.03396281 0.04727713]\n",
      " [0.03396281 0.04727713]\n",
      " [0.03396281 0.04727713]\n",
      " [0.03396282 0.04727713]\n",
      " [0.03396282 0.04727714]\n",
      " [0.03396281 0.04727713]\n",
      " [0.03396282 0.04727713]\n",
      " [0.03396282 0.04727714]\n",
      " [0.03396282 0.04727714]\n",
      " [0.03396282 0.04727713]\n",
      " [0.03396282 0.04727712]\n",
      " [0.03396282 0.04727714]\n",
      " [0.03396282 0.04727714]\n",
      " [0.03396282 0.04727713]\n",
      " [0.03396282 0.04727712]\n",
      " [0.03396282 0.04727713]\n",
      " [0.03396282 0.04727713]\n",
      " [0.03396282 0.04727713]\n",
      " [0.03396282 0.04727713]\n",
      " [0.03396282 0.04727713]\n",
      " [0.03396282 0.04727712]\n",
      " [0.03396282 0.04727711]\n",
      " [0.03396282 0.04727713]\n",
      " [0.03396282 0.04727713]\n",
      " [0.03396281 0.04727713]\n",
      " [0.03396282 0.04727713]\n",
      " [0.03396282 0.04727713]\n",
      " [0.03396282 0.04727713]\n",
      " [0.03396282 0.04727712]\n",
      " [0.03396282 0.04727712]\n",
      " [0.03396282 0.04727712]\n",
      " [0.03396282 0.04727712]\n",
      " [0.03396282 0.04727713]\n",
      " [0.03396282 0.04727713]\n",
      " [0.03396283 0.04727712]\n",
      " [0.03396283 0.04727712]\n",
      " [0.03396283 0.04727712]\n",
      " [0.03396283 0.04727712]\n",
      " [0.03396283 0.04727712]\n",
      " [0.03396283 0.04727712]\n",
      " [0.03396283 0.04727713]\n",
      " [0.03396283 0.04727712]\n",
      " [0.03396283 0.04727712]\n",
      " [0.03396283 0.04727713]\n",
      " [0.03396283 0.04727713]\n",
      " [0.03396283 0.04727712]\n",
      " [0.03396283 0.04727712]\n",
      " [0.03396283 0.04727712]\n",
      " [0.03396283 0.04727712]\n",
      " [0.03396283 0.04727712]\n",
      " [0.03396283 0.04727712]\n",
      " [0.03396283 0.04727712]\n",
      " [0.03396283 0.04727712]\n",
      " [0.03396283 0.04727712]\n",
      " [0.03396283 0.04727712]\n",
      " [0.03396284 0.04727712]\n",
      " [0.03396284 0.04727711]\n",
      " [0.03396285 0.04727711]\n",
      " [0.03396285 0.04727711]\n",
      " [0.03396285 0.04727712]\n",
      " [0.03396285 0.04727712]\n",
      " [0.03396285 0.04727712]\n",
      " [0.03396285 0.04727711]\n",
      " [0.03396285 0.04727711]\n",
      " [0.03396285 0.04727712]\n",
      " [0.03396285 0.04727712]\n",
      " [0.03396285 0.04727712]\n",
      " [0.03396285 0.04727712]\n",
      " [0.03396284 0.04727712]\n",
      " [0.03396285 0.04727712]\n",
      " [0.03396285 0.04727712]\n",
      " [0.03396285 0.04727712]\n",
      " [0.03396285 0.04727711]\n",
      " [0.03396285 0.04727712]\n",
      " [0.03396285 0.04727711]\n",
      " [0.03396285 0.04727712]\n",
      " [0.03396285 0.04727712]\n",
      " [0.03396285 0.04727711]\n",
      " [0.03396285 0.04727712]\n",
      " [0.03396285 0.04727712]\n",
      " [0.03396285 0.04727712]\n",
      " [0.03396285 0.04727712]\n",
      " [0.03396285 0.04727711]\n",
      " [0.03396285 0.04727712]\n",
      " [0.03396285 0.04727711]\n",
      " [0.03396285 0.04727711]\n",
      " [0.03396285 0.04727711]\n",
      " [0.03396285 0.04727712]\n",
      " [0.03396285 0.04727711]\n",
      " [0.03396286 0.04727711]\n",
      " [0.03396286 0.0472771 ]\n",
      " [0.03396286 0.04727711]\n",
      " [0.03396286 0.0472771 ]\n",
      " [0.03396286 0.04727712]\n",
      " [0.03396286 0.04727711]\n",
      " [0.03396286 0.04727712]\n",
      " [0.03396286 0.04727711]\n",
      " [0.03396286 0.04727711]\n",
      " [0.03396286 0.04727711]\n",
      " [0.03396286 0.0472771 ]\n",
      " [0.03396286 0.0472771 ]\n",
      " [0.03396286 0.0472771 ]\n",
      " [0.03396286 0.0472771 ]\n",
      " [0.03396286 0.0472771 ]\n",
      " [0.03396286 0.0472771 ]\n",
      " [0.03396287 0.0472771 ]\n",
      " [0.03396287 0.0472771 ]\n",
      " [0.03396287 0.0472771 ]\n",
      " [0.03396287 0.0472771 ]\n",
      " [0.03396287 0.0472771 ]\n",
      " [0.03396287 0.0472771 ]\n",
      " [0.03396288 0.0472771 ]\n",
      " [0.03396287 0.0472771 ]\n",
      " [0.03396287 0.0472771 ]\n",
      " [0.03396287 0.0472771 ]]\n",
      "test_loss [0.032296   0.04566798]\n"
     ]
    }
   ],
   "source": [
    "filename1 = modeldirName + model_name + '_Model.pt'\n",
    "model = torch.load(filename1, map_location=torch.device(device)) #pickle.load(open(filename1, 'rb'))\n",
    "model.train()\n",
    "\n",
    "filename3 = modeldirName + model_name + '_Separation.npz'\n",
    "learn_params = np.load(filename3, allow_pickle=True)\n",
    "\n",
    "printNPZ(learn_params)\n",
    "\n",
    "dr_thresh = learn_params['dr_thresh'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6033283c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T16:18:02.624105Z",
     "start_time": "2022-10-27T12:17:27.693519Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | train Loss: [2.7097, 0.1933] | valid Loss: [2.5105, 0.1870]\n",
      "Epoch 1 | train Loss: [2.7058, 0.1928] | valid Loss: [2.5378, 0.1885]\n",
      "Epoch 2 | train Loss: [2.7089, 0.1917] | valid Loss: [2.5472, 0.1879]\n",
      "Epoch 3 | train Loss: [2.6962, 0.1939] | valid Loss: [2.5655, 0.1893]\n",
      "Epoch 4 | train Loss: [2.6881, 0.1927] | valid Loss: [2.5510, 0.1891]\n",
      "Epoch 5 | train Loss: [2.7079, 0.1916] | valid Loss: [2.5676, 0.1897]\n",
      "Epoch 6 | train Loss: [2.7021, 0.1934] | valid Loss: [2.4987, 0.1879]\n",
      "Epoch 7 | train Loss: [2.6808, 0.1926] | valid Loss: [2.4818, 0.1873]\n",
      "Epoch 8 | train Loss: [2.6873, 0.1925] | valid Loss: [2.4950, 0.1892]\n",
      "Epoch 9 | train Loss: [2.7006, 0.1942] | valid Loss: [2.5226, 0.1892]\n",
      "Epoch 10 | train Loss: [2.7167, 0.1914] | valid Loss: [2.5047, 0.1887]\n",
      "Epoch 11 | train Loss: [2.6827, 0.1950] | valid Loss: [2.5499, 0.1905]\n",
      "Epoch 12 | train Loss: [2.6946, 0.1953] | valid Loss: [2.5603, 0.1905]\n",
      "Epoch 00014: reducing learning rate of group 0 to 1.5000e-06.\n",
      "Epoch 13 | train Loss: [2.6672, 0.1962] | valid Loss: [2.5575, 0.1919]\n",
      "Epoch 14 | train Loss: [2.6813, 0.1974] | valid Loss: [2.5848, 0.1922]\n",
      "Epoch 15 | train Loss: [2.6746, 0.1934] | valid Loss: [2.5229, 0.1907]\n",
      "Epoch 16 | train Loss: [2.6602, 0.1965] | valid Loss: [2.5717, 0.1920]\n",
      "Epoch 17 | train Loss: [2.6621, 0.1970] | valid Loss: [2.5483, 0.1924]\n",
      "Epoch 18 | train Loss: [2.6929, 0.1975] | valid Loss: [2.5404, 0.1914]\n",
      "Epoch 00020: reducing learning rate of group 0 to 7.5000e-07.\n",
      "Epoch 19 | train Loss: [2.6856, 0.1967] | valid Loss: [2.5727, 0.1929]\n",
      "Epoch 20 | train Loss: [2.7169, 0.1978] | valid Loss: [2.5608, 0.1930]\n",
      "Epoch 21 | train Loss: [2.7246, 0.1974] | valid Loss: [2.5434, 0.1922]\n",
      "Epoch 22 | train Loss: [2.6853, 0.1948] | valid Loss: [2.5252, 0.1916]\n",
      "Epoch 23 | train Loss: [2.7135, 0.1969] | valid Loss: [2.5808, 0.1942]\n",
      "Epoch 24 | train Loss: [2.6954, 0.1985] | valid Loss: [2.5383, 0.1920]\n",
      "Epoch 00026: reducing learning rate of group 0 to 3.7500e-07.\n",
      "Epoch 25 | train Loss: [2.6838, 0.1984] | valid Loss: [2.5366, 0.1920]\n",
      "Epoch 26 | train Loss: [2.6810, 0.1980] | valid Loss: [2.5518, 0.1925]\n",
      "Epoch 27 | train Loss: [2.6841, 0.1961] | valid Loss: [2.5158, 0.1919]\n",
      "Epoch 28 | train Loss: [2.6938, 0.1977] | valid Loss: [2.5718, 0.1933]\n",
      "Epoch 29 | train Loss: [2.7270, 0.1996] | valid Loss: [2.5644, 0.1934]\n",
      "Epoch 30 | train Loss: [2.6989, 0.1971] | valid Loss: [2.5317, 0.1919]\n",
      "Epoch 00032: reducing learning rate of group 0 to 1.8750e-07.\n",
      "Epoch 31 | train Loss: [2.6868, 0.1979] | valid Loss: [2.5472, 0.1922]\n",
      "Epoch 32 | train Loss: [2.6926, 0.1982] | valid Loss: [2.5789, 0.1931]\n",
      "Epoch 33 | train Loss: [2.6699, 0.1992] | valid Loss: [2.5534, 0.1925]\n",
      "Epoch 34 | train Loss: [2.6869, 0.1966] | valid Loss: [2.5612, 0.1924]\n",
      "Epoch 35 | train Loss: [2.6905, 0.1985] | valid Loss: [2.5421, 0.1927]\n",
      "Epoch 36 | train Loss: [2.6848, 0.1968] | valid Loss: [2.5384, 0.1917]\n",
      "Epoch 00038: reducing learning rate of group 0 to 9.3750e-08.\n",
      "Epoch 37 | train Loss: [2.6874, 0.1984] | valid Loss: [2.5411, 0.1919]\n",
      "Epoch 38 | train Loss: [2.6841, 0.1978] | valid Loss: [2.5597, 0.1926]\n",
      "Epoch 39 | train Loss: [2.6916, 0.1982] | valid Loss: [2.5514, 0.1934]\n",
      "Epoch 40 | train Loss: [2.6903, 0.1986] | valid Loss: [2.5322, 0.1925]\n",
      "Epoch 41 | train Loss: [2.6742, 0.1968] | valid Loss: [2.5635, 0.1928]\n",
      "Epoch 42 | train Loss: [2.6881, 0.1974] | valid Loss: [2.5245, 0.1922]\n",
      "Epoch 00044: reducing learning rate of group 0 to 4.6875e-08.\n",
      "Epoch 43 | train Loss: [2.6839, 0.1983] | valid Loss: [2.5333, 0.1919]\n",
      "Epoch 44 | train Loss: [2.6971, 0.1991] | valid Loss: [2.5653, 0.1928]\n",
      "Epoch 45 | train Loss: [2.7018, 0.1989] | valid Loss: [2.5464, 0.1923]\n",
      "Epoch 46 | train Loss: [2.6894, 0.1991] | valid Loss: [2.5799, 0.1933]\n",
      "Epoch 47 | train Loss: [2.7004, 0.1981] | valid Loss: [2.5747, 0.1935]\n",
      "Epoch 48 | train Loss: [2.7204, 0.1981] | valid Loss: [2.5736, 0.1934]\n",
      "Epoch 00050: reducing learning rate of group 0 to 2.3438e-08.\n",
      "Epoch 49 | train Loss: [2.6977, 0.1985] | valid Loss: [2.5524, 0.1933]\n"
     ]
    }
   ],
   "source": [
    "# モデルのインスタンス生成\n",
    "xy_dim = 2\n",
    "\n",
    "#model = ActiveNet(xy_dim, dr_thresh, dropout=0, batchN=True, bias=True, Nchannels=128).to(device)\n",
    "# input data\n",
    "#data = dataset[0]\n",
    "\n",
    "def calc_multiSteps(x0):\n",
    "    outs = []\n",
    "    x_i = x0\n",
    "    for i_step in range(T_pred):\n",
    "        x_i = x_i + model(x_i) * dt\n",
    "        outs.append(x_i.clone())\n",
    "    return torch.stack(outs, dim=0)\n",
    "\n",
    "# optimizer\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-6)#, weight_decay=5e-4)\n",
    "#optimizer = torch.optim.Adadelta(model.parameters())#, rho=0.95)#, lr=1e-1, momentum=0.9)\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "val_loss_log = []\n",
    "\n",
    "val_loss_min = np.Inf\n",
    "\n",
    "# learnig loop\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    for batch_x, batch_y, batch_ct in train_data:\n",
    "        optimizer.zero_grad()\n",
    "        lossv = 0\n",
    "        losstheta = 0\n",
    "        for ib in range(batch_x.size(0)):\n",
    "            model.load_celltypes(batch_ct[ib].to(device))\n",
    "            out = calc_multiSteps(batch_x[ib].to(device))\n",
    "            lv, ltheta = myLoss(out, batch_y[ib].to(device))\n",
    "            lossv = lossv + lv\n",
    "            losstheta = losstheta + ltheta\n",
    "        lossv = lossv / batch_x.size(0)\n",
    "        losstheta = losstheta / batch_x.size(0)\n",
    "        (lossv+losstheta).backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    val_lossv = 0\n",
    "    val_losstheta = 0\n",
    "    val_count = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y, batch_ct in valid_data:\n",
    "            for ib in range(batch_x.size(0)):\n",
    "                model.load_celltypes(batch_ct[ib].to(device))\n",
    "                val_out = calc_multiSteps(batch_x[ib].to(device))\n",
    "                lv, ltheta = myLoss(val_out, batch_y[ib].to(device))\n",
    "                val_lossv = val_lossv + lv\n",
    "                val_losstheta = val_losstheta + ltheta\n",
    "            val_count = val_count + batch_x.size(0)\n",
    "    val_lossv = val_lossv/val_count\n",
    "    val_losstheta = val_losstheta/val_count\n",
    "    val_loss = val_lossv + val_losstheta\n",
    "    scheduler.step(val_loss)\n",
    "    print('Epoch %d | train Loss: [%.4f, %.4f] | valid Loss: [%.4f, %.4f]' % (epoch,\n",
    "                                                                              lossv.item(), \n",
    "                                                                              losstheta.item(),\n",
    "                                                                              val_lossv.item(), \n",
    "                                                                              val_losstheta.item()))\n",
    "    val_loss_log.append([val_lossv.cpu().item(), val_losstheta.cpu().item()])\n",
    "    if val_loss.item() < val_loss_min:\n",
    "        stored_model = model\n",
    "        val_loss_min = val_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "605ebb18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T16:18:02.631630Z",
     "start_time": "2022-10-27T16:18:02.626820Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 400, 3])\n",
      "torch.Size([8, 10, 400, 3])\n",
      "torch.Size([8, 400, 1])\n"
     ]
    }
   ],
   "source": [
    "print(batch_x.shape)\n",
    "print(batch_y.shape)\n",
    "print(batch_ct.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "b3cf1e91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T16:18:02.837263Z",
     "start_time": "2022-10-27T16:18:02.635134Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('selfpropel', tensor(0.8617, device='cuda:0')),\n",
       "             ('interactNN.bNorm1.weight',\n",
       "              tensor([0.9173, 0.9910, 1.1749, 0.9685, 0.8320, 1.1078, 1.0181, 0.8897, 0.8472,\n",
       "                      1.1797, 0.9780, 0.8649, 0.9766, 0.9301, 1.0359, 1.1456, 1.0157, 1.0834,\n",
       "                      0.8767, 0.9756, 0.9457, 1.0907, 0.8168, 0.8911, 0.9850, 1.1956, 0.8828,\n",
       "                      1.0226, 1.0311, 1.2722, 0.7459, 0.9651, 0.9768, 0.9565, 0.7992, 1.0840,\n",
       "                      0.8385, 0.8655, 1.0383, 0.9432, 1.1059, 1.0224, 0.9422, 0.9494, 0.9876,\n",
       "                      0.9649, 1.0489, 1.0169, 0.7972, 0.9525, 1.2413, 1.0787, 0.9296, 0.9439,\n",
       "                      1.0845, 1.0305, 1.0956, 0.9808, 0.8791, 1.0735, 0.9594, 1.2018, 0.8853,\n",
       "                      1.0334, 0.9027, 0.9483, 0.9781, 1.1861, 1.1026, 0.7283, 1.1525, 0.9674,\n",
       "                      0.9822, 0.9392, 0.9987, 0.7888, 0.9872, 1.0062, 0.9404, 0.9287, 0.9716,\n",
       "                      0.7328, 1.0533, 1.1927, 1.1836, 0.8267, 0.9615, 0.9459, 0.9709, 0.9348,\n",
       "                      1.0409, 1.1271, 1.0208, 1.2309, 1.2476, 1.0777, 0.9653, 1.2047, 0.7944,\n",
       "                      1.0914, 1.1499, 0.7569, 0.8649, 0.9015, 1.1293, 0.9631, 1.0683, 1.1382,\n",
       "                      1.0279, 0.9516, 1.0221, 0.9395, 1.0018, 0.9403, 0.9161, 0.9832, 1.1220,\n",
       "                      1.1472, 1.0096, 1.2480, 0.9162, 1.0187, 0.8646, 0.8061, 0.9839, 0.8373,\n",
       "                      1.3027, 0.9439], device='cuda:0')),\n",
       "             ('interactNN.bNorm1.bias',\n",
       "              tensor([ 0.1026,  0.1198, -0.0268, -0.0438, -0.0366,  0.3046,  0.1064,  0.0923,\n",
       "                       0.1141,  0.0742, -0.1029, -0.0846,  0.0360,  0.1791,  0.1309,  0.1892,\n",
       "                       0.2344,  0.1275, -0.0048,  0.3524, -0.1084,  0.1894,  0.0839,  0.0563,\n",
       "                       0.1039,  0.1890,  0.1181,  0.0588,  0.1108,  0.2514,  0.0305, -0.0669,\n",
       "                       0.0257, -0.0216,  0.0933, -0.0221, -0.0399, -0.0631,  0.0861,  0.1932,\n",
       "                       0.1282, -0.1248, -0.0051,  0.1332,  0.0751,  0.0141,  0.2005,  0.0611,\n",
       "                      -0.1298,  0.0376,  0.3087,  0.0170,  0.0498,  0.1612,  0.1021,  0.0248,\n",
       "                       0.1287,  0.0539,  0.0845,  0.0880,  0.1937,  0.2067, -0.0495,  0.0509,\n",
       "                       0.1367,  0.1310,  0.0209,  0.2082,  0.1747, -0.1688,  0.1908, -0.0248,\n",
       "                       0.0623,  0.0601,  0.0351, -0.0096,  0.0354,  0.1460,  0.2211,  0.1115,\n",
       "                      -0.0462,  0.0560,  0.2109,  0.2299,  0.1364,  0.0048, -0.0555,  0.0563,\n",
       "                      -0.0061,  0.0185,  0.0874,  0.1708,  0.1246,  0.2378,  0.2782, -0.0541,\n",
       "                      -0.0079,  0.1723, -0.0155,  0.0447,  0.1040, -0.0301, -0.0225,  0.0389,\n",
       "                       0.1148, -0.0060,  0.1485,  0.2514,  0.0451,  0.1358,  0.1068,  0.2020,\n",
       "                      -0.0952,  0.0102,  0.0186, -0.0259,  0.1917,  0.2129,  0.0482,  0.2600,\n",
       "                       0.1001,  0.2478,  0.0719, -0.0222,  0.1518,  0.0575,  0.2038,  0.0919],\n",
       "                     device='cuda:0')),\n",
       "             ('interactNN.bNorm1.running_mean',\n",
       "              tensor([0.1826, 0.3017, 0.0408, 0.2893, 0.2083, 0.3212, 0.2449, 0.1755, 0.3276,\n",
       "                      0.2328, 0.6652, 0.0150, 0.1999, 0.1028, 0.0093, 0.2224, 0.2982, 0.1407,\n",
       "                      0.4931, 0.0549, 0.4288, 0.2133, 0.5384, 0.5409, 0.2690, 0.0607, 0.0852,\n",
       "                      0.0461, 0.0309, 0.2180, 0.2679, 0.5042, 0.0041, 0.2407, 0.0570, 0.1245,\n",
       "                      0.3948, 0.5000, 0.1769, 0.0973, 0.0297, 0.0071, 0.3663, 0.1195, 0.0029,\n",
       "                      0.2687, 0.1407, 0.4032, 0.2905, 0.2928, 0.0541, 0.0982, 0.2584, 0.0563,\n",
       "                      0.2693, 0.0552, 0.0688, 0.2493, 0.2897, 0.0645, 0.2118, 0.1774, 0.1728,\n",
       "                      0.1796, 0.1508, 0.0610, 0.4370, 0.0357, 0.2138, 0.3371, 0.0827, 0.2686,\n",
       "                      0.0380, 0.0750, 0.3065, 0.4371, 0.0160, 0.2823, 0.1311, 0.1274, 0.0294,\n",
       "                      0.0789, 0.2343, 0.0772, 0.2652, 0.4764, 0.1633, 0.0454, 0.0363, 0.1738,\n",
       "                      0.3409, 0.2912, 0.0599, 0.2783, 0.3445, 0.3507, 0.2979, 0.2844, 0.1145,\n",
       "                      0.2720, 0.1563, 0.5829, 0.0822, 0.5442, 0.3277, 0.0622, 0.3842, 0.0784,\n",
       "                      0.1463, 0.2375, 0.0652, 0.0432, 0.4085, 0.3863, 0.3397, 0.1291, 0.2958,\n",
       "                      0.2279, 0.2045, 0.0847, 0.1776, 0.2676, 0.4181, 0.6111, 0.0440, 0.0467,\n",
       "                      0.1402, 0.0360], device='cuda:0')),\n",
       "             ('interactNN.bNorm1.running_var',\n",
       "              tensor([0.0562, 0.1087, 0.0078, 0.0723, 0.0550, 0.1185, 0.0864, 0.0555, 0.0431,\n",
       "                      0.0914, 0.1539, 0.0028, 0.0566, 0.0330, 0.0014, 0.0606, 0.1277, 0.0520,\n",
       "                      0.1686, 0.0139, 0.1482, 0.0695, 0.1074, 0.1060, 0.0661, 0.0188, 0.0243,\n",
       "                      0.0132, 0.0067, 0.0818, 0.0938, 0.1233, 0.0008, 0.0843, 0.0122, 0.0473,\n",
       "                      0.1210, 0.0934, 0.0534, 0.0359, 0.0072, 0.0012, 0.0967, 0.0327, 0.0003,\n",
       "                      0.1000, 0.0531, 0.0889, 0.0927, 0.0805, 0.0132, 0.0311, 0.0817, 0.0160,\n",
       "                      0.0872, 0.0131, 0.0178, 0.0775, 0.1017, 0.0189, 0.0751, 0.0675, 0.0244,\n",
       "                      0.0598, 0.0344, 0.0177, 0.0897, 0.0068, 0.0786, 0.0589, 0.0222, 0.0838,\n",
       "                      0.0089, 0.0215, 0.0975, 0.1146, 0.0034, 0.0840, 0.0597, 0.0358, 0.0069,\n",
       "                      0.0219, 0.0638, 0.0255, 0.0904, 0.1068, 0.0520, 0.0134, 0.0071, 0.0578,\n",
       "                      0.0984, 0.1016, 0.0146, 0.0943, 0.1317, 0.1192, 0.0541, 0.0911, 0.0364,\n",
       "                      0.0779, 0.0457, 0.0752, 0.0288, 0.1412, 0.1113, 0.0177, 0.1320, 0.0267,\n",
       "                      0.0542, 0.0699, 0.0200, 0.0133, 0.0668, 0.1038, 0.1196, 0.0474, 0.1136,\n",
       "                      0.0765, 0.0759, 0.0318, 0.0716, 0.1220, 0.1124, 0.1318, 0.0092, 0.0110,\n",
       "                      0.0533, 0.0123], device='cuda:0')),\n",
       "             ('interactNN.bNorm1.num_batches_tracked',\n",
       "              tensor(2388000, device='cuda:0')),\n",
       "             ('interactNN.bNorm2.weight',\n",
       "              tensor([0.9381, 1.0940, 1.0354, 1.0402, 1.1028, 1.0358, 1.0020, 1.0119, 0.9988,\n",
       "                      0.9556, 0.9138, 0.9631, 0.9841, 0.9687, 1.0312, 0.9440, 1.0743, 1.0302,\n",
       "                      0.9972, 0.9702, 0.9755, 0.9521, 1.0157, 1.0673, 1.0669, 1.1090, 1.1529,\n",
       "                      0.9339, 0.9520, 0.9051, 0.9165, 0.9854, 0.9473, 1.0566, 1.0859, 0.9748,\n",
       "                      0.9808, 0.9167, 1.0194, 0.8920, 0.9777, 1.0479, 1.0941, 0.9464, 1.1327,\n",
       "                      1.0149, 1.0620, 1.0162, 0.9685, 0.9899, 0.9105, 1.0045, 1.0515, 1.0890,\n",
       "                      1.0538, 1.0849, 1.0472, 0.9078, 1.0065, 1.0687, 1.0186, 1.0641, 0.9433,\n",
       "                      1.0504, 0.9494, 0.9955, 1.0134, 1.1238, 0.9508, 1.0255, 1.0792, 0.8804,\n",
       "                      0.9063, 0.9755, 0.9689, 1.0064, 0.9617, 0.9576, 0.9715, 1.0338, 1.0853,\n",
       "                      0.9894, 1.0187, 1.1072, 1.0271, 0.9682, 0.9693, 0.9790, 1.0211, 1.0211,\n",
       "                      1.0941, 0.9742, 0.9131, 1.0045, 1.0149, 1.0357, 0.9760, 1.0676, 1.0108,\n",
       "                      0.9807, 1.0005, 1.0029, 0.9584, 1.0894, 1.0293, 1.0430, 0.9360, 1.0039,\n",
       "                      1.0378, 0.9823, 1.0801, 0.8646, 1.0328, 1.0826, 0.9910, 0.9631, 0.9225,\n",
       "                      1.0248, 0.9794, 0.9380, 0.9916, 1.0420, 0.9845, 0.9955, 0.9102, 0.9664,\n",
       "                      0.9400, 0.8876], device='cuda:0')),\n",
       "             ('interactNN.bNorm2.bias',\n",
       "              tensor([ 0.1310,  0.1672,  0.1733, -0.0878, -0.0881,  0.0359,  0.2191,  0.0854,\n",
       "                       0.1884,  0.0245,  0.1619,  0.2338,  0.0713,  0.1154,  0.2633, -0.0282,\n",
       "                      -0.1433,  0.1292,  0.2638,  0.1152,  0.2296,  0.1238,  0.0537, -0.0187,\n",
       "                       0.0377,  0.0861,  0.0617,  0.1706,  0.1448,  0.1819,  0.0049,  0.2666,\n",
       "                       0.0068,  0.1975,  0.1381,  0.1345,  0.1282,  0.0433,  0.0206,  0.0195,\n",
       "                       0.2154,  0.0222, -0.2146, -0.0853, -0.0522,  0.1149,  0.0722,  0.0915,\n",
       "                      -0.0243,  0.0716,  0.0797,  0.2509, -0.0545,  0.1442,  0.2407,  0.0831,\n",
       "                       0.0604,  0.0552, -0.0961,  0.1473,  0.0410,  0.2376,  0.0122,  0.1629,\n",
       "                       0.2243, -0.2035,  0.0794,  0.1156, -0.1318, -0.0870,  0.0664,  0.1553,\n",
       "                       0.0286,  0.3146,  0.1896,  0.1578, -0.0453,  0.3062,  0.1040, -0.2233,\n",
       "                       0.0566,  0.2337,  0.0596,  0.0261, -0.0321,  0.0063,  0.0799,  0.1213,\n",
       "                       0.2443,  0.1144,  0.0509,  0.1553,  0.1074,  0.1845,  0.1245,  0.0649,\n",
       "                      -0.0897,  0.0560,  0.0865,  0.0901,  0.2543,  0.0041,  0.1521,  0.0249,\n",
       "                       0.0160,  0.2115,  0.1503, -0.0580,  0.0812,  0.0713,  0.0644,  0.0063,\n",
       "                       0.1801,  0.1306,  0.1320,  0.0972, -0.0606,  0.0022, -0.0064,  0.0272,\n",
       "                       0.0093,  0.2924,  0.0449, -0.0513, -0.0454,  0.1469,  0.0446,  0.0121],\n",
       "                     device='cuda:0')),\n",
       "             ('interactNN.bNorm2.running_mean',\n",
       "              tensor([0.6670, 0.4080, 0.8483, 0.4422, 0.0990, 0.3431, 0.9235, 0.3593, 0.6871,\n",
       "                      0.4873, 0.6665, 1.0096, 0.2990, 0.7328, 0.8251, 0.2486, 0.3483, 1.0107,\n",
       "                      0.8707, 0.4181, 0.3136, 0.5735, 0.4265, 0.3588, 0.4342, 0.2997, 0.3499,\n",
       "                      0.4661, 0.9462, 0.7977, 0.7454, 1.2500, 0.9062, 0.7745, 0.9496, 0.6461,\n",
       "                      0.6861, 0.6815, 1.1194, 0.4063, 0.9458, 0.1091, 0.2045, 0.5222, 0.3553,\n",
       "                      0.5118, 0.3201, 0.8525, 0.3582, 0.5358, 0.2463, 0.6413, 0.2514, 0.5427,\n",
       "                      0.8764, 1.0609, 0.3498, 0.6377, 0.3813, 0.5561, 0.7255, 0.7223, 0.9387,\n",
       "                      0.6119, 0.7882, 0.3441, 0.5934, 0.4415, 0.3649, 0.2659, 0.2188, 0.6653,\n",
       "                      0.4616, 0.2579, 0.5493, 0.9037, 0.3764, 0.6626, 0.3474, 0.4428, 0.2809,\n",
       "                      0.5718, 1.0234, 0.2798, 0.9455, 0.2213, 0.8975, 0.7547, 1.0740, 0.5468,\n",
       "                      0.2991, 0.6895, 0.8099, 0.3456, 0.2779, 1.0137, 0.5633, 0.7838, 0.2303,\n",
       "                      0.8777, 0.5973, 0.9908, 0.7286, 0.3494, 1.1201, 0.2224, 0.8008, 0.1755,\n",
       "                      1.4091, 0.4076, 0.3974, 0.1903, 0.8166, 0.4012, 1.2160, 1.0116, 0.4682,\n",
       "                      0.4845, 0.8265, 0.6570, 0.1895, 0.8123, 0.8327, 0.3285, 0.3955, 0.6346,\n",
       "                      0.5471, 0.2393], device='cuda:0')),\n",
       "             ('interactNN.bNorm2.running_var',\n",
       "              tensor([0.5467, 0.3680, 1.6701, 0.3573, 0.0423, 0.2637, 1.3817, 0.2622, 1.3276,\n",
       "                      0.3672, 0.8139, 2.4909, 0.1933, 1.1454, 1.3663, 0.1807, 0.2732, 2.4868,\n",
       "                      1.7893, 0.5398, 0.1908, 0.4822, 0.3536, 0.3402, 0.3685, 0.2788, 0.2811,\n",
       "                      0.4507, 1.7744, 0.9649, 1.4122, 2.5695, 1.8858, 1.3243, 1.2435, 0.8930,\n",
       "                      0.7275, 0.8775, 2.8281, 0.4265, 1.6040, 0.0654, 0.1360, 0.4837, 0.3734,\n",
       "                      0.4322, 0.2654, 1.6528, 0.3510, 0.5021, 0.1621, 0.9817, 0.1731, 0.5938,\n",
       "                      1.8799, 2.2541, 0.4839, 0.9207, 0.2605, 0.4490, 0.9815, 1.6083, 1.7961,\n",
       "                      0.4963, 1.3653, 0.2970, 0.4881, 0.3887, 0.2032, 0.2131, 0.1402, 0.8893,\n",
       "                      0.5278, 0.2296, 0.6216, 1.9765, 0.2864, 0.8375, 0.2554, 0.4745, 0.1804,\n",
       "                      0.4788, 1.9491, 0.2288, 1.9894, 0.1656, 1.1987, 1.3762, 2.1522, 0.5805,\n",
       "                      0.1918, 1.0206, 1.4798, 0.3549, 0.1458, 2.3322, 0.5693, 1.2163, 0.1437,\n",
       "                      1.4326, 0.8558, 2.0696, 0.5938, 0.2065, 3.1238, 0.2044, 0.9603, 0.1069,\n",
       "                      3.5826, 0.3781, 0.3221, 0.2061, 1.6292, 0.4765, 2.6326, 1.7889, 0.4813,\n",
       "                      0.6432, 1.4305, 0.7148, 0.1085, 1.4945, 1.4629, 0.2131, 0.3100, 0.6670,\n",
       "                      0.4687, 0.1281], device='cuda:0')),\n",
       "             ('interactNN.bNorm2.num_batches_tracked',\n",
       "              tensor(2388000, device='cuda:0')),\n",
       "             ('interactNN.bNorm3.weight',\n",
       "              tensor([0.5999, 0.2374, 0.2895, 0.2553, 0.3398, 0.5632, 0.6838, 0.0834, 0.5097,\n",
       "                      0.2230, 0.3512, 0.2862, 0.7562, 0.5378, 0.2334, 0.4654, 0.3455, 0.1753,\n",
       "                      0.2844, 0.0540, 0.3183, 0.2316, 0.1233, 0.1918, 0.3673, 0.4187, 0.2781,\n",
       "                      0.1984, 0.1821, 0.3487, 0.1496, 0.7188, 0.2453, 0.6773, 0.1293, 0.2992,\n",
       "                      0.8734, 0.2881, 0.1000, 0.1831, 0.1188, 0.1539, 0.3631, 0.2315, 0.2231,\n",
       "                      0.1995, 0.3015, 0.2527, 0.0450, 0.6655, 0.2463, 0.1084, 0.2506, 0.2231,\n",
       "                      0.1974, 0.4804, 0.8365, 0.2755, 0.0860, 0.1694, 0.4637, 0.1312, 0.5777,\n",
       "                      0.0141, 0.1373, 0.2974, 0.2463, 0.3012, 0.1308, 0.1880, 0.2805, 0.1571,\n",
       "                      0.1266, 0.2522, 0.2775, 0.1549, 0.3472, 0.5882, 0.3767, 0.2900, 0.7593,\n",
       "                      0.3434, 0.2686, 0.2474, 0.2436, 0.1525, 0.1731, 0.3130, 0.4594, 0.2626,\n",
       "                      0.5316, 0.1371, 0.3604, 0.3798, 0.3962, 0.2535, 0.4783, 0.6463, 0.1930,\n",
       "                      0.2407, 0.5446, 0.1595, 0.2495, 0.4819, 0.1526, 0.1859, 0.2907, 0.1962,\n",
       "                      0.1960, 0.3048, 0.2302, 0.2809, 0.4362, 0.2821, 0.6439, 0.3257, 0.1915,\n",
       "                      0.5755, 0.3044, 0.1004, 0.1940, 0.1797, 0.2323, 0.2976, 0.3297, 0.1792,\n",
       "                      0.2459, 0.2290], device='cuda:0')),\n",
       "             ('interactNN.bNorm3.bias',\n",
       "              tensor([ 1.5228e-02, -4.7507e-03, -3.7378e-04, -4.8515e-04,  7.7775e-04,\n",
       "                      -1.7392e-03,  9.4774e-03,  1.1753e-03,  4.0449e-03,  3.2111e-04,\n",
       "                       2.9112e-03, -1.6651e-03,  7.0950e-03, -2.1403e-04,  2.0319e-03,\n",
       "                       1.3854e-03, -4.7648e-03,  1.3693e-03,  1.1621e-03,  5.1582e-04,\n",
       "                      -6.9939e-04,  9.7892e-04, -3.4454e-04, -1.8169e-03, -2.6116e-03,\n",
       "                       2.9452e-03, -1.4869e-03,  5.8948e-04, -4.8357e-04, -2.3065e-04,\n",
       "                       1.7310e-03,  6.9639e-03,  6.4186e-04,  4.4734e-03, -4.0128e-05,\n",
       "                       1.9357e-03, -3.1436e-03, -8.9127e-04,  1.4127e-03, -3.4011e-03,\n",
       "                       2.0403e-04,  1.8252e-04,  6.4744e-04, -5.1022e-04, -2.4225e-04,\n",
       "                      -2.8714e-03, -1.0239e-03,  9.2155e-04,  1.9941e-03, -1.2814e-03,\n",
       "                      -1.1162e-03, -1.3547e-04,  1.3970e-03, -7.2388e-04, -2.3087e-04,\n",
       "                      -1.3798e-03, -3.2216e-03, -1.4563e-03,  7.5306e-04,  2.1142e-03,\n",
       "                       1.4866e-03, -2.9969e-03, -1.9261e-02,  1.8261e-04,  6.5793e-04,\n",
       "                      -1.5570e-03, -6.7474e-04, -3.3595e-03,  1.3134e-03,  2.0131e-04,\n",
       "                      -4.5037e-03,  3.2403e-03,  4.8065e-04, -3.1591e-03, -3.8011e-04,\n",
       "                       8.4065e-04, -1.6834e-03,  4.5802e-03, -4.9591e-03,  4.2007e-04,\n",
       "                      -7.5018e-03,  9.7626e-05,  3.0209e-03, -1.3728e-03,  1.7310e-03,\n",
       "                      -8.7251e-04, -1.9068e-03,  9.3438e-04, -6.7849e-04, -4.2158e-03,\n",
       "                       6.6170e-03,  4.4737e-04,  6.4370e-04, -1.9391e-03,  1.8147e-03,\n",
       "                      -1.6234e-03, -5.0573e-03, -7.0624e-03,  1.2361e-03, -5.9071e-04,\n",
       "                       1.2271e-03,  2.2506e-03,  2.4345e-04,  4.4682e-03,  1.6002e-03,\n",
       "                       9.5011e-04,  2.4560e-03, -6.4536e-04, -1.8877e-03,  1.7831e-03,\n",
       "                       2.2848e-03, -5.1164e-04,  2.8380e-04, -2.1232e-03, -2.6546e-03,\n",
       "                      -3.9194e-03,  9.5617e-04, -7.0533e-03,  2.7545e-03, -3.7845e-04,\n",
       "                       1.7215e-05,  1.0401e-03,  2.7768e-04, -1.1997e-03, -8.7502e-04,\n",
       "                       1.2911e-03, -6.4657e-04, -1.5140e-04], device='cuda:0')),\n",
       "             ('interactNN.bNorm3.running_mean',\n",
       "              tensor([0.8139, 0.0928, 0.1187, 0.3253, 0.7099, 0.3283, 0.5808, 0.6860, 0.2141,\n",
       "                      0.4682, 0.2161, 0.3246, 0.4764, 0.8064, 0.3617, 0.0843, 0.0467, 0.2968,\n",
       "                      0.4573, 0.5761, 0.3878, 0.3344, 0.4874, 0.5116, 0.1376, 0.0726, 0.2559,\n",
       "                      0.4189, 0.1957, 0.4073, 0.3615, 0.6239, 0.2206, 0.4759, 0.2241, 0.2024,\n",
       "                      0.5547, 0.2958, 0.1802, 0.3407, 0.4655, 0.2161, 0.1871, 0.4121, 0.3259,\n",
       "                      0.2570, 0.3430, 0.3228, 0.4602, 0.4918, 0.2977, 0.5305, 0.3578, 0.1640,\n",
       "                      0.4056, 0.0470, 0.4984, 0.1710, 0.3427, 0.3963, 0.1574, 0.3362, 1.2836,\n",
       "                      0.6385, 0.3809, 0.3945, 0.3626, 0.2329, 0.4735, 0.3934, 0.0969, 0.3505,\n",
       "                      0.5227, 0.0420, 0.1984, 0.3776, 0.0918, 0.4984, 0.0623, 0.2775, 0.5037,\n",
       "                      0.3163, 0.4010, 0.2488, 0.2611, 0.1816, 0.3294, 0.0842, 0.1020, 0.2966,\n",
       "                      0.8391, 0.2805, 0.1263, 0.2852, 0.1593, 0.1222, 0.1100, 0.6730, 0.5665,\n",
       "                      0.4189, 0.1446, 0.3714, 0.2211, 0.0924, 0.4705, 0.4748, 0.1385, 0.4078,\n",
       "                      0.2838, 0.4025, 0.1561, 0.3994, 0.2008, 0.2611, 0.1865, 0.3464, 0.4391,\n",
       "                      0.6512, 0.2667, 0.3719, 0.3840, 0.2335, 0.1311, 0.2113, 0.2484, 0.2865,\n",
       "                      0.1877, 0.2655], device='cuda:0')),\n",
       "             ('interactNN.bNorm3.running_var',\n",
       "              tensor([1.9006, 0.0399, 0.0659, 0.2657, 1.3806, 0.3357, 1.1489, 1.5664, 0.1647,\n",
       "                      0.4618, 0.1884, 0.2184, 0.8826, 1.5033, 0.3378, 0.0556, 0.0174, 0.2410,\n",
       "                      0.2876, 0.7037, 0.4771, 0.3732, 0.9617, 0.7607, 0.1079, 0.0474, 0.1905,\n",
       "                      0.3498, 0.1670, 0.4101, 0.3375, 1.0490, 0.1673, 0.9226, 0.1575, 0.1578,\n",
       "                      1.0689, 0.2182, 0.1670, 0.2596, 0.8264, 0.1697, 0.1351, 0.3515, 0.2580,\n",
       "                      0.2456, 0.3360, 0.2630, 0.4137, 0.8625, 0.2149, 0.5296, 0.2703, 0.1857,\n",
       "                      0.3323, 0.0280, 0.8998, 0.1052, 0.2896, 0.3513, 0.0946, 0.3652, 2.9929,\n",
       "                      1.0179, 0.2789, 0.3444, 0.3040, 0.2018, 0.4279, 0.2963, 0.0646, 0.2639,\n",
       "                      0.4297, 0.0190, 0.1424, 0.3335, 0.0592, 0.6525, 0.0269, 0.1959, 1.0090,\n",
       "                      0.3740, 0.3217, 0.1709, 0.2243, 0.1189, 0.2235, 0.0342, 0.0555, 0.3549,\n",
       "                      1.4562, 0.4031, 0.0999, 0.3108, 0.1241, 0.0711, 0.0735, 1.0564, 0.3780,\n",
       "                      0.5109, 0.1176, 0.6870, 0.1418, 0.0566, 0.4420, 0.5511, 0.0769, 0.7485,\n",
       "                      0.2103, 0.3337, 0.0847, 0.3040, 0.1641, 0.2084, 0.1440, 0.5123, 0.2982,\n",
       "                      1.5249, 0.1935, 0.3696, 0.3209, 0.3246, 0.0765, 0.2323, 0.2004, 0.2137,\n",
       "                      0.1265, 0.2166], device='cuda:0')),\n",
       "             ('interactNN.bNorm3.num_batches_tracked',\n",
       "              tensor(2388000, device='cuda:0')),\n",
       "             ('interactNN.layer1.weight',\n",
       "              tensor([[-4.4352e-01, -3.0289e-01, -1.8222e-01,  5.1389e-02,  4.7780e-02,\n",
       "                        2.4379e-01],\n",
       "                      [-6.6403e-01,  3.1243e-01,  2.1790e-01,  8.5708e-02,  6.4698e-02,\n",
       "                       -2.9817e-01],\n",
       "                      [-2.3741e-01, -4.3282e-01,  1.3072e-02, -4.2396e-02,  6.7448e-04,\n",
       "                        2.7525e-02],\n",
       "                      [ 2.2395e-01, -4.7622e-01,  6.1354e-02,  2.2102e-01,  8.1155e-03,\n",
       "                        1.0930e-02],\n",
       "                      [-4.0246e-01,  1.3110e-01,  2.4010e-01,  6.5875e-02,  2.0861e-01,\n",
       "                       -4.7120e-01],\n",
       "                      [-5.8803e-01,  4.8420e-01,  1.7209e-02,  4.8590e-02,  3.2474e-02,\n",
       "                        1.4693e-01],\n",
       "                      [ 4.9985e-01,  3.9160e-01, -9.4811e-02,  1.5010e-01,  3.5580e-02,\n",
       "                       -3.9627e-02],\n",
       "                      [ 3.4093e-01,  3.6542e-01, -2.4716e-01,  2.9884e-02, -1.4040e-01,\n",
       "                        1.4309e-01],\n",
       "                      [ 1.3506e-01,  1.9104e-01,  2.3879e-01, -2.3348e-02,  1.1152e-01,\n",
       "                       -2.8246e-01],\n",
       "                      [ 5.6869e-01, -4.7786e-01,  1.4548e-01, -1.0641e-01,  2.3117e-02,\n",
       "                       -3.8767e-02],\n",
       "                      [ 4.9091e-01,  1.2911e-01,  4.5976e-01, -1.5026e-01,  2.6632e-03,\n",
       "                        1.3344e-01],\n",
       "                      [ 2.2903e-01,  2.6529e-03, -1.0637e-01, -2.1199e-01, -3.9351e-01,\n",
       "                       -3.5657e-01],\n",
       "                      [ 5.3742e-01,  8.6163e-03, -6.5940e-02,  4.0288e-02,  9.1579e-02,\n",
       "                       -5.0844e-02],\n",
       "                      [-4.5757e-01, -3.0633e-01,  3.3686e-01, -2.1269e-01,  2.1344e-01,\n",
       "                       -1.9431e-01],\n",
       "                      [ 2.7240e-01,  3.6342e-01, -7.8951e-02,  9.5489e-02, -4.0810e-03,\n",
       "                       -3.0555e-02],\n",
       "                      [-5.3041e-01,  2.5095e-01,  2.4275e-01, -1.2446e-01, -2.7105e-02,\n",
       "                        2.1781e-02],\n",
       "                      [ 4.6332e-01, -5.8182e-01,  5.7236e-02, -2.7719e-01,  1.4272e-01,\n",
       "                        2.2832e-02],\n",
       "                      [-2.3607e-01, -5.9966e-01, -1.3905e-01, -1.0972e-01,  4.1858e-02,\n",
       "                        2.9103e-01],\n",
       "                      [ 3.2482e-01,  4.2668e-01,  1.1259e-01,  3.2545e-01, -3.0829e-01,\n",
       "                        4.2603e-01],\n",
       "                      [ 5.5517e-01, -3.1539e-02,  3.9498e-02,  5.2147e-02, -1.6370e-02,\n",
       "                        8.6223e-03],\n",
       "                      [ 3.6558e-01,  3.8966e-01,  5.1000e-01,  3.0867e-01, -2.4616e-01,\n",
       "                        2.8978e-01],\n",
       "                      [ 5.9836e-01, -2.5576e-02,  3.7340e-01, -8.1400e-02,  8.6118e-03,\n",
       "                       -4.6559e-03],\n",
       "                      [-4.8150e-02,  3.8111e-01,  3.3983e-01,  4.2575e-02, -7.5918e-03,\n",
       "                       -4.4652e-01],\n",
       "                      [ 3.5982e-01,  2.7068e-01,  2.9491e-01,  5.5511e-02,  1.3958e-01,\n",
       "                        4.3937e-02],\n",
       "                      [ 3.6075e-01,  3.2718e-01,  2.3739e-01, -4.6711e-02,  4.6060e-02,\n",
       "                       -1.6413e-02],\n",
       "                      [ 2.2983e-03, -7.5070e-01,  1.6210e-01,  1.2975e-01, -7.5423e-03,\n",
       "                       -4.7909e-02],\n",
       "                      [ 3.2638e-01, -9.0977e-02, -3.8619e-01,  8.7335e-02, -4.8868e-02,\n",
       "                       -1.3754e-02],\n",
       "                      [ 3.5049e-01, -4.3779e-01, -1.1907e-01, -2.1239e-01, -1.4477e-02,\n",
       "                       -5.7532e-02],\n",
       "                      [-4.1597e-01,  5.1672e-01, -8.5758e-02,  2.2133e-02,  4.2973e-02,\n",
       "                        5.0496e-02],\n",
       "                      [-7.9519e-01,  1.2957e-01,  2.5692e-01,  1.7142e-02, -6.5767e-03,\n",
       "                        2.5776e-02],\n",
       "                      [ 1.3458e-01,  5.5276e-01,  1.8598e-01, -3.3242e-01,  1.5807e-01,\n",
       "                        3.6007e-01],\n",
       "                      [ 5.0670e-01, -3.2779e-02,  3.3868e-01, -1.7019e-01,  1.6840e-02,\n",
       "                       -2.7108e-02],\n",
       "                      [ 1.0311e-01, -2.9854e-01, -3.5964e-01,  9.9033e-02, -7.3902e-03,\n",
       "                        4.5611e-02],\n",
       "                      [ 6.0384e-01,  1.3125e-01, -1.7725e-01, -4.7688e-03, -1.6756e-01,\n",
       "                        2.3393e-01],\n",
       "                      [ 3.2614e-01,  1.4206e-01,  2.2856e-01,  7.3372e-02, -1.5797e-01,\n",
       "                       -3.8942e-01],\n",
       "                      [ 4.7417e-01,  5.7726e-01, -1.6702e-01, -1.3993e-01,  1.5332e-02,\n",
       "                        4.5264e-02],\n",
       "                      [ 3.1408e-01,  4.4594e-01, -2.7114e-02,  1.6035e-01,  1.0458e-01,\n",
       "                        3.1653e-01],\n",
       "                      [ 2.1768e-01,  1.3779e-01,  4.8569e-01,  1.2010e-01, -1.2465e-01,\n",
       "                        3.2244e-01],\n",
       "                      [ 5.3576e-01, -2.1815e-01,  1.1559e-01, -3.1737e-02,  5.3098e-02,\n",
       "                       -4.4909e-02],\n",
       "                      [-2.8390e-01,  5.7117e-01, -2.0838e-01, -2.7544e-01, -1.4721e-01,\n",
       "                        1.0973e-01],\n",
       "                      [ 4.5344e-01,  2.9574e-01, -5.9562e-02,  6.8519e-02, -1.8072e-03,\n",
       "                        2.4187e-01],\n",
       "                      [ 1.0942e-01,  2.2662e-01, -1.8875e-01, -1.2128e-01, -1.3851e-02,\n",
       "                        6.3861e-03],\n",
       "                      [ 1.1247e-01, -4.4955e-01, -1.2767e-01, -1.0810e-01, -2.7497e-02,\n",
       "                        3.2182e-01],\n",
       "                      [ 6.9597e-02, -4.9658e-01,  3.1819e-01, -1.3380e-01, -8.3883e-02,\n",
       "                       -1.2115e-02],\n",
       "                      [-3.1844e-01, -7.5577e-03,  6.1359e-03, -2.2201e-01, -3.1369e-01,\n",
       "                        5.0933e-03],\n",
       "                      [-3.0006e-01, -5.4421e-01, -4.2788e-02, -1.9860e-01,  2.0005e-01,\n",
       "                       -2.9205e-01],\n",
       "                      [ 2.6730e-01,  6.5492e-01, -8.5142e-02,  1.0338e-01, -2.1244e-02,\n",
       "                       -1.1770e-01],\n",
       "                      [ 4.5967e-01,  2.6488e-02,  1.6115e-01,  6.3738e-03, -3.9140e-02,\n",
       "                        2.0868e-01],\n",
       "                      [-8.7936e-02, -4.5869e-01,  1.3816e-01, -3.4246e-01, -2.0393e-01,\n",
       "                       -1.4926e-01],\n",
       "                      [ 4.0298e-03,  4.7355e-01,  2.1345e-01,  1.1070e-01,  1.0724e-02,\n",
       "                        3.2322e-01],\n",
       "                      [ 2.8047e-01,  4.8342e-01,  3.9379e-02,  6.0302e-02, -1.2722e-02,\n",
       "                        4.9941e-03],\n",
       "                      [ 5.8592e-01,  1.8639e-01, -1.3017e-01, -6.8030e-02, -4.8869e-02,\n",
       "                        3.4123e-02],\n",
       "                      [-3.0194e-01,  5.0158e-01,  3.6339e-01,  1.6939e-01,  9.4483e-02,\n",
       "                       -2.3364e-01],\n",
       "                      [ 3.8400e-01, -1.3877e-01, -3.5726e-01,  2.2760e-03,  6.4704e-02,\n",
       "                        4.5056e-02],\n",
       "                      [ 3.4857e-01, -5.3340e-01, -1.3257e-01,  2.0752e-01,  2.5148e-02,\n",
       "                       -3.5019e-02],\n",
       "                      [ 3.1552e-01,  2.7953e-01, -9.9891e-02,  9.9553e-02,  8.2173e-03,\n",
       "                       -2.0976e-01],\n",
       "                      [-2.0230e-01,  5.4656e-01,  2.1579e-01, -2.2485e-02, -1.9303e-02,\n",
       "                       -7.0313e-03],\n",
       "                      [-4.9892e-01, -4.3147e-01,  1.2528e-01,  6.7817e-02,  1.1020e-01,\n",
       "                        2.7971e-02],\n",
       "                      [ 6.9246e-02,  4.6081e-01, -3.4431e-01,  1.3662e-01,  4.3159e-02,\n",
       "                        3.3447e-01],\n",
       "                      [ 2.9776e-01, -5.7485e-01,  2.1635e-01, -2.4164e-02, -2.2288e-03,\n",
       "                       -5.6475e-02],\n",
       "                      [ 4.7809e-01,  3.8326e-01,  1.2489e-01,  2.5308e-01, -9.9798e-02,\n",
       "                        6.3562e-02],\n",
       "                      [-6.3737e-01,  4.7054e-01, -9.1887e-02, -2.6084e-02, -1.1039e-02,\n",
       "                        1.2870e-02],\n",
       "                      [ 1.2321e-02, -2.4144e-01,  2.5582e-01, -1.0394e-01, -2.9904e-02,\n",
       "                        4.8145e-02],\n",
       "                      [ 1.3727e-01, -6.1731e-01, -1.3220e-01,  9.8291e-02, -1.2638e-01,\n",
       "                       -5.2877e-02],\n",
       "                      [-3.1380e-01, -1.9528e-01, -1.3222e-01, -2.0041e-02, -5.8327e-02,\n",
       "                       -3.3690e-01],\n",
       "                      [-5.5482e-01,  4.1853e-01, -1.0367e-01, -3.9495e-02,  1.7146e-01,\n",
       "                       -1.6046e-01],\n",
       "                      [-2.0386e-01,  4.5837e-01, -6.5504e-02, -9.1645e-02, -6.1990e-02,\n",
       "                        9.6537e-02],\n",
       "                      [-4.8053e-01,  1.6399e-01, -9.3341e-02,  1.1757e-02, -2.6620e-02,\n",
       "                        4.1456e-02],\n",
       "                      [-3.2203e-01, -6.2527e-01, -6.9760e-02,  1.8667e-01, -4.9751e-02,\n",
       "                        2.0552e-01],\n",
       "                      [-2.5185e-01,  1.2835e-01,  5.0419e-01, -7.3258e-02,  1.4902e-01,\n",
       "                       -2.4775e-01],\n",
       "                      [ 2.3145e-01,  4.9291e-01,  2.1465e-02,  6.7766e-02,  7.6907e-03,\n",
       "                        6.3391e-02],\n",
       "                      [ 5.5851e-01,  1.4114e-01, -2.7242e-02, -1.6485e-01, -4.7502e-02,\n",
       "                        2.3399e-01],\n",
       "                      [-4.7718e-01, -3.2581e-01, -1.2837e-01, -8.9801e-02,  6.0671e-02,\n",
       "                       -5.8551e-02],\n",
       "                      [-5.4294e-01,  3.0727e-01,  2.6396e-02,  3.5364e-02,  6.8588e-02,\n",
       "                       -3.3830e-01],\n",
       "                      [-1.0051e-01,  6.2412e-01, -1.3606e-01, -1.2760e-01, -7.1321e-02,\n",
       "                        1.3195e-01],\n",
       "                      [-1.5786e-01,  4.5099e-01, -9.0405e-02,  2.2575e-01,  1.4202e-01,\n",
       "                        9.1907e-02],\n",
       "                      [-5.4600e-01, -1.1696e-01, -4.6974e-02,  2.3487e-01,  8.8632e-03,\n",
       "                       -1.7373e-03],\n",
       "                      [ 3.9128e-01,  4.4520e-01, -1.3309e-01, -1.7518e-01,  9.2351e-02,\n",
       "                       -6.6894e-02],\n",
       "                      [ 2.2920e-01, -6.2497e-01, -2.8628e-01, -2.7063e-01, -2.2225e-01,\n",
       "                       -3.2408e-01],\n",
       "                      [-2.5406e-01, -4.3863e-01,  2.0092e-01,  1.3942e-01, -4.4574e-03,\n",
       "                       -4.6169e-01],\n",
       "                      [ 3.1657e-01,  1.0679e-02, -9.0302e-03, -3.2923e-02, -1.9938e-02,\n",
       "                        4.0889e-01],\n",
       "                      [-8.1299e-02,  2.3912e-01, -8.7667e-02, -3.7998e-01, -4.1596e-02,\n",
       "                       -3.5669e-01],\n",
       "                      [-1.5615e-01,  5.0619e-01,  4.0947e-01,  5.1706e-02, -1.2702e-02,\n",
       "                       -5.5498e-02],\n",
       "                      [ 6.8795e-01, -1.6955e-01,  5.5590e-02, -2.2103e-02,  1.4127e-03,\n",
       "                       -7.2116e-02],\n",
       "                      [-5.4682e-01,  4.9305e-01,  1.7037e-01, -1.4406e-01, -9.5253e-03,\n",
       "                        2.4644e-02],\n",
       "                      [-2.4559e-01,  4.3809e-01,  3.4622e-01, -1.5852e-01, -1.7246e-01,\n",
       "                       -1.8739e-01],\n",
       "                      [ 5.0157e-01, -2.8672e-01,  1.8548e-01,  2.7339e-01, -2.4751e-02,\n",
       "                        3.8060e-02],\n",
       "                      [ 4.0370e-01, -3.1694e-01, -2.6861e-01,  1.7178e-01, -1.1985e-01,\n",
       "                       -2.4741e-01],\n",
       "                      [ 3.3525e-01,  1.1279e-01,  3.1940e-01,  1.4519e-01, -1.5481e-02,\n",
       "                        1.1335e-01],\n",
       "                      [-4.6921e-01, -4.2618e-01, -7.0389e-02,  1.0833e-01, -2.7382e-01,\n",
       "                       -2.0733e-01],\n",
       "                      [ 3.1570e-01,  4.8813e-01,  9.8412e-02,  4.6587e-02, -1.8674e-02,\n",
       "                       -1.5292e-01],\n",
       "                      [-6.7689e-01, -9.2381e-02, -1.2335e-01,  2.2650e-02, -3.9557e-02,\n",
       "                        1.3801e-01],\n",
       "                      [-5.7875e-01,  1.2659e-01,  1.0810e-01,  6.2914e-02, -3.0713e-02,\n",
       "                       -1.6618e-01],\n",
       "                      [-4.9558e-01, -4.1751e-01, -1.5532e-01, -1.1609e-02, -7.5717e-03,\n",
       "                        2.4307e-02],\n",
       "                      [-6.8125e-01, -4.7510e-01,  1.4466e-01,  1.4441e-01, -1.6552e-03,\n",
       "                       -2.7094e-02],\n",
       "                      [-3.8312e-01, -5.8452e-01,  1.4896e-01, -3.6445e-03, -1.2923e-01,\n",
       "                        2.7145e-01],\n",
       "                      [-3.5311e-01, -1.5840e-01,  1.5050e-01,  7.9207e-02, -3.6105e-02,\n",
       "                        2.5076e-01],\n",
       "                      [-6.7937e-01, -1.7862e-01,  1.1912e-01,  6.6812e-02,  3.9900e-03,\n",
       "                        3.8321e-02],\n",
       "                      [ 9.5082e-02,  1.5186e-01, -2.8099e-01, -2.6681e-01, -1.9742e-02,\n",
       "                        4.7421e-01],\n",
       "                      [-2.7610e-01,  5.3897e-01,  2.3035e-02, -5.9831e-03, -1.2055e-02,\n",
       "                       -2.0638e-02],\n",
       "                      [ 1.1129e-01, -5.6025e-01,  3.7682e-01,  8.1882e-02,  1.2645e-02,\n",
       "                        3.6068e-02],\n",
       "                      [-1.4325e-01,  2.5316e-01,  1.5792e-01, -2.6115e-02,  1.4869e-01,\n",
       "                        3.9526e-01],\n",
       "                      [-6.0646e-02,  4.3472e-01, -2.0025e-01, -2.3621e-01, -4.7316e-02,\n",
       "                        4.3714e-01],\n",
       "                      [ 4.1344e-01,  4.2579e-01,  1.1591e-01, -2.0678e-02,  1.5170e-01,\n",
       "                        1.7080e-01],\n",
       "                      [-6.7608e-01, -3.0849e-01,  3.2464e-01,  7.9636e-02, -7.0729e-02,\n",
       "                        8.6418e-02],\n",
       "                      [ 3.2387e-01,  2.0811e-01, -7.9602e-02, -3.7787e-01,  9.9272e-03,\n",
       "                        7.8873e-02],\n",
       "                      [-4.1190e-01, -5.0289e-01, -1.2704e-01, -1.5138e-01, -1.5154e-02,\n",
       "                        1.2631e-01],\n",
       "                      [ 7.1711e-01, -1.9643e-01, -1.6272e-02, -3.2194e-03, -5.5507e-03,\n",
       "                        4.8997e-02],\n",
       "                      [-4.7164e-01, -5.2630e-01, -1.5786e-01,  7.2521e-02,  8.8828e-02,\n",
       "                       -2.8208e-01],\n",
       "                      [-4.2239e-01,  4.5895e-01,  1.0815e-01, -1.5110e-01,  7.5063e-02,\n",
       "                       -1.1043e-01],\n",
       "                      [ 3.8984e-01, -5.2268e-01, -1.1298e-01,  1.3108e-01, -4.5766e-02,\n",
       "                        2.0111e-01],\n",
       "                      [ 6.5457e-02, -2.3674e-01, -4.4341e-02, -2.4599e-01, -7.8843e-02,\n",
       "                        5.1564e-01],\n",
       "                      [-2.5789e-01,  3.2997e-01,  1.9561e-01,  4.3080e-03,  1.7370e-02,\n",
       "                       -5.6408e-02],\n",
       "                      [-2.7866e-02, -5.4206e-01,  2.9039e-01,  4.7532e-03,  1.0972e-01,\n",
       "                       -2.3266e-01],\n",
       "                      [-4.1947e-01,  3.2960e-01, -2.7850e-01,  1.8053e-01, -1.4846e-01,\n",
       "                        2.8632e-01],\n",
       "                      [ 6.0493e-01, -5.5417e-02,  8.8870e-02, -2.7059e-01, -6.9682e-02,\n",
       "                        1.0890e-01],\n",
       "                      [-4.9849e-01,  6.4452e-01,  1.0238e-01, -1.0451e-01, -3.5055e-02,\n",
       "                        1.0931e-01],\n",
       "                      [ 4.2977e-01,  4.7275e-01, -1.5128e-01, -1.5778e-01,  2.0566e-02,\n",
       "                       -1.7561e-03],\n",
       "                      [ 5.5315e-01,  4.2496e-01,  2.2314e-01, -1.4387e-02,  1.3168e-01,\n",
       "                       -2.2608e-01],\n",
       "                      [ 7.7915e-01,  2.5115e-01,  7.3758e-02,  4.0752e-02,  3.8324e-03,\n",
       "                       -1.9322e-02],\n",
       "                      [ 4.2313e-01,  3.6671e-01, -3.7251e-01,  2.0447e-01,  2.9750e-02,\n",
       "                       -5.5902e-02],\n",
       "                      [-2.7929e-01,  6.3873e-01, -2.6338e-01,  2.1037e-01,  1.1280e-01,\n",
       "                       -1.4811e-01],\n",
       "                      [-6.7613e-02,  4.9562e-01,  1.8699e-01,  1.2665e-01,  1.0690e-01,\n",
       "                        3.2447e-01],\n",
       "                      [ 4.1079e-01, -1.4092e-01,  1.5617e-01,  9.3142e-02,  1.4979e-01,\n",
       "                        4.5755e-01],\n",
       "                      [-3.3526e-01,  2.6424e-01,  2.2361e-01, -8.2335e-02, -5.2420e-02,\n",
       "                       -2.1941e-01],\n",
       "                      [ 9.1151e-04, -3.8338e-01, -1.6545e-01, -8.6180e-02,  2.1091e-01,\n",
       "                       -9.9976e-02],\n",
       "                      [ 4.1698e-01, -6.1665e-01, -8.4577e-02,  1.2876e-03,  4.4224e-03,\n",
       "                        2.5724e-02],\n",
       "                      [-3.1712e-01,  2.4676e-01, -3.0190e-01, -3.7130e-01,  2.0381e-02,\n",
       "                       -6.4990e-02]], device='cuda:0')),\n",
       "             ('interactNN.layer1.bias',\n",
       "              tensor([ 4.0104e-02,  5.3592e-02, -2.8596e-01,  2.1982e-01,  5.9013e-03,\n",
       "                       8.8528e-02,  2.2563e-01,  2.4374e-01,  2.3302e-01,  1.9819e-02,\n",
       "                       3.7811e-01, -5.7486e-02,  1.8121e-01, -3.9213e-01, -3.5911e-01,\n",
       "                      -7.0386e-02,  1.0011e-01, -1.3997e-01,  3.6813e-01, -2.2338e-01,\n",
       "                       4.9223e-02, -1.1582e-01,  4.4637e-01,  3.3319e-01,  9.0319e-02,\n",
       "                      -4.4311e-01,  2.1437e-01, -2.2877e-01, -4.6548e-01, -2.0479e-01,\n",
       "                      -8.2220e-02,  3.2470e-01, -3.4482e-01,  2.7096e-01, -1.4256e-01,\n",
       "                      -4.2151e-02,  2.7127e-01,  1.4993e-01,  1.2715e-02, -9.0481e-02,\n",
       "                      -3.8048e-01, -1.6316e-01,  3.3846e-01, -2.3144e-01, -4.4185e-01,\n",
       "                       1.7197e-01, -1.1564e-02,  2.8081e-01,  2.1039e-01,  4.7521e-03,\n",
       "                      -2.6253e-01, -1.7509e-02, -7.1673e-02,  3.7801e-02,  2.9590e-01,\n",
       "                      -3.2895e-02, -3.4932e-01, -1.8807e-02,  3.1885e-01, -3.8569e-01,\n",
       "                       2.5593e-02, -7.3199e-02, -2.7147e-02,  1.7583e-01,  2.2031e-01,\n",
       "                      -3.3852e-01,  4.3406e-01, -2.7804e-01,  3.2492e-02,  5.6567e-03,\n",
       "                      -1.7358e-01,  1.9717e-01, -3.2666e-01, -2.3487e-01,  2.8419e-01,\n",
       "                       3.8310e-01, -5.1103e-01,  3.1846e-01,  1.4206e-01, -6.9747e-02,\n",
       "                      -3.4053e-01,  6.5495e-02, -1.1250e-01, -2.4461e-01, -2.0063e-02,\n",
       "                       3.3142e-01, -7.1589e-02,  3.6758e-03, -4.1737e-01,  1.3576e-01,\n",
       "                       3.0215e-01,  1.7377e-01, -3.0531e-01,  2.2615e-01,  8.7789e-02,\n",
       "                       1.0204e-01,  9.4167e-02,  3.5325e-02, -3.2699e-03,  1.5935e-01,\n",
       "                      -2.4571e-01,  3.1910e-01, -1.6688e-01,  4.0326e-01, -3.4916e-02,\n",
       "                      -1.1438e-01,  3.2672e-01, -2.5246e-01,  3.2761e-04,  4.1832e-02,\n",
       "                      -2.2889e-01, -3.8749e-01,  2.7185e-01,  2.0422e-01,  3.6018e-01,\n",
       "                      -1.0896e-01,  2.4477e-02,  2.3667e-01, -4.2274e-02, -3.2797e-01,\n",
       "                       2.7215e-01,  2.4676e-01,  1.4143e-01,  3.7509e-01, -2.7528e-01,\n",
       "                      -1.3252e-01, -4.3692e-02, -2.3233e-01], device='cuda:0')),\n",
       "             ('interactNN.layer2.weight',\n",
       "              tensor([[ 0.0463, -0.0743, -0.0488,  ..., -0.0009, -0.1221, -0.0315],\n",
       "                      [-0.0564, -0.0445,  0.1111,  ..., -0.0927, -0.0311, -0.0276],\n",
       "                      [ 0.0727,  0.0058, -0.0662,  ...,  0.0577,  0.0717, -0.0912],\n",
       "                      ...,\n",
       "                      [-0.1010, -0.0353,  0.0768,  ...,  0.0678, -0.0375, -0.1098],\n",
       "                      [-0.0040,  0.0204, -0.0597,  ..., -0.0486,  0.0248, -0.1043],\n",
       "                      [-0.1113,  0.0700, -0.1222,  ..., -0.0331, -0.0420, -0.0164]],\n",
       "                     device='cuda:0')),\n",
       "             ('interactNN.layer2.bias',\n",
       "              tensor([ 0.0948, -0.0244, -0.1118, -0.0777, -0.1617, -0.0343,  0.0488, -0.0853,\n",
       "                      -0.0408, -0.0977,  0.0326, -0.0148, -0.0791,  0.0294, -0.0397, -0.1919,\n",
       "                      -0.0900, -0.1214, -0.0904, -0.1503, -0.1119,  0.1001,  0.0987, -0.1729,\n",
       "                      -0.1772, -0.1022, -0.3031,  0.0853, -0.0197, -0.0060, -0.0474,  0.0032,\n",
       "                      -0.0984, -0.1034,  0.1282,  0.0300,  0.0497, -0.0389, -0.0544, -0.0709,\n",
       "                      -0.0086, -0.2311, -0.1835,  0.0267, -0.1952,  0.0183, -0.0686, -0.0130,\n",
       "                      -0.0691,  0.0232, -0.1618, -0.1181, -0.1156, -0.0082, -0.0621, -0.1059,\n",
       "                      -0.0796, -0.0744,  0.0455, -0.0885, -0.0050, -0.1231, -0.0369, -0.0257,\n",
       "                      -0.0415, -0.1272,  0.0150, -0.0480, -0.0794, -0.1777, -0.0460,  0.0266,\n",
       "                       0.0946, -0.1727, -0.0367, -0.0704, -0.1288, -0.0607,  0.0216, -0.0814,\n",
       "                      -0.1452, -0.0013, -0.1100, -0.1283, -0.0500, -0.1465, -0.0593, -0.0385,\n",
       "                      -0.1236, -0.0228, -0.1492, -0.0176, -0.0338, -0.1594, -0.0759, -0.0965,\n",
       "                       0.0324, -0.0327, -0.1412, -0.0118, -0.0693, -0.0983,  0.0613,  0.1029,\n",
       "                      -0.0609, -0.0958,  0.0650, -0.2202, -0.0201, -0.1227, -0.1173, -0.1097,\n",
       "                      -0.0885, -0.1587,  0.0576,  0.0321, -0.0791, -0.1785, -0.1624, -0.0483,\n",
       "                      -0.0878, -0.1624, -0.0926,  0.0339,  0.1162, -0.0043,  0.0284, -0.0821],\n",
       "                     device='cuda:0')),\n",
       "             ('interactNN.layer3.weight',\n",
       "              tensor([[-0.0573,  0.0588, -0.0058,  ..., -0.1404,  0.0351, -0.1419],\n",
       "                      [ 0.0496, -0.0911,  0.0076,  ...,  0.0279,  0.0495,  0.0625],\n",
       "                      [ 0.0385, -0.0227, -0.0553,  ...,  0.0109, -0.0607, -0.0654],\n",
       "                      ...,\n",
       "                      [-0.0655, -0.0291, -0.0301,  ...,  0.0645,  0.1265, -0.0748],\n",
       "                      [-0.0108, -0.0199, -0.0927,  ..., -0.0602, -0.0155,  0.0689],\n",
       "                      [-0.0517, -0.0769, -0.1414,  ..., -0.0799,  0.1016, -0.0765]],\n",
       "                     device='cuda:0')),\n",
       "             ('interactNN.layer3.bias',\n",
       "              tensor([-1.2150e-01,  8.6608e-03, -1.2368e-01, -2.1946e-01, -8.2294e-02,\n",
       "                       1.4455e-04, -1.7669e-01,  1.7317e-02,  5.9878e-02, -9.3803e-02,\n",
       "                      -1.2929e-01, -7.6391e-02, -1.3111e-01, -4.3172e-02, -5.2254e-02,\n",
       "                      -2.4652e-01, -2.5188e-01, -1.3184e-01, -9.7492e-03, -4.2589e-02,\n",
       "                      -7.9701e-02, -2.9568e-02, -8.4023e-02,  9.0198e-03, -1.1099e-01,\n",
       "                      -1.9603e-01, -5.9679e-03,  6.2772e-03, -3.0940e-02, -9.3492e-02,\n",
       "                      -5.7950e-02,  5.3519e-02, -6.3650e-03, -2.7626e-01, -8.1464e-02,\n",
       "                      -9.6738e-02, -4.4214e-02, -1.3005e-02, -1.8843e-01, -1.6424e-02,\n",
       "                      -6.8946e-02, -1.0406e-01, -1.5694e-01,  2.4893e-02, -3.8103e-02,\n",
       "                      -7.6679e-02, -7.7518e-02, -4.8354e-02,  5.3398e-02, -1.1818e-02,\n",
       "                      -6.1269e-02, -3.2464e-02, -2.7518e-02, -1.7378e-01,  7.0005e-02,\n",
       "                      -2.3227e-01, -1.4411e-01, -6.8642e-03, -9.7511e-02, -8.9543e-02,\n",
       "                      -1.3154e-01, -2.2268e-02,  2.3859e-02,  7.3816e-03,  1.5167e-02,\n",
       "                      -2.6705e-02, -7.5178e-02,  9.4030e-03, -8.3297e-02, -1.3551e-01,\n",
       "                      -1.7468e-01,  1.0089e-02,  1.7401e-02, -9.3127e-02, -1.8629e-01,\n",
       "                      -9.5634e-02, -1.7391e-01, -2.1781e-02, -2.0158e-01, -1.1439e-01,\n",
       "                      -1.0410e-01, -8.6833e-02, -5.0249e-02, -5.0082e-02,  4.3685e-02,\n",
       "                      -1.2243e-01, -2.3094e-02, -5.2711e-02, -2.3058e-01, -7.7993e-02,\n",
       "                       3.6373e-02, -3.1797e-02, -1.5256e-01, -5.9879e-02, -5.6253e-02,\n",
       "                      -5.1103e-02, -1.4559e-01, -7.6449e-02,  9.2382e-02,  4.4218e-02,\n",
       "                      -2.5866e-01, -1.7131e-01, -7.2432e-02, -6.3100e-02, -2.9865e-03,\n",
       "                      -2.0826e-02, -1.2458e-01, -4.6734e-02, -3.4573e-02,  2.0522e-02,\n",
       "                      -1.3850e-01,  2.2447e-02, -4.0256e-02, -3.7967e-02, -1.9970e-01,\n",
       "                      -8.7628e-02, -2.4456e-02, -9.5443e-02, -8.8183e-02, -8.1807e-02,\n",
       "                      -2.9368e-02, -2.1062e-01, -4.2578e-02, -1.2364e-01, -1.6297e-01,\n",
       "                      -8.1194e-03, -1.1100e-01, -6.9347e-02], device='cuda:0')),\n",
       "             ('interactNN.layer4.weight',\n",
       "              tensor([[ 2.8845e-02, -2.8291e-03, -2.1371e-03, -6.3188e-03,  1.3665e-02,\n",
       "                       -1.5727e-02,  1.3489e-02,  2.4513e-03, -1.1077e-02, -1.0121e-03,\n",
       "                        2.1090e-03,  5.8872e-03, -2.8342e-02, -2.9807e-03,  2.4772e-03,\n",
       "                        8.8695e-03,  2.4089e-02,  4.5811e-03,  2.4562e-03,  1.6754e-03,\n",
       "                       -2.4574e-03, -8.5793e-03,  1.7192e-03, -1.4735e-03, -4.5334e-03,\n",
       "                        3.2854e-03, -7.0323e-03, -4.1271e-03,  2.5429e-03, -2.0985e-03,\n",
       "                        5.5876e-04, -3.6272e-02,  4.4216e-04,  2.8024e-02,  5.9232e-04,\n",
       "                        4.0856e-03, -1.4392e-02,  6.1626e-03,  1.6202e-03, -3.0795e-03,\n",
       "                       -7.5591e-04, -9.6053e-04, -6.1112e-04, -3.3374e-03,  9.4656e-03,\n",
       "                       -6.7765e-03,  5.3136e-03,  6.8011e-04,  2.3527e-03, -2.9047e-02,\n",
       "                        6.4821e-03, -2.2664e-04, -1.2513e-03, -1.5203e-03, -3.1300e-03,\n",
       "                       -8.8926e-03, -1.0332e-02, -3.1719e-03,  1.8145e-03,  5.9962e-04,\n",
       "                       -1.7805e-02, -1.8281e-03,  6.6137e-02,  7.6506e-04, -7.0974e-06,\n",
       "                       -1.1848e-03, -2.4619e-03, -3.7887e-03, -7.4290e-05, -4.4192e-03,\n",
       "                       -3.5855e-03,  2.7778e-04,  5.0931e-03, -5.5624e-03, -3.4464e-03,\n",
       "                       -3.4576e-03,  1.8171e-02, -2.0599e-02, -1.1818e-02,  6.1989e-03,\n",
       "                        5.8345e-02,  8.0796e-04,  3.1986e-03, -2.4536e-03,  2.4346e-03,\n",
       "                       -1.4931e-03, -9.0675e-04, -1.3705e-02, -1.7406e-02, -4.3457e-03,\n",
       "                        1.9355e-02,  1.5022e-03, -6.0324e-04, -2.1013e-03, -1.7246e-02,\n",
       "                       -8.8484e-03, -3.8756e-03, -1.8818e-02,  2.3151e-03,  1.3156e-02,\n",
       "                       -2.2791e-02,  4.3117e-03, -8.5524e-03, -1.1049e-02, -2.8195e-04,\n",
       "                        8.6100e-03,  7.1447e-03,  7.3505e-03, -3.7436e-03,  4.9569e-04,\n",
       "                        4.3258e-03, -1.4209e-03, -1.3290e-02, -3.7995e-03, -2.0664e-02,\n",
       "                       -3.9013e-03, -1.0089e-03,  4.1823e-02,  4.0720e-03, -5.8061e-06,\n",
       "                       -5.9146e-03, -6.3812e-03,  6.8028e-03, -3.9772e-03, -1.0270e-04,\n",
       "                        2.2046e-03,  5.2639e-03, -2.9921e-03],\n",
       "                      [ 4.7809e-02, -1.2464e-02,  4.1911e-03, -2.2268e-03,  6.5504e-03,\n",
       "                       -1.0233e-02, -4.3888e-02,  8.0840e-04,  8.3174e-03,  5.0567e-03,\n",
       "                        1.3814e-02, -2.3782e-03,  2.3450e-02,  3.5367e-02,  2.2110e-03,\n",
       "                       -1.8615e-02,  4.0078e-03, -3.4610e-03, -2.9331e-03,  6.7664e-04,\n",
       "                       -1.3352e-03, -1.4194e-03, -3.9084e-03, -1.5867e-03, -5.8132e-03,\n",
       "                        1.6711e-02,  1.1235e-02,  3.8043e-03, -3.4420e-03,  5.3464e-03,\n",
       "                       -9.2880e-04, -1.8645e-02,  5.3186e-03,  2.3192e-02, -7.8787e-03,\n",
       "                       -2.6433e-03,  5.3671e-02,  1.5258e-03,  2.8180e-03, -8.7553e-03,\n",
       "                        1.6172e-03, -4.7343e-05, -7.0071e-03,  1.9154e-03, -5.5267e-03,\n",
       "                       -9.0214e-03, -2.0749e-03, -7.0247e-04,  4.1997e-03, -2.3729e-02,\n",
       "                        2.3551e-03, -1.7658e-03,  5.8462e-03, -1.8842e-03,  2.4760e-03,\n",
       "                       -5.2951e-03, -5.0114e-02,  7.9651e-03, -4.7276e-03, -6.7655e-03,\n",
       "                        8.8090e-03, -3.9021e-03, -8.3199e-03, -7.6563e-04,  4.9459e-04,\n",
       "                       -4.0722e-03,  1.9428e-03, -1.2480e-02,  1.4839e-03,  2.0239e-03,\n",
       "                       -1.1561e-02,  5.1086e-03, -6.9860e-04,  1.0120e-02,  2.7743e-03,\n",
       "                       -1.7298e-04,  2.8880e-03,  2.2849e-02, -1.2551e-02,  5.2686e-03,\n",
       "                       -1.3925e-02,  7.8376e-03,  4.2162e-03,  1.1089e-02, -1.2597e-02,\n",
       "                        3.8179e-03, -3.9598e-03,  3.1141e-03,  1.9396e-02,  8.2090e-03,\n",
       "                       -4.4742e-02,  5.9195e-03, -9.0841e-03,  5.4914e-04,  6.7411e-03,\n",
       "                       -4.5370e-03, -2.5792e-02, -2.5150e-02,  1.6431e-03,  1.3579e-03,\n",
       "                        1.7133e-02,  1.0317e-02,  2.4561e-04,  3.2241e-03,  2.5236e-03,\n",
       "                        3.4959e-03,  1.2700e-02, -3.9216e-03, -4.3390e-03,  2.6699e-03,\n",
       "                        8.3928e-03,  7.8875e-03,  3.2153e-03,  8.0659e-03, -9.9982e-03,\n",
       "                       -1.5085e-03, -2.1933e-05,  7.5743e-03, -5.9982e-03, -2.4754e-03,\n",
       "                       -2.3848e-03,  1.9718e-04,  4.0575e-03,  6.4032e-03,  8.9044e-03,\n",
       "                        2.1359e-03,  2.7670e-03,  2.1062e-03]], device='cuda:0')),\n",
       "             ('interactNN.layer4.bias',\n",
       "              tensor([-0.0202, -0.0012], device='cuda:0')),\n",
       "             ('thetaDotNN.bNorm1.weight',\n",
       "              tensor([1.0579, 0.9902, 0.9671, 0.9726, 1.0088, 0.9850, 1.0470, 1.1038, 1.0648,\n",
       "                      0.9817, 1.0028, 0.9196, 0.9844, 0.8990, 1.0777, 1.0779, 0.9698, 0.8845,\n",
       "                      0.9363, 0.9351, 0.9805, 1.0063, 1.0661, 1.0110, 1.0729, 1.0242, 1.0421,\n",
       "                      0.9578, 1.0089, 0.9846, 1.0964, 0.9424, 0.9891, 1.0056, 1.1479, 0.9575,\n",
       "                      0.9230, 0.9569, 1.1444, 1.0174, 1.0117, 1.0519, 1.1315, 1.0207, 1.0213,\n",
       "                      0.9436, 0.9784, 0.9552, 1.0385, 0.9508, 1.0660, 1.0448, 0.9448, 1.0406,\n",
       "                      1.0253, 0.9803, 1.0264, 1.1023, 1.0086, 1.1540, 1.0465, 1.0753, 0.9256,\n",
       "                      0.8684, 1.0405, 0.9275, 1.0494, 0.9212, 0.9079, 0.9762, 0.9342, 1.0107,\n",
       "                      0.9856, 0.9816, 0.9100, 1.1514, 0.9741, 0.9147, 1.0202, 0.9779, 0.9611,\n",
       "                      1.0406, 0.9896, 1.0353, 0.9782, 0.9057, 0.9107, 0.9912, 0.9757, 0.9672,\n",
       "                      1.0064, 0.9212, 1.0469, 1.1013, 0.9566, 1.0036, 1.0266, 1.0448, 0.9242,\n",
       "                      0.9869, 0.9420, 0.9478, 0.9634, 0.9779, 0.9421, 0.9786, 0.9723, 1.0261,\n",
       "                      0.9875, 0.9475, 1.0268, 0.9977, 0.9735, 1.0231, 0.9977, 1.0327, 0.8913,\n",
       "                      0.9736, 0.9308, 1.0704, 1.0125, 0.9956, 1.0892, 1.0405, 0.9589, 0.9680,\n",
       "                      1.0211, 0.9885], device='cuda:0')),\n",
       "             ('thetaDotNN.bNorm1.bias',\n",
       "              tensor([ 0.0651, -0.0733, -0.1416, -0.1021, -0.1827, -0.0523, -0.0352,  0.0488,\n",
       "                      -0.1182,  0.0902, -0.1027, -0.0536, -0.0163, -0.0319,  0.2439,  0.1577,\n",
       "                      -0.0146,  0.0122, -0.0034, -0.0197,  0.0798, -0.0578, -0.1165, -0.1367,\n",
       "                       0.1389,  0.1377,  0.0840,  0.0210,  0.0102,  0.2039,  0.0007, -0.0427,\n",
       "                      -0.0945,  0.0634,  0.1721, -0.0899, -0.0597, -0.0385,  0.0985,  0.0454,\n",
       "                       0.1148,  0.0956,  0.0830,  0.1854,  0.1743, -0.0406, -0.1188,  0.0885,\n",
       "                       0.0325,  0.0203,  0.0637,  0.0662, -0.1912, -0.0487, -0.1810,  0.0323,\n",
       "                      -0.0562,  0.1030, -0.0103,  0.2252, -0.0145, -0.0261,  0.0326,  0.0468,\n",
       "                       0.0100,  0.0039,  0.0165, -0.0786, -0.1049,  0.0669, -0.1686, -0.0755,\n",
       "                       0.0469, -0.0083, -0.0542, -0.0018, -0.0146, -0.0387, -0.0014, -0.0423,\n",
       "                      -0.0531,  0.0700, -0.0634,  0.1075, -0.0849, -0.0457, -0.0642, -0.0443,\n",
       "                       0.0375, -0.1880,  0.1365,  0.0933,  0.0173,  0.1029,  0.1425,  0.0536,\n",
       "                      -0.1262,  0.1541,  0.1030,  0.0344, -0.0655,  0.0067,  0.1393, -0.1365,\n",
       "                      -0.0390,  0.1300, -0.1049, -0.1008,  0.0600, -0.1817,  0.0545,  0.1111,\n",
       "                       0.1180, -0.0874, -0.0064,  0.0797, -0.0600, -0.0372, -0.1454, -0.0061,\n",
       "                      -0.0616,  0.0371,  0.0492, -0.0409, -0.0008,  0.1267,  0.0424,  0.1681],\n",
       "                     device='cuda:0')),\n",
       "             ('thetaDotNN.bNorm1.running_mean',\n",
       "              tensor([1.0019e-01, 8.9822e-05, 5.6768e-02, 6.7752e-02, 5.4462e-02, 3.4041e-01,\n",
       "                      1.5993e-01, 1.8704e-01, 1.8850e-01, 2.4748e-01, 2.6498e-01, 6.9584e-01,\n",
       "                      1.8085e-01, 8.1248e-02, 2.3544e-01, 1.8672e-01, 2.8243e-01, 2.6067e-01,\n",
       "                      1.8925e-02, 2.2161e-02, 1.0294e-01, 7.8795e-02, 2.5313e-02, 2.8453e-01,\n",
       "                      1.9852e-01, 2.8758e-02, 1.2999e-01, 9.0204e-02, 1.0322e-03, 2.9258e-01,\n",
       "                      1.1013e-01, 8.0974e-02, 2.8417e-03, 1.8596e-01, 7.3611e-02, 5.4851e-01,\n",
       "                      2.1822e-02, 1.4639e-01, 9.2745e-02, 1.3722e-02, 1.3073e-01, 1.2776e-01,\n",
       "                      1.2426e-01, 1.8589e-01, 1.0785e-01, 6.5525e-02, 4.7255e-01, 2.5918e-01,\n",
       "                      8.0779e-02, 1.7605e-01, 7.6111e-02, 1.5146e-01, 6.6395e-02, 3.9695e-02,\n",
       "                      2.3746e-01, 1.5443e-01, 2.9557e-01, 1.3587e-01, 5.7915e-01, 1.9219e-02,\n",
       "                      1.6535e-02, 6.6817e-02, 3.3478e-01, 3.4406e-01, 2.8633e-02, 2.7317e-01,\n",
       "                      1.5634e-01, 4.4192e-01, 1.9066e-01, 1.0943e-01, 4.1026e-01, 4.0583e-01,\n",
       "                      1.9917e-02, 5.3368e-04, 1.2901e-01, 2.0919e-01, 1.2738e-01, 2.2025e-01,\n",
       "                      4.3389e-01, 1.3456e-01, 3.1174e-01, 1.1518e-01, 1.1928e-01, 1.3542e-01,\n",
       "                      2.0781e-01, 2.7458e-01, 2.2801e-01, 8.5660e-02, 1.9139e-01, 3.3901e-01,\n",
       "                      3.2496e-02, 1.7669e-01, 3.3627e-01, 2.0969e-01, 4.8954e-01, 1.0713e-01,\n",
       "                      2.5967e-01, 2.5386e-01, 3.2011e-01, 4.1277e-01, 2.8977e-04, 8.3083e-02,\n",
       "                      6.6725e-03, 2.5208e-01, 5.4104e-02, 1.9841e-01, 1.2425e-01, 1.7131e-01,\n",
       "                      3.9280e-02, 1.0572e-01, 4.9061e-01, 2.1495e-01, 2.3257e-02, 1.9243e-01,\n",
       "                      2.1097e-05, 1.8623e-01, 5.0627e-01, 2.1903e-02, 2.6271e-01, 9.8864e-02,\n",
       "                      1.3551e-01, 7.8297e-02, 9.3455e-02, 1.1222e-01, 2.5451e-01, 3.9095e-01,\n",
       "                      2.0524e-03, 1.2787e-01], device='cuda:0')),\n",
       "             ('thetaDotNN.bNorm1.running_var',\n",
       "              tensor([2.6390e-02, 6.0879e-06, 1.2109e-02, 1.6645e-02, 1.4997e-02, 5.1578e-02,\n",
       "                      5.1898e-02, 7.5545e-02, 4.7092e-02, 5.6812e-02, 8.5229e-02, 1.4395e-01,\n",
       "                      5.7489e-02, 2.2399e-02, 8.3567e-02, 5.4681e-02, 6.8735e-02, 4.7598e-02,\n",
       "                      5.3780e-03, 5.8377e-03, 3.2990e-02, 2.5671e-02, 5.3015e-03, 7.3120e-02,\n",
       "                      5.4761e-02, 7.1161e-03, 4.8235e-02, 3.0327e-02, 1.6858e-04, 5.5087e-02,\n",
       "                      3.4584e-02, 2.5070e-02, 3.4969e-04, 4.7824e-02, 1.9813e-02, 1.3464e-01,\n",
       "                      4.4219e-03, 4.1195e-02, 2.1132e-02, 2.0527e-03, 5.2742e-02, 4.0164e-02,\n",
       "                      3.0160e-02, 5.5147e-02, 4.0256e-02, 2.2901e-02, 8.4939e-02, 7.5361e-02,\n",
       "                      2.5599e-02, 3.1767e-02, 2.4796e-02, 4.2831e-02, 1.6031e-02, 9.3714e-03,\n",
       "                      6.6363e-02, 5.0427e-02, 9.0367e-02, 5.4677e-02, 9.0195e-02, 3.2862e-03,\n",
       "                      4.2005e-03, 1.9813e-02, 3.9642e-02, 7.5673e-02, 6.2637e-03, 4.5964e-02,\n",
       "                      6.0181e-02, 9.6663e-02, 3.8517e-02, 3.8803e-02, 7.2012e-02, 1.1367e-01,\n",
       "                      5.6053e-03, 4.0487e-05, 4.5954e-02, 5.8907e-02, 4.6838e-02, 5.4698e-02,\n",
       "                      1.0907e-01, 4.3656e-02, 6.1027e-02, 3.2517e-02, 4.5664e-02, 3.4229e-02,\n",
       "                      7.2810e-02, 3.2563e-02, 4.6520e-02, 2.3505e-02, 6.4392e-02, 9.7916e-02,\n",
       "                      6.1241e-03, 4.4908e-02, 8.2503e-02, 7.4759e-02, 1.2354e-01, 3.6052e-02,\n",
       "                      5.4045e-02, 1.1040e-01, 6.4453e-02, 9.0449e-02, 1.6182e-05, 2.8759e-02,\n",
       "                      1.7502e-03, 8.4609e-02, 1.5377e-02, 4.8766e-02, 3.3498e-02, 3.1561e-02,\n",
       "                      1.0167e-02, 3.2828e-02, 1.3825e-01, 4.4467e-02, 7.6047e-03, 4.0169e-02,\n",
       "                      6.9289e-07, 6.4071e-02, 1.0890e-01, 5.6556e-03, 6.7815e-02, 2.8024e-02,\n",
       "                      4.7838e-02, 2.6876e-02, 2.8184e-02, 2.9123e-02, 7.6532e-02, 4.9150e-02,\n",
       "                      1.9204e-04, 3.9506e-02], device='cuda:0')),\n",
       "             ('thetaDotNN.bNorm1.num_batches_tracked',\n",
       "              tensor(2388000, device='cuda:0')),\n",
       "             ('thetaDotNN.bNorm2.weight',\n",
       "              tensor([0.9750, 1.2292, 1.1130, 0.9758, 0.9031, 1.0259, 0.9677, 1.0145, 1.1191,\n",
       "                      0.9956, 0.9778, 0.9538, 1.0684, 0.9690, 0.9610, 1.0152, 0.9384, 1.0501,\n",
       "                      0.9625, 1.0857, 1.0061, 1.1066, 0.9568, 0.9785, 0.9748, 1.0344, 1.0034,\n",
       "                      1.0360, 0.9967, 1.0370, 0.9975, 1.0074, 1.0297, 0.9794, 0.9698, 0.9206,\n",
       "                      0.9749, 0.9602, 0.9378, 0.9890, 1.0054, 1.0615, 0.9843, 1.1037, 1.0348,\n",
       "                      0.9252, 0.9788, 1.0863, 1.0244, 0.9939, 1.0022, 0.9196, 1.0076, 0.9376,\n",
       "                      0.9997, 1.0673, 1.0096, 0.9226, 0.9878, 1.0403, 1.0025, 0.9134, 0.9923,\n",
       "                      0.9538, 0.9819, 0.9706, 0.9063, 0.9375, 0.9516, 0.9979, 0.9631, 0.9087,\n",
       "                      0.9618, 0.9662, 1.0152, 0.9570, 1.0158, 1.0065, 1.0065, 0.9459, 0.9819,\n",
       "                      1.0285, 0.9938, 1.0541, 1.0540, 0.9564, 0.9993, 1.0297, 0.8797, 1.0168,\n",
       "                      1.0705, 0.9120, 1.0099, 1.0782, 1.0349, 1.0176, 1.0080, 1.0904, 1.0335,\n",
       "                      1.0545, 1.0112, 1.0017, 0.9892, 0.9660, 0.9847, 0.9722, 1.0294, 1.0499,\n",
       "                      0.9574, 0.9447, 1.0014, 0.9806, 0.9463, 0.9931, 1.0593, 0.9670, 0.8725,\n",
       "                      0.9413, 1.0246, 1.0340, 1.0422, 0.9577, 1.0046, 0.9730, 1.0177, 1.0241,\n",
       "                      0.9845, 1.0129], device='cuda:0')),\n",
       "             ('thetaDotNN.bNorm2.bias',\n",
       "              tensor([-0.0964,  0.1795, -0.1393,  0.1832, -0.0913, -0.1806, -0.1236, -0.0208,\n",
       "                      -0.0974,  0.0721,  0.0998,  0.1379,  0.1462,  0.0486,  0.0599,  0.1753,\n",
       "                       0.0357,  0.0037, -0.0315, -0.0370, -0.0498,  0.1547,  0.1280, -0.0572,\n",
       "                      -0.1195,  0.0497,  0.0559,  0.0173,  0.1175,  0.1013, -0.0111, -0.0314,\n",
       "                       0.0615,  0.0901,  0.0911, -0.0464,  0.1172, -0.0268,  0.1770, -0.0495,\n",
       "                       0.1067,  0.0909,  0.0782,  0.1005,  0.1409, -0.0281,  0.0522,  0.1240,\n",
       "                      -0.1119,  0.1036, -0.0309, -0.0104, -0.0219, -0.1680,  0.0786,  0.1446,\n",
       "                       0.0826, -0.1087, -0.0981, -0.0067,  0.0380,  0.0687,  0.0266,  0.1395,\n",
       "                       0.0854, -0.0243,  0.0655, -0.1516, -0.1418,  0.1669, -0.0537, -0.0657,\n",
       "                       0.1189, -0.0328,  0.1983,  0.0008,  0.0442,  0.0151, -0.0209,  0.1281,\n",
       "                       0.0325,  0.0469, -0.0152,  0.2665,  0.0544,  0.1042, -0.1214, -0.0039,\n",
       "                      -0.0636,  0.2247,  0.2048, -0.0006,  0.0287, -0.2001,  0.0382, -0.1025,\n",
       "                       0.0752,  0.1098,  0.0541, -0.1986,  0.1020, -0.0501,  0.1598,  0.0420,\n",
       "                       0.0153, -0.0877,  0.1034,  0.2065,  0.0748,  0.0330, -0.0341,  0.0715,\n",
       "                       0.0126,  0.0269, -0.2187,  0.0662, -0.1906,  0.0460,  0.1406, -0.0318,\n",
       "                       0.1087,  0.0966,  0.0811, -0.0541,  0.0048,  0.1988,  0.1020,  0.0994],\n",
       "                     device='cuda:0')),\n",
       "             ('thetaDotNN.bNorm2.running_mean',\n",
       "              tensor([0.8284, 0.3791, 0.2047, 0.7597, 0.2819, 0.3686, 0.6900, 0.7594, 0.2680,\n",
       "                      0.6280, 0.8052, 0.6191, 0.8511, 0.8371, 0.6460, 0.6900, 0.5878, 0.4521,\n",
       "                      0.3801, 0.3990, 0.7350, 0.3044, 0.6058, 0.5891, 0.6338, 0.7850, 0.7765,\n",
       "                      0.5189, 0.7065, 0.5057, 0.6827, 0.1787, 0.3662, 0.5541, 0.6693, 0.2561,\n",
       "                      0.4973, 0.3573, 0.7879, 0.6350, 0.8616, 0.5618, 0.4684, 0.4495, 0.5950,\n",
       "                      0.4729, 0.5524, 0.7868, 0.5246, 0.4707, 0.6125, 0.3358, 0.2987, 0.2355,\n",
       "                      0.8032, 0.7113, 0.5075, 0.1864, 0.3063, 0.5540, 0.5775, 0.8511, 0.5987,\n",
       "                      0.5752, 0.6329, 0.4274, 0.4503, 0.6395, 0.4831, 0.4146, 0.9186, 0.3267,\n",
       "                      0.7372, 0.7898, 0.7897, 0.4772, 0.6648, 0.9484, 0.6269, 0.6266, 0.7674,\n",
       "                      0.5633, 0.5487, 0.6883, 0.4369, 0.7567, 0.2071, 0.6219, 0.3315, 0.6948,\n",
       "                      0.7333, 0.5080, 0.6693, 0.1557, 0.7585, 0.3389, 0.5694, 0.5901, 0.5855,\n",
       "                      0.3073, 0.4333, 0.1771, 0.3567, 0.6339, 0.6438, 0.2666, 0.5137, 0.9931,\n",
       "                      0.8125, 0.5086, 0.2060, 0.7094, 0.7138, 0.7250, 0.2473, 0.6868, 0.2124,\n",
       "                      0.6822, 0.5777, 0.5461, 0.8714, 0.6771, 0.7540, 0.4968, 0.5919, 0.7513,\n",
       "                      0.5963, 0.6078], device='cuda:0')),\n",
       "             ('thetaDotNN.bNorm2.running_var',\n",
       "              tensor([1.6625, 0.3273, 0.1335, 0.8591, 0.2300, 0.3336, 1.0435, 1.4834, 0.1649,\n",
       "                      1.1148, 1.0137, 0.7498, 1.2608, 1.5822, 1.1365, 1.1603, 0.6896, 0.2947,\n",
       "                      0.5723, 0.2889, 0.7746, 0.2133, 0.8647, 0.9896, 0.5941, 1.1231, 1.1871,\n",
       "                      0.4422, 1.2271, 0.6976, 1.1964, 0.1608, 0.2051, 0.6568, 0.9389, 0.2619,\n",
       "                      0.5213, 0.5177, 1.3171, 1.0587, 1.1508, 0.8708, 0.4888, 0.2730, 0.9427,\n",
       "                      0.4629, 0.7499, 1.0802, 0.3979, 0.4965, 0.9539, 0.1949, 0.2346, 0.1239,\n",
       "                      1.3222, 0.9898, 0.5266, 0.1678, 0.2308, 0.6111, 0.7878, 1.2664, 0.8293,\n",
       "                      0.8656, 0.8813, 0.5159, 0.5804, 1.1310, 0.6705, 0.4240, 2.3007, 0.3698,\n",
       "                      1.3543, 1.4926, 1.1558, 0.6535, 0.6454, 1.6466, 0.9292, 0.9506, 0.9439,\n",
       "                      0.7028, 1.1119, 0.6819, 0.6207, 1.2648, 0.1504, 0.8105, 0.3918, 0.8956,\n",
       "                      1.0676, 0.4212, 1.3399, 0.1093, 1.3418, 0.2932, 0.5878, 0.8520, 0.6616,\n",
       "                      0.2045, 0.4811, 0.0882, 0.3527, 1.1709, 1.0699, 0.1645, 0.6490, 1.7850,\n",
       "                      1.4261, 0.8474, 0.1250, 0.9380, 0.8364, 0.8917, 0.1709, 1.2544, 0.1967,\n",
       "                      0.9165, 0.8521, 0.7196, 1.5345, 1.1539, 0.9619, 0.4956, 0.4687, 1.0198,\n",
       "                      0.7047, 0.5167], device='cuda:0')),\n",
       "             ('thetaDotNN.bNorm2.num_batches_tracked',\n",
       "              tensor(2388000, device='cuda:0')),\n",
       "             ('thetaDotNN.bNorm3.weight',\n",
       "              tensor([0.4404, 0.3688, 0.2917, 0.2464, 0.4458, 0.4514, 0.5754, 0.4880, 0.4321,\n",
       "                      0.5647, 0.3425, 0.4562, 0.2898, 0.3271, 0.5007, 0.5796, 0.3817, 0.5485,\n",
       "                      0.3316, 0.5185, 0.5151, 0.4804, 0.5168, 0.5078, 0.3078, 0.2850, 0.7018,\n",
       "                      0.5703, 0.4785, 0.3319, 0.6310, 0.3256, 0.3106, 0.6244, 0.4728, 0.5231,\n",
       "                      0.4950, 0.2265, 0.5451, 0.4196, 0.3521, 0.2563, 0.2228, 0.4609, 0.5380,\n",
       "                      0.3764, 0.4468, 0.3422, 0.4317, 0.4875, 0.5655, 0.5013, 0.5610, 0.4953,\n",
       "                      0.5964, 0.4159, 0.5949, 0.5809, 0.4255, 0.6309, 0.5105, 0.3654, 0.5279,\n",
       "                      0.5012, 0.5319, 0.4896, 0.3630, 0.4368, 0.4507, 0.4914, 0.3898, 0.5240,\n",
       "                      0.4608, 0.4034, 0.3694, 0.5859, 0.3862, 0.6909, 0.3865, 0.3368, 0.4686,\n",
       "                      0.2602, 0.2619, 0.4737, 0.5048, 0.4436, 0.5551, 0.4403, 0.3074, 0.4540,\n",
       "                      0.4043, 0.2785, 0.6619, 0.4996, 0.5181, 0.4353, 0.4551, 0.5146, 0.5477,\n",
       "                      0.4182, 0.2573, 0.7184, 0.3521, 0.4101, 0.6509, 0.4081, 0.5104, 0.5031,\n",
       "                      0.2965, 0.4807, 0.7778, 0.4314, 0.4042, 0.4227, 0.6008, 0.5991, 0.4775,\n",
       "                      0.5405, 0.5791, 0.5832, 0.3845, 0.5564, 0.6114, 0.6540, 0.6792, 0.5556,\n",
       "                      0.4364, 0.5919], device='cuda:0')),\n",
       "             ('thetaDotNN.bNorm3.bias',\n",
       "              tensor([ 4.1929e-03,  1.6667e-03, -2.8162e-03,  7.4214e-03, -3.8386e-03,\n",
       "                      -7.3440e-04, -3.6419e-04,  1.5297e-02,  8.7135e-03, -1.7216e-03,\n",
       "                      -6.7337e-03,  5.7934e-03, -3.3706e-03,  2.3554e-03,  4.0064e-03,\n",
       "                      -9.7566e-04, -7.1493e-03, -1.9978e-03,  5.6163e-03, -8.0673e-04,\n",
       "                      -4.4191e-03,  1.2570e-03,  2.9303e-03, -4.7067e-03, -3.5189e-03,\n",
       "                      -3.9542e-03,  1.7646e-02, -1.8069e-03, -2.5556e-03, -9.5683e-03,\n",
       "                      -4.1306e-03,  5.5053e-03, -2.7855e-03,  1.9320e-04,  5.2599e-03,\n",
       "                       2.2801e-03,  2.6039e-03,  5.4778e-03, -1.4102e-03, -3.8004e-03,\n",
       "                      -4.6320e-04,  1.4056e-02,  4.5635e-04,  4.1547e-03,  1.6934e-03,\n",
       "                       4.7808e-03,  5.0678e-03,  3.0456e-03,  2.8973e-03,  3.8177e-03,\n",
       "                      -4.4737e-03,  2.4810e-03,  3.3130e-03,  1.8314e-03,  4.2206e-03,\n",
       "                      -6.0068e-04, -3.9524e-03, -2.1342e-03, -1.0125e-03, -2.9805e-03,\n",
       "                       7.3254e-03, -1.0340e-03, -6.9617e-03,  4.3315e-03,  4.4341e-03,\n",
       "                      -4.0880e-03,  5.8839e-04,  1.0072e-02,  1.0158e-02, -7.8918e-03,\n",
       "                       1.7211e-03, -5.5615e-03,  6.8844e-03, -7.7962e-04,  2.8840e-03,\n",
       "                       1.7361e-03,  4.5194e-03,  7.6878e-03,  2.3715e-03,  2.9723e-03,\n",
       "                       4.1977e-03,  1.2720e-02, -7.6572e-03,  1.1405e-02, -4.4194e-03,\n",
       "                       2.4218e-03,  2.7025e-03,  5.2825e-03, -3.4830e-03, -5.0154e-03,\n",
       "                       4.3815e-03,  7.6411e-03,  1.2040e-03,  7.4247e-04,  7.7194e-03,\n",
       "                       9.5464e-03,  4.0660e-03,  5.3753e-04, -4.4477e-03,  5.1969e-04,\n",
       "                       4.6351e-03,  6.1589e-03,  1.1108e-03,  2.9025e-03, -2.0179e-03,\n",
       "                       3.5682e-04,  9.5905e-03, -1.8178e-03, -5.4501e-04,  1.9883e-03,\n",
       "                       1.0844e-02, -1.1886e-02,  4.7035e-03,  1.7952e-03, -5.7276e-03,\n",
       "                       9.8187e-04,  1.9612e-04, -2.8388e-03, -8.5287e-03,  5.8263e-03,\n",
       "                      -4.1476e-03,  1.1098e-03,  8.3354e-05,  8.5530e-03,  8.3339e-03,\n",
       "                       4.5812e-03,  3.9197e-03,  1.9051e-04], device='cuda:0')),\n",
       "             ('thetaDotNN.bNorm3.running_mean',\n",
       "              tensor([0.3849, 0.2650, 0.5177, 0.3775, 0.2254, 0.5066, 0.2740, 0.4851, 0.1239,\n",
       "                      0.2497, 0.4807, 0.2230, 0.1639, 0.5076, 0.1768, 0.1394, 0.4164, 0.3805,\n",
       "                      0.2918, 0.4232, 0.2115, 0.2858, 0.0923, 0.1989, 0.1912, 0.7450, 0.7256,\n",
       "                      0.2744, 0.4396, 0.2399, 0.1759, 0.3216, 0.1579, 0.3205, 0.1018, 0.4514,\n",
       "                      0.0769, 0.3840, 0.3543, 0.3450, 0.1992, 0.3178, 0.4754, 0.2276, 0.2863,\n",
       "                      0.3453, 0.5758, 0.2421, 0.4383, 0.1233, 0.1690, 0.3325, 0.2497, 0.4640,\n",
       "                      0.3263, 0.2107, 0.3252, 0.1383, 0.2943, 0.3243, 0.5441, 0.2067, 0.1669,\n",
       "                      0.1212, 0.3171, 0.1195, 0.2079, 0.1298, 0.2335, 0.2145, 0.4074, 0.1877,\n",
       "                      0.5983, 0.4314, 0.2580, 0.2350, 0.4712, 0.4412, 0.2482, 0.3248, 0.3130,\n",
       "                      0.4414, 0.3807, 0.1899, 0.2408, 0.3566, 0.2593, 0.2288, 0.4723, 0.2609,\n",
       "                      0.4855, 0.1405, 0.4401, 0.2958, 0.3866, 0.2169, 0.1859, 0.2551, 0.3515,\n",
       "                      0.3567, 0.4411, 0.4588, 0.3247, 0.5269, 0.2023, 0.4601, 0.2915, 0.2364,\n",
       "                      0.7813, 0.0536, 0.6559, 0.8121, 0.3099, 0.2045, 0.2338, 0.3607, 0.2948,\n",
       "                      0.4068, 0.2378, 0.3492, 0.3000, 0.4875, 0.2911, 1.1382, 0.2024, 0.1496,\n",
       "                      0.3457, 0.1565], device='cuda:0')),\n",
       "             ('thetaDotNN.bNorm3.running_var',\n",
       "              tensor([0.4754, 0.2293, 0.7052, 0.2600, 0.1478, 1.0591, 0.1413, 0.4593, 0.0573,\n",
       "                      0.1039, 0.6474, 0.1168, 0.1105, 0.7546, 0.1177, 0.0865, 0.2752, 0.2359,\n",
       "                      0.3433, 0.2673, 0.0979, 0.1517, 0.0353, 0.0916, 0.1333, 0.7256, 1.1241,\n",
       "                      0.1372, 0.2734, 0.2519, 0.0805, 0.2622, 0.0640, 0.2607, 0.0394, 0.5014,\n",
       "                      0.0306, 0.5462, 0.1770, 0.3790, 0.1258, 0.3520, 0.6774, 0.1262, 0.1688,\n",
       "                      0.4427, 1.2682, 0.1977, 0.6852, 0.0579, 0.0834, 0.1685, 0.1657, 0.8824,\n",
       "                      0.2215, 0.1087, 0.1940, 0.0563, 0.2098, 0.2012, 1.1269, 0.1199, 0.1161,\n",
       "                      0.0596, 0.1822, 0.0634, 0.0922, 0.0877, 0.1356, 0.0867, 0.2847, 0.1376,\n",
       "                      0.9394, 0.6385, 0.1741, 0.1198, 0.4122, 0.4522, 0.2712, 0.2560, 0.2306,\n",
       "                      0.5489, 0.5395, 0.0965, 0.1816, 0.1886, 0.1603, 0.2392, 0.3530, 0.1577,\n",
       "                      0.9085, 0.0611, 0.3762, 0.1820, 0.3667, 0.1618, 0.0865, 0.1538, 0.2063,\n",
       "                      0.3561, 0.6227, 0.4119, 0.2896, 0.6852, 0.0967, 0.7198, 0.1931, 0.1051,\n",
       "                      1.2423, 0.0215, 0.8174, 1.2217, 0.3251, 0.1221, 0.1419, 0.1910, 0.2347,\n",
       "                      0.3244, 0.1224, 0.2963, 0.1295, 0.3702, 0.1797, 1.5429, 0.1821, 0.0756,\n",
       "                      0.3167, 0.0895], device='cuda:0')),\n",
       "             ('thetaDotNN.bNorm3.num_batches_tracked',\n",
       "              tensor(2388000, device='cuda:0')),\n",
       "             ('thetaDotNN.layer1.weight',\n",
       "              tensor([[ 1.7182e-01, -4.3698e-01,  3.3367e-01, -1.2363e-01,  3.7098e-03,\n",
       "                       -1.9127e-01],\n",
       "                      [ 2.4966e-01, -2.7331e-02, -1.9399e-01, -1.0898e-01, -2.2213e-01,\n",
       "                       -4.0621e-01],\n",
       "                      [-1.6033e-01, -2.0708e-01,  2.1822e-01,  4.4061e-01,  2.5541e-02,\n",
       "                        3.9676e-02],\n",
       "                      [-3.0422e-01,  8.8092e-02,  2.0384e-01, -3.3993e-01, -9.1562e-03,\n",
       "                       -3.5640e-01],\n",
       "                      [-2.9482e-01,  4.4323e-01, -8.8039e-02,  4.4429e-02,  1.2991e-01,\n",
       "                        2.9512e-01],\n",
       "                      [-2.7298e-01,  2.0959e-01,  2.2833e-01,  9.8628e-02, -8.8833e-02,\n",
       "                        5.8376e-02],\n",
       "                      [-4.9963e-01,  1.8853e-01, -1.7405e-01,  1.4078e-01, -1.9144e-01,\n",
       "                       -1.1780e-01],\n",
       "                      [-9.6075e-03, -6.1681e-01, -1.0539e-01, -2.3676e-01,  2.2870e-01,\n",
       "                       -1.9222e-01],\n",
       "                      [-2.6385e-01,  4.1801e-01,  2.5790e-02,  1.1871e-02,  8.2932e-02,\n",
       "                        1.3044e-01],\n",
       "                      [ 3.3137e-01,  1.4374e-01,  3.8992e-01, -2.5872e-02, -6.5832e-02,\n",
       "                       -2.8024e-01],\n",
       "                      [ 2.1586e-01, -4.8915e-01,  2.5189e-01, -2.8407e-01,  1.1165e-01,\n",
       "                        3.5751e-02],\n",
       "                      [-3.7932e-01,  3.2082e-01,  1.5771e-01, -2.3102e-01,  2.2928e-01,\n",
       "                        3.8386e-01],\n",
       "                      [-2.5417e-01, -2.2655e-01, -1.0384e-01, -3.6993e-01, -9.6948e-02,\n",
       "                       -2.2673e-01],\n",
       "                      [ 1.5632e-01,  7.2834e-02, -2.1241e-01,  2.4539e-01,  3.1336e-01,\n",
       "                       -1.1656e-01],\n",
       "                      [-4.6452e-01,  4.7115e-01, -1.3287e-01, -1.1570e-01, -1.5462e-01,\n",
       "                        9.9407e-02],\n",
       "                      [ 3.7287e-01,  4.0273e-01, -1.1987e-01, -3.4612e-02, -9.6868e-02,\n",
       "                       -3.5407e-02],\n",
       "                      [-9.2049e-02, -4.7703e-01,  3.3609e-01,  1.4954e-01, -1.3210e-01,\n",
       "                       -7.8532e-02],\n",
       "                      [-9.6513e-02, -8.1783e-02,  3.7354e-01,  3.1374e-01,  3.0333e-01,\n",
       "                        6.8674e-02],\n",
       "                      [-5.9113e-02, -3.2649e-01, -3.0793e-01,  2.2372e-01, -2.6181e-01,\n",
       "                        1.9579e-01],\n",
       "                      [ 2.1031e-01,  1.3512e-01, -2.8824e-01,  2.4372e-01,  1.3950e-01,\n",
       "                        2.3767e-01],\n",
       "                      [-4.8577e-01, -7.5121e-02,  2.9465e-01, -3.4886e-01, -2.5877e-01,\n",
       "                        9.0004e-02],\n",
       "                      [ 8.7043e-02,  5.7486e-01, -5.0242e-02, -2.8895e-01, -1.6856e-01,\n",
       "                       -2.3211e-01],\n",
       "                      [-5.8010e-02, -4.3773e-01,  5.0352e-02, -2.1530e-01, -2.4675e-01,\n",
       "                       -1.0648e-02],\n",
       "                      [ 3.0275e-01, -4.3108e-01,  1.5395e-01,  9.7053e-02, -1.3731e-02,\n",
       "                        7.7630e-02],\n",
       "                      [-4.9432e-01,  2.3864e-01,  4.3958e-02,  1.2847e-01,  1.8388e-02,\n",
       "                        3.5333e-02],\n",
       "                      [ 4.6995e-01, -1.0658e-01, -1.3544e-01,  1.5575e-01, -4.3872e-01,\n",
       "                       -7.0068e-02],\n",
       "                      [ 4.3951e-01,  4.0540e-01, -1.8616e-01,  1.9900e-01,  1.3183e-01,\n",
       "                       -7.1115e-02],\n",
       "                      [ 1.0389e-01,  4.8128e-01, -1.5705e-01, -2.9744e-01, -1.5439e-01,\n",
       "                        2.4789e-01],\n",
       "                      [ 3.5124e-01, -3.9220e-02, -3.0138e-01, -1.0184e-01,  1.2464e-01,\n",
       "                       -3.0148e-01],\n",
       "                      [-1.9868e-01,  3.8256e-01,  9.1529e-02, -1.4088e-01,  2.9284e-02,\n",
       "                       -1.1897e-01],\n",
       "                      [-8.9372e-02, -5.8939e-01, -4.0834e-02, -1.2055e-01,  9.5951e-02,\n",
       "                       -1.2868e-01],\n",
       "                      [ 4.1063e-01,  2.7419e-01, -2.4013e-01, -1.4693e-01,  1.7639e-01,\n",
       "                        2.6915e-01],\n",
       "                      [-1.4108e-01,  1.7025e-01, -2.7046e-01,  1.2793e-01, -4.1221e-02,\n",
       "                       -4.9250e-02],\n",
       "                      [-4.0902e-01, -4.6597e-03, -1.4790e-01,  2.3345e-02, -1.7064e-01,\n",
       "                        2.3684e-01],\n",
       "                      [ 3.0854e-01, -4.5172e-01, -1.3453e-01,  1.3304e-01,  2.3522e-02,\n",
       "                        4.1173e-02],\n",
       "                      [-2.4042e-01,  4.4205e-01,  3.8426e-01,  1.2855e-01,  2.7765e-01,\n",
       "                       -2.1120e-01],\n",
       "                      [-2.8342e-02, -1.7962e-02, -3.3447e-01, -3.4499e-01,  1.1258e-01,\n",
       "                        2.0923e-02],\n",
       "                      [-3.9653e-01,  1.0223e-01,  1.9313e-01,  3.2741e-01,  1.5271e-01,\n",
       "                       -1.3120e-01],\n",
       "                      [-4.3479e-01, -8.3250e-02,  2.0748e-01, -1.1945e-01,  2.8411e-02,\n",
       "                       -5.4284e-02],\n",
       "                      [ 2.0701e-01, -2.4446e-01, -1.2251e-01, -4.0741e-02,  4.9339e-02,\n",
       "                       -3.6000e-01],\n",
       "                      [-3.1534e-01,  4.4171e-01, -2.7424e-01,  2.0314e-01, -3.2993e-01,\n",
       "                        2.9766e-01],\n",
       "                      [ 5.4975e-01, -1.8526e-03, -1.2756e-01, -6.2303e-02, -1.8556e-01,\n",
       "                        3.5341e-02],\n",
       "                      [-2.7517e-02, -4.6555e-01, -4.8213e-02,  4.1545e-02, -5.6265e-02,\n",
       "                        1.9844e-02],\n",
       "                      [-5.5996e-01, -2.0751e-01,  1.4582e-01, -1.3981e-01, -1.0831e-01,\n",
       "                       -7.2415e-02],\n",
       "                      [ 4.9011e-01,  5.0351e-01,  2.9526e-01, -1.4491e-01,  1.2976e-01,\n",
       "                       -1.0141e-01],\n",
       "                      [ 3.8368e-01, -2.0093e-01, -3.4429e-01, -2.3889e-01,  2.0339e-01,\n",
       "                       -2.5216e-01],\n",
       "                      [-4.0179e-01,  6.8787e-02,  3.4432e-01,  3.7551e-02, -9.2305e-02,\n",
       "                        2.7374e-01],\n",
       "                      [-4.4695e-01,  1.7079e-01,  1.7108e-01, -3.2692e-01, -1.2149e-01,\n",
       "                       -3.3128e-01],\n",
       "                      [-5.5631e-01, -1.6839e-01, -1.6146e-01, -7.0403e-02,  2.4662e-01,\n",
       "                        1.8922e-01],\n",
       "                      [-1.2704e-01, -2.2708e-01,  3.3307e-01,  3.9035e-03, -5.8579e-03,\n",
       "                       -3.2632e-01],\n",
       "                      [ 6.2376e-01, -8.6990e-02,  6.1415e-02, -1.4976e-01,  1.5500e-01,\n",
       "                        1.9180e-01],\n",
       "                      [-2.1302e-01, -4.1074e-01, -1.8402e-01, -6.9312e-02, -1.1237e-01,\n",
       "                       -9.6478e-02],\n",
       "                      [ 2.5775e-01, -2.3314e-01,  5.5378e-02, -1.6682e-01,  3.1025e-01,\n",
       "                        4.3858e-02],\n",
       "                      [ 4.1858e-01,  5.5022e-02,  2.2227e-01,  1.4847e-01, -1.8154e-01,\n",
       "                       -1.8310e-01],\n",
       "                      [-1.0627e-02, -5.0007e-01,  3.2178e-01, -1.2191e-01,  8.2601e-02,\n",
       "                        1.6343e-01],\n",
       "                      [ 4.3382e-01, -1.6409e-01,  4.3708e-01, -3.1229e-01,  2.2282e-01,\n",
       "                       -3.6276e-01],\n",
       "                      [ 5.8201e-02,  4.8963e-01,  3.6851e-01, -9.4119e-03,  9.0857e-02,\n",
       "                        3.7979e-01],\n",
       "                      [ 5.0538e-01, -4.9406e-01, -7.2629e-02, -2.0988e-01,  1.2601e-01,\n",
       "                       -9.4905e-02],\n",
       "                      [-1.8376e-01,  3.9795e-01,  3.2580e-01, -3.8285e-02,  4.2227e-03,\n",
       "                       -1.1531e-01],\n",
       "                      [-7.1208e-02,  5.3168e-01,  2.2358e-02, -7.7646e-02,  7.7278e-02,\n",
       "                        3.9286e-02],\n",
       "                      [-3.9844e-01, -1.3957e-01, -2.7077e-01, -2.6923e-01, -5.7883e-02,\n",
       "                       -9.1367e-02],\n",
       "                      [ 5.8962e-01,  8.5169e-02, -1.5564e-02, -8.3054e-02, -9.6351e-02,\n",
       "                        1.7139e-01],\n",
       "                      [-2.5181e-01,  1.9011e-01,  3.8013e-02, -1.2526e-01,  1.9215e-02,\n",
       "                       -1.1652e-01],\n",
       "                      [-2.7860e-01,  3.1446e-01,  2.3361e-01, -2.4762e-01, -3.1299e-01,\n",
       "                       -1.6813e-02],\n",
       "                      [ 3.8467e-01, -1.0735e-01, -1.2481e-02, -8.9656e-02, -2.5517e-01,\n",
       "                       -3.5848e-01],\n",
       "                      [ 9.7543e-02,  3.6439e-01,  1.4838e-01, -1.4422e-01,  9.2000e-04,\n",
       "                       -6.2954e-03],\n",
       "                      [ 4.9861e-01,  4.1163e-01,  3.3530e-01,  3.1171e-01, -9.4545e-03,\n",
       "                       -1.1449e-01],\n",
       "                      [ 8.3592e-02,  4.8533e-01,  2.5235e-01, -1.3041e-01,  2.3133e-01,\n",
       "                       -9.3127e-02],\n",
       "                      [ 1.2304e-01, -1.1605e-01,  4.4599e-01, -3.7373e-01, -2.8643e-01,\n",
       "                        1.4154e-01],\n",
       "                      [-4.1002e-01, -1.6636e-01, -2.0193e-01, -2.8459e-01,  2.7180e-02,\n",
       "                        2.1805e-01],\n",
       "                      [ 2.0531e-01, -2.3662e-02,  1.6929e-01,  2.9757e-01,  9.4906e-02,\n",
       "                        3.5202e-01],\n",
       "                      [-2.0867e-01, -5.3186e-01,  3.2433e-01, -1.2186e-01,  1.7822e-02,\n",
       "                        7.1041e-02],\n",
       "                      [ 3.3319e-01, -1.4794e-01, -3.2066e-01, -2.6041e-01,  3.0959e-02,\n",
       "                       -2.1784e-01],\n",
       "                      [ 8.6789e-02, -2.6429e-01, -6.9238e-02,  8.5006e-02,  1.3692e-02,\n",
       "                       -1.6361e-01],\n",
       "                      [-1.2285e-01, -6.6022e-03, -2.3048e-01, -3.5098e-01,  2.4966e-01,\n",
       "                        4.8347e-01],\n",
       "                      [-4.4414e-01, -3.0540e-01, -1.1521e-01,  1.0770e-02,  6.7077e-03,\n",
       "                        3.3702e-03],\n",
       "                      [ 3.6811e-01,  3.2234e-01,  2.6011e-01,  2.4059e-01,  2.9672e-01,\n",
       "                        3.7683e-01],\n",
       "                      [-3.2724e-01,  1.7198e-01, -7.5550e-02,  1.8715e-01,  2.5523e-01,\n",
       "                       -4.6887e-02],\n",
       "                      [ 4.4328e-01,  1.7981e-01,  2.7161e-01,  1.5906e-01, -1.2685e-01,\n",
       "                       -1.8689e-01],\n",
       "                      [ 1.2609e-01,  3.2255e-01, -1.5751e-01,  3.0714e-01, -6.2616e-02,\n",
       "                       -3.7519e-01],\n",
       "                      [ 3.6577e-02, -2.8396e-01,  3.4278e-01, -1.7890e-01,  6.2594e-02,\n",
       "                       -2.8740e-01],\n",
       "                      [-5.2083e-01, -2.8825e-01,  7.6680e-02,  1.0089e-01,  4.0248e-02,\n",
       "                        1.6986e-01],\n",
       "                      [ 4.3051e-01, -5.6952e-01,  3.3863e-02,  1.8031e-01, -3.1008e-01,\n",
       "                        1.3980e-01],\n",
       "                      [ 4.2931e-01,  4.8613e-02,  2.1653e-01,  8.6660e-02, -1.6300e-01,\n",
       "                        1.8660e-01],\n",
       "                      [ 4.2432e-01,  3.0416e-02, -3.3469e-01, -1.7912e-01,  2.2858e-01,\n",
       "                        3.9678e-01],\n",
       "                      [-1.1565e-01, -1.5952e-01,  5.5692e-02, -1.1543e-01,  1.5492e-01,\n",
       "                       -2.4545e-01],\n",
       "                      [ 2.5743e-01, -1.4532e-02,  2.5348e-01,  2.9216e-01,  1.6089e-01,\n",
       "                       -2.7417e-01],\n",
       "                      [-2.8956e-01, -4.3246e-01,  9.9612e-02,  2.8862e-04, -2.4999e-01,\n",
       "                       -3.3175e-01],\n",
       "                      [ 2.0739e-01, -5.9825e-01, -2.6229e-02,  1.0984e-01, -1.6767e-01,\n",
       "                        2.0231e-01],\n",
       "                      [ 3.2863e-01, -4.1780e-01,  2.0238e-01,  2.1713e-01, -2.6718e-01,\n",
       "                        3.1500e-01],\n",
       "                      [-2.6243e-01, -6.5890e-02,  2.0637e-01,  2.3389e-01, -3.7370e-01,\n",
       "                       -9.8040e-02],\n",
       "                      [-2.3743e-01,  1.2211e-01,  6.2362e-02, -3.7515e-01, -2.6947e-01,\n",
       "                        1.7865e-01],\n",
       "                      [-3.6398e-01, -3.8580e-01,  3.0851e-02, -8.7051e-03,  3.4303e-02,\n",
       "                       -1.8197e-01],\n",
       "                      [-6.6177e-01, -3.5175e-01,  1.9420e-01,  1.1065e-01, -8.0790e-02,\n",
       "                        5.1908e-02],\n",
       "                      [-2.3789e-01,  4.4478e-01,  2.9736e-01,  4.8716e-02, -3.2400e-01,\n",
       "                       -2.4013e-01],\n",
       "                      [-4.8600e-01,  1.2911e-01, -2.7580e-01, -7.2093e-02, -3.5589e-01,\n",
       "                        1.3133e-01],\n",
       "                      [ 2.9122e-01,  1.1351e-01,  3.2433e-01,  3.1524e-01, -3.5552e-02,\n",
       "                       -3.1396e-02],\n",
       "                      [-4.5350e-01,  2.5263e-01, -3.2827e-01,  3.0641e-01, -2.5934e-01,\n",
       "                        2.4130e-01],\n",
       "                      [ 3.3604e-01, -6.4017e-02,  3.4487e-01,  8.1044e-02, -1.3503e-01,\n",
       "                       -1.9264e-01],\n",
       "                      [-1.6163e-02, -4.8980e-01,  2.6154e-01,  5.2065e-02, -1.6254e-01,\n",
       "                       -5.5791e-03],\n",
       "                      [-2.1333e-02,  1.8862e-02, -3.0478e-01,  5.7761e-02,  1.9382e-01,\n",
       "                       -3.0252e-01],\n",
       "                      [-6.7162e-02, -4.5338e-01, -1.0469e-01,  2.8726e-01,  3.3964e-01,\n",
       "                       -2.6369e-01],\n",
       "                      [ 6.5603e-02,  4.0758e-01, -3.4704e-01, -2.9703e-02,  2.5958e-01,\n",
       "                       -3.2240e-01],\n",
       "                      [-4.7945e-01, -2.5553e-01, -2.8755e-01,  5.3916e-02,  1.9074e-01,\n",
       "                        1.0764e-01],\n",
       "                      [-2.4199e-02, -1.1029e-01, -3.1053e-01, -2.1405e-01, -3.3357e-01,\n",
       "                       -1.6545e-01],\n",
       "                      [-3.4582e-01,  3.3053e-01,  8.9857e-02, -2.2389e-01, -1.7623e-02,\n",
       "                       -1.3944e-01],\n",
       "                      [-1.4644e-01, -3.5001e-01,  1.1223e-01,  1.7086e-01,  4.2413e-02,\n",
       "                        3.9830e-01],\n",
       "                      [ 9.4402e-02, -2.2072e-01,  2.4180e-01, -2.7184e-01, -1.2445e-01,\n",
       "                        1.0994e-01],\n",
       "                      [-2.3173e-01,  1.2412e-01, -1.5652e-01,  3.4810e-01, -2.0690e-01,\n",
       "                       -1.0582e-01],\n",
       "                      [ 1.6709e-01,  3.0402e-01, -5.6478e-02,  3.9990e-01,  1.7929e-01,\n",
       "                        1.8781e-01],\n",
       "                      [-2.6667e-01,  4.6218e-01,  3.9477e-01,  2.2930e-01, -1.7372e-01,\n",
       "                       -1.7663e-01],\n",
       "                      [ 2.1037e-01, -2.8146e-01,  1.0704e-01, -5.0508e-02, -6.3102e-02,\n",
       "                       -2.8490e-01],\n",
       "                      [ 3.3909e-01,  4.0254e-01, -2.5324e-01,  2.8418e-01,  1.6704e-01,\n",
       "                       -3.7904e-01],\n",
       "                      [ 3.1151e-01, -1.2372e-01,  3.4841e-01, -2.1487e-01, -1.9078e-02,\n",
       "                        1.4751e-02],\n",
       "                      [ 8.5500e-02,  5.7095e-02, -1.0438e-01, -2.1246e-01,  1.0656e-01,\n",
       "                        1.2072e-02],\n",
       "                      [-1.8428e-01,  4.1997e-01, -2.9494e-01,  1.0258e-01,  2.2360e-01,\n",
       "                       -1.3140e-01],\n",
       "                      [-1.5096e-01,  4.1880e-01,  3.8731e-01, -2.2796e-01,  2.6203e-01,\n",
       "                        1.7072e-01],\n",
       "                      [-4.1634e-01,  2.0012e-01, -1.9315e-01,  1.4017e-01, -2.6723e-01,\n",
       "                       -3.6451e-01],\n",
       "                      [ 1.9973e-02,  3.3837e-01,  4.2034e-01,  3.1094e-01,  2.9453e-01,\n",
       "                       -3.7225e-02],\n",
       "                      [-2.2597e-01,  4.6781e-01, -8.4757e-02, -5.1907e-03,  2.0462e-02,\n",
       "                       -3.5446e-01],\n",
       "                      [-1.7165e-01, -3.6583e-01, -2.3051e-01, -1.7500e-01, -3.1738e-01,\n",
       "                        2.8793e-01],\n",
       "                      [-3.6605e-01, -3.7027e-01, -1.4411e-01, -2.1955e-01,  3.0896e-01,\n",
       "                        1.5540e-01],\n",
       "                      [ 3.2205e-01, -4.0140e-01, -1.8140e-01, -1.4946e-01, -2.4792e-02,\n",
       "                       -6.6726e-03],\n",
       "                      [-3.9476e-01, -3.0718e-01,  1.9108e-01,  1.8415e-02,  1.3418e-01,\n",
       "                       -1.3863e-01],\n",
       "                      [-5.3573e-01, -1.3156e-02,  2.8535e-01,  2.9456e-01, -2.2540e-01,\n",
       "                        1.7627e-01],\n",
       "                      [ 2.4450e-01,  1.1110e-03,  3.2209e-01, -6.2531e-02, -7.4449e-02,\n",
       "                       -9.3147e-02],\n",
       "                      [-1.6201e-01, -5.9121e-02, -2.5753e-01, -2.3802e-01, -4.0016e-02,\n",
       "                        2.6147e-03],\n",
       "                      [ 5.0546e-01,  6.9908e-02, -1.4851e-01, -2.7042e-02,  1.9074e-01,\n",
       "                       -2.2053e-01]], device='cuda:0')),\n",
       "             ('thetaDotNN.layer1.bias',\n",
       "              tensor([-0.2453, -0.4039, -0.3126, -0.1881, -0.3700,  0.1764,  0.1500,  0.0476,\n",
       "                      -0.0015,  0.0731, -0.0275,  0.3876,  0.1964,  0.0150,  0.1615,  0.2201,\n",
       "                       0.0786, -0.1327, -0.1910, -0.2765, -0.3076, -0.0478, -0.3395,  0.1470,\n",
       "                       0.0057, -0.1178,  0.0271, -0.0576, -0.4710,  0.2204, -0.1082, -0.1158,\n",
       "                      -0.3237,  0.1475, -0.0805,  0.2553, -0.2361, -0.1466, -0.2072, -0.1369,\n",
       "                       0.0096,  0.1287,  0.0485, -0.0383, -0.3369,  0.0135,  0.1700,  0.1639,\n",
       "                      -0.3021, -0.0018, -0.3467,  0.1851, -0.2459, -0.2554, -0.1277, -0.2500,\n",
       "                      -0.1341, -0.0687,  0.3962, -0.4401, -0.3660, -0.2091,  0.3134,  0.2410,\n",
       "                      -0.0949,  0.1726, -0.2371,  0.2388, -0.1585, -0.0935,  0.1840,  0.1215,\n",
       "                      -0.1603, -0.3130, -0.1479,  0.1458, -0.4486,  0.1195,  0.3695,  0.1911,\n",
       "                       0.1345, -0.2375, -0.0949, -0.0971,  0.1503,  0.2486,  0.0602, -0.0742,\n",
       "                       0.0762,  0.1749, -0.2256,  0.0592,  0.2900, -0.1271,  0.4277,  0.0535,\n",
       "                       0.0368,  0.2871,  0.2021,  0.2843, -0.4440, -0.1222, -0.4329,  0.2011,\n",
       "                       0.1560,  0.0829, -0.1998, -0.0457, -0.1246, -0.1827,  0.2910,  0.2237,\n",
       "                      -0.3646, -0.0779, -0.4220,  0.2002,  0.1193, -0.2131, -0.1657,  0.0054,\n",
       "                       0.0965, -0.3189,  0.0137, -0.1864, -0.0459,  0.2581, -0.3892,  0.1186],\n",
       "                     device='cuda:0')),\n",
       "             ('thetaDotNN.layer2.weight',\n",
       "              tensor([[ 0.1076,  0.0274, -0.0018,  ...,  0.0635, -0.0263, -0.0277],\n",
       "                      [ 0.0397,  0.0288,  0.0178,  ..., -0.0776,  0.0281, -0.0018],\n",
       "                      [ 0.0064,  0.0496,  0.0831,  ..., -0.0193, -0.0682, -0.0876],\n",
       "                      ...,\n",
       "                      [-0.0064, -0.0467, -0.0258,  ..., -0.0756, -0.0669,  0.0731],\n",
       "                      [-0.0139,  0.0189, -0.0734,  ...,  0.0466,  0.0137,  0.0733],\n",
       "                      [ 0.0139, -0.0263, -0.0724,  ...,  0.0262,  0.0298, -0.0605]],\n",
       "                     device='cuda:0')),\n",
       "             ('thetaDotNN.layer2.bias',\n",
       "              tensor([-0.0571, -0.2806, -0.2824,  0.0655,  0.0237, -0.0157, -0.0463, -0.0091,\n",
       "                      -0.1887, -0.0325, -0.0391,  0.0088,  0.1012,  0.0093, -0.0384,  0.0276,\n",
       "                       0.0078, -0.1035, -0.1521, -0.0928,  0.0845, -0.1189, -0.0760, -0.0709,\n",
       "                      -0.0560,  0.0350,  0.0464,  0.0642, -0.0222, -0.1109,  0.0148, -0.1148,\n",
       "                      -0.0877, -0.0136, -0.0114, -0.1335,  0.0314, -0.0843,  0.0503, -0.1105,\n",
       "                       0.0402, -0.1324, -0.0115, -0.0163, -0.0875, -0.0722, -0.0783,  0.0334,\n",
       "                       0.0092,  0.0702, -0.0231, -0.0397, -0.1086, -0.1077,  0.0429,  0.0064,\n",
       "                      -0.0929, -0.1034, -0.1465,  0.0363,  0.0483,  0.0813, -0.0501, -0.0903,\n",
       "                      -0.0630, -0.0918, -0.0721, -0.0887, -0.1877, -0.0638, -0.0126, -0.0658,\n",
       "                      -0.0846, -0.0671, -0.0240, -0.0866,  0.0405, -0.0149, -0.0850, -0.0159,\n",
       "                      -0.0991,  0.0264, -0.2027,  0.0872, -0.1015, -0.0432, -0.1428,  0.0697,\n",
       "                      -0.1330,  0.0310, -0.0950,  0.0613, -0.1406, -0.2416, -0.0737, -0.0220,\n",
       "                       0.1047, -0.0741, -0.0878, -0.1298, -0.1373, -0.0931, -0.0472, -0.0813,\n",
       "                      -0.1282, -0.0700, -0.1250,  0.0175, -0.0130, -0.1738, -0.1677,  0.0324,\n",
       "                       0.0757,  0.0744, -0.1286,  0.0133, -0.0879, -0.0137, -0.0265, -0.1479,\n",
       "                      -0.0605, -0.0177, -0.0359, -0.0276, -0.0059, -0.0041,  0.0789, -0.0317],\n",
       "                     device='cuda:0')),\n",
       "             ('thetaDotNN.layer3.weight',\n",
       "              tensor([[-0.0389, -0.1093,  0.1352,  ...,  0.0022,  0.0436,  0.0059],\n",
       "                      [ 0.0309,  0.0186,  0.0803,  ..., -0.0499,  0.0023, -0.0708],\n",
       "                      [ 0.0880,  0.0094,  0.0066,  ..., -0.0473,  0.0402, -0.0709],\n",
       "                      ...,\n",
       "                      [ 0.0761, -0.1786, -0.0315,  ..., -0.1064, -0.0120,  0.0368],\n",
       "                      [-0.0143, -0.0432,  0.0079,  ...,  0.0351,  0.0861, -0.1064],\n",
       "                      [ 0.0134,  0.0488,  0.0144,  ...,  0.0344,  0.0751, -0.0045]],\n",
       "                     device='cuda:0')),\n",
       "             ('thetaDotNN.layer3.bias',\n",
       "              tensor([-0.1460,  0.0030, -0.0071,  0.0056, -0.0624, -0.0776, -0.0258, -0.1099,\n",
       "                      -0.0675,  0.0464, -0.1400, -0.0946, -0.1378,  0.1067, -0.0749, -0.1739,\n",
       "                      -0.0135,  0.0501, -0.0864, -0.0267, -0.1345, -0.0141, -0.1818, -0.0367,\n",
       "                      -0.0677,  0.0822,  0.0760,  0.0013,  0.0927, -0.1084, -0.1006,  0.0297,\n",
       "                      -0.0675, -0.0417, -0.1618, -0.1643, -0.2124, -0.0870, -0.0478, -0.0567,\n",
       "                      -0.0890, -0.1496, -0.0758, -0.1137, -0.0682, -0.0436, -0.0867, -0.0445,\n",
       "                      -0.1566, -0.0606, -0.0914,  0.0570, -0.0474, -0.0958,  0.0487,  0.0330,\n",
       "                      -0.0309, -0.1355, -0.0550, -0.0839, -0.0537, -0.0646, -0.1546, -0.1966,\n",
       "                      -0.0157, -0.1602, -0.0284, -0.1429,  0.0048, -0.0746,  0.0406, -0.0902,\n",
       "                      -0.0084, -0.2162, -0.1340, -0.0406, -0.0022,  0.0053, -0.1325, -0.0616,\n",
       "                      -0.1456, -0.0884, -0.1367, -0.0181, -0.1524, -0.0392,  0.0151, -0.2241,\n",
       "                       0.0536, -0.0876, -0.0168, -0.0692, -0.0635, -0.0053,  0.0465, -0.1003,\n",
       "                      -0.0256, -0.1055,  0.0536, -0.0593,  0.0036,  0.0468, -0.0633, -0.0827,\n",
       "                      -0.1161, -0.0391,  0.0214, -0.0962, -0.0847, -0.2058,  0.0411,  0.0425,\n",
       "                      -0.0499, -0.0179, -0.0884,  0.0441, -0.0339, -0.0764, -0.0071, -0.0213,\n",
       "                      -0.0069,  0.1078, -0.0566,  0.0606, -0.2499, -0.1747, -0.0541, -0.1851],\n",
       "                     device='cuda:0')),\n",
       "             ('thetaDotNN.layer4.weight',\n",
       "              tensor([[-5.0699e-03,  3.7057e-03,  1.1796e-04, -3.7712e-03,  3.9313e-03,\n",
       "                        4.5921e-03, -2.7467e-03, -9.9981e-03, -6.0128e-03,  2.0489e-03,\n",
       "                        9.7870e-03, -5.3156e-03, -1.6056e-02, -1.8569e-03, -1.6241e-02,\n",
       "                       -2.4832e-03,  4.1764e-03, -1.9984e-02,  5.4297e-03,  3.5055e-03,\n",
       "                        6.2517e-03,  6.1287e-04, -1.1001e-02, -9.2620e-03,  2.2489e-03,\n",
       "                       -1.6728e-03,  3.4757e-02, -5.0311e-04,  6.9678e-03,  2.2753e-03,\n",
       "                        6.4857e-03,  2.1409e-03,  1.6942e-03, -2.0718e-02, -7.5891e-03,\n",
       "                       -7.5976e-03,  6.2583e-04, -1.9945e-03, -3.9251e-03,  4.9394e-03,\n",
       "                        1.0376e-02, -2.3981e-03,  3.4913e-04, -5.2219e-03, -3.0020e-03,\n",
       "                       -3.3395e-03, -6.7324e-04,  6.2635e-04,  1.5326e-03, -9.6403e-03,\n",
       "                        4.0837e-03, -2.4744e-03,  1.9375e-02,  7.9262e-03, -5.6867e-03,\n",
       "                        1.0114e-02,  2.2392e-03,  1.0066e-02,  7.2197e-03,  1.4341e-03,\n",
       "                       -8.6640e-03,  5.4372e-03, -6.6658e-04, -1.4525e-02,  8.4571e-03,\n",
       "                        9.2536e-03,  1.9949e-03,  8.2585e-03,  1.8920e-03,  1.1786e-03,\n",
       "                       -3.2547e-03,  6.4449e-03, -1.9656e-03,  7.2088e-03,  3.1162e-03,\n",
       "                       -3.5902e-03, -2.0130e-03,  2.1026e-02, -9.1242e-03, -6.0507e-03,\n",
       "                        1.3535e-02, -2.4990e-03,  5.7676e-03, -1.5834e-03,  1.2777e-02,\n",
       "                       -3.7029e-04,  1.2160e-03,  7.9250e-04, -6.0759e-03,  9.2593e-03,\n",
       "                       -4.4623e-03,  1.8870e-03,  2.0094e-02,  1.0444e-02,  2.3046e-02,\n",
       "                       -8.7453e-03, -4.1036e-03,  1.6296e-02,  4.4574e-03,  1.6693e-03,\n",
       "                        5.9678e-03,  2.0683e-02, -1.0994e-02, -4.0329e-03,  3.1887e-04,\n",
       "                        1.7000e-03, -5.1569e-03,  1.5069e-04, -5.7737e-03, -6.1595e-03,\n",
       "                       -4.2639e-02,  4.5919e-03, -8.2197e-03,  1.2889e-03,  9.9351e-04,\n",
       "                       -5.2271e-03,  1.3475e-02,  6.0714e-03,  4.6286e-03, -3.0664e-02,\n",
       "                        4.3626e-03, -4.8640e-04,  8.0955e-05, -3.8956e-02,  1.9015e-02,\n",
       "                       -1.5063e-02, -6.4603e-03,  9.2521e-03]], device='cuda:0')),\n",
       "             ('thetaDotNN.layer4.bias', tensor([0.0010], device='cuda:0'))])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "44265599",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T16:19:00.827186Z",
     "start_time": "2022-10-27T16:18:02.840919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: [2.5776, 0.1946]\n"
     ]
    }
   ],
   "source": [
    "# モデルを評価モードに設定\n",
    "stored_model.eval()\n",
    "\n",
    "# 推論\n",
    "test_lossv = 0\n",
    "test_losstheta = 0\n",
    "test_count = 0\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y, batch_ct in test_data:\n",
    "        for ib in range(batch_x.size(0)):\n",
    "            model.load_celltypes(batch_ct[ib].to(device))\n",
    "            test_out = calc_multiSteps(batch_x[ib].to(device))\n",
    "            lv, ltheta = myLoss(test_out, batch_y[ib].to(device))\n",
    "            test_lossv = test_lossv + lv\n",
    "            test_losstheta = test_losstheta + ltheta\n",
    "        test_count = test_count + batch_x.size(0)\n",
    "test_lossv = test_lossv/test_count\n",
    "test_losstheta = test_losstheta/test_count\n",
    "print('test Loss: [%.4f, %.4f]' % (test_lossv.item(), test_losstheta.item()))\n",
    "test_loss = [test_lossv.item(), test_losstheta.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "d0283033",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T16:19:00.837660Z",
     "start_time": "2022-10-27T16:19:00.831322Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "nowstr = now.strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "os.makedirs(savedirName + nowstr + '/', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "445915ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T16:19:00.856063Z",
     "start_time": "2022-10-27T16:19:00.844341Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8617, device='cuda:0')"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stored_model.selfpropel.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "62154d31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-27T16:19:00.915009Z",
     "start_time": "2022-10-27T16:19:00.859270Z"
    }
   },
   "outputs": [],
   "source": [
    "stored_model = stored_model.to('cpu')\n",
    "\n",
    "filename1 = savedirName + nowstr + '/' + nowstr + '_Model.pkl'\n",
    "with open(filename1, \"wb\") as f:\n",
    "    pickle.dump(stored_model, f)\n",
    "\n",
    "filename1_2 = savedirName + nowstr + '/' + nowstr + '_Model.pt'\n",
    "torch.save(stored_model, filename1_2)\n",
    "\n",
    "filename2 = savedirName + nowstr + '/' + nowstr\n",
    "torch.save(stored_model.interactNN.state_dict(), filename2 + '_interactNN.pkl')\n",
    "torch.save(stored_model.thetaDotNN.state_dict(), filename2 + '_thetaDotNN.pkl')\n",
    "torch.save(stored_model.selfpropel.detach(), filename2 + '_selfpropel.pkl')\n",
    "\n",
    "filename3 = savedirName + nowstr + '/' + nowstr + '_Separation.npz'\n",
    "np.savez(filename3, dr_thresh=dr_thresh, T_pred=T_pred, batch_size=batch_size,\n",
    "         train_inds=train_inds, valid_inds=valid_inds, test_inds=test_inds, \n",
    "         val_loss_log=val_loss_log, test_loss=test_loss,\n",
    "         transfer_origin=model_dir)\n",
    "\n",
    "filename4 = savedirName + nowstr + '/' + nowstr + '_optimizer.pt'\n",
    "torch.save(optimizer, filename4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0bd69a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 249.41666600000002,
   "position": {
    "height": "40px",
    "left": "554px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
