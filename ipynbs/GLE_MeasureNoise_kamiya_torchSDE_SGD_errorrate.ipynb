{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-03T10:32:20.947524Z",
     "start_time": "2022-10-03T10:32:20.926687Z"
    },
    "executionInfo": {
     "elapsed": 2320,
     "status": "ok",
     "timestamp": 1663048735407,
     "user": {
      "displayName": "上道 雅仁.",
      "userId": "02361249356017468398"
     },
     "user_tz": -540
    },
    "id": "oqt3xMwXyqHS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchsde import BrownianInterval, sdeint\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# numbers of cells, freedom, and noise source\n",
    "batch_size, state_size, brownian_size = 25, 6, 2\n",
    "\n",
    "# duration of simulation\n",
    "t_max = 500\n",
    "\n",
    "# interval of evaluation\n",
    "t_eval = 1\n",
    "\n",
    "# method to solve SDE\n",
    "methodSDE = 'euler'\n",
    "isIto = True\n",
    "\n",
    "# time step to simulate\n",
    "stepSDE = 2e-3\n",
    "\n",
    "# delay (steps with t_eval interval) for autocorrelation calculation\n",
    "delaystep = np.arange(50)\n",
    "\n",
    "# bins for v histogram calculation\n",
    "vbinwidth = 0.1\n",
    "vmin = 0\n",
    "vmax = 5\n",
    "vbins = torch.tensor(np.arange(vmin, vmax+vbinwidth, vbinwidth), dtype=torch.float, device=device)\n",
    "\n",
    "# list of steps at which output is collected\n",
    "ts = torch.arange(0, t_max+t_eval, t_eval, device=device)\n",
    "Nts = ts.size()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-03T10:32:20.960795Z",
     "start_time": "2022-10-03T10:32:20.952542Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1663048735409,
     "user": {
      "displayName": "上道 雅仁.",
      "userId": "02361249356017468398"
     },
     "user_tz": -540
    },
    "id": "OO-5DcgyaX6m",
    "outputId": "cc6dd522-0ace-4785-b7fc-8993bbaff320"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000, 0.1000, 0.2000, 0.3000, 0.4000, 0.5000, 0.6000, 0.7000, 0.8000,\n",
      "        0.9000, 1.0000, 1.1000, 1.2000, 1.3000, 1.4000, 1.5000, 1.6000, 1.7000,\n",
      "        1.8000, 1.9000, 2.0000, 2.1000, 2.2000, 2.3000, 2.4000, 2.5000, 2.6000,\n",
      "        2.7000, 2.8000, 2.9000, 3.0000, 3.1000, 3.2000, 3.3000, 3.4000, 3.5000,\n",
      "        3.6000, 3.7000, 3.8000, 3.9000, 4.0000, 4.1000, 4.2000, 4.3000, 4.4000,\n",
      "        4.5000, 4.6000, 4.7000, 4.8000, 4.9000, 5.0000], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(vbins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-03T10:32:20.971581Z",
     "start_time": "2022-10-03T10:32:20.964353Z"
    },
    "executionInfo": {
     "elapsed": 250,
     "status": "ok",
     "timestamp": 1663048779885,
     "user": {
      "displayName": "上道 雅仁.",
      "userId": "02361249356017468398"
     },
     "user_tz": -540
    },
    "id": "NagIZU7WrdjH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "dirName = \"/home/uwamichi/miura_kamiya/\"\n",
    "\n",
    "csvdir = dirName + \"graph_frameOut_yflip0.142/\"\n",
    "\n",
    "def loadcsv(prefix, surfix):\n",
    "    return np.loadtxt(csvdir+prefix+surfix, delimiter=',', skiprows=1)\n",
    "\n",
    "csv_prefix = 'L2_skip{}_'.format(str(t_eval))\n",
    "csv_surfix = '.csv'\n",
    "\n",
    "savedir = dirName + 'torchSDE_Adam/'\n",
    "os.makedirs(savedir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-03T10:32:20.997447Z",
     "start_time": "2022-10-03T10:32:20.976984Z"
    },
    "executionInfo": {
     "elapsed": 404,
     "status": "ok",
     "timestamp": 1663048780558,
     "user": {
      "displayName": "上道 雅仁.",
      "userId": "02361249356017468398"
     },
     "user_tz": -540
    },
    "id": "_J-blOg-HHtP"
   },
   "outputs": [],
   "source": [
    "class betasigma(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super(betasigma, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Linear(1,1,bias=True, device=device)\n",
    "       # self.layer2 = nn.Linear(1,1,bias=False)\n",
    "        self.layer3 = nn.Linear(1,1,bias=False, device=device)\n",
    "\n",
    "        nn.init.constant_(self.layer1.bias, params[0])\n",
    "        nn.init.constant_(self.layer1.weight, params[1])\n",
    "        nn.init.constant_(self.layer3.weight, params[2])\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x has shape [N, 1]\n",
    "        x01 = self.layer1(x)\n",
    "        x2 = self.layer3(torch.square(x))\n",
    "        return x01 + x2\n",
    "\n",
    "\n",
    "class SDE(nn.Module):\n",
    "    noise_type = 'general'\n",
    "    sde_type = 'ito' if isIto else 'stratonovich'\n",
    "\n",
    "    def __init__(self, alpha, beta, gamma, sigma):\n",
    "        super().__init__()\n",
    "        self.alpha = nn.Parameter(torch.tensor([[alpha]], requires_grad=True, device=device))\n",
    "        self.gamma = nn.Parameter(torch.tensor([[gamma]], requires_grad=True, device=device))\n",
    "        self.beta = betasigma(beta)\n",
    "        self.sigma = betasigma(sigma)\n",
    "\n",
    "        self.alpha.register_hook(lambda grad: print('alpha grad', grad))\n",
    "        self.gamma.register_hook(lambda grad: print('gamma grad', grad))\n",
    "        self.beta.layer1.bias.register_hook(lambda grad: print('beta0 grad', grad))\n",
    "        self.beta.layer1.weight.register_hook(lambda grad: print('beta1 grad', grad))\n",
    "        self.beta.layer3.weight.register_hook(lambda grad: print('beta2 grad', grad))\n",
    "        self.sigma.layer1.bias.register_hook(lambda grad: print('sigma0 grad', grad))\n",
    "        self.sigma.layer1.weight.register_hook(lambda grad: print('sigma1 grad', grad))\n",
    "        self.sigma.layer3.weight.register_hook(lambda grad: print('sigma2 grad', grad))\n",
    "\n",
    "        \n",
    "    # Drift\n",
    "    def f(self, t, y):\n",
    "        vsmall = y[:, 2:4]\n",
    "        vlarge = y[:, 4:]\n",
    "\n",
    "        v_abs = torch.norm(vsmall, dim=1, keepdim=True)\n",
    "        \n",
    "        betas = self.beta(v_abs)\n",
    "        dvsmall = -betas*vsmall + self.alpha * vlarge\n",
    "\n",
    "        dvlarge = self.alpha * vsmall - self.gamma * vlarge\n",
    "\n",
    "        return torch.cat((vsmall, dvsmall, dvlarge), 1)  # shape (batch_size, state_size)\n",
    "\n",
    "    # Diffusion\n",
    "    def g(self, t, y):\n",
    "        v_abs_ = torch.unsqueeze(torch.norm(y[:, 2:4], dim=1, keepdim=True), 2)\n",
    "        sigmas_v = self.sigma(v_abs_)\n",
    "        sigmas_vx = torch.cat((sigmas_v, torch.zeros_like(sigmas_v)), 2)\n",
    "        sigmas_vy = torch.cat((torch.zeros_like(sigmas_v), sigmas_v), 2)\n",
    "        \n",
    "        sigmas_v2 = torch.cat((sigmas_vx, sigmas_vy), 1)\n",
    "        sigmas_xy = torch.zeros_like(sigmas_v2)\n",
    "        sigmas_vlarge = torch.zeros_like(sigmas_v2)\n",
    "\n",
    "        return torch.cat((sigmas_xy, sigmas_v2, sigmas_vlarge), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-03T10:32:21.009543Z",
     "start_time": "2022-10-03T10:32:21.000755Z"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1663048780559,
     "user": {
      "displayName": "上道 雅仁.",
      "userId": "02361249356017468398"
     },
     "user_tz": -540
    },
    "id": "SyhRFMIOkcWX"
   },
   "outputs": [],
   "source": [
    "class moduleSDE(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super(moduleSDE, self).__init__()\n",
    "    \n",
    "        self.sde = SDE(params['alpha'], [params['beta0'], params['beta1'], params['beta2']],\n",
    "                       params['gamma'], [params['sigma0'], params['sigma1'], params['sigma2']])\n",
    "        \n",
    "        self.sigmaX = nn.Parameter(torch.tensor([[[params['sigmaX']]]], requires_grad=True, device=device))\n",
    "\n",
    "        self.sigmaX.register_hook(lambda grad: print('sigmaX grad', grad))\n",
    "\n",
    "    def forward(self, yInit, bm, rn):\n",
    "\n",
    "        ys = sdeint(self.sde, yInit, ts, bm=bm, dt=stepSDE, method=methodSDE)\n",
    "\n",
    "        return ys[...,:2] + self.sigmaX * rn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-03T10:32:21.024956Z",
     "start_time": "2022-10-03T10:32:21.012320Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1663048780559,
     "user": {
      "displayName": "上道 雅仁.",
      "userId": "02361249356017468398"
     },
     "user_tz": -540
    },
    "id": "GaGAhb_oCdyc",
    "outputId": "ba87dbdd-2d20-4d9b-d108-bfffe1f6f93e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[0.]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[4.]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[2.]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([1.], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[3.]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[6.]], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([5.], device='cuda:0', requires_grad=True), Parameter containing:\n",
      "tensor([[7.]], device='cuda:0', requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "model = SDE(0.0, [1,2,3], 4.0, [5,6,7])\n",
    "print(list(model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-03T10:32:21.058403Z",
     "start_time": "2022-10-03T10:32:21.028824Z"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1663048780560,
     "user": {
      "displayName": "上道 雅仁.",
      "userId": "02361249356017468398"
     },
     "user_tz": -540
    },
    "id": "ZiVN0QRhtepT"
   },
   "outputs": [],
   "source": [
    "def binnedSum(y0, x0, bins):\n",
    "    # out[i] = sum_j(y[j] | bins[i] <= x[j] < bins[i+1])\n",
    "\n",
    "    flg = torch.logical_and(torch.isfinite(x0), torch.isfinite(y0))\n",
    "\n",
    "    x = x0[flg]\n",
    "    y = y0[flg]\n",
    "\n",
    "    dbins = (bins[1:] - bins[:-1]).view(1,-1) / 1e3\n",
    "    #print(dbins)\n",
    "    \n",
    "    cond = torch.special.expit((x.view(-1,1) - bins[:-1].view(1, -1))/dbins) - torch.special.expit((x.view(-1,1) - bins[1:].view(1, -1))/dbins)\n",
    "    #print(cond)\n",
    "\n",
    "    #if x.requires_grad:\n",
    "    #    sumc = torch.sum(cond)\n",
    "    #    sumc.backward()\n",
    "\n",
    "    return torch.squeeze(y.view(1,-1) @ cond)\n",
    "\n",
    "def calc_velocity(xy):\n",
    "    return (xy[1:] - xy[:-1])/t_eval\n",
    "\n",
    "def calc_acceleration(v):\n",
    "    return (v[1:] - v[:-1])/t_eval\n",
    "\n",
    "def calc_v_histogram(vabs):\n",
    "    h = binnedSum(torch.ones_like(vabs), vabs, vbins)\n",
    "    #h = nn.functional.normalize(h, p=1, dim=0) / (vbins[1:] - vbins[:-1])\n",
    "\n",
    "    #if vabs.requires_grad:\n",
    "    #   sumh = torch.sum(h)\n",
    "    #   sumh.backward()\n",
    "\n",
    "    return nn.functional.normalize(h, p=1, dim=0) / (vbins[1:] - vbins[:-1])#h\n",
    "\n",
    "def calc_v_autocorrelation(v):\n",
    "    #print(v.size())\n",
    "    flg = torch.isfinite(v)\n",
    "    #print(torch.count_nonzero(~flg))\n",
    "    if torch.any(~flg):\n",
    "        v[~flg] = torch.zeros_like(v[~flg])\n",
    "        flg2 = torch.all(flg, dim=2)\n",
    "        Ncor = torch.count_nonzero(torch.logical_and(flg2.view(v.size()[0],1,v.size()[1]), flg2.view(1,v.size()[0],v.size()[1])), 2)\n",
    "    else:\n",
    "        Ncor = v.size()[1]\n",
    "    #print(Ncor)\n",
    "    v_cor = ((v[:,:,0] @ v[:,:,0].T) + (v[:,:,1] @ v[:,:,1].T)) / Ncor\n",
    "    \n",
    "    vac = torch.concat( tuple([torch.nanmean(torch.diag(v_cor, dt)).view(1) for idt, dt in enumerate(delaystep)]) )\n",
    "    return vac\n",
    "\n",
    "def calc_va4(v_normalized, vabs, a):\n",
    "    i_bins = vabs.div(vbinwidth, rounding_mode=\"floor\").to(torch.int32)\n",
    "    Nbins = np.int_(np.divmod(vmax, vbinwidth)[0])\n",
    "    flg_inrange = torch.logical_and(torch.logical_and(vabs>=vmin, i_bins<Nbins), torch.logical_and(torch.all(torch.isfinite(a), 2), torch.all(torch.isfinite(v_normalized), 2)))\n",
    "    j_dummy = torch.zeros_like(i_bins)\n",
    "    a_dummy = torch.ones_like(i_bins)\n",
    "\n",
    "    a_para = v_normalized[:,:,0] * a[:,:,0] + v_normalized[:,:,1] * a[:,:,1]\n",
    "    a_perp = v_normalized[:,:,0] * a[:,:,1] - v_normalized[:,:,1] * a[:,:,0]\n",
    "\n",
    "    inds_sparse = torch.concat((i_bins[flg_inrange].view(1,-1), j_dummy[flg_inrange].view(1,-1)), 0)\n",
    "    #print('inds', inds_sparse)\n",
    "\n",
    "    a_para_sum = torch.sparse_coo_tensor(inds_sparse, a_para[flg_inrange], size=[Nbins,1], dtype=float, device=device).to_dense()\n",
    "    a_perp_sum = torch.sparse_coo_tensor(inds_sparse, a_perp[flg_inrange], size=[Nbins,1], dtype=float, device=device).to_dense()\n",
    "\n",
    "    count_vabs = torch.sparse_coo_tensor(inds_sparse, a_dummy[flg_inrange], size=[Nbins,1], dtype=float, device=device).to_dense()\n",
    "    #print('count', count_vabs)\n",
    "\n",
    "    a_para_mean = a_para_sum/count_vabs #torch.maximum(count_vabs, torch.tensor([1.0]))\n",
    "    #print(a_para_mean)\n",
    "    a_perp_mean = a_perp_sum/count_vabs #torch.maximum(count_vabs, torch.tensor([1.0]))\n",
    "\n",
    "    d_a_para_mean = a_para[flg_inrange] - a_para_mean[:,0][i_bins[flg_inrange].to(torch.int64)]\n",
    "    d_a_perp_mean = a_perp[flg_inrange] - a_perp_mean[:,0][i_bins[flg_inrange].to(torch.int64)]\n",
    "    #print(a_para_var)\n",
    "    #print(a_perp_var)\n",
    "\n",
    "    flg_for_std = (count_vabs>=2)[:,0][i_bins[flg_inrange].to(torch.int64)]\n",
    "\n",
    "    d_a_para_mean2 = d_a_para_mean[flg_for_std]\n",
    "    d_a_perp_mean2 = d_a_perp_mean[flg_for_std]\n",
    "\n",
    "    inds_sparse2 = inds_sparse.T[flg_for_std].T\n",
    "\n",
    "    a_para_std = torch.sqrt(torch.sparse_coo_tensor(inds_sparse2, torch.square(d_a_para_mean2), size=[Nbins,1], dtype=float, device=device).to_dense() / (count_vabs-1))#torch.maximum(count_vabs-1, torch.tensor([1.0])))\n",
    "    a_perp_std = torch.sqrt(torch.sparse_coo_tensor(inds_sparse2, torch.square(d_a_perp_mean2), size=[Nbins,1], dtype=float, device=device).to_dense() / (count_vabs-1))#torch.maximum(count_vabs-1, torch.tensor([1.0])))\n",
    "\n",
    "    #print(a_para_std)\n",
    "    #print(a_perp_std)\n",
    "\n",
    "    #if vabs.requires_grad:\n",
    "        #a_para_var.register_hook(lambda grad: print('a_para_var grad', grad))\n",
    "        #a_perp_var.register_hook(lambda grad: print('a_perp_var grad', grad))\n",
    "\n",
    "    return a_para_mean, a_perp_mean, a_para_std, a_perp_std#, count_vabs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-03T10:32:21.206635Z",
     "start_time": "2022-10-03T10:32:21.087189Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8381,
     "status": "ok",
     "timestamp": 1663048788930,
     "user": {
      "displayName": "上道 雅仁.",
      "userId": "02361249356017468398"
     },
     "user_tz": -540
    },
    "id": "ZHtZpdgYO4bV",
    "outputId": "62c4f1d9-36df-46e8-cb3b-3d6dcdcb6c52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7.7382e-02, 1.9442e-01, 3.1161e-01, 3.9839e-01, 5.0349e-01, 5.6932e-01,\n",
      "        6.3120e-01, 7.1836e-01, 7.8103e-01, 8.0358e-01, 7.9743e-01, 7.4059e-01,\n",
      "        6.6378e-01, 5.5074e-01, 4.8309e-01, 3.6264e-01, 2.9296e-01, 2.4451e-01,\n",
      "        1.8147e-01, 1.4667e-01, 1.1110e-01, 8.5229e-02, 7.8882e-02, 6.4705e-02,\n",
      "        4.6304e-02, 4.0165e-02, 2.9394e-02, 2.3630e-02, 1.5841e-02, 1.0321e-02,\n",
      "        8.7670e-03, 6.7941e-03, 1.9412e-03, 4.2059e-03, 3.5588e-03, 3.5588e-03,\n",
      "        2.5882e-03, 1.9412e-03, 1.6176e-03, 1.6177e-03, 6.4706e-04, 3.2353e-04,\n",
      "        1.6176e-03, 0.0000e+00, 3.2353e-04, 6.4706e-04, 9.7059e-04, 0.0000e+00,\n",
      "        0.0000e+00, 6.4706e-04], device='cuda:0')\n",
      "tensor([1.4615, 1.2273, 1.1752, 1.1293, 1.0923, 1.0602, 1.0255, 0.9928, 0.9759,\n",
      "        0.9502, 0.9306, 0.9140, 0.8981, 0.8798, 0.8652, 0.8493, 0.8334, 0.8222,\n",
      "        0.8067, 0.7953, 0.7796, 0.7705, 0.7567, 0.7428, 0.7337, 0.7200, 0.7034,\n",
      "        0.6944, 0.6840, 0.6693, 0.6632, 0.6571, 0.6506, 0.6373, 0.6277, 0.6207,\n",
      "        0.6125, 0.5980, 0.5950, 0.5875, 0.5753, 0.5647, 0.5578, 0.5513, 0.5423,\n",
      "        0.5365, 0.5318, 0.5246, 0.5144, 0.5107], device='cuda:0')\n",
      "tensor([[-1.9393e-02, -2.2693e-02,  2.9426e-01,  2.9498e-01],\n",
      "        [-2.2598e-02, -1.7053e-03,  2.9900e-01,  3.1958e-01],\n",
      "        [-1.9371e-02, -1.6612e-02,  5.6726e-01,  4.4850e-01],\n",
      "        [ 3.0748e-02, -1.2093e-02,  3.5723e-01,  3.1023e-01],\n",
      "        [ 2.6655e-02, -1.6621e-02,  4.0142e-01,  3.6954e-01],\n",
      "        [ 4.1019e-02,  3.7665e-03,  3.7173e-01,  3.7385e-01],\n",
      "        [ 2.9419e-02,  5.2978e-03,  3.7960e-01,  3.5172e-01],\n",
      "        [ 1.5984e-02, -1.4418e-02,  3.7653e-01,  3.6976e-01],\n",
      "        [ 4.2992e-02, -9.1624e-03,  4.5007e-01,  3.7815e-01],\n",
      "        [-9.7018e-03, -1.6308e-02,  3.8955e-01,  3.3338e-01],\n",
      "        [-3.3102e-02, -1.5984e-03,  4.4881e-01,  3.6179e-01],\n",
      "        [-3.2280e-02,  8.3006e-03,  3.9669e-01,  3.4577e-01],\n",
      "        [-9.0745e-02, -1.4153e-04,  4.2685e-01,  3.6820e-01],\n",
      "        [-1.3679e-01, -3.7557e-03,  4.0134e-01,  3.6040e-01],\n",
      "        [-1.6891e-01, -3.9895e-03,  4.4452e-01,  3.5225e-01],\n",
      "        [-2.2292e-01,  1.1962e-02,  4.3924e-01,  3.6010e-01],\n",
      "        [-2.6433e-01,  2.0189e-02,  4.6096e-01,  3.5261e-01],\n",
      "        [-2.9307e-01, -1.2407e-02,  5.2289e-01,  4.2085e-01],\n",
      "        [-3.1284e-01,  5.2788e-04,  5.1778e-01,  3.6941e-01],\n",
      "        [-3.6083e-01, -1.9096e-02,  5.4413e-01,  3.8449e-01],\n",
      "        [-3.5241e-01,  1.9485e-02,  5.4234e-01,  3.7055e-01],\n",
      "        [-4.1316e-01, -3.6041e-02,  5.6399e-01,  4.3412e-01],\n",
      "        [-4.4222e-01,  1.6082e-02,  6.7227e-01,  4.1762e-01],\n",
      "        [-5.0193e-01, -2.9446e-02,  6.4030e-01,  4.0322e-01],\n",
      "        [-4.1263e-01,  2.2502e-02,  5.7535e-01,  3.3932e-01],\n",
      "        [-6.0397e-01,  3.4003e-04,  5.8788e-01,  3.4270e-01],\n",
      "        [-7.0563e-01, -8.2850e-03,  7.0002e-01,  3.7798e-01],\n",
      "        [-7.4207e-01,  2.4857e-02,  6.5806e-01,  3.9044e-01],\n",
      "        [-9.9758e-01, -2.1438e-02,  7.8587e-01,  3.9765e-01],\n",
      "        [-1.0413e+00, -3.4262e-02,  5.5983e-01,  3.3924e-01],\n",
      "        [-9.7411e-01, -8.4978e-02,  9.4732e-01,  4.4687e-01],\n",
      "        [-1.2507e+00,  4.0216e-02,  1.4376e+00,  3.9177e-01],\n",
      "        [-1.4889e+00,  1.9244e-01,  4.8581e-01,  2.8443e-01],\n",
      "        [-1.0797e+00,  1.2813e-01,  9.0146e-01,  2.8690e-01],\n",
      "        [-1.4049e+00, -1.0056e-03,  5.3312e-01,  3.7031e-01],\n",
      "        [-1.7116e+00,  1.3740e-01,  7.9739e-01,  5.6027e-01],\n",
      "        [-1.0145e+00, -4.2079e-02,  7.0944e-01,  3.0480e-01],\n",
      "        [-1.0234e+00,  2.5731e-01,  6.6910e-01,  6.3784e-01],\n",
      "        [-1.9097e+00,  1.7395e-01,  1.0935e+00,  2.2497e-01],\n",
      "        [-1.2552e+00,  7.2781e-02,  6.8792e-01,  4.4819e-01],\n",
      "        [-3.2986e+00, -3.4221e-01,         nan,         nan],\n",
      "        [-1.2520e+00, -1.0546e-01,         nan,         nan],\n",
      "        [-3.1170e+00,  9.3221e-02,  2.2980e+00,  7.8269e-01],\n",
      "        [        nan,         nan, -0.0000e+00, -0.0000e+00],\n",
      "        [-2.2959e+00, -7.2525e-02,         nan,         nan],\n",
      "        [-2.7187e+00,  2.1283e-01,  1.3674e+00,  2.6526e-01],\n",
      "        [-1.5748e+00, -2.0694e-02,  3.7296e-01,  4.1456e-01],\n",
      "        [        nan,         nan, -0.0000e+00, -0.0000e+00],\n",
      "        [        nan,         nan, -0.0000e+00, -0.0000e+00]], device='cuda:0',\n",
      "       dtype=torch.float64)\n",
      "tensor(5.5764, device='cuda:0')\n",
      "tensor([1.4615, 1.2273, 1.1752, 1.1293, 1.0923, 1.0602, 1.0255, 0.9928, 0.9759,\n",
      "        0.9502, 0.9306, 0.9140, 0.8981, 0.8798, 0.8652, 0.8493, 0.8334, 0.8222,\n",
      "        0.8067, 0.7953, 0.7796, 0.7705, 0.7567, 0.7428, 0.7337, 0.7200, 0.7034,\n",
      "        0.6944, 0.6840, 0.6693, 0.6632, 0.6571, 0.6506, 0.6373, 0.6277, 0.6207,\n",
      "        0.6125, 0.5980, 0.5950, 0.5875, 0.5753, 0.5647, 0.5578, 0.5513, 0.5423,\n",
      "        0.5365, 0.5318, 0.5246, 0.5144, 0.5107], device='cuda:0')\n",
      "tensor([60.3086,  0.3812, 22.5552,  6.6702], device='cuda:0',\n",
      "       dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "\n",
    "    x_csv = loadcsv(csv_prefix, 'x'+csv_surfix)\n",
    "    y_csv = loadcsv(csv_prefix, 'y'+csv_surfix)\n",
    "\n",
    "    xy_csv = torch.tensor(np.concatenate((np.expand_dims(x_csv, 2), np.expand_dims(y_csv, 2)), 2), dtype=torch.float, device=device)\n",
    "\n",
    "    v_csv = calc_velocity(xy_csv)\n",
    "    a_csv = calc_acceleration(v_csv)\n",
    "\n",
    "    vabs_csv = torch.norm(v_csv, dim=2)\n",
    "\n",
    "    v_normalized_csv = nn.functional.normalize(v_csv, dim=2)\n",
    "\n",
    "    hist_csv = calc_v_histogram(vabs_csv)\n",
    "    vac_csv = calc_v_autocorrelation(v_csv)\n",
    "    va4_csv = calc_va4(v_normalized_csv[:-1], vabs_csv[:-1], a_csv)\n",
    "    va4_csv = torch.concat(va4_csv, 1)\n",
    "\n",
    "    print(hist_csv)\n",
    "    print(vac_csv)\n",
    "    print(va4_csv)\n",
    "\n",
    "    hist_norm = torch.nansum(hist_csv**2)\n",
    "    print(hist_norm)\n",
    "\n",
    "    vac_norm = torch.abs(vac_csv)\n",
    "    print(vac_norm)\n",
    "\n",
    "    va4_norm = torch.nansum(va4_csv**2, dim=0)\n",
    "    print(va4_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-03T10:32:21.216138Z",
     "start_time": "2022-10-03T10:32:21.213202Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1663048788933,
     "user": {
      "displayName": "上道 雅仁.",
      "userId": "02361249356017468398"
     },
     "user_tz": -540
    },
    "id": "NxeNg8ZYLBYj",
    "outputId": "36363416-2cf8-4914-cbdc-6b5891e4768c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(xy_csv.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-03T10:32:21.237520Z",
     "start_time": "2022-10-03T10:32:21.221514Z"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1663048788935,
     "user": {
      "displayName": "上道 雅仁.",
      "userId": "02361249356017468398"
     },
     "user_tz": -540
    },
    "id": "9DckwdRcsdC9"
   },
   "outputs": [],
   "source": [
    "def compare_v_histogram(vabs):\n",
    "    h = calc_v_histogram(vabs)\n",
    "    dh = h - hist_csv\n",
    "    flg = torch.isfinite(dh)\n",
    "    hist_norm_ = torch.nansum(hist_csv[flg]**2)\n",
    "\n",
    "    dhsq = torch.square(dh[flg])\n",
    "    dhsumsq = torch.sum(dhsq)\n",
    "\n",
    "    out = dhsumsq / hist_norm_\n",
    "\n",
    "    #print('vhist', out)\n",
    "    #if vabs.requires_grad:\n",
    "        #h.register_hook(lambda grad: print('hist grad', grad))\n",
    "        #dh.register_hook(lambda grad: print('d hist grad', grad))\n",
    "        #dhsq.register_hook(lambda grad: print('d hist square grad', grad))\n",
    "        #dhsumsq.register_hook(lambda grad: print('d hist square sum grad', grad))\n",
    "\n",
    "        #out.backward()\n",
    "    #print(2*dh[flg]/hist_norm_)\n",
    "    return out\n",
    "\n",
    "def compare_v_autocorrelation(v):\n",
    "    vac = calc_v_autocorrelation(v)\n",
    "    #if v.requires_grad:\n",
    "      #vac.register_hook(lambda grad: print('vac grad', grad))\n",
    "    dvac = vac - vac_csv\n",
    "    flg = torch.isfinite(dvac)\n",
    "    vac_norm_ = torch.abs(vac_csv[flg])\n",
    "    return torch.mean(torch.abs(dvac[flg])/vac_norm_)\n",
    "\n",
    "def compare_acceleration(v_normalized, vabs, a):\n",
    "\n",
    "    a_para_mean, a_perp_mean, a_para_std, a_perp_std = calc_va4(v_normalized, vabs, a)\n",
    "    #print(a_para_mean - va4_csv[:,:1])\n",
    "\n",
    "    flg0 = torch.logical_and(torch.isfinite(a_para_mean), torch.isfinite(va4_csv[:,:1]))\n",
    "    flg1 = torch.logical_and(torch.isfinite(a_perp_mean), torch.isfinite(va4_csv[:,1:2]))\n",
    "    flg2 = torch.logical_and(torch.isfinite(a_para_std), torch.isfinite(va4_csv[:,2:3]))\n",
    "    flg3 = torch.logical_and(torch.isfinite(a_perp_std), torch.isfinite(va4_csv[:,3:4]))\n",
    "\n",
    "    #flg0 = torch.logical_and(count_vabs>=1, va4_csv[:,4:]>=1)\n",
    "    #flg1 = torch.logical_and(count_vabs>=1, va4_csv[:,4:]>=1)\n",
    "    #flg2 = torch.logical_and(count_vabs>=2, va4_csv[:,4:]>=2)\n",
    "    #flg3 = torch.logical_and(count_vabs>=2, va4_csv[:,4:]>=2)\n",
    "\n",
    "    a_para_mean2 = torch.where(flg0, a_para_mean, torch.tensor(0.0, device=device))\n",
    "    a_perp_mean2 = torch.where(flg1, a_perp_mean, torch.tensor(0.0, device=device))\n",
    "    a_para_std2 = torch.where(flg2, a_para_std, torch.tensor(0.0, device=device))\n",
    "    a_perp_std2 = torch.where(flg3, a_perp_std, torch.tensor(0.0, device=device))\n",
    "\n",
    "    d_para_mean = a_para_mean2 - torch.where(flg0, va4_csv[:,:1], torch.tensor(0.0, device=device))\n",
    "    d_perp_mean = a_perp_mean2 - torch.where(flg1, va4_csv[:,1:2], torch.tensor(0.0, device=device))\n",
    "    d_para_std = a_para_std2 - torch.where(flg2, va4_csv[:,2:3], torch.tensor(0.0, device=device))\n",
    "    d_perp_std = a_perp_std2 - torch.where(flg3, va4_csv[:,3:4], torch.tensor(0.0, device=device))\n",
    "\n",
    "    a_para_mean_norm = torch.sum(torch.square(va4_csv[:,:1][flg0]))\n",
    "    a_perp_mean_norm = torch.sum(torch.square(va4_csv[:,1:2][flg1]))\n",
    "    a_para_std_norm = torch.sum(torch.square(va4_csv[:,2:3][flg2]))\n",
    "    a_perp_std_norm = torch.sum(torch.square(va4_csv[:,3:4][flg3]))\n",
    "\n",
    "    dif_para_mean = torch.sum(torch.square(d_para_mean[flg0])) / a_para_mean_norm\n",
    "    dif_perp_mean = torch.sum(torch.square(d_perp_mean[flg1])) / a_perp_mean_norm\n",
    "    dif_para_std = torch.sum(torch.square(d_para_std[flg2])) / a_para_std_norm\n",
    "    dif_perp_std = torch.sum(torch.square(d_perp_std[flg3])) / a_perp_std_norm\n",
    "\n",
    "    #if vabs.requires_grad:\n",
    "        #a_para_mean.register_hook(lambda grad: print('a_para_mean grad', grad))\n",
    "        #a_perp_mean.register_hook(lambda grad: print('a_perp_mean grad', grad))\n",
    "        #a_para_std.register_hook(lambda grad: print('a_para_std grad', grad))\n",
    "        #a_perp_std.register_hook(lambda grad: print('a_perp_std grad', grad))\n",
    "\n",
    "        #dif_para_std.backward()\n",
    "        #d_para_std[flg2][0].backward()\n",
    "\n",
    "    return dif_para_mean, dif_perp_mean, dif_para_std, dif_perp_std\n",
    "\n",
    "def eval_function(xy):\n",
    "\n",
    "    v = calc_velocity(xy)\n",
    "    a = calc_acceleration(v)\n",
    "\n",
    "    vabs = torch.norm(v, dim=2)\n",
    "\n",
    "    v_normalized = nn.functional.normalize(v, dim=2)\n",
    "    #j_vals = torch.zeros([5])\n",
    "\n",
    "    j_hist = compare_v_histogram(vabs)\n",
    "    j_vac = compare_v_autocorrelation(v)\n",
    "    j_av0, j_av1, j_av2, j_av3 = compare_acceleration(v_normalized[:-1], vabs[:-1], a)\n",
    "\n",
    "    j_vals = torch.concat((j_hist.view(1), j_vac.view(1),\n",
    "                           j_av0.view(1), j_av2.view(1), j_av3.view(1)))\n",
    "    # warning: if a member of concat has NaN grad, others also show NaN grad even if its grad was finite before concat.\n",
    "\n",
    "    #print('jhist', j_hist)\n",
    "\n",
    "    #if xy.requires_grad:\n",
    "        #sumv = torch.sum(v)\n",
    "        #sumv.backward()\n",
    "        #j_vals[0].backward()\n",
    "        #j_av2.backward()\n",
    "\n",
    "    return j_vals\n",
    "\n",
    "def treatOuts(x):\n",
    "    return torch.arctan(6*(x**3))*2/np.pi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-03T14:59:27.071454Z",
     "start_time": "2022-10-03T14:59:27.060941Z"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1663048788938,
     "user": {
      "displayName": "上道 雅仁.",
      "userId": "02361249356017468398"
     },
     "user_tz": -540
    },
    "id": "G_4QjrFjOmIS"
   },
   "outputs": [],
   "source": [
    "class customLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 初期化処理\n",
    "        # self.param = ... \n",
    "\n",
    "    def forward(self, outputs):\n",
    "        '''\n",
    "        outputs: 予測結果(ネットワークの出力)\n",
    "         targets: 正解\n",
    "        '''\n",
    "        # 損失の計算\n",
    "\n",
    "        J = eval_function(outputs)\n",
    "        print(J)\n",
    "\n",
    "        J2 = J * torch.tensor([1.0, 100.0, 1.0, 1.0, 1.0], device=device)\n",
    "\n",
    "        #J0.register_hook(lambda grad: print('J_hist back', grad))\n",
    "        #J1.register_hook(lambda grad: print('J_vac back', grad))\n",
    "        #J2.register_hook(lambda grad: print('J_va_para_mean back', grad))\n",
    "        #J3.register_hook(lambda grad: print('J_va_para_sd back', grad))\n",
    "        #J4.register_hook(lambda grad: print('J_va_perp_sd back', grad))\n",
    "\n",
    "        return torch.sum(J2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-03T14:59:27.133757Z",
     "start_time": "2022-10-03T14:59:27.076556Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2695,
     "status": "ok",
     "timestamp": 1663048791609,
     "user": {
      "displayName": "上道 雅仁.",
      "userId": "02361249356017468398"
     },
     "user_tz": -540
    },
    "id": "1fhAxWwctN2c",
    "outputId": "6cdbac9b-6219-46b0-989d-03c96cd6a033"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 4.5358e-32, 8.5929e-32],\n",
      "       device='cuda:0', dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "J_csv = eval_function(xy_csv)\n",
    "\n",
    "print(J_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-03T14:59:27.149525Z",
     "start_time": "2022-10-03T14:59:27.139084Z"
    }
   },
   "outputs": [],
   "source": [
    "def extractParams(model):\n",
    "    alpha = model.sde.alpha[0,0].cpu().detach().numpy()\n",
    "    beta0 = model.sde.beta.layer1.bias[0].cpu().detach().numpy()\n",
    "    beta1 = model.sde.beta.layer1.weight[0,0].cpu().detach().numpy()\n",
    "    beta2 = model.sde.beta.layer3.weight[0,0].cpu().detach().numpy()\n",
    "    gamma = model.sde.gamma[0,0].cpu().detach().numpy()\n",
    "    sigma0 = model.sde.sigma.layer1.bias[0].cpu().detach().numpy()\n",
    "    sigma1 = model.sde.sigma.layer1.weight[0,0].cpu().detach().numpy()\n",
    "    sigma2 = model.sde.sigma.layer3.weight[0,0].cpu().detach().numpy()\n",
    "    sigmaX = model.sigmaX[0,0,0].cpu().detach().numpy()\n",
    "\n",
    "    return {'alpha': alpha, \n",
    "            'beta0': beta0,\n",
    "            'beta1': beta1, \n",
    "            'beta2': beta2,\n",
    "            'gamma': gamma, \n",
    "            'sigma0': sigma0,\n",
    "            'sigma1': sigma1,\n",
    "            'sigma2': sigma2, \n",
    "            'sigmaX': sigmaX}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-03T14:59:27.161839Z",
     "start_time": "2022-10-03T14:59:27.153625Z"
    },
    "executionInfo": {
     "elapsed": 245,
     "status": "ok",
     "timestamp": 1663048791847,
     "user": {
      "displayName": "上道 雅仁.",
      "userId": "02361249356017468398"
     },
     "user_tz": -540
    },
    "id": "Lp0xexKv5irE"
   },
   "outputs": [],
   "source": [
    "def printparams(model):\n",
    "    alpha = model.sde.alpha[0,0].cpu().detach().numpy()\n",
    "    beta0 = model.sde.beta.layer1.bias[0].cpu().detach().numpy()\n",
    "    beta1 = model.sde.beta.layer1.weight[0,0].cpu().detach().numpy()\n",
    "    beta2 = model.sde.beta.layer3.weight[0,0].cpu().detach().numpy()\n",
    "    gamma = model.sde.gamma[0,0].cpu().detach().numpy()\n",
    "    sigma0 = model.sde.sigma.layer1.bias[0].cpu().detach().numpy()\n",
    "    sigma1 = model.sde.sigma.layer1.weight[0,0].cpu().detach().numpy()\n",
    "    sigma2 = model.sde.sigma.layer3.weight[0,0].cpu().detach().numpy()\n",
    "    sigmaX = model.sigmaX[0,0,0].cpu().detach().numpy()\n",
    "\n",
    "    print('alpha: {}, beta0: {}, beta1: {}, beta2: {}, '.format(alpha, beta0, beta1, beta2))\n",
    "    print('gamma: {}, sigma0: {}, sigma1: {}, sigma2: {}, sigmaX: {}'.format(gamma, sigma0, sigma1, sigma2, sigmaX))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T16:23:24.474022Z",
     "start_time": "2022-10-03T16:08:58.301833Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9BGtMCDyJdch",
    "outputId": "bacb5294-f7f2-43a7-c118-8aef67e25890",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.07410000264644623, beta0: 0.11599999666213989, beta1: 0.0, beta2: 0.0, \n",
      "gamma: 0.0640999972820282, sigma0: 0.26600000262260437, sigma1: 0.0, sigma2: 0.0, sigmaX: 0.1550000011920929\n",
      "forward done\n",
      "tensor([0.0230, 0.0937, 0.3319, 0.5554, 0.3204], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.2962]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-910.3673]], device='cuda:0')\n",
      "sigma0 grad tensor([-670.5792], device='cuda:0')\n",
      "sigma1 grad tensor([[-684.6074]], device='cuda:0')\n",
      "gamma grad tensor([[3847.4697]], device='cuda:0')\n",
      "alpha grad tensor([[-7791.7129]], device='cuda:0')\n",
      "beta2 grad tensor([[9597.1201]], device='cuda:0')\n",
      "beta0 grad tensor([3830.7024], device='cuda:0')\n",
      "beta1 grad tensor([[5676.2412]], device='cuda:0')\n",
      "Epoch 0 | Loss: 10.6017\n",
      "alpha: 0.07417792081832886, beta0: 0.11596169322729111, beta1: -5.6762411986710504e-05, beta2: -9.597119787940755e-05, \n",
      "gamma: 0.06406152248382568, sigma0: 0.2660067081451416, sigma1: 6.846073574706679e-06, sigma2: 9.103672709898092e-06, sigmaX: 0.15500003099441528\n",
      "forward done\n",
      "tensor([0.0284, 0.1668, 0.3065, 0.6096, 0.3647], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.2278]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-686.7021]], device='cuda:0')\n",
      "sigma0 grad tensor([-633.1934], device='cuda:0')\n",
      "sigma1 grad tensor([[-577.7257]], device='cuda:0')\n",
      "gamma grad tensor([[3745.7434]], device='cuda:0')\n",
      "alpha grad tensor([[-7479.1543]], device='cuda:0')\n",
      "beta2 grad tensor([[8742.0488]], device='cuda:0')\n",
      "beta0 grad tensor([3647.3545], device='cuda:0')\n",
      "beta1 grad tensor([[5266.7778]], device='cuda:0')\n",
      "Epoch 1 | Loss: 17.9883\n",
      "alpha: 0.07431504875421524, beta0: 0.11589457094669342, beta1: -0.0001548401196487248, beta2: -0.00026016865740530193, \n",
      "gamma: 0.06399328261613846, sigma0: 0.2660183906555176, sigma1: 1.81001905730227e-05, sigma2: 2.325363311683759e-05, sigmaX: 0.15500007569789886\n",
      "forward done\n",
      "tensor([0.0098, 0.0650, 0.3992, 0.6096, 0.3172], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-4.5924]]], device='cuda:0')\n",
      "sigma2 grad tensor([[1098.4241]], device='cuda:0')\n",
      "sigma0 grad tensor([791.1346], device='cuda:0')\n",
      "sigma1 grad tensor([[823.8465]], device='cuda:0')\n",
      "gamma grad tensor([[-5221.1206]], device='cuda:0')\n",
      "alpha grad tensor([[10260.0391]], device='cuda:0')\n",
      "beta2 grad tensor([[-13319.6689]], device='cuda:0')\n",
      "beta0 grad tensor([-4927.2119], device='cuda:0')\n",
      "beta1 grad tensor([[-7623.6528]], device='cuda:0')\n",
      "Epoch 2 | Loss: 7.8348\n",
      "alpha: 0.07432214915752411, beta0: 0.11589014530181885, beta1: -0.00015706576232332736, beta2: -0.0002583299356047064, \n",
      "gamma: 0.06399090588092804, sigma0: 0.2660198509693146, sigma1: 1.8865019228542224e-05, sigma2: 2.3589362172060646e-05, sigmaX: 0.15500015020370483\n",
      "forward done\n",
      "tensor([0.0173, 0.0727, 0.4519, 0.5361, 0.3015], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.1639]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-856.9037]], device='cuda:0')\n",
      "sigma0 grad tensor([-712.7517], device='cuda:0')\n",
      "sigma1 grad tensor([[-684.2612]], device='cuda:0')\n",
      "gamma grad tensor([[4245.5513]], device='cuda:0')\n",
      "alpha grad tensor([[-8522.7285]], device='cuda:0')\n",
      "beta2 grad tensor([[10340.6631]], device='cuda:0')\n",
      "beta0 grad tensor([4167.2520], device='cuda:0')\n",
      "beta1 grad tensor([[6155.9897]], device='cuda:0')\n",
      "Epoch 3 | Loss: 8.5782\n",
      "alpha: 0.07441305369138718, beta0: 0.11584493517875671, beta1: -0.00022040617477614433, beta2: -0.000360265577910468, \n",
      "gamma: 0.06394654512405396, sigma0: 0.26602813601493835, sigma1: 2.6319494281779043e-05, sigma2: 3.242698221583851e-05, sigmaX: 0.155000239610672\n",
      "forward done\n",
      "tensor([0.0193, 0.0318, 0.4188, 0.5779, 0.3152], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.0111]]], device='cuda:0')\n",
      "sigma2 grad tensor([[534.7542]], device='cuda:0')\n",
      "sigma0 grad tensor([373.5583], device='cuda:0')\n",
      "sigma1 grad tensor([[395.8205]], device='cuda:0')\n",
      "gamma grad tensor([[-2710.3142]], device='cuda:0')\n",
      "alpha grad tensor([[5300.4883]], device='cuda:0')\n",
      "beta2 grad tensor([[-6930.2427]], device='cuda:0')\n",
      "beta0 grad tensor([-2493.3132], device='cuda:0')\n",
      "beta1 grad tensor([[-3891.6223]], device='cuda:0')\n",
      "Epoch 4 | Loss: 4.5122\n",
      "alpha: 0.07443277537822723, beta0: 0.11583369970321655, beta1: -0.00023216228873934597, beta2: -0.0003725116839632392, \n",
      "gamma: 0.06393816322088242, sigma0: 0.26603102684020996, sigma1: 2.832486825354863e-05, sigma2: 3.4149536077165976e-05, sigmaX: 0.15500032901763916\n",
      "forward done\n",
      "tensor([0.0298, 0.0596, 0.2267, 0.6317, 0.3465], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.0772]]], device='cuda:0')\n",
      "sigma2 grad tensor([[470.1453]], device='cuda:0')\n",
      "sigma0 grad tensor([332.4818], device='cuda:0')\n",
      "sigma1 grad tensor([[351.2264]], device='cuda:0')\n",
      "gamma grad tensor([[-2767.0867]], device='cuda:0')\n",
      "alpha grad tensor([[5268.7192]], device='cuda:0')\n",
      "beta2 grad tensor([[-6542.9990]], device='cuda:0')\n",
      "beta0 grad tensor([-2419.1685], device='cuda:0')\n",
      "beta1 grad tensor([[-3745.5891]], device='cuda:0')\n",
      "Epoch 5 | Loss: 7.1978\n",
      "alpha: 0.07439586520195007, beta0: 0.11584890633821487, beta1: -0.0002041112893493846, beta2: -0.0003168785769958049, \n",
      "gamma: 0.06395912915468216, sigma0: 0.2660300135612488, sigma1: 2.641690480231773e-05, sigma2: 3.082612602156587e-05, sigmaX: 0.15500041842460632\n",
      "forward done\n",
      "tensor([0.0279, 0.0640, 0.2434, 0.6018, 0.3185], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.7652]]], device='cuda:0')\n",
      "sigma2 grad tensor([[234.8677]], device='cuda:0')\n",
      "sigma0 grad tensor([145.3504], device='cuda:0')\n",
      "sigma1 grad tensor([[165.6735]], device='cuda:0')\n",
      "gamma grad tensor([[-1866.0146]], device='cuda:0')\n",
      "alpha grad tensor([[3404.9954]], device='cuda:0')\n",
      "beta2 grad tensor([[-4110.1250]], device='cuda:0')\n",
      "beta0 grad tensor([-1465.1991], device='cuda:0')\n",
      "beta1 grad tensor([[-2304.4663]], device='cuda:0')\n",
      "Epoch 6 | Loss: 7.5952\n",
      "alpha: 0.07433228939771652, beta0: 0.1158757209777832, beta1: -0.0001586258294992149, beta2: -0.00023127083841245621, \n",
      "gamma: 0.06399456411600113, sigma0: 0.2660277485847473, sigma1: 2.3233798856381327e-05, sigma2: 2.581872104201466e-05, sigmaX: 0.1550005078315735\n",
      "forward done\n",
      "tensor([0.0152, 0.0873, 0.1938, 0.6480, 0.3601], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.3657]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-739.2905]], device='cuda:0')\n",
      "sigma0 grad tensor([-638.2509], device='cuda:0')\n",
      "sigma1 grad tensor([[-619.7505]], device='cuda:0')\n",
      "gamma grad tensor([[4025.3857]], device='cuda:0')\n",
      "alpha grad tensor([[-7980.9595]], device='cuda:0')\n",
      "beta2 grad tensor([[9306.9941]], device='cuda:0')\n",
      "beta0 grad tensor([3857.9612], device='cuda:0')\n",
      "beta1 grad tensor([[5652.6250]], device='cuda:0')\n",
      "Epoch 7 | Loss: 9.9440\n",
      "alpha: 0.07436123490333557, beta0: 0.11585859209299088, beta1: -0.00017876370111480355, beta2: -0.0002558545966167003, \n",
      "gamma: 0.06398265808820724, sigma0: 0.26603230834007263, sigma1: 2.688481799850706e-05, sigma2: 2.9205701139289886e-05, sigmaX: 0.15500059723854065\n",
      "forward done\n",
      "tensor([0.0273, 0.2394, 0.2739, 0.5887, 0.3540], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-3.3147]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-593.6602]], device='cuda:0')\n",
      "sigma0 grad tensor([-579.9854], device='cuda:0')\n",
      "sigma1 grad tensor([[-515.0084]], device='cuda:0')\n",
      "gamma grad tensor([[3287.3630]], device='cuda:0')\n",
      "alpha grad tensor([[-6685.4731]], device='cuda:0')\n",
      "beta2 grad tensor([[7357.0044]], device='cuda:0')\n",
      "beta0 grad tensor([3303.4663], device='cuda:0')\n",
      "beta1 grad tensor([[4630.4082]], device='cuda:0')\n",
      "Epoch 8 | Loss: 25.1853\n",
      "alpha: 0.07445124536752701, beta0: 0.11581185460090637, beta1: -0.00024117808789014816, beta2: -0.00034909165697172284, \n",
      "gamma: 0.06394025683403015, sigma0: 0.26604175567626953, sigma1: 3.495571581879631e-05, sigma2: 3.785188891924918e-05, sigmaX: 0.155000701546669\n",
      "forward done\n",
      "tensor([0.0163, 0.1411, 0.2019, 0.6797, 0.3871], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.6866]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigma2 grad tensor([[-742.4192]], device='cuda:0')\n",
      "sigma0 grad tensor([-662.7762], device='cuda:0')\n",
      "sigma1 grad tensor([[-633.6287]], device='cuda:0')\n",
      "gamma grad tensor([[3597.7993]], device='cuda:0')\n",
      "alpha grad tensor([[-7407.8145]], device='cuda:0')\n",
      "beta2 grad tensor([[8494.1064]], device='cuda:0')\n",
      "beta0 grad tensor([3699.6809], device='cuda:0')\n",
      "beta1 grad tensor([[5293.0078]], device='cuda:0')\n",
      "Epoch 9 | Loss: 15.3902\n",
      "alpha: 0.07459733635187149, beta0: 0.11573746800422668, beta1: -0.0003440396685618907, beta2: -0.0005086223827674985, \n",
      "gamma: 0.06387035548686981, sigma0: 0.2660559415817261, sigma1: 4.774872286361642e-05, sigma2: 5.2193030569469556e-05, sigmaX: 0.15500080585479736\n",
      "forward done\n",
      "tensor([0.0192, 0.1033, 0.4250, 0.5705, 0.3147], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.1367]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-789.1835]], device='cuda:0')\n",
      "sigma0 grad tensor([-713.9178], device='cuda:0')\n",
      "sigma1 grad tensor([[-668.9185]], device='cuda:0')\n",
      "gamma grad tensor([[4182.8105]], device='cuda:0')\n",
      "alpha grad tensor([[-8468.3301]], device='cuda:0')\n",
      "beta2 grad tensor([[10229.5049]], device='cuda:0')\n",
      "beta0 grad tensor([4167.7793], device='cuda:0')\n",
      "beta1 grad tensor([[6146.6519]], device='cuda:0')\n",
      "Epoch 10 | Loss: 11.6575\n",
      "alpha: 0.07479888945817947, beta0: 0.11563628166913986, beta1: -0.0004877954488620162, beta2: -0.0007385420030914247, \n",
      "gamma: 0.06377261132001877, sigma0: 0.26607444882392883, sigma1: 6.467231287388131e-05, sigma2: 7.155777711886913e-05, sigmaX: 0.15500091016292572\n",
      "forward done\n",
      "tensor([0.0188, 0.0529, 0.2619, 0.5847, 0.3018], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.7584]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-929.8476]], device='cuda:0')\n",
      "sigma0 grad tensor([-740.5148], device='cuda:0')\n",
      "sigma1 grad tensor([[-730.4163]], device='cuda:0')\n",
      "gamma grad tensor([[4428.1021]], device='cuda:0')\n",
      "alpha grad tensor([[-8937.3242]], device='cuda:0')\n",
      "beta2 grad tensor([[11441.2422]], device='cuda:0')\n",
      "beta0 grad tensor([4405.1001], device='cuda:0')\n",
      "beta1 grad tensor([[6669.9570]], device='cuda:0')\n",
      "Epoch 11 | Loss: 6.4547\n",
      "alpha: 0.0750495046377182, beta0: 0.11551128327846527, beta1: -0.0006694996263831854, beta2: -0.0010368900839239359, \n",
      "gamma: 0.06365013122558594, sigma0: 0.26609665155410767, sigma1: 8.551534847356379e-05, sigma2: 9.634805610403419e-05, sigmaX: 0.15500101447105408\n",
      "forward done\n",
      "tensor([0.0406, 0.4347, 0.3045, 0.5806, 0.3230], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.7277]]], device='cuda:0')\n",
      "sigma2 grad tensor([[2094.5496]], device='cuda:0')\n",
      "sigma0 grad tensor([1311.2131], device='cuda:0')\n",
      "sigma1 grad tensor([[1535.9030]], device='cuda:0')\n",
      "gamma grad tensor([[-9122.7363]], device='cuda:0')\n",
      "alpha grad tensor([[17826.6094]], device='cuda:0')\n",
      "beta2 grad tensor([[-27240.0820]], device='cuda:0')\n",
      "beta0 grad tensor([-8578.9404], device='cuda:0')\n",
      "beta1 grad tensor([[-14571.1006]], device='cuda:0')\n",
      "Epoch 12 | Loss: 44.7217\n",
      "alpha: 0.07507172971963882, beta0: 0.11549707502126694, beta1: -0.0006691519520245492, beta2: -0.0010031677084043622, \n",
      "gamma: 0.06364337354898453, sigma0: 0.26610130071640015, sigma1: 8.683074702275917e-05, sigma2: 9.523478365736082e-05, sigmaX: 0.15500110387802124\n",
      "forward done\n",
      "tensor([0.0156, 0.2597, 0.9984, 0.2784, 0.2287], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[1.8625]]], device='cuda:0')\n",
      "sigma2 grad tensor([[1807.9248]], device='cuda:0')\n",
      "sigma0 grad tensor([1133.9792], device='cuda:0')\n",
      "sigma1 grad tensor([[1263.5221]], device='cuda:0')\n",
      "gamma grad tensor([[-7524.0444]], device='cuda:0')\n",
      "alpha grad tensor([[14797.0859]], device='cuda:0')\n",
      "beta2 grad tensor([[-22133.0918]], device='cuda:0')\n",
      "beta0 grad tensor([-7171.9526], device='cuda:0')\n",
      "beta1 grad tensor([[-11779.0400]], device='cuda:0')\n",
      "Epoch 13 | Loss: 27.4938\n",
      "alpha: 0.07494153827428818, beta0: 0.11555742472410202, beta1: -0.0005510834162123501, beta2: -0.0007548589492216706, \n",
      "gamma: 0.0637132078409195, sigma0: 0.2660936713218689, sigma1: 7.524784450652078e-05, sigma2: 7.626491424161941e-05, sigmaX: 0.15500116348266602\n",
      "forward done\n",
      "tensor([0.0221, 0.1976, 0.1071, 0.6838, 0.4053], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.2049]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-516.3399]], device='cuda:0')\n",
      "sigma0 grad tensor([-645.8096], device='cuda:0')\n",
      "sigma1 grad tensor([[-536.4742]], device='cuda:0')\n",
      "gamma grad tensor([[3858.7664]], device='cuda:0')\n",
      "alpha grad tensor([[-7825.4478]], device='cuda:0')\n",
      "beta2 grad tensor([[8446.3555]], device='cuda:0')\n",
      "beta0 grad tensor([3855.7207], device='cuda:0')\n",
      "beta1 grad tensor([[5400.7783]], device='cuda:0')\n",
      "Epoch 14 | Loss: 20.9751\n",
      "alpha: 0.07491564005613327, beta0: 0.115567147731781, beta1: -0.0005106363678351045, beta2: -0.0006406754837371409, \n",
      "gamma: 0.06373048573732376, sigma0: 0.26609402894973755, sigma1: 7.134626503102481e-05, sigma2: 6.62524180370383e-05, sigmaX: 0.1550012230873108\n",
      "forward done\n",
      "tensor([0.0209, 0.0855, 0.4460, 0.5109, 0.2161], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-4.6827]]], device='cuda:0')\n",
      "sigma2 grad tensor([[1592.3174]], device='cuda:0')\n",
      "sigma0 grad tensor([885.1042], device='cuda:0')\n",
      "sigma1 grad tensor([[1031.1409]], device='cuda:0')\n",
      "gamma grad tensor([[-6529.1094]], device='cuda:0')\n",
      "alpha grad tensor([[12559.8613]], device='cuda:0')\n",
      "beta2 grad tensor([[-19253.6738]], device='cuda:0')\n",
      "beta0 grad tensor([-5960.7744], device='cuda:0')\n",
      "beta1 grad tensor([[-10019.0732]], device='cuda:0')\n",
      "Epoch 15 | Loss: 9.7420\n",
      "alpha: 0.07476932555437088, beta0: 0.11563453078269958, beta1: -0.00037808800698257983, beta2: -0.0003567919775377959, \n",
      "gamma: 0.0638096034526825, sigma0: 0.2660854756832123, sigma1: 5.791359581053257e-05, sigma2: 4.2319246858824044e-05, sigmaX: 0.15500131249427795\n",
      "forward done\n",
      "tensor([0.0359, 0.2157, 0.3671, 0.6143, 0.4509], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.4924]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-833.5891]], device='cuda:0')\n",
      "sigma0 grad tensor([-617.0043], device='cuda:0')\n",
      "sigma1 grad tensor([[-633.7972]], device='cuda:0')\n",
      "gamma grad tensor([[3466.0046]], device='cuda:0')\n",
      "alpha grad tensor([[-7076.2363]], device='cuda:0')\n",
      "beta2 grad tensor([[8966.3213]], device='cuda:0')\n",
      "beta0 grad tensor([3506.9009], device='cuda:0')\n",
      "beta1 grad tensor([[5256.0874]], device='cuda:0')\n",
      "Epoch 16 | Loss: 23.0355\n",
      "alpha: 0.07472303509712219, beta0: 0.1156533733010292, beta1: -0.00032461018417961895, beta2: -0.0002193483815062791, \n",
      "gamma: 0.06383823603391647, sigma0: 0.26608479022979736, sigma1: 5.350543142412789e-05, sigma2: 3.1508599931839854e-05, sigmaX: 0.1550014168024063\n",
      "forward done\n",
      "tensor([0.0127, 0.0721, 0.2529, 0.6283, 0.3855], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.2095]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-781.8893]], device='cuda:0')\n",
      "sigma0 grad tensor([-715.1891], device='cuda:0')\n",
      "sigma1 grad tensor([[-664.7388]], device='cuda:0')\n",
      "gamma grad tensor([[4458.0952]], device='cuda:0')\n",
      "alpha grad tensor([[-8868.2930]], device='cuda:0')\n",
      "beta2 grad tensor([[10163.8975]], device='cuda:0')\n",
      "beta0 grad tensor([4301.2617], device='cuda:0')\n",
      "beta1 grad tensor([[6233.8066]], device='cuda:0')\n",
      "Epoch 17 | Loss: 8.4858\n",
      "alpha: 0.07477468252182007, beta0: 0.11562543362379074, beta1: -0.0003441660082899034, beta2: -0.00021103247127030045, \n",
      "gamma: 0.06381656229496002, sigma0: 0.26609140634536743, sigma1: 5.662628973368555e-05, sigma2: 3.0678977054776624e-05, sigmaX: 0.15500152111053467\n",
      "forward done\n",
      "tensor([0.0107, 0.1020, 0.4828, 0.4877, 0.3092], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-4.0296]]], device='cuda:0')\n",
      "sigma2 grad tensor([[1211.5968]], device='cuda:0')\n",
      "sigma0 grad tensor([821.5147], device='cuda:0')\n",
      "sigma1 grad tensor([[871.0477]], device='cuda:0')\n",
      "gamma grad tensor([[-5692.2178]], device='cuda:0')\n",
      "alpha grad tensor([[11106.9922]], device='cuda:0')\n",
      "beta2 grad tensor([[-15700.8691]], device='cuda:0')\n",
      "beta0 grad tensor([-5297.3511], device='cuda:0')\n",
      "beta1 grad tensor([[-8520.6094]], device='cuda:0')\n",
      "Epoch 18 | Loss: 11.4881\n",
      "alpha: 0.07470493018627167, beta0: 0.1156560555100441, beta1: -0.00027460456476546824, beta2: -4.737105700769462e-05, \n",
      "gamma: 0.06385614722967148, sigma0: 0.26608848571777344, sigma1: 5.0412498239893466e-05, sigma2: 1.7899310478242114e-05, sigmaX: 0.15500164031982422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0108, 0.0836, 0.6779, 0.5066, 0.2038], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.0113]]], device='cuda:0')\n",
      "sigma2 grad tensor([[1284.3613]], device='cuda:0')\n",
      "sigma0 grad tensor([761.4216], device='cuda:0')\n",
      "sigma1 grad tensor([[835.0756]], device='cuda:0')\n",
      "gamma grad tensor([[-5263.0034]], device='cuda:0')\n",
      "alpha grad tensor([[10279.4756]], device='cuda:0')\n",
      "beta2 grad tensor([[-14767.3896]], device='cuda:0')\n",
      "beta0 grad tensor([-4891.5674], device='cuda:0')\n",
      "beta1 grad tensor([[-7842.2544]], device='cuda:0')\n",
      "Epoch 19 | Loss: 9.7627\n",
      "alpha: 0.07454633712768555, beta0: 0.11572946608066559, beta1: -0.00014053286577109247, beta2: 0.00023123197024688125, \n",
      "gamma: 0.06394044309854507, sigma0: 0.26607853174209595, sigma1: 3.7090707337483764e-05, sigma2: -5.168035386304837e-06, sigmaX: 0.15500175952911377\n",
      "forward done\n",
      "tensor([0.0367, 0.1854, 0.4705, 0.5990, 0.2965], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.4647]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-684.5419]], device='cuda:0')\n",
      "sigma0 grad tensor([-594.4012], device='cuda:0')\n",
      "sigma1 grad tensor([[-545.4388]], device='cuda:0')\n",
      "gamma grad tensor([[3645.0115]], device='cuda:0')\n",
      "alpha grad tensor([[-7267.1465]], device='cuda:0')\n",
      "beta2 grad tensor([[8468.3379]], device='cuda:0')\n",
      "beta0 grad tensor([3521.4807], device='cuda:0')\n",
      "beta1 grad tensor([[5084.2808]], device='cuda:0')\n",
      "Epoch 20 | Loss: 19.9422\n",
      "alpha: 0.07449213415384293, beta0: 0.11575298011302948, beta1: -8.411831367993727e-05, beta2: 0.0003694310144055635, \n",
      "gamma: 0.06397143006324768, sigma0: 0.2660765051841736, sigma1: 3.188766277162358e-05, sigma2: -1.6776493794168346e-05, sigmaX: 0.15500187873840332\n",
      "forward done\n",
      "tensor([0.0279, 0.2271, 0.2578, 0.6707, 0.3690], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.2978]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-571.9031]], device='cuda:0')\n",
      "sigma0 grad tensor([-557.6426], device='cuda:0')\n",
      "sigma1 grad tensor([[-491.3421]], device='cuda:0')\n",
      "gamma grad tensor([[3169.0007]], device='cuda:0')\n",
      "alpha grad tensor([[-6448.9136]], device='cuda:0')\n",
      "beta2 grad tensor([[7112.0015]], device='cuda:0')\n",
      "beta0 grad tensor([3167.4675], device='cuda:0')\n",
      "beta1 grad tensor([[4450.9902]], device='cuda:0')\n",
      "Epoch 21 | Loss: 24.0327\n",
      "alpha: 0.0745132565498352, beta0: 0.11574012041091919, beta1: -8.349656854989007e-05, beta2: 0.0004088702262379229, \n",
      "gamma: 0.06396453082561493, sigma0: 0.26608046889305115, sigma1: 3.263864709879272e-05, sigma2: -2.0344228687463328e-05, sigmaX: 0.15500198304653168\n",
      "forward done\n",
      "tensor([0.0417, 0.2877, 0.1691, 0.6161, 0.3847], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.6469]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-452.3181]], device='cuda:0')\n",
      "sigma0 grad tensor([-515.8170], device='cuda:0')\n",
      "sigma1 grad tensor([[-433.6890]], device='cuda:0')\n",
      "gamma grad tensor([[2834.6411]], device='cuda:0')\n",
      "alpha grad tensor([[-5808.9575]], device='cuda:0')\n",
      "beta2 grad tensor([[6050.9165]], device='cuda:0')\n",
      "beta0 grad tensor([2869.4739], device='cuda:0')\n",
      "beta1 grad tensor([[3921.9126]], device='cuda:0')\n",
      "Epoch 22 | Loss: 29.9789\n",
      "alpha: 0.07458824664354324, beta0: 0.11570113897323608, beta1: -0.0001222183054778725, beta2: 0.0003799124388024211, \n",
      "gamma: 0.06393066048622131, sigma0: 0.2660887837409973, sigma1: 3.757632657652721e-05, sigma2: -1.867523678811267e-05, sigmaX: 0.15500210225582123\n",
      "forward done\n",
      "tensor([0.0274, 0.1439, 0.4270, 0.5746, 0.3395], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.3897]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-857.4091]], device='cuda:0')\n",
      "sigma0 grad tensor([-612.7222], device='cuda:0')\n",
      "sigma1 grad tensor([[-631.1220]], device='cuda:0')\n",
      "gamma grad tensor([[3770.2039]], device='cuda:0')\n",
      "alpha grad tensor([[-7516.0005]], device='cuda:0')\n",
      "beta2 grad tensor([[9995.3525]], device='cuda:0')\n",
      "beta0 grad tensor([3632.0168], device='cuda:0')\n",
      "beta1 grad tensor([[5606.9194]], device='cuda:0')\n",
      "Epoch 23 | Loss: 15.7536\n",
      "alpha: 0.07472340017557144, beta0: 0.11563362926244736, beta1: -0.0002092648937832564, beta2: 0.00025679267127998173, \n",
      "gamma: 0.06386586278676987, sigma0: 0.26610156893730164, sigma1: 4.783768963534385e-05, sigma2: -8.765951861278154e-06, sigmaX: 0.15500222146511078\n",
      "forward done\n",
      "tensor([0.0236, 0.1268, 0.2673, 0.6107, 0.3415], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.5215]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-726.7735]], device='cuda:0')\n",
      "sigma0 grad tensor([-635.1046], device='cuda:0')\n",
      "sigma1 grad tensor([[-615.4412]], device='cuda:0')\n",
      "gamma grad tensor([[3691.8401]], device='cuda:0')\n",
      "alpha grad tensor([[-7491.0347]], device='cuda:0')\n",
      "beta2 grad tensor([[8995.2324]], device='cuda:0')\n",
      "beta0 grad tensor([3671.5979], device='cuda:0')\n",
      "beta1 grad tensor([[5429.9990]], device='cuda:0')\n",
      "Epoch 24 | Loss: 13.9182\n",
      "alpha: 0.07490643113851547, beta0: 0.11554290354251862, beta1: -0.00033320215879939497, beta2: 6.83445468894206e-05, \n",
      "gamma: 0.06377711147069931, sigma0: 0.2661181390285492, sigma1: 6.220119394129142e-05, sigma2: 6.429211680369917e-06, sigmaX: 0.15500234067440033\n",
      "forward done\n",
      "tensor([0.0307, 0.1047, 0.4379, 0.5811, 0.2775], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.1100]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-833.4992]], device='cuda:0')\n",
      "sigma0 grad tensor([-671.0316], device='cuda:0')\n",
      "sigma1 grad tensor([[-644.5731]], device='cuda:0')\n",
      "gamma grad tensor([[4271.0874]], device='cuda:0')\n",
      "alpha grad tensor([[-8453.2148]], device='cuda:0')\n",
      "beta2 grad tensor([[10607.0010]], device='cuda:0')\n",
      "beta0 grad tensor([4075.0747], device='cuda:0')\n",
      "beta1 grad tensor([[6120.5703]], device='cuda:0')\n",
      "Epoch 25 | Loss: 11.7999\n",
      "alpha: 0.07513739168643951, beta0: 0.11542957276105881, beta1: -0.000493557658046484, beta2: -0.00018848397303372622, \n",
      "gamma: 0.06366339325904846, sigma0: 0.26613810658454895, sigma1: 8.013772458070889e-05, sigma2: 2.6920333766611293e-05, sigmaX: 0.15500245988368988\n",
      "forward done\n",
      "tensor([0.0118, 0.1372, 0.6643, 0.5367, 0.3358], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.3836]]], device='cuda:0')\n",
      "sigma2 grad tensor([[951.9362]], device='cuda:0')\n",
      "sigma0 grad tensor([840.9327], device='cuda:0')\n",
      "sigma1 grad tensor([[791.4609]], device='cuda:0')\n",
      "gamma grad tensor([[-5760.3350]], device='cuda:0')\n",
      "alpha grad tensor([[11286.1113]], device='cuda:0')\n",
      "beta2 grad tensor([[-13346.7354]], device='cuda:0')\n",
      "beta0 grad tensor([-5403.9951], device='cuda:0')\n",
      "beta1 grad tensor([[-7986.9126]], device='cuda:0')\n",
      "Epoch 26 | Loss: 15.2708\n",
      "alpha: 0.07520929723978043, beta0: 0.11539295315742493, beta1: -0.000541972927749157, beta2: -0.00026047942810691893, \n",
      "gamma: 0.06363002210855484, sigma0: 0.2661456763744354, sigma1: 8.657234138809144e-05, sigma2: 3.379387271706946e-05, sigmaX: 0.15500257909297943\n",
      "forward done\n",
      "tensor([0.0134, 0.0451, 0.4528, 0.5513, 0.2745], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.8840]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-331.3223]], device='cuda:0')\n",
      "sigma0 grad tensor([-241.1635], device='cuda:0')\n",
      "sigma1 grad tensor([[-245.9758]], device='cuda:0')\n",
      "gamma grad tensor([[861.1674]], device='cuda:0')\n",
      "alpha grad tensor([[-1967.2567]], device='cuda:0')\n",
      "beta2 grad tensor([[2910.1956]], device='cuda:0')\n",
      "beta0 grad tensor([1088.7883], device='cuda:0')\n",
      "beta1 grad tensor([[1660.2056]], device='cuda:0')\n",
      "Epoch 27 | Loss: 5.8068\n",
      "alpha: 0.07528649270534515, beta0: 0.11535276472568512, beta1: -0.000597307225689292, beta2: -0.0003471777599770576, \n",
      "gamma: 0.06359471380710602, sigma0: 0.26615414023399353, sigma1: 9.417979163117707e-05, sigma2: 4.2605926864780486e-05, sigmaX: 0.1550026834011078\n",
      "forward done\n",
      "tensor([0.0184, 0.0625, 0.4088, 0.5472, 0.2320], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-4.5811]]], device='cuda:0')\n",
      "sigma2 grad tensor([[1226.6210]], device='cuda:0')\n",
      "sigma0 grad tensor([819.0007], device='cuda:0')\n",
      "sigma1 grad tensor([[892.5437]], device='cuda:0')\n",
      "gamma grad tensor([[-5562.4150]], device='cuda:0')\n",
      "alpha grad tensor([[10894.7393]], device='cuda:0')\n",
      "beta2 grad tensor([[-14509.7383]], device='cuda:0')\n",
      "beta0 grad tensor([-5223.9141], device='cuda:0')\n",
      "beta1 grad tensor([[-8129.3599]], device='cuda:0')\n",
      "Epoch 28 | Loss: 7.4531\n",
      "alpha: 0.07523930072784424, beta0: 0.11537285149097443, beta1: -0.0005602810415439308, beta2: -0.0002714390284381807, \n",
      "gamma: 0.06362209469079971, sigma0: 0.2661527395248413, sigma1: 9.134032006841153e-05, sigma2: 3.7389359931694344e-05, sigmaX: 0.15500281751155853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0233, 0.0418, 0.3732, 0.5659, 0.3096], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.2818]]], device='cuda:0')\n",
      "sigma2 grad tensor([[834.6008]], device='cuda:0')\n",
      "sigma0 grad tensor([572.4511], device='cuda:0')\n",
      "sigma1 grad tensor([[614.9898]], device='cuda:0')\n",
      "gamma grad tensor([[-4595.8857]], device='cuda:0')\n",
      "alpha grad tensor([[8806.6611]], device='cuda:0')\n",
      "beta2 grad tensor([[-11863.4609]], device='cuda:0')\n",
      "beta0 grad tensor([-4097.3931], device='cuda:0')\n",
      "beta1 grad tensor([[-6562.9897]], device='cuda:0')\n",
      "Epoch 29 | Loss: 5.4487\n",
      "alpha: 0.07511348277330399, beta0: 0.11542990058660507, beta1: -0.00046503019984811544, beta2: -9.221344225807115e-05, \n",
      "gamma: 0.0636899545788765, sigma0: 0.26614588499069214, sigma1: 8.291884296340868e-05, sigma2: 2.4870098059182055e-05, sigmaX: 0.15500295162200928\n",
      "forward done\n",
      "tensor([0.0134, 0.2543, 0.4726, 0.5643, 0.3119], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.1193]]], device='cuda:0')\n",
      "sigma2 grad tensor([[1351.3395]], device='cuda:0')\n",
      "sigma0 grad tensor([953.4795], device='cuda:0')\n",
      "sigma1 grad tensor([[1010.4554]], device='cuda:0')\n",
      "gamma grad tensor([[-6742.3291]], device='cuda:0')\n",
      "alpha grad tensor([[13074.3643]], device='cuda:0')\n",
      "beta2 grad tensor([[-17968.9219]], device='cuda:0')\n",
      "beta0 grad tensor([-6213.1641], device='cuda:0')\n",
      "beta1 grad tensor([[-9942.8867]], device='cuda:0')\n",
      "Epoch 30 | Loss: 26.7958\n",
      "alpha: 0.07488208264112473, beta0: 0.11553766578435898, beta1: -0.0002894006611313671, beta2: 0.00023085623979568481, \n",
      "gamma: 0.06381166726350784, sigma0: 0.26613086462020874, sigma1: 6.607710383832455e-05, sigma2: 1.3412944781521219e-06, sigmaX: 0.15500305593013763\n",
      "forward done\n",
      "tensor([0.0185, 0.1345, 0.5586, 0.4833, 0.1805], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-3.9553]]], device='cuda:0')\n",
      "sigma2 grad tensor([[1368.9506]], device='cuda:0')\n",
      "sigma0 grad tensor([799.2901], device='cuda:0')\n",
      "sigma1 grad tensor([[895.4341]], device='cuda:0')\n",
      "gamma grad tensor([[-5360.0327]], device='cuda:0')\n",
      "alpha grad tensor([[10466.0459]], device='cuda:0')\n",
      "beta2 grad tensor([[-15180.7607]], device='cuda:0')\n",
      "beta0 grad tensor([-4992.2466], device='cuda:0')\n",
      "beta1 grad tensor([[-8057.6255]], device='cuda:0')\n",
      "Epoch 31 | Loss: 14.6909\n",
      "alpha: 0.07459229975938797, beta0: 0.11567380279302597, beta1: -6.832077633589506e-05, beta2: 0.0006411196081899107, \n",
      "gamma: 0.06396263837814331, sigma0: 0.2661108672618866, sigma1: 4.364937558420934e-05, sigma2: -3.1171253795037046e-05, sigmaX: 0.15500317513942719\n",
      "forward done\n",
      "tensor([0.0187, 0.1630, 0.1862, 0.6708, 0.3810], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.8852]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-608.9235]], device='cuda:0')\n",
      "sigma0 grad tensor([-586.3145], device='cuda:0')\n",
      "sigma1 grad tensor([[-529.2531]], device='cuda:0')\n",
      "gamma grad tensor([[3251.0781]], device='cuda:0')\n",
      "alpha grad tensor([[-6655.6284]], device='cuda:0')\n",
      "beta2 grad tensor([[7328.7563]], device='cuda:0')\n",
      "beta0 grad tensor([3284.4062], device='cuda:0')\n",
      "beta1 grad tensor([[4613.6948]], device='cuda:0')\n",
      "Epoch 32 | Loss: 17.5525\n",
      "alpha: 0.074427030980587, beta0: 0.11574986577033997, beta1: 6.240617949515581e-05, beta2: 0.0008960427367128432, \n",
      "gamma: 0.06405090540647507, sigma0: 0.2661007344722748, sigma1: 3.099972309428267e-05, sigma2: -5.109205812914297e-05, sigmaX: 0.15500329434871674\n",
      "forward done\n",
      "tensor([0.0181, 0.0737, 0.2227, 0.6739, 0.4005], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.9900]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-672.1102]], device='cuda:0')\n",
      "sigma0 grad tensor([-576.4646], device='cuda:0')\n",
      "sigma1 grad tensor([[-560.2861]], device='cuda:0')\n",
      "gamma grad tensor([[3237.2605]], device='cuda:0')\n",
      "alpha grad tensor([[-6586.3789]], device='cuda:0')\n",
      "beta2 grad tensor([[7486.4004]], device='cuda:0')\n",
      "beta0 grad tensor([3230.5269], device='cuda:0')\n",
      "beta1 grad tensor([[4644.4985]], device='cuda:0')\n",
      "Epoch 33 | Loss: 8.6892\n",
      "alpha: 0.0743606835603714, beta0: 0.11577841639518738, beta1: 0.00012054275430273265, beta2: 0.0010251172352582216, \n",
      "gamma: 0.06408914178609848, sigma0: 0.26609838008880615, sigma1: 2.6482861358090304e-05, sigma2: -6.0307600506348535e-05, sigmaX: 0.1550034135580063\n",
      "forward done\n",
      "tensor([0.0301, 0.2273, 0.2624, 0.5943, 0.3419], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.6853]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-590.7303]], device='cuda:0')\n",
      "sigma0 grad tensor([-520.2065], device='cuda:0')\n",
      "sigma1 grad tensor([[-486.9998]], device='cuda:0')\n",
      "gamma grad tensor([[3049.6904]], device='cuda:0')\n",
      "alpha grad tensor([[-6109.4600]], device='cuda:0')\n",
      "beta2 grad tensor([[6556.0786]], device='cuda:0')\n",
      "beta0 grad tensor([2971.8582], device='cuda:0')\n",
      "beta1 grad tensor([[4141.9087]], device='cuda:0')\n",
      "Epoch 34 | Loss: 23.9596\n",
      "alpha: 0.07436870038509369, beta0: 0.11577153205871582, beta1: 0.000125632926938124, beta2: 0.001062816008925438, \n",
      "gamma: 0.06408923864364624, sigma0: 0.2661016881465912, sigma1: 2.7739370125345886e-05, sigma2: -6.1772734625265e-05, sigmaX: 0.15500353276729584\n",
      "forward done\n",
      "tensor([0.0098, 0.0981, 0.2601, 0.6390, 0.3943], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.6266]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-603.9917]], device='cuda:0')\n",
      "sigma0 grad tensor([-601.3754], device='cuda:0')\n",
      "sigma1 grad tensor([[-546.9775]], device='cuda:0')\n",
      "gamma grad tensor([[3542.1609]], device='cuda:0')\n",
      "alpha grad tensor([[-7131.6704]], device='cuda:0')\n",
      "beta2 grad tensor([[7707.7246]], device='cuda:0')\n",
      "beta0 grad tensor([3467.0818], device='cuda:0')\n",
      "beta1 grad tensor([[4887.9922]], device='cuda:0')\n",
      "Epoch 35 | Loss: 11.1085\n",
      "alpha: 0.0744464322924614, beta0: 0.11573135852813721, beta1: 8.082514250418171e-05, beta2: 0.0010158978402614594, \n",
      "gamma: 0.06405389308929443, sigma0: 0.266110360622406, sigma1: 3.421435030759312e-05, sigma2: -5.690492253052071e-05, sigmaX: 0.1550036370754242\n",
      "forward done\n",
      "tensor([0.0386, 0.2221, 0.2529, 0.6522, 0.3621], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.4225]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-558.9984]], device='cuda:0')\n",
      "sigma0 grad tensor([-532.3063], device='cuda:0')\n",
      "sigma1 grad tensor([[-477.9712]], device='cuda:0')\n",
      "gamma grad tensor([[3029.2310]], device='cuda:0')\n",
      "alpha grad tensor([[-6130.1655]], device='cuda:0')\n",
      "beta2 grad tensor([[6552.8989]], device='cuda:0')\n",
      "beta0 grad tensor([2992.5916], device='cuda:0')\n",
      "beta1 grad tensor([[4165.3940]], device='cuda:0')\n",
      "Epoch 36 | Loss: 23.5117\n",
      "alpha: 0.07456991821527481, beta0: 0.11566929519176483, beta1: 3.324976887597586e-06, beta2: 0.0009128343081101775, \n",
      "gamma: 0.06399532407522202, sigma0: 0.26612260937690735, sigma1: 4.417404852574691e-05, sigma2: -4.742068631458096e-05, sigmaX: 0.15500375628471375\n",
      "forward done\n",
      "tensor([0.0355, 0.2505, 0.1859, 0.6682, 0.4104], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.0045]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-555.7267]], device='cuda:0')\n",
      "sigma0 grad tensor([-506.8017], device='cuda:0')\n",
      "sigma1 grad tensor([[-461.3969]], device='cuda:0')\n",
      "gamma grad tensor([[2719.5908]], device='cuda:0')\n",
      "alpha grad tensor([[-5664.7178]], device='cuda:0')\n",
      "beta2 grad tensor([[6155.0518]], device='cuda:0')\n",
      "beta0 grad tensor([2813.8484], device='cuda:0')\n",
      "beta1 grad tensor([[3911.8066]], device='cuda:0')\n",
      "Epoch 37 | Loss: 26.3500\n",
      "alpha: 0.07472535222768784, beta0: 0.11559150367975235, beta1: -9.779322863323614e-05, beta2: 0.0007688329787924886, \n",
      "gamma: 0.06392127275466919, sigma0: 0.2661374807357788, sigma1: 5.675577631336637e-05, sigma2: -3.427603223826736e-05, sigmaX: 0.1550038605928421\n",
      "forward done\n",
      "tensor([0.0282, 0.1904, 0.2514, 0.6846, 0.3960], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.4432]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-605.9879]], device='cuda:0')\n",
      "sigma0 grad tensor([-559.9265], device='cuda:0')\n",
      "sigma1 grad tensor([[-511.9088]], device='cuda:0')\n",
      "gamma grad tensor([[3748.9587]], device='cuda:0')\n",
      "alpha grad tensor([[-7330.6328]], device='cuda:0')\n",
      "beta2 grad tensor([[7666.1860]], device='cuda:0')\n",
      "beta0 grad tensor([3482.0085], device='cuda:0')\n",
      "beta1 grad tensor([[4849.6953]], device='cuda:0')\n",
      "Epoch 38 | Loss: 20.4038\n",
      "alpha: 0.07492300868034363, beta0: 0.11549445241689682, beta1: -0.00022718474792782217, beta2: 0.0005769700510427356, \n",
      "gamma: 0.06382454186677933, sigma0: 0.2661549746990204, sigma1: 7.194024510681629e-05, sigma2: -1.7700429452816024e-05, sigmaX: 0.15500396490097046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0142, 0.0755, 0.3418, 0.6055, 0.3758], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.6861]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-824.9781]], device='cuda:0')\n",
      "sigma0 grad tensor([-648.0067], device='cuda:0')\n",
      "sigma1 grad tensor([[-642.9019]], device='cuda:0')\n",
      "gamma grad tensor([[4139.8389]], device='cuda:0')\n",
      "alpha grad tensor([[-8187.1138]], device='cuda:0')\n",
      "beta2 grad tensor([[9804.2158]], device='cuda:0')\n",
      "beta0 grad tensor([3930.2356], device='cuda:0')\n",
      "beta1 grad tensor([[5814.4512]], device='cuda:0')\n",
      "Epoch 39 | Loss: 8.8825\n",
      "alpha: 0.07516300678253174, beta0: 0.1153775081038475, beta1: -0.0003888424835167825, beta2: 0.0003254375187680125, \n",
      "gamma: 0.06370575726032257, sigma0: 0.26617544889450073, sigma1: 9.051684173755348e-05, sigma2: 3.80983419745462e-06, sigmaX: 0.15500406920909882\n",
      "forward done\n",
      "tensor([0.0103, 0.0478, 0.2023, 0.6462, 0.3639], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.3529]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-381.9237]], device='cuda:0')\n",
      "sigma0 grad tensor([-343.8067], device='cuda:0')\n",
      "sigma1 grad tensor([[-321.0607]], device='cuda:0')\n",
      "gamma grad tensor([[1512.8162]], device='cuda:0')\n",
      "alpha grad tensor([[-3279.9207]], device='cuda:0')\n",
      "beta2 grad tensor([[3872.3064]], device='cuda:0')\n",
      "beta0 grad tensor([1711.5486], device='cuda:0')\n",
      "beta1 grad tensor([[2425.2156]], device='cuda:0')\n",
      "Epoch 40 | Loss: 6.0000\n",
      "alpha: 0.07538779824972153, beta0: 0.1152668371796608, beta1: -0.0005424208356998861, beta2: 8.548843470634893e-05, \n",
      "gamma: 0.06359560042619705, sigma0: 0.26619526743888855, sigma1: 0.0001085887270164676, sigma2: 2.4837283490342088e-05, sigmaX: 0.15500417351722717\n",
      "forward done\n",
      "tensor([0.0229, 0.0609, 0.4892, 0.5184, 0.2441], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.6425]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-852.2241]], device='cuda:0')\n",
      "sigma0 grad tensor([-702.8362], device='cuda:0')\n",
      "sigma1 grad tensor([[-681.1104]], device='cuda:0')\n",
      "gamma grad tensor([[5072.4390]], device='cuda:0')\n",
      "alpha grad tensor([[-9775.8105]], device='cuda:0')\n",
      "beta2 grad tensor([[12433.4463]], device='cuda:0')\n",
      "beta0 grad tensor([4619.3911], device='cuda:0')\n",
      "beta1 grad tensor([[7087.5132]], device='cuda:0')\n",
      "Epoch 41 | Loss: 7.3675\n",
      "alpha: 0.07566539198160172, beta0: 0.11513210833072662, beta1: -0.0007361586322076619, beta2: -0.00023080530809238553, \n",
      "gamma: 0.06345675140619278, sigma0: 0.2662181556224823, sigma1: 0.00012985733337700367, sigma2: 5.0181482947664335e-05, sigmaX: 0.15500427782535553\n",
      "forward done\n",
      "tensor([0.0111, 0.1130, 0.3221, 0.5740, 0.3478], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-4.1759]]], device='cuda:0')\n",
      "sigma2 grad tensor([[1009.7375]], device='cuda:0')\n",
      "sigma0 grad tensor([828.3967], device='cuda:0')\n",
      "sigma1 grad tensor([[812.6417]], device='cuda:0')\n",
      "gamma grad tensor([[-6745.2798]], device='cuda:0')\n",
      "alpha grad tensor([[12838.7939]], device='cuda:0')\n",
      "beta2 grad tensor([[-15829.7188]], device='cuda:0')\n",
      "beta0 grad tensor([-5990.3711], device='cuda:0')\n",
      "beta1 grad tensor([[-9163.0566]], device='cuda:0')\n",
      "Epoch 42 | Loss: 12.5565\n",
      "alpha: 0.07575907558202744, beta0: 0.1150842234492302, beta1: -0.0007995183113962412, beta2: -0.00032554310746490955, \n",
      "gamma: 0.06341312825679779, sigma0: 0.26622816920280457, sigma1: 0.00013874580326955765, sigma2: 6.035946717020124e-05, sigmaX: 0.15500439703464508\n",
      "forward done\n",
      "tensor([0.0131, 0.1101, 0.3192, 0.5919, 0.3200], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-4.6886]]], device='cuda:0')\n",
      "sigma2 grad tensor([[1162.3483]], device='cuda:0')\n",
      "sigma0 grad tensor([854.0362], device='cuda:0')\n",
      "sigma1 grad tensor([[894.4275]], device='cuda:0')\n",
      "gamma grad tensor([[-6037.6826]], device='cuda:0')\n",
      "alpha grad tensor([[11838.4785]], device='cuda:0')\n",
      "beta2 grad tensor([[-16125.2256]], device='cuda:0')\n",
      "beta0 grad tensor([-5659.0820], device='cuda:0')\n",
      "beta1 grad tensor([[-8974.4014]], device='cuda:0')\n",
      "Epoch 43 | Loss: 12.2531\n",
      "alpha: 0.07571563869714737, beta0: 0.11510250717401505, beta1: -0.000760462018661201, beta2: -0.00024008109176065773, \n",
      "gamma: 0.06343860179185867, sigma0: 0.266227662563324, sigma1: 0.00013691230560652912, sigma2: 5.687837256118655e-05, sigmaX: 0.15500454604625702\n",
      "forward done\n",
      "tensor([0.0134, 0.3501, 0.3848, 0.5793, 0.3136], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.9462]]], device='cuda:0')\n",
      "sigma2 grad tensor([[1741.2844]], device='cuda:0')\n",
      "sigma0 grad tensor([1085.6809], device='cuda:0')\n",
      "sigma1 grad tensor([[1217.6460]], device='cuda:0')\n",
      "gamma grad tensor([[-8484.6797]], device='cuda:0')\n",
      "alpha grad tensor([[16117.8721]], device='cuda:0')\n",
      "beta2 grad tensor([[-22861.9629]], device='cuda:0')\n",
      "beta0 grad tensor([-7538.9673], device='cuda:0')\n",
      "beta1 grad tensor([[-12314.9502]], device='cuda:0')\n",
      "Epoch 44 | Loss: 36.3004\n",
      "alpha: 0.07551971077919006, beta0: 0.11519252508878708, beta1: -0.0006060675368644297, beta2: 5.690814577974379e-05, \n",
      "gamma: 0.06354382634162903, sigma0: 0.2662163972854614, sigma1: 0.00012326905562076718, sigma2: 3.668065255624242e-05, sigmaX: 0.15500466525554657\n",
      "forward done\n",
      "tensor([0.0195, 0.1321, 0.4950, 0.5415, 0.2376], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-3.9953]]], device='cuda:0')\n",
      "sigma2 grad tensor([[1104.1313]], device='cuda:0')\n",
      "sigma0 grad tensor([805.8097], device='cuda:0')\n",
      "sigma1 grad tensor([[823.9013]], device='cuda:0')\n",
      "gamma grad tensor([[-5509.3823]], device='cuda:0')\n",
      "alpha grad tensor([[10880.8037]], device='cuda:0')\n",
      "beta2 grad tensor([[-14927.9424]], device='cuda:0')\n",
      "beta0 grad tensor([-5220.3433], device='cuda:0')\n",
      "beta1 grad tensor([[-8281.6797]], device='cuda:0')\n",
      "Epoch 45 | Loss: 14.5029\n",
      "alpha: 0.0752541646361351, beta0: 0.11531674116849899, beta1: -0.00039973511593416333, beta2: 0.00044377896119840443, \n",
      "gamma: 0.06368310004472733, sigma0: 0.2661993205547333, sigma1: 0.00010411543917143717, sigma2: 9.481163033342455e-06, sigmaX: 0.15500479936599731\n",
      "forward done\n",
      "tensor([0.0243, 0.0557, 0.4319, 0.5233, 0.3144], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.4741]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-39.9289]], device='cuda:0')\n",
      "sigma0 grad tensor([-50.1002], device='cuda:0')\n",
      "sigma1 grad tensor([[-41.1667]], device='cuda:0')\n",
      "gamma grad tensor([[-454.8097]], device='cuda:0')\n",
      "alpha grad tensor([[633.2450]], device='cuda:0')\n",
      "beta2 grad tensor([[-535.9619]], device='cuda:0')\n",
      "beta0 grad tensor([-154.1549], device='cuda:0')\n",
      "beta1 grad tensor([[-266.8639]], device='cuda:0')\n",
      "Epoch 46 | Loss: 6.8645\n",
      "alpha: 0.07503539323806763, beta0: 0.11541765928268433, beta1: -0.00023200054420158267, beta2: 0.0007586352294310927, \n",
      "gamma: 0.06379906833171844, sigma0: 0.2661861479282379, sigma1: 8.920420805225149e-05, sigma2: -1.1879139492521062e-05, sigmaX: 0.15500491857528687\n",
      "forward done\n",
      "tensor([0.0153, 0.1424, 0.3403, 0.6290, 0.3558], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.8739]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-626.1748]], device='cuda:0')\n",
      "sigma0 grad tensor([-601.0608], device='cuda:0')\n",
      "sigma1 grad tensor([[-548.8484]], device='cuda:0')\n",
      "gamma grad tensor([[3912.8438]], device='cuda:0')\n",
      "alpha grad tensor([[-7689.5225]], device='cuda:0')\n",
      "beta2 grad tensor([[8317.3379]], device='cuda:0')\n",
      "beta0 grad tensor([3669.3179], device='cuda:0')\n",
      "beta1 grad tensor([[5189.8047]], device='cuda:0')\n",
      "Epoch 47 | Loss: 15.5799\n",
      "alpha: 0.07493726909160614, beta0: 0.11546169966459274, beta1: -0.0001497109333286062, beta2: 0.0009273468749597669, \n",
      "gamma: 0.0638527125120163, sigma0: 0.266181617975235, sigma1: 8.276371227111667e-05, sigma2: -2.2705633455188945e-05, sigmaX: 0.1550050526857376\n",
      "forward done\n",
      "tensor([0.0170, 0.2245, 0.1212, 0.6713, 0.3812], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.3928]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-467.4410]], device='cuda:0')\n",
      "sigma0 grad tensor([-526.0414], device='cuda:0')\n",
      "sigma1 grad tensor([[-443.3710]], device='cuda:0')\n",
      "gamma grad tensor([[3320.4875]], device='cuda:0')\n",
      "alpha grad tensor([[-6608.0186]], device='cuda:0')\n",
      "beta2 grad tensor([[6333.0981]], device='cuda:0')\n",
      "beta0 grad tensor([3186.7498], device='cuda:0')\n",
      "beta1 grad tensor([[4241.6685]], device='cuda:0')\n",
      "Epoch 48 | Loss: 23.6448\n",
      "alpha: 0.07492484897375107, beta0: 0.11546506732702255, beta1: -0.00012629592674784362, beta2: 0.000998985255137086, \n",
      "gamma: 0.06386242806911469, sigma0: 0.2661832571029663, sigma1: 8.204502228181809e-05, sigma2: -2.6692418032325804e-05, sigmaX: 0.15500517189502716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0176, 0.2041, 0.3058, 0.7038, 0.4153], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.7695]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-476.7251]], device='cuda:0')\n",
      "sigma0 grad tensor([-545.0062], device='cuda:0')\n",
      "sigma1 grad tensor([[-470.2962]], device='cuda:0')\n",
      "gamma grad tensor([[3317.3196]], device='cuda:0')\n",
      "alpha grad tensor([[-6645.9473]], device='cuda:0')\n",
      "beta2 grad tensor([[6527.5552]], device='cuda:0')\n",
      "beta0 grad tensor([3213.6470], device='cuda:0')\n",
      "beta1 grad tensor([[4337.1611]], device='cuda:0')\n",
      "Epoch 49 | Loss: 21.8562\n",
      "alpha: 0.07498137652873993, beta0: 0.11543562263250351, beta1: -0.00015093553520273417, beta2: 0.0009910203516483307, \n",
      "gamma: 0.06383702158927917, sigma0: 0.2661900222301483, sigma1: 8.617302955826744e-05, sigma2: -2.5114595700870268e-05, sigmaX: 0.1550052911043167\n",
      "forward done\n",
      "tensor([0.0128, 0.0819, 0.4581, 0.5178, 0.3766], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.3615]]], device='cuda:0')\n",
      "sigma2 grad tensor([[489.5062]], device='cuda:0')\n",
      "sigma0 grad tensor([335.1819], device='cuda:0')\n",
      "sigma1 grad tensor([[343.6075]], device='cuda:0')\n",
      "gamma grad tensor([[-2889.9216]], device='cuda:0')\n",
      "alpha grad tensor([[5502.0908]], device='cuda:0')\n",
      "beta2 grad tensor([[-6689.3584]], device='cuda:0')\n",
      "beta0 grad tensor([-2493.1570], device='cuda:0')\n",
      "beta1 grad tensor([[-3795.3821]], device='cuda:0')\n",
      "Epoch 50 | Loss: 9.5552\n",
      "alpha: 0.07497157901525497, beta0: 0.11543700098991394, beta1: -0.00013269339979160577, beta2: 0.001051541999913752, \n",
      "gamma: 0.06384559720754623, sigma0: 0.26619207859039307, sigma1: 8.603936294093728e-05, sigma2: -2.8747399483108893e-05, sigmaX: 0.15500539541244507\n",
      "forward done\n",
      "tensor([0.0144, 0.0499, 0.2031, 0.6245, 0.3241], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.6590]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-97.5064]], device='cuda:0')\n",
      "sigma0 grad tensor([-81.4152], device='cuda:0')\n",
      "sigma1 grad tensor([[-80.8858]], device='cuda:0')\n",
      "gamma grad tensor([[-236.0534]], device='cuda:0')\n",
      "alpha grad tensor([[198.7925]], device='cuda:0')\n",
      "beta2 grad tensor([[147.8341]], device='cuda:0')\n",
      "beta0 grad tensor([51.5387], device='cuda:0')\n",
      "beta1 grad tensor([[85.8176]], device='cuda:0')\n",
      "Epoch 51 | Loss: 6.1602\n",
      "alpha: 0.07496175169944763, beta0: 0.1154375895857811, beta1: -0.00011895786883542314, beta2: 0.0010984810069203377, \n",
      "gamma: 0.06385482102632523, sigma0: 0.26619455218315125, sigma1: 8.674128912389278e-05, sigma2: -3.067858051508665e-05, sigmaX: 0.15500549972057343\n",
      "forward done\n",
      "tensor([0.0143, 0.0754, 0.2028, 0.6276, 0.3590], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.9779]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-624.4352]], device='cuda:0')\n",
      "sigma0 grad tensor([-615.4935], device='cuda:0')\n",
      "sigma1 grad tensor([[-555.5940]], device='cuda:0')\n",
      "gamma grad tensor([[4132.5347]], device='cuda:0')\n",
      "alpha grad tensor([[-8073.8120]], device='cuda:0')\n",
      "beta2 grad tensor([[8447.8506]], device='cuda:0')\n",
      "beta0 grad tensor([3832.3699], device='cuda:0')\n",
      "beta1 grad tensor([[5380.1030]], device='cuda:0')\n",
      "Epoch 52 | Loss: 8.7391\n",
      "alpha: 0.07503462582826614, beta0: 0.11539973318576813, beta1: -0.0001617704692762345, beta2: 0.0010515537578612566, \n",
      "gamma: 0.06382087618112564, sigma0: 0.2662026882171631, sigma1: 9.285876876674592e-05, sigma2: -2.5979172278312035e-05, sigmaX: 0.15500560402870178\n",
      "forward done\n",
      "tensor([0.0228, 0.1952, 0.1988, 0.6684, 0.3876], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.9164]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-457.4874]], device='cuda:0')\n",
      "sigma0 grad tensor([-553.6857], device='cuda:0')\n",
      "sigma1 grad tensor([[-437.7856]], device='cuda:0')\n",
      "gamma grad tensor([[3773.3252]], device='cuda:0')\n",
      "alpha grad tensor([[-7337.3989]], device='cuda:0')\n",
      "beta2 grad tensor([[6831.6562]], device='cuda:0')\n",
      "beta0 grad tensor([3467.5361], device='cuda:0')\n",
      "beta1 grad tensor([[4581.3447]], device='cuda:0')\n",
      "Epoch 53 | Loss: 20.7963\n",
      "alpha: 0.07516629993915558, beta0: 0.11533477157354355, beta1: -0.00024183400091715157, beta2: 0.0009456953848712146, \n",
      "gamma: 0.06375598162412643, sigma0: 0.2662147283554077, sigma1: 0.00010213060886599123, sigma2: -1.764477201504633e-05, sigmaX: 0.15500570833683014\n",
      "forward done\n",
      "tensor([0.0126, 0.0678, 0.3199, 0.5693, 0.3452], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.6182]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-764.3126]], device='cuda:0')\n",
      "sigma0 grad tensor([-631.4871], device='cuda:0')\n",
      "sigma1 grad tensor([[-606.1764]], device='cuda:0')\n",
      "gamma grad tensor([[3941.8042]], device='cuda:0')\n",
      "alpha grad tensor([[-7854.9209]], device='cuda:0')\n",
      "beta2 grad tensor([[9155.5264]], device='cuda:0')\n",
      "beta0 grad tensor([3780.0400], device='cuda:0')\n",
      "beta1 grad tensor([[5529.8613]], device='cuda:0')\n",
      "Epoch 54 | Loss: 8.0282\n",
      "alpha: 0.07535018771886826, beta0: 0.11524500697851181, beta1: -0.000361183425411582, beta2: 0.0007694534142501652, \n",
      "gamma: 0.06366465240716934, sigma0: 0.26623067259788513, sigma1: 0.00011560984421521425, sigma2: -3.334125040055369e-06, sigmaX: 0.1550058126449585\n",
      "forward done\n",
      "tensor([0.0193, 0.1606, 0.5151, 0.6614, 0.3111], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.0401]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-664.9687]], device='cuda:0')\n",
      "sigma0 grad tensor([-586.3506], device='cuda:0')\n",
      "sigma1 grad tensor([[-548.1135]], device='cuda:0')\n",
      "gamma grad tensor([[3622.0759]], device='cuda:0')\n",
      "alpha grad tensor([[-7263.0498]], device='cuda:0')\n",
      "beta2 grad tensor([[8346.3086]], device='cuda:0')\n",
      "beta0 grad tensor([3505.2551], device='cuda:0')\n",
      "beta1 grad tensor([[5082.5122]], device='cuda:0')\n",
      "Epoch 55 | Loss: 17.5670\n",
      "alpha: 0.07556992769241333, beta0: 0.11513814330101013, beta1: -0.0005074880900792778, beta2: 0.0005449967575259507, \n",
      "gamma: 0.06355536729097366, sigma0: 0.26624929904937744, sigma1: 0.0001318743743468076, sigma2: 1.4764080333407037e-05, sigmaX: 0.15500591695308685\n",
      "forward done\n",
      "tensor([0.0215, 0.0429, 0.5623, 0.5361, 0.2670], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.3123]]], device='cuda:0')\n",
      "sigma2 grad tensor([[350.8555]], device='cuda:0')\n",
      "sigma0 grad tensor([249.6046], device='cuda:0')\n",
      "sigma1 grad tensor([[259.1648]], device='cuda:0')\n",
      "gamma grad tensor([[-2495.7820]], device='cuda:0')\n",
      "alpha grad tensor([[4649.9517]], device='cuda:0')\n",
      "beta2 grad tensor([[-5557.0874]], device='cuda:0')\n",
      "beta0 grad tensor([-2064.5190], device='cuda:0')\n",
      "beta1 grad tensor([[-3175.2725]], device='cuda:0')\n",
      "Epoch 56 | Loss: 5.6792\n",
      "alpha: 0.07569921761751175, beta0: 0.1150732934474945, beta1: -0.0005927790771238506, beta2: 0.0004210022743791342, \n",
      "gamma: 0.06349289417266846, sigma0: 0.2662616968154907, sigma1: 0.00014229434600565583, sigma2: 2.5734090741025284e-05, sigmaX: 0.1550060212612152\n",
      "forward done\n",
      "tensor([0.0123, 0.0329, 0.4326, 0.6139, 0.3206], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.2977]]], device='cuda:0')\n",
      "sigma2 grad tensor([[252.4346]], device='cuda:0')\n",
      "sigma0 grad tensor([194.2213], device='cuda:0')\n",
      "sigma1 grad tensor([[191.7172]], device='cuda:0')\n",
      "gamma grad tensor([[-1961.3766]], device='cuda:0')\n",
      "alpha grad tensor([[3634.4895]], device='cuda:0')\n",
      "beta2 grad tensor([[-4376.6216]], device='cuda:0')\n",
      "beta0 grad tensor([-1610.1620], device='cuda:0')\n",
      "beta1 grad tensor([[-2477.6809]], device='cuda:0')\n",
      "Epoch 57 | Loss: 4.6692\n",
      "alpha: 0.07576631009578705, beta0: 0.11503751575946808, beta1: -0.0006362350541166961, beta2: 0.0003655729233287275, \n",
      "gamma: 0.06346253305673599, sigma0: 0.2662696838378906, sigma1: 0.00014871315215714276, sigma2: 3.1985753594199196e-05, sigmaX: 0.15500611066818237\n",
      "forward done\n",
      "tensor([0.0279, 0.4818, 0.4659, 0.5544, 0.2313], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.3201]]], device='cuda:0')\n",
      "sigma2 grad tensor([[1737.9380]], device='cuda:0')\n",
      "sigma0 grad tensor([1056.7719], device='cuda:0')\n",
      "sigma1 grad tensor([[1207.8489]], device='cuda:0')\n",
      "gamma grad tensor([[-8642.1582]], device='cuda:0')\n",
      "alpha grad tensor([[16251.8486]], device='cuda:0')\n",
      "beta2 grad tensor([[-22910.4941]], device='cuda:0')\n",
      "beta0 grad tensor([-7511.6553], device='cuda:0')\n",
      "beta1 grad tensor([[-12361.9277]], device='cuda:0')\n",
      "Epoch 58 | Loss: 49.4603\n",
      "alpha: 0.07565746456384659, beta0: 0.11508400738239288, beta1: -0.0005473805940710008, beta2: 0.0005503343418240547, \n",
      "gamma: 0.06352466344833374, sigma0: 0.26626551151275635, sigma1: 0.00014176970580592752, sigma2: 1.960770350706298e-05, sigmaX: 0.15500620007514954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0115, 0.0941, 0.2301, 0.5881, 0.3325], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-4.7411]]], device='cuda:0')\n",
      "sigma2 grad tensor([[821.6948]], device='cuda:0')\n",
      "sigma0 grad tensor([742.5289], device='cuda:0')\n",
      "sigma1 grad tensor([[702.3035]], device='cuda:0')\n",
      "gamma grad tensor([[-5348.4795]], device='cuda:0')\n",
      "alpha grad tensor([[10373.5439]], device='cuda:0')\n",
      "beta2 grad tensor([[-11951.2959]], device='cuda:0')\n",
      "beta0 grad tensor([-4894.3286], device='cuda:0')\n",
      "beta1 grad tensor([[-7229.0718]], device='cuda:0')\n",
      "Epoch 59 | Loss: 10.5721\n",
      "alpha: 0.07546665519475937, beta0: 0.11517014354467392, beta1: -0.0004040063067805022, beta2: 0.0008176564588211477, \n",
      "gamma: 0.06362785398960114, sigma0: 0.266254723072052, sigma1: 0.00012919191794935614, sigma2: 1.4883139556332026e-06, sigmaX: 0.1550063192844391\n",
      "forward done\n",
      "tensor([0.0158, 0.1686, 0.4772, 0.5310, 0.2456], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.7506]]], device='cuda:0')\n",
      "sigma2 grad tensor([[1271.1749]], device='cuda:0')\n",
      "sigma0 grad tensor([782.0569], device='cuda:0')\n",
      "sigma1 grad tensor([[870.5996]], device='cuda:0')\n",
      "gamma grad tensor([[-5616.2876]], device='cuda:0')\n",
      "alpha grad tensor([[10826.4004]], device='cuda:0')\n",
      "beta2 grad tensor([[-14492.3662]], device='cuda:0')\n",
      "beta0 grad tensor([-5092.6890], device='cuda:0')\n",
      "beta1 grad tensor([[-8044.7188]], device='cuda:0')\n",
      "Epoch 60 | Loss: 18.1255\n",
      "alpha: 0.0752057433128357, beta0: 0.11528997868299484, beta1: -0.00020885966659989208, beta2: 0.0011764378286898136, \n",
      "gamma: 0.06376656889915466, sigma0: 0.266238272190094, sigma1: 0.00011042368714697659, sigma2: -2.571894583525136e-05, sigmaX: 0.15500642359256744\n",
      "forward done\n",
      "tensor([0.0102, 0.0904, 0.1193, 0.6347, 0.3518], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.1133]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-567.6270]], device='cuda:0')\n",
      "sigma0 grad tensor([-598.3632], device='cuda:0')\n",
      "sigma1 grad tensor([[-514.9822]], device='cuda:0')\n",
      "gamma grad tensor([[3930.3960]], device='cuda:0')\n",
      "alpha grad tensor([[-7750.1978]], device='cuda:0')\n",
      "beta2 grad tensor([[8207.6924]], device='cuda:0')\n",
      "beta0 grad tensor([3699.9546], device='cuda:0')\n",
      "beta1 grad tensor([[5201.6919]], device='cuda:0')\n",
      "Epoch 61 | Loss: 10.1517\n",
      "alpha: 0.07507451623678207, beta0: 0.11534885317087173, beta1: -0.00010475927410880104, beta2: 0.001381385955028236, \n",
      "gamma: 0.06383823603391647, sigma0: 0.26623108983039856, sigma1: 0.00010055892926175147, sigma2: -4.180848554824479e-05, sigmaX: 0.1550065279006958\n",
      "forward done\n",
      "tensor([0.0235, 0.2678, 0.1314, 0.7101, 0.4210], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.9981]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-343.4160]], device='cuda:0')\n",
      "sigma0 grad tensor([-482.7136], device='cuda:0')\n",
      "sigma1 grad tensor([[-370.6449]], device='cuda:0')\n",
      "gamma grad tensor([[3263.0354]], device='cuda:0')\n",
      "alpha grad tensor([[-6399.8350]], device='cuda:0')\n",
      "beta2 grad tensor([[5800.0654]], device='cuda:0')\n",
      "beta0 grad tensor([3034.5068], device='cuda:0')\n",
      "beta1 grad tensor([[3968.7056]], device='cuda:0')\n",
      "Epoch 62 | Loss: 28.0651\n",
      "alpha: 0.0750335305929184, beta0: 0.11536560207605362, beta1: -6.116601434769109e-05, beta2: 0.001487343804910779, \n",
      "gamma: 0.06386294215917587, sigma0: 0.26623019576072693, sigma1: 9.637356561142951e-05, sigma2: -5.124595554661937e-05, sigmaX: 0.15500663220882416\n",
      "forward done\n",
      "tensor([0.0182, 0.1701, 0.2605, 0.6476, 0.3916], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.7604]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-514.6647]], device='cuda:0')\n",
      "sigma0 grad tensor([-540.4891], device='cuda:0')\n",
      "sigma1 grad tensor([[-464.1642]], device='cuda:0')\n",
      "gamma grad tensor([[3394.7603]], device='cuda:0')\n",
      "alpha grad tensor([[-6752.4287]], device='cuda:0')\n",
      "beta2 grad tensor([[6788.2896]], device='cuda:0')\n",
      "beta0 grad tensor([3237.0754], device='cuda:0')\n",
      "beta1 grad tensor([[4415.4961]], device='cuda:0')\n",
      "Epoch 63 | Loss: 18.3242\n",
      "alpha: 0.07506826519966125, beta0: 0.11534663289785385, beta1: -7.0446367317345e-05, beta2: 0.0015042271697893739, \n",
      "gamma: 0.06384875625371933, sigma0: 0.2662348747253418, sigma1: 9.766691800905392e-05, sigma2: -5.364928438211791e-05, sigmaX: 0.15500673651695251\n",
      "forward done\n",
      "tensor([0.0125, 0.0580, 0.3887, 0.5932, 0.3517], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.7644]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-432.6055]], device='cuda:0')\n",
      "sigma0 grad tensor([-356.0919], device='cuda:0')\n",
      "sigma1 grad tensor([[-349.8411]], device='cuda:0')\n",
      "gamma grad tensor([[1726.2770]], device='cuda:0')\n",
      "alpha grad tensor([[-3641.2278]], device='cuda:0')\n",
      "beta2 grad tensor([[4279.9546]], device='cuda:0')\n",
      "beta0 grad tensor([1840.9835], device='cuda:0')\n",
      "beta1 grad tensor([[2651.5830]], device='cuda:0')\n",
      "Epoch 64 | Loss: 7.1416\n",
      "alpha: 0.07513246685266495, beta0: 0.11531304568052292, beta1: -0.00010438647586852312, beta2: 0.001474934397265315, \n",
      "gamma: 0.06382014602422714, sigma0: 0.2662421762943268, sigma1: 0.00010220001422567293, sigma2: -5.124589370097965e-05, sigmaX: 0.15500684082508087\n",
      "forward done\n",
      "tensor([0.0152, 0.0984, 0.1908, 0.6459, 0.3612], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.8102]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-620.9088]], device='cuda:0')\n",
      "sigma0 grad tensor([-569.3143], device='cuda:0')\n",
      "sigma1 grad tensor([[-530.6628]], device='cuda:0')\n",
      "gamma grad tensor([[3898.6853]], device='cuda:0')\n",
      "alpha grad tensor([[-7609.7881]], device='cuda:0')\n",
      "beta2 grad tensor([[8211.4863]], device='cuda:0')\n",
      "beta0 grad tensor([3598.1262], device='cuda:0')\n",
      "beta1 grad tensor([[5124.6489]], device='cuda:0')\n",
      "Epoch 65 | Loss: 11.0554\n",
      "alpha: 0.07525992393493652, beta0: 0.11525019258260727, beta1: -0.0001827850501285866, beta2: 0.0013693852815777063, \n",
      "gamma: 0.06375826895236969, sigma0: 0.2662537097930908, sigma1: 0.00011113311484223232, sigma2: -4.3114094296470284e-05, sigmaX: 0.15500696003437042\n",
      "forward done\n",
      "tensor([0.0148, 0.1506, 0.3564, 0.5317, 0.2931], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-4.5228]]], device='cuda:0')\n",
      "sigma2 grad tensor([[1031.2965]], device='cuda:0')\n",
      "sigma0 grad tensor([708.4073], device='cuda:0')\n",
      "sigma1 grad tensor([[752.7241]], device='cuda:0')\n",
      "gamma grad tensor([[-5163.5322]], device='cuda:0')\n",
      "alpha grad tensor([[9889.3271]], device='cuda:0')\n",
      "beta2 grad tensor([[-12423.9746]], device='cuda:0')\n",
      "beta0 grad tensor([-4599.5532], device='cuda:0')\n",
      "beta1 grad tensor([[-7103.2539]], device='cuda:0')\n",
      "Epoch 66 | Loss: 16.2573\n",
      "alpha: 0.07526300102472305, beta0: 0.11524590849876404, beta1: -0.00017447136633563787, beta2: 0.0014091857010498643, \n",
      "gamma: 0.06376040726900101, sigma0: 0.26625585556030273, sigma1: 0.00011075235670432448, sigma2: -4.69216174678877e-05, sigmaX: 0.15500709414482117\n",
      "forward done\n",
      "tensor([0.0147, 0.0791, 0.3206, 0.6233, 0.3549], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.7733]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-643.6901]], device='cuda:0')\n",
      "sigma0 grad tensor([-601.7820], device='cuda:0')\n",
      "sigma1 grad tensor([[-546.4058]], device='cuda:0')\n",
      "gamma grad tensor([[3926.0808]], device='cuda:0')\n",
      "alpha grad tensor([[-7729.3726]], device='cuda:0')\n",
      "beta2 grad tensor([[8508.5400]], device='cuda:0')\n",
      "beta0 grad tensor([3674.0811], device='cuda:0')\n",
      "beta1 grad tensor([[5257.3887]], device='cuda:0')\n",
      "Epoch 67 | Loss: 9.2284\n",
      "alpha: 0.07534275203943253, beta0: 0.11520574241876602, beta1: -0.0002203943149652332, beta2: 0.0013559407088905573, \n",
      "gamma: 0.06372285634279251, sigma0: 0.26626360416412354, sigma1: 0.00011591181100811809, sigma2: -4.353073381935246e-05, sigmaX: 0.1550072282552719\n",
      "forward done\n",
      "tensor([0.0140, 0.0578, 0.1750, 0.6256, 0.3638], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.4021]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-660.7524]], device='cuda:0')\n",
      "sigma0 grad tensor([-612.8694], device='cuda:0')\n",
      "sigma1 grad tensor([[-568.5060]], device='cuda:0')\n",
      "gamma grad tensor([[3696.7139]], device='cuda:0')\n",
      "alpha grad tensor([[-7474.6313]], device='cuda:0')\n",
      "beta2 grad tensor([[8245.1924]], device='cuda:0')\n",
      "beta0 grad tensor([3621.2151], device='cuda:0')\n",
      "beta1 grad tensor([[5161.0469]], device='cuda:0')\n",
      "Epoch 68 | Loss: 6.9633\n",
      "alpha: 0.07548130303621292, beta0: 0.11513739824295044, beta1: -0.0003087431541644037, beta2: 0.001230892725288868, \n",
      "gamma: 0.06365584582090378, sigma0: 0.26627591252326965, sigma1: 0.00012572442938107997, sigma2: -3.4210504963994026e-05, sigmaX: 0.15500736236572266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0277, 0.1414, 0.1014, 0.6656, 0.3922], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.4649]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-600.5223]], device='cuda:0')\n",
      "sigma0 grad tensor([-570.2278], device='cuda:0')\n",
      "sigma1 grad tensor([[-529.6145]], device='cuda:0')\n",
      "gamma grad tensor([[3672.6794]], device='cuda:0')\n",
      "alpha grad tensor([[-7287.7646]], device='cuda:0')\n",
      "beta2 grad tensor([[8129.0649]], device='cuda:0')\n",
      "beta0 grad tensor([3481.5259], device='cuda:0')\n",
      "beta1 grad tensor([[5038.7397]], device='cuda:0')\n",
      "Epoch 69 | Loss: 15.3239\n",
      "alpha: 0.07566501945257187, beta0: 0.11504790931940079, beta1: -0.00042980961734429, beta2: 0.001049563754349947, \n",
      "gamma: 0.06356551498174667, sigma0: 0.26629146933555603, sigma1: 0.00013887067325413227, sigma2: -2.074909752991516e-05, sigmaX: 0.1550074964761734\n",
      "forward done\n",
      "tensor([0.0133, 0.0384, 0.2394, 0.6494, 0.3606], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.1709]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-224.6344]], device='cuda:0')\n",
      "sigma0 grad tensor([-196.7525], device='cuda:0')\n",
      "sigma1 grad tensor([[-186.8102]], device='cuda:0')\n",
      "gamma grad tensor([[483.1628]], device='cuda:0')\n",
      "alpha grad tensor([[-1245.5732]], device='cuda:0')\n",
      "beta2 grad tensor([[1794.2347]], device='cuda:0')\n",
      "beta0 grad tensor([746.0765], device='cuda:0')\n",
      "beta1 grad tensor([[1092.1556]], device='cuda:0')\n",
      "Epoch 70 | Loss: 5.1017\n",
      "alpha: 0.07582444697618484, beta0: 0.11496885120868683, beta1: -0.0005375843611545861, beta2: 0.0008865582058206201, \n",
      "gamma: 0.0634884163737297, sigma0: 0.2663058936595917, sigma1: 0.0001512557646492496, sigma2: -7.733628081041388e-06, sigmaX: 0.15500763058662415\n",
      "forward done\n",
      "tensor([0.0115, 0.0403, 0.2675, 0.6207, 0.3557], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.0717]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-586.1077]], device='cuda:0')\n",
      "sigma0 grad tensor([-464.1505], device='cuda:0')\n",
      "sigma1 grad tensor([[-458.2975]], device='cuda:0')\n",
      "gamma grad tensor([[2917.0527]], device='cuda:0')\n",
      "alpha grad tensor([[-5776.5659]], device='cuda:0')\n",
      "beta2 grad tensor([[7014.0532]], device='cuda:0')\n",
      "beta0 grad tensor([2790.0991], device='cuda:0')\n",
      "beta1 grad tensor([[4152.4829]], device='cuda:0')\n",
      "Epoch 71 | Loss: 5.2894\n",
      "alpha: 0.07600975781679153, beta0: 0.11487770825624466, beta1: -0.0006653289892710745, beta2: 0.000686013197991997, \n",
      "gamma: 0.06339756399393082, sigma0: 0.2663220763206482, sigma1: 0.00016574682376813143, sigma2: 8.539826012565754e-06, sigmaX: 0.1550077497959137\n",
      "forward done\n",
      "tensor([0.0144, 0.1022, 0.3380, 0.5930, 0.3435], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.5699]]], device='cuda:0')\n",
      "sigma2 grad tensor([[945.0215]], device='cuda:0')\n",
      "sigma0 grad tensor([712.5239], device='cuda:0')\n",
      "sigma1 grad tensor([[725.4798]], device='cuda:0')\n",
      "gamma grad tensor([[-5444.3179]], device='cuda:0')\n",
      "alpha grad tensor([[10427.7451]], device='cuda:0')\n",
      "beta2 grad tensor([[-13647.1270]], device='cuda:0')\n",
      "beta0 grad tensor([-4859.0308], device='cuda:0')\n",
      "beta1 grad tensor([[-7627.2998]], device='cuda:0')\n",
      "Epoch 72 | Loss: 11.5120\n",
      "alpha: 0.07605372369289398, beta0: 0.1148533821105957, beta1: -0.0006912517128512263, beta2: 0.0006620484637096524, \n",
      "gamma: 0.06337932497262955, sigma0: 0.2663278877735138, sigma1: 0.00017008486611302942, sigma2: 1.2108374903618824e-05, sigmaX: 0.15500786900520325\n",
      "forward done\n",
      "tensor([0.0090, 0.0733, 0.3623, 0.5777, 0.3041], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.7903]]], device='cuda:0')\n",
      "sigma2 grad tensor([[688.1951]], device='cuda:0')\n",
      "sigma0 grad tensor([693.0882], device='cuda:0')\n",
      "sigma1 grad tensor([[622.4543]], device='cuda:0')\n",
      "gamma grad tensor([[-5750.2163]], device='cuda:0')\n",
      "alpha grad tensor([[10858.2393]], device='cuda:0')\n",
      "beta2 grad tensor([[-11884.2285]], device='cuda:0')\n",
      "beta0 grad tensor([-5006.0273], device='cuda:0')\n",
      "beta1 grad tensor([[-7311.8545]], device='cuda:0')\n",
      "Epoch 73 | Loss: 8.5800\n",
      "alpha: 0.07598032057285309, beta0: 0.11488398164510727, beta1: -0.000638871337287128, beta2: 0.0007617189548909664, \n",
      "gamma: 0.06342224031686783, sigma0: 0.26632559299468994, sigma1: 0.00016733075608499348, sigma2: 8.081262421910651e-06, sigmaX: 0.1550079882144928\n",
      "forward done\n",
      "tensor([0.0204, 0.3731, 0.4373, 0.5223, 0.2741], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.4075]]], device='cuda:0')\n",
      "sigma2 grad tensor([[1412.8530]], device='cuda:0')\n",
      "sigma0 grad tensor([934.0272], device='cuda:0')\n",
      "sigma1 grad tensor([[1005.9615]], device='cuda:0')\n",
      "gamma grad tensor([[-8582.2930]], device='cuda:0')\n",
      "alpha grad tensor([[15721.9785]], device='cuda:0')\n",
      "beta2 grad tensor([[-20516.0488]], device='cuda:0')\n",
      "beta0 grad tensor([-7086.0474], device='cuda:0')\n",
      "beta1 grad tensor([[-11313.3350]], device='cuda:0')\n",
      "Epoch 74 | Loss: 38.5641\n",
      "alpha: 0.07576437294483185, beta0: 0.1149793192744255, beta1: -0.0004838336899410933, beta2: 0.0010466158855706453, \n",
      "gamma: 0.06354239583015442, sigma0: 0.26631441712379456, sigma1: 0.00015506785712204874, sigma2: -9.26895700104069e-06, sigmaX: 0.15500809252262115\n",
      "forward done\n",
      "tensor([0.0123, 0.0738, 0.3534, 0.6064, 0.3548], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.9811]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-678.7107]], device='cuda:0')\n",
      "sigma0 grad tensor([-627.7717], device='cuda:0')\n",
      "sigma1 grad tensor([[-587.7141]], device='cuda:0')\n",
      "gamma grad tensor([[4257.3535]], device='cuda:0')\n",
      "alpha grad tensor([[-8320.1943]], device='cuda:0')\n",
      "beta2 grad tensor([[9097.0781]], device='cuda:0')\n",
      "beta0 grad tensor([3947.4688], device='cuda:0')\n",
      "beta1 grad tensor([[5655.5420]], device='cuda:0')\n",
      "Epoch 75 | Loss: 8.7110\n",
      "alpha: 0.07567481696605682, beta0: 0.11501611769199371, beta1: -0.00041635899106040597, beta2: 0.0011835626792162657, \n",
      "gamma: 0.06359594315290451, sigma0: 0.26631176471710205, sigma1: 0.00015113467816263437, sigma2: -1.6362026144634e-05, sigmaX: 0.1550081968307495\n",
      "forward done\n",
      "tensor([0.0224, 0.1977, 0.1486, 0.6638, 0.3776], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.1012]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-458.7521]], device='cuda:0')\n",
      "sigma0 grad tensor([-534.7629], device='cuda:0')\n",
      "sigma1 grad tensor([[-439.5951]], device='cuda:0')\n",
      "gamma grad tensor([[3736.3506]], device='cuda:0')\n",
      "alpha grad tensor([[-7288.8979]], device='cuda:0')\n",
      "beta2 grad tensor([[7435.9175]], device='cuda:0')\n",
      "beta0 grad tensor([3442.8459], device='cuda:0')\n",
      "beta1 grad tensor([[4771.5498]], device='cuda:0')\n",
      "Epoch 76 | Loss: 20.9810\n",
      "alpha: 0.07567606121301651, beta0: 0.11501112580299377, beta1: -0.00041009471169672906, beta2: 0.0012187608517706394, \n",
      "gamma: 0.06360141932964325, sigma0: 0.2663149833679199, sigma1: 0.00015238409105222672, sigma2: -1.744895962474402e-05, sigmaX: 0.15500828623771667\n",
      "forward done\n",
      "tensor([0.0180, 0.1615, 0.0867, 0.6980, 0.4122], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.5247]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-533.3201]], device='cuda:0')\n",
      "sigma0 grad tensor([-558.1184], device='cuda:0')\n",
      "sigma1 grad tensor([[-489.7875]], device='cuda:0')\n",
      "gamma grad tensor([[4134.1260]], device='cuda:0')\n",
      "alpha grad tensor([[-7933.5112]], device='cuda:0')\n",
      "beta2 grad tensor([[7985.8223]], device='cuda:0')\n",
      "beta0 grad tensor([3704.0664], device='cuda:0')\n",
      "beta1 grad tensor([[5141.7788]], device='cuda:0')\n",
      "Epoch 77 | Loss: 17.3693\n",
      "alpha: 0.07575639337301254, beta0: 0.11497009545564651, beta1: -0.000456501089502126, beta2: 0.0011670611565932631, \n",
      "gamma: 0.06356445699930191, sigma0: 0.26632314920425415, sigma1: 0.00015828148752916604, sigma2: -1.2985306057089474e-05, sigmaX: 0.15500836074352264\n",
      "forward done\n",
      "tensor([0.0151, 0.0754, 0.5075, 0.4744, 0.1831], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.6400]]], device='cuda:0')\n",
      "sigma2 grad tensor([[400.6170]], device='cuda:0')\n",
      "sigma0 grad tensor([276.4874], device='cuda:0')\n",
      "sigma1 grad tensor([[283.9418]], device='cuda:0')\n",
      "gamma grad tensor([[-2612.6421]], device='cuda:0')\n",
      "alpha grad tensor([[4826.3901]], device='cuda:0')\n",
      "beta2 grad tensor([[-6087.8672]], device='cuda:0')\n",
      "beta0 grad tensor([-2145.9919], device='cuda:0')\n",
      "beta1 grad tensor([[-3353.0642]], device='cuda:0')\n",
      "Epoch 78 | Loss: 8.7221\n",
      "alpha: 0.07577239722013474, beta0: 0.11495872586965561, beta1: -0.0004600955580826849, beta2: 0.0011865801643580198, \n",
      "gamma: 0.06356101483106613, sigma0: 0.266326904296875, sigma1: 0.00016015999426599592, sigma2: -1.3420552932075225e-05, sigmaX: 0.1550084501504898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0131, 0.0679, 0.2513, 0.6337, 0.3442], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-3.0890]]], device='cuda:0')\n",
      "sigma2 grad tensor([[267.6020]], device='cuda:0')\n",
      "sigma0 grad tensor([243.0684], device='cuda:0')\n",
      "sigma1 grad tensor([[227.6312]], device='cuda:0')\n",
      "gamma grad tensor([[-2781.9492]], device='cuda:0')\n",
      "alpha grad tensor([[5085.7681]], device='cuda:0')\n",
      "beta2 grad tensor([[-5283.9346]], device='cuda:0')\n",
      "beta0 grad tensor([-2213.5049], device='cuda:0')\n",
      "beta1 grad tensor([[-3229.2637]], device='cuda:0')\n",
      "Epoch 79 | Loss: 8.0292\n",
      "alpha: 0.07573433965444565, beta0: 0.11497176438570023, beta1: -0.00043067848309874535, beta2: 0.001255034701898694, \n",
      "gamma: 0.06358607858419418, sigma0: 0.26632747054100037, sigma1: 0.00015938648721203208, sigma2: -1.64447701536119e-05, sigmaX: 0.15500855445861816\n",
      "forward done\n",
      "tensor([0.0118, 0.0673, 0.1773, 0.6112, 0.3144], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.0095]]], device='cuda:0')\n",
      "sigma2 grad tensor([[810.3920]], device='cuda:0')\n",
      "sigma0 grad tensor([633.6660], device='cuda:0')\n",
      "sigma1 grad tensor([[641.0347]], device='cuda:0')\n",
      "gamma grad tensor([[-4930.8423]], device='cuda:0')\n",
      "alpha grad tensor([[9424.7676]], device='cuda:0')\n",
      "beta2 grad tensor([[-11062.9961]], device='cuda:0')\n",
      "beta0 grad tensor([-4366.5757], device='cuda:0')\n",
      "beta1 grad tensor([[-6567.0151]], device='cuda:0')\n",
      "Epoch 80 | Loss: 7.8481\n",
      "alpha: 0.07560964673757553, beta0: 0.11502586305141449, beta1: -0.0003414746606722474, beta2: 0.0014204282779246569, \n",
      "gamma: 0.06365543603897095, sigma0: 0.26632159948349, sigma1: 0.00015235733008012176, sigma2: -2.6968064048560336e-05, sigmaX: 0.15500865876674652\n",
      "forward done\n",
      "tensor([0.0096, 0.0488, 0.2862, 0.6316, 0.3598], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.4122]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-260.9267]], device='cuda:0')\n",
      "sigma0 grad tensor([-234.9180], device='cuda:0')\n",
      "sigma1 grad tensor([[-220.2086]], device='cuda:0')\n",
      "gamma grad tensor([[907.6584]], device='cuda:0')\n",
      "alpha grad tensor([[-2010.5669]], device='cuda:0')\n",
      "beta2 grad tensor([[2481.6135]], device='cuda:0')\n",
      "beta0 grad tensor([1077.8646], device='cuda:0')\n",
      "beta1 grad tensor([[1546.1785]], device='cuda:0')\n",
      "Epoch 81 | Loss: 6.1703\n",
      "alpha: 0.07553000003099442, beta0: 0.11505836248397827, beta1: -0.0002855733910109848, beta2: 0.0015279270010069013, \n",
      "gamma: 0.06370184570550919, sigma0: 0.26631924510002136, sigma1: 0.00014893608749844134, sigma2: -3.277743235230446e-05, sigmaX: 0.15500876307487488\n",
      "forward done\n",
      "tensor([0.0082, 0.1101, 0.3581, 0.6886, 0.4084], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.0919]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-507.1321]], device='cuda:0')\n",
      "sigma0 grad tensor([-575.0067], device='cuda:0')\n",
      "sigma1 grad tensor([[-487.0063]], device='cuda:0')\n",
      "gamma grad tensor([[4064.8179]], device='cuda:0')\n",
      "alpha grad tensor([[-7882.9858]], device='cuda:0')\n",
      "beta2 grad tensor([[7776.4717]], device='cuda:0')\n",
      "beta0 grad tensor([3704.7859], device='cuda:0')\n",
      "beta1 grad tensor([[5070.1099]], device='cuda:0')\n",
      "Epoch 82 | Loss: 12.4772\n",
      "alpha: 0.07554510980844498, beta0: 0.11504731327295303, beta1: -0.0002915534714702517, beta2: 0.001536161289550364, \n",
      "gamma: 0.06369832903146744, sigma0: 0.26632311940193176, sigma1: 0.00015106916544027627, sigma2: -3.2353607821278274e-05, sigmaX: 0.15500885248184204\n",
      "forward done\n",
      "tensor([0.0096, 0.0639, 0.2298, 0.6875, 0.4345], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.6061]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-385.5580]], device='cuda:0')\n",
      "sigma0 grad tensor([-399.1994], device='cuda:0')\n",
      "sigma1 grad tensor([[-349.6492]], device='cuda:0')\n",
      "gamma grad tensor([[2400.3503]], device='cuda:0')\n",
      "alpha grad tensor([[-4810.0396]], device='cuda:0')\n",
      "beta2 grad tensor([[5115.3335]], device='cuda:0')\n",
      "beta0 grad tensor([2335.5432], device='cuda:0')\n",
      "beta1 grad tensor([[3265.2859]], device='cuda:0')\n",
      "Epoch 83 | Loss: 7.7507\n",
      "alpha: 0.07560529559850693, beta0: 0.11501511931419373, beta1: -0.00032899039797484875, beta2: 0.0014915954088792205, \n",
      "gamma: 0.06367151439189911, sigma0: 0.26633021235466003, sigma1: 0.00015627211541868746, sigma2: -2.815896732499823e-05, sigmaX: 0.155008926987648\n",
      "forward done\n",
      "tensor([0.0144, 0.0742, 0.2228, 0.5946, 0.3687], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.8041]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-325.6863]], device='cuda:0')\n",
      "sigma0 grad tensor([-291.1817], device='cuda:0')\n",
      "sigma1 grad tensor([[-270.6064]], device='cuda:0')\n",
      "gamma grad tensor([[1525.2059]], device='cuda:0')\n",
      "alpha grad tensor([[-3151.4639]], device='cuda:0')\n",
      "beta2 grad tensor([[3718.2764]], device='cuda:0')\n",
      "beta0 grad tensor([1575.3733], device='cuda:0')\n",
      "beta1 grad tensor([[2280.8572]], device='cuda:0')\n",
      "Epoch 84 | Loss: 8.6227\n",
      "alpha: 0.07568496465682983, beta0: 0.11497361212968826, beta1: -0.00038174851215444505, beta2: 0.001418759929947555, \n",
      "gamma: 0.06363480538129807, sigma0: 0.2663387954235077, sigma1: 0.00016314054664690048, sigma2: -2.154639150830917e-05, sigmaX: 0.15500901639461517\n",
      "forward done\n",
      "tensor([0.0096, 0.0814, 0.2028, 0.6757, 0.4234], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.0266]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-533.9651]], device='cuda:0')\n",
      "sigma0 grad tensor([-606.0495], device='cuda:0')\n",
      "sigma1 grad tensor([[-521.2929]], device='cuda:0')\n",
      "gamma grad tensor([[3922.1819]], device='cuda:0')\n",
      "alpha grad tensor([[-7779.7959]], device='cuda:0')\n",
      "beta2 grad tensor([[7812.7153]], device='cuda:0')\n",
      "beta0 grad tensor([3718.6379], device='cuda:0')\n",
      "beta1 grad tensor([[5112.9180]], device='cuda:0')\n",
      "Epoch 85 | Loss: 9.4500\n",
      "alpha: 0.075826495885849, beta0: 0.11490321904420853, beta1: -0.000475084176287055, beta2: 0.0012823643628507853, \n",
      "gamma: 0.06356621533632278, sigma0: 0.26635172963142395, sigma1: 0.00017384820966981351, sigma2: -1.0916679457295686e-05, sigmaX: 0.15500910580158234\n",
      "forward done\n",
      "tensor([0.0122, 0.2011, 0.4525, 0.5788, 0.3396], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[0.0632]]], device='cuda:0')\n",
      "sigma2 grad tensor([[1085.0874]], device='cuda:0')\n",
      "sigma0 grad tensor([770.6333], device='cuda:0')\n",
      "sigma1 grad tensor([[803.4170]], device='cuda:0')\n",
      "gamma grad tensor([[-5889.6411]], device='cuda:0')\n",
      "alpha grad tensor([[11228.5049]], device='cuda:0')\n",
      "beta2 grad tensor([[-14061.6318]], device='cuda:0')\n",
      "beta0 grad tensor([-5203.0845], device='cuda:0')\n",
      "beta1 grad tensor([[-8041.1953]], device='cuda:0')\n",
      "Epoch 86 | Loss: 21.4945\n",
      "alpha: 0.07582743465900421, beta0: 0.1148989349603653, beta1: -0.0004693407681770623, beta2: 0.001313864253461361, \n",
      "gamma: 0.06357023864984512, sigma0: 0.26635435223579407, sigma1: 0.0001743801694829017, sigma2: -1.3263784239825327e-05, sigmaX: 0.1550091803073883\n",
      "forward done\n",
      "tensor([0.0096, 0.0641, 0.2382, 0.6453, 0.3547], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.3568]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-361.8278]], device='cuda:0')\n",
      "sigma0 grad tensor([-360.8558], device='cuda:0')\n",
      "sigma1 grad tensor([[-324.3597]], device='cuda:0')\n",
      "gamma grad tensor([[1923.0669]], device='cuda:0')\n",
      "alpha grad tensor([[-3974.0364]], device='cuda:0')\n",
      "beta2 grad tensor([[4430.2451]], device='cuda:0')\n",
      "beta0 grad tensor([1979.3134], device='cuda:0')\n",
      "beta1 grad tensor([[2792.2175]], device='cuda:0')\n",
      "Epoch 87 | Loss: 7.6618\n",
      "alpha: 0.07586792856454849, beta0: 0.11487571150064468, beta1: -0.0004926681867800653, beta2: 0.0012947616633027792, \n",
      "gamma: 0.06355422735214233, sigma0: 0.2663600742816925, sigma1: 0.0001780493330443278, sigma2: -1.152318964159349e-05, sigmaX: 0.15500926971435547\n",
      "forward done\n",
      "tensor([0.0128, 0.0718, 0.3573, 0.6320, 0.3587], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.1362]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-490.3276]], device='cuda:0')\n",
      "sigma0 grad tensor([-536.3897], device='cuda:0')\n",
      "sigma1 grad tensor([[-464.6930]], device='cuda:0')\n",
      "gamma grad tensor([[3585.6152]], device='cuda:0')\n",
      "alpha grad tensor([[-7056.5239]], device='cuda:0')\n",
      "beta2 grad tensor([[7367.3174]], device='cuda:0')\n",
      "beta0 grad tensor([3361.8667], device='cuda:0')\n",
      "beta1 grad tensor([[4693.3335]], device='cuda:0')\n",
      "Epoch 88 | Loss: 8.5407\n",
      "alpha: 0.07597088813781738, beta0: 0.11482352018356323, beta1: -0.0005582635058090091, beta2: 0.0012058065040037036, \n",
      "gamma: 0.06350556015968323, sigma0: 0.2663699984550476, sigma1: 0.00018563159392215312, sigma2: -5.227438123256434e-06, sigmaX: 0.15500935912132263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0128, 0.0634, 0.4824, 0.4992, 0.2453], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.8550]]], device='cuda:0')\n",
      "sigma2 grad tensor([[246.7818]], device='cuda:0')\n",
      "sigma0 grad tensor([216.9479], device='cuda:0')\n",
      "sigma1 grad tensor([[202.7777]], device='cuda:0')\n",
      "gamma grad tensor([[-2488.7751]], device='cuda:0')\n",
      "alpha grad tensor([[4577.1606]], device='cuda:0')\n",
      "beta2 grad tensor([[-5017.3364]], device='cuda:0')\n",
      "beta0 grad tensor([-1987.0968], device='cuda:0')\n",
      "beta1 grad tensor([[-2966.2407]], device='cuda:0')\n",
      "Epoch 89 | Loss: 7.5825\n",
      "alpha: 0.07600748538970947, beta0: 0.11480163782835007, beta1: -0.0005810773582197726, beta2: 0.001184815657325089, \n",
      "gamma: 0.06349151581525803, sigma0: 0.2663757801055908, sigma1: 0.0001896696339827031, sigma2: -2.658654466358712e-06, sigmaX: 0.1550094485282898\n",
      "forward done\n",
      "tensor([0.0100, 0.0557, 0.2011, 0.6481, 0.3739], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.4562]]], device='cuda:0')\n",
      "sigma2 grad tensor([[55.6171]], device='cuda:0')\n",
      "sigma0 grad tensor([82.2204], device='cuda:0')\n",
      "sigma1 grad tensor([[62.4618]], device='cuda:0')\n",
      "gamma grad tensor([[-1690.4724]], device='cuda:0')\n",
      "alpha grad tensor([[2935.9016]], device='cuda:0')\n",
      "beta2 grad tensor([[-2783.1501]], device='cuda:0')\n",
      "beta0 grad tensor([-1185.7706], device='cuda:0')\n",
      "beta1 grad tensor([[-1716.5730]], device='cuda:0')\n",
      "Epoch 90 | Loss: 6.8081\n",
      "alpha: 0.0760074034333229, beta0: 0.1147959902882576, beta1: -0.0005821626982651651, beta2: 0.0011958545073866844, \n",
      "gamma: 0.06349718570709229, sigma0: 0.26637959480285645, sigma1: 0.00019227544544264674, sigma2: -1.159798330263584e-06, sigmaX: 0.15500953793525696\n",
      "forward done\n",
      "tensor([0.0136, 0.0551, 0.4500, 0.6354, 0.3539], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.2404]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-268.7531]], device='cuda:0')\n",
      "sigma0 grad tensor([-233.4763], device='cuda:0')\n",
      "sigma1 grad tensor([[-219.5855]], device='cuda:0')\n",
      "gamma grad tensor([[1008.9406]], device='cuda:0')\n",
      "alpha grad tensor([[-2183.2041]], device='cuda:0')\n",
      "beta2 grad tensor([[2685.7708]], device='cuda:0')\n",
      "beta0 grad tensor([1146.5353], device='cuda:0')\n",
      "beta1 grad tensor([[1647.4451]], device='cuda:0')\n",
      "Epoch 91 | Loss: 6.9610\n",
      "alpha: 0.07602916657924652, beta0: 0.1147800013422966, beta1: -0.000599505438003689, beta2: 0.0011778278276324272, \n",
      "gamma: 0.06349163502454758, sigma0: 0.26638495922088623, sigma1: 0.00019655594951473176, sigma2: 2.7268172289041104e-06, sigmaX: 0.15500962734222412\n",
      "forward done\n",
      "tensor([0.0102, 0.0657, 0.1465, 0.6450, 0.3505], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.1825]]], device='cuda:0')\n",
      "sigma2 grad tensor([[635.2703]], device='cuda:0')\n",
      "sigma0 grad tensor([649.1714], device='cuda:0')\n",
      "sigma1 grad tensor([[588.8262]], device='cuda:0')\n",
      "gamma grad tensor([[-4816.3262]], device='cuda:0')\n",
      "alpha grad tensor([[9342.3643]], device='cuda:0')\n",
      "beta2 grad tensor([[-9972.5938]], device='cuda:0')\n",
      "beta0 grad tensor([-4387.8726], device='cuda:0')\n",
      "beta1 grad tensor([[-6268.8999]], device='cuda:0')\n",
      "Epoch 92 | Loss: 7.7267\n",
      "alpha: 0.0759531557559967, beta0: 0.11481109261512756, beta1: -0.000550690630916506, beta2: 0.0012631324352696538, \n",
      "gamma: 0.06353535503149033, sigma0: 0.26638275384902954, sigma1: 0.00019409209198784083, sigma2: -5.165933885109553e-07, sigmaX: 0.15500971674919128\n",
      "forward done\n",
      "tensor([0.0180, 0.2353, 0.3340, 0.6103, 0.3274], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.6970]]], device='cuda:0')\n",
      "sigma2 grad tensor([[1093.8241]], device='cuda:0')\n",
      "sigma0 grad tensor([794.0003], device='cuda:0')\n",
      "sigma1 grad tensor([[833.1779]], device='cuda:0')\n",
      "gamma grad tensor([[-5658.0547]], device='cuda:0')\n",
      "alpha grad tensor([[10953.1182]], device='cuda:0')\n",
      "beta2 grad tensor([[-14230.2520]], device='cuda:0')\n",
      "beta0 grad tensor([-5147.8872], device='cuda:0')\n",
      "beta1 grad tensor([[-8079.7622]], device='cuda:0')\n",
      "Epoch 93 | Loss: 24.8219\n",
      "alpha: 0.07578281313180923, beta0: 0.11488744616508484, beta1: -0.00043084114440716803, beta2: 0.001473678625188768, \n",
      "gamma: 0.06362691521644592, sigma0: 0.26637306809425354, sigma1: 0.00018378921959083527, sigma2: -1.4049563105800189e-05, sigmaX: 0.15500980615615845\n",
      "forward done\n",
      "tensor([0.0084, 0.0495, 0.1505, 0.6277, 0.3495], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-3.1239]]], device='cuda:0')\n",
      "sigma2 grad tensor([[175.0350]], device='cuda:0')\n",
      "sigma0 grad tensor([198.0212], device='cuda:0')\n",
      "sigma1 grad tensor([[173.7364]], device='cuda:0')\n",
      "gamma grad tensor([[-2370.9897]], device='cuda:0')\n",
      "alpha grad tensor([[4357.5591]], device='cuda:0')\n",
      "beta2 grad tensor([[-4218.0190]], device='cuda:0')\n",
      "beta0 grad tensor([-1885.1433], device='cuda:0')\n",
      "beta1 grad tensor([[-2668.7769]], device='cuda:0')\n",
      "Epoch 94 | Loss: 6.0828\n",
      "alpha: 0.07560296356678009, beta0: 0.11496737599372864, beta1: -0.0003082737675867975, beta2: 0.0016842958284541965, \n",
      "gamma: 0.06372386962175369, sigma0: 0.26636332273483276, sigma1: 0.00017380955978296697, sigma2: -2.6626288672559895e-05, sigmaX: 0.1550099104642868\n",
      "forward done\n",
      "tensor([0.0180, 0.1649, 0.1221, 0.6887, 0.3823], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.7020]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-405.3506]], device='cuda:0')\n",
      "sigma0 grad tensor([-535.8958], device='cuda:0')\n",
      "sigma1 grad tensor([[-419.7812]], device='cuda:0')\n",
      "gamma grad tensor([[3737.1877]], device='cuda:0')\n",
      "alpha grad tensor([[-7308.1367]], device='cuda:0')\n",
      "beta2 grad tensor([[6822.9849]], device='cuda:0')\n",
      "beta0 grad tensor([3447.4141], device='cuda:0')\n",
      "beta1 grad tensor([[4588.6489]], device='cuda:0')\n",
      "Epoch 95 | Loss: 17.7017\n",
      "alpha: 0.07553216814994812, beta0: 0.11499685049057007, beta1: -0.0002561063738539815, beta2: 0.0017845596885308623, \n",
      "gamma: 0.0637640655040741, sigma0: 0.26636090874671936, sigma1: 0.00017002364620566368, sigma2: -3.263416147092357e-05, sigmaX: 0.15500999987125397\n",
      "forward done\n",
      "tensor([0.0096, 0.0806, 0.2750, 0.6394, 0.3361], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.0874]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-600.0809]], device='cuda:0')\n",
      "sigma0 grad tensor([-568.0898], device='cuda:0')\n",
      "sigma1 grad tensor([[-526.7794]], device='cuda:0')\n",
      "gamma grad tensor([[4353.2339]], device='cuda:0')\n",
      "alpha grad tensor([[-8286.3193]], device='cuda:0')\n",
      "beta2 grad tensor([[8410.3936]], device='cuda:0')\n",
      "beta0 grad tensor([3835.7683], device='cuda:0')\n",
      "beta1 grad tensor([[5352.8647]], device='cuda:0')\n",
      "Epoch 96 | Loss: 9.3237\n",
      "alpha: 0.07555839419364929, beta0: 0.11498206853866577, beta1: -0.0002679011086001992, beta2: 0.0017806668765842915, \n",
      "gamma: 0.0637526884675026, sigma0: 0.2663646340370178, sigma1: 0.0001722627057461068, sigma2: -3.1439649319509044e-05, sigmaX: 0.15501008927822113\n",
      "forward done\n",
      "tensor([0.0203, 0.1829, 0.1757, 0.6585, 0.3867], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.9928]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-527.0187]], device='cuda:0')\n",
      "sigma0 grad tensor([-514.6705], device='cuda:0')\n",
      "sigma1 grad tensor([[-459.9036]], device='cuda:0')\n",
      "gamma grad tensor([[3582.6047]], device='cuda:0')\n",
      "alpha grad tensor([[-6996.3896]], device='cuda:0')\n",
      "beta2 grad tensor([[7080.2988]], device='cuda:0')\n",
      "beta0 grad tensor([3294.5273], device='cuda:0')\n",
      "beta1 grad tensor([[4547.0522]], device='cuda:0')\n",
      "Epoch 97 | Loss: 19.5358\n",
      "alpha: 0.07564933598041534, beta0: 0.11493729799985886, beta1: -0.0003228074056096375, beta2: 0.0017067496664822102, \n",
      "gamma: 0.06370776146650314, sigma0: 0.26637277007102966, sigma1: 0.00017865299014374614, sigma2: -2.521385431464296e-05, sigmaX: 0.1550101786851883\n",
      "forward done\n",
      "tensor([0.0190, 0.2356, 0.1799, 0.6989, 0.4113], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.1843]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-374.6953]], device='cuda:0')\n",
      "sigma0 grad tensor([-487.4885], device='cuda:0')\n",
      "sigma1 grad tensor([[-385.1323]], device='cuda:0')\n",
      "gamma grad tensor([[3114.4934]], device='cuda:0')\n",
      "alpha grad tensor([[-6237.3613]], device='cuda:0')\n",
      "beta2 grad tensor([[5822.4106]], device='cuda:0')\n",
      "beta0 grad tensor([3001.9656], device='cuda:0')\n",
      "beta1 grad tensor([[3953.9373]], device='cuda:0')\n",
      "Epoch 98 | Loss: 24.8664\n",
      "alpha: 0.07578446716070175, beta0: 0.11487146466970444, beta1: -0.00040627180715091527, beta2: 0.0015893917297944427, \n",
      "gamma: 0.06364067643880844, sigma0: 0.26638415455818176, sigma1: 0.0001876165479188785, sigma2: -1.6486264939885587e-05, sigmaX: 0.15501025319099426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0102, 0.0444, 0.3798, 0.6259, 0.4005], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.8268]]], device='cuda:0')\n",
      "sigma2 grad tensor([[181.7284]], device='cuda:0')\n",
      "sigma0 grad tensor([167.9086], device='cuda:0')\n",
      "sigma1 grad tensor([[151.6449]], device='cuda:0')\n",
      "gamma grad tensor([[-1950.9703]], device='cuda:0')\n",
      "alpha grad tensor([[3583.0168]], device='cuda:0')\n",
      "beta2 grad tensor([[-3693.7839]], device='cuda:0')\n",
      "beta0 grad tensor([-1546.6288], device='cuda:0')\n",
      "beta1 grad tensor([[-2245.4751]], device='cuda:0')\n",
      "Epoch 99 | Loss: 5.8520\n",
      "alpha: 0.07585673779249191, beta0: 0.114834263920784, beta1: -0.0004505885881371796, beta2: 0.0015324432170018554, \n",
      "gamma: 0.06360651552677155, sigma0: 0.2663915753364563, sigma1: 0.00019327094196341932, sigma2: -1.1321477359160781e-05, sigmaX: 0.15501032769680023\n",
      "forward done\n",
      "tensor([0.0120, 0.1215, 0.3416, 0.6040, 0.3423], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.1472]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-479.1753]], device='cuda:0')\n",
      "sigma0 grad tensor([-566.9252], device='cuda:0')\n",
      "sigma1 grad tensor([[-465.6872]], device='cuda:0')\n",
      "gamma grad tensor([[4000.4990]], device='cuda:0')\n",
      "alpha grad tensor([[-7782.8232]], device='cuda:0')\n",
      "beta2 grad tensor([[7760.0986]], device='cuda:0')\n",
      "beta0 grad tensor([3667.6440], device='cuda:0')\n",
      "beta1 grad tensor([[5027.2051]], device='cuda:0')\n",
      "Epoch 100 | Loss: 13.4503\n",
      "alpha: 0.07599238306283951, beta0: 0.11476782709360123, beta1: -0.0005363140371628106, beta2: 0.001409283489920199, \n",
      "gamma: 0.06353918462991714, sigma0: 0.2664031982421875, sigma1: 0.00020245132327545434, sigma2: -2.3978946046554483e-06, sigmaX: 0.1550104171037674\n",
      "forward done\n",
      "tensor([0.0123, 0.0539, 0.1509, 0.6770, 0.3805], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.1166]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-698.1644]], device='cuda:0')\n",
      "sigma0 grad tensor([-612.8240], device='cuda:0')\n",
      "sigma1 grad tensor([[-586.0856]], device='cuda:0')\n",
      "gamma grad tensor([[3928.7073]], device='cuda:0')\n",
      "alpha grad tensor([[-7847.5503]], device='cuda:0')\n",
      "beta2 grad tensor([[8845.7842]], device='cuda:0')\n",
      "beta0 grad tensor([3769.7039], device='cuda:0')\n",
      "beta1 grad tensor([[5449.5430]], device='cuda:0')\n",
      "Epoch 101 | Loss: 6.6065\n",
      "alpha: 0.0761793777346611, beta0: 0.11467698216438293, beta1: -0.0006593898287974298, beta2: 0.0012222977820783854, \n",
      "gamma: 0.0634460300207138, sigma0: 0.26641860604286194, sigma1: 0.0002156564878532663, sigma2: 1.1722615454345942e-05, sigmaX: 0.15501049160957336\n",
      "forward done\n",
      "tensor([0.0151, 0.1913, 0.3827, 0.5924, 0.4695], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[0.7708]]], device='cuda:0')\n",
      "sigma2 grad tensor([[991.8790]], device='cuda:0')\n",
      "sigma0 grad tensor([763.3487], device='cuda:0')\n",
      "sigma1 grad tensor([[780.7236]], device='cuda:0')\n",
      "gamma grad tensor([[-6043.6201]], device='cuda:0')\n",
      "alpha grad tensor([[11483.9922]], device='cuda:0')\n",
      "beta2 grad tensor([[-14155.6699]], device='cuda:0')\n",
      "beta0 grad tensor([-5316.3784], device='cuda:0')\n",
      "beta1 grad tensor([[-8194.0762]], device='cuda:0')\n",
      "Epoch 102 | Loss: 20.5887\n",
      "alpha: 0.07621413469314575, beta0: 0.11465746909379959, beta1: -0.000675909745041281, beta2: 0.0012142659397795796, \n",
      "gamma: 0.06343194097280502, sigma0: 0.2664233148097992, sigma1: 0.00021841337729711086, sigma2: 1.3100233445584308e-05, sigmaX: 0.15501055121421814\n",
      "forward done\n",
      "tensor([0.0138, 0.0485, 0.2710, 0.6220, 0.3583], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-3.0613]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-671.1293]], device='cuda:0')\n",
      "sigma0 grad tensor([-623.2035], device='cuda:0')\n",
      "sigma1 grad tensor([[-588.6677]], device='cuda:0')\n",
      "gamma grad tensor([[4426.9116]], device='cuda:0')\n",
      "alpha grad tensor([[-8651.9883]], device='cuda:0')\n",
      "beta2 grad tensor([[9394.5830]], device='cuda:0')\n",
      "beta0 grad tensor([4094.4729], device='cuda:0')\n",
      "beta1 grad tensor([[5867.4854]], device='cuda:0')\n",
      "Epoch 103 | Loss: 6.1117\n",
      "alpha: 0.07632845640182495, beta0: 0.11460091173648834, beta1: -0.0007478005136363208, beta2: 0.0011138946283608675, \n",
      "gamma: 0.06337640434503555, sigma0: 0.2664332985877991, sigma1: 0.0002265055663883686, sigma2: 2.0913621483487077e-05, sigmaX: 0.1550106257200241\n",
      "forward done\n",
      "tensor([0.0126, 0.0746, 0.2560, 0.5959, 0.3426], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-4.7982]]], device='cuda:0')\n",
      "sigma2 grad tensor([[844.3486]], device='cuda:0')\n",
      "sigma0 grad tensor([689.5296], device='cuda:0')\n",
      "sigma1 grad tensor([[671.7780]], device='cuda:0')\n",
      "gamma grad tensor([[-5348.2998]], device='cuda:0')\n",
      "alpha grad tensor([[10214.4102]], device='cuda:0')\n",
      "beta2 grad tensor([[-12060.0127]], device='cuda:0')\n",
      "beta0 grad tensor([-4744.6660], device='cuda:0')\n",
      "beta1 grad tensor([[-7122.9814]], device='cuda:0')\n",
      "Epoch 104 | Loss: 8.6718\n",
      "alpha: 0.07631777226924896, beta0: 0.11460311710834503, beta1: -0.0007340832962654531, beta2: 0.0011541977291926742, \n",
      "gamma: 0.06338545680046082, sigma0: 0.2664344012737274, sigma1: 0.00022626154532190412, sigma2: 1.8720844309427775e-05, sigmaX: 0.15501073002815247\n",
      "forward done\n",
      "tensor([0.0138, 0.0818, 0.1297, 0.6171, 0.3162], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.3599]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-650.5382]], device='cuda:0')\n",
      "sigma0 grad tensor([-604.5702], device='cuda:0')\n",
      "sigma1 grad tensor([[-545.5618]], device='cuda:0')\n",
      "gamma grad tensor([[4814.5244]], device='cuda:0')\n",
      "alpha grad tensor([[-9131.9766]], device='cuda:0')\n",
      "beta2 grad tensor([[9822.5107]], device='cuda:0')\n",
      "beta0 grad tensor([4234.5254], device='cuda:0')\n",
      "beta1 grad tensor([[6047.4258]], device='cuda:0')\n",
      "Epoch 105 | Loss: 9.2538\n",
      "alpha: 0.07640054076910019, beta0: 0.11456253379583359, beta1: -0.0007835837895981967, beta2: 0.0010882150381803513, \n",
      "gamma: 0.0633445531129837, sigma0: 0.26644131541252136, sigma1: 0.0002315219462616369, sigma2: 2.3472004613722675e-05, sigmaX: 0.15501083433628082\n",
      "forward done\n",
      "tensor([0.0159, 0.1575, 0.3292, 0.6372, 0.3512], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-4.0503]]], device='cuda:0')\n",
      "sigma2 grad tensor([[751.0480]], device='cuda:0')\n",
      "sigma0 grad tensor([728.8139], device='cuda:0')\n",
      "sigma1 grad tensor([[659.0447]], device='cuda:0')\n",
      "gamma grad tensor([[-6137.9336]], device='cuda:0')\n",
      "alpha grad tensor([[11585.0078]], device='cuda:0')\n",
      "beta2 grad tensor([[-13198.2188]], device='cuda:0')\n",
      "beta0 grad tensor([-5331.0806], device='cuda:0')\n",
      "beta1 grad tensor([[-7915.9209]], device='cuda:0')\n",
      "Epoch 106 | Loss: 17.0835\n",
      "alpha: 0.07635090500116348, beta0: 0.11458338052034378, beta1: -0.0007440249901264906, beta2: 0.001167411101050675, \n",
      "gamma: 0.06337320804595947, sigma0: 0.2664395570755005, sigma1: 0.0002291398122906685, sigma2: 1.976245221158024e-05, sigmaX: 0.15501096844673157\n",
      "forward done\n",
      "tensor([0.0151, 0.2706, 0.4576, 0.5528, 0.2908], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.5976]]], device='cuda:0')\n",
      "sigma2 grad tensor([[1157.6444]], device='cuda:0')\n",
      "sigma0 grad tensor([824.1938], device='cuda:0')\n",
      "sigma1 grad tensor([[863.3740]], device='cuda:0')\n",
      "gamma grad tensor([[-6807.6157]], device='cuda:0')\n",
      "alpha grad tensor([[12796.2803]], device='cuda:0')\n",
      "beta2 grad tensor([[-16559.7520]], device='cuda:0')\n",
      "beta0 grad tensor([-5866.2324], device='cuda:0')\n",
      "beta1 grad tensor([[-9260.3262]], device='cuda:0')\n",
      "Epoch 107 | Loss: 28.3736\n",
      "alpha: 0.07618323713541031, beta0: 0.11465872079133987, beta1: -0.0006197746843099594, beta2: 0.001396365463733673, \n",
      "gamma: 0.0634642094373703, sigma0: 0.26642993092536926, sigma1: 0.00021860036940779537, sigma2: 5.2183668231009506e-06, sigmaX: 0.15501107275485992\n",
      "forward done\n",
      "tensor([0.0136, 0.2894, 0.3577, 0.6014, 0.3303], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.2530]]], device='cuda:0')\n",
      "sigma2 grad tensor([[1115.8319]], device='cuda:0')\n",
      "sigma0 grad tensor([818.5238], device='cuda:0')\n",
      "sigma1 grad tensor([[849.1144]], device='cuda:0')\n",
      "gamma grad tensor([[-6356.5547]], device='cuda:0')\n",
      "alpha grad tensor([[12098.4014]], device='cuda:0')\n",
      "beta2 grad tensor([[-14683.3203]], device='cuda:0')\n",
      "beta0 grad tensor([-5601.9282], device='cuda:0')\n",
      "beta1 grad tensor([[-8529.0986]], device='cuda:0')\n",
      "Epoch 108 | Loss: 30.2409\n",
      "alpha: 0.07592811435461044, beta0: 0.11477500945329666, beta1: -0.00043508343514986336, beta2: 0.0017263621557503939, \n",
      "gamma: 0.0636005774140358, sigma0: 0.2664140462875366, sigma1: 0.00020167767070233822, sigma2: -1.757522113621235e-05, sigmaX: 0.15501117706298828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0153, 0.0405, 0.1662, 0.6884, 0.4063], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.6098]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-28.5329]], device='cuda:0')\n",
      "sigma0 grad tensor([-12.8257], device='cuda:0')\n",
      "sigma1 grad tensor([[-18.2170]], device='cuda:0')\n",
      "gamma grad tensor([[-876.2151]], device='cuda:0')\n",
      "alpha grad tensor([[1408.8293]], device='cuda:0')\n",
      "beta2 grad tensor([[-1149.4070]], device='cuda:0')\n",
      "beta0 grad tensor([-490.2572], device='cuda:0')\n",
      "beta1 grad tensor([[-710.3933]], device='cuda:0')\n",
      "Epoch 109 | Loss: 5.3293\n",
      "alpha: 0.07570993155241013, beta0: 0.11487293988466263, beta1: -0.0002802264934871346, beta2: 0.002001853659749031, \n",
      "gamma: 0.06371843069791794, sigma0: 0.266401469707489, sigma1: 0.00018832169007509947, sigma2: -3.5524764825822785e-05, sigmaX: 0.15501126646995544\n",
      "forward done\n",
      "tensor([0.0082, 0.0514, 0.1208, 0.6882, 0.3905], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.7700]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-94.1726]], device='cuda:0')\n",
      "sigma0 grad tensor([-80.1577], device='cuda:0')\n",
      "sigma1 grad tensor([[-77.5305]], device='cuda:0')\n",
      "gamma grad tensor([[-288.8342]], device='cuda:0')\n",
      "alpha grad tensor([[276.8647]], device='cuda:0')\n",
      "beta2 grad tensor([[54.6309]], device='cuda:0')\n",
      "beta0 grad tensor([21.9439], device='cuda:0')\n",
      "beta1 grad tensor([[33.7232]], device='cuda:0')\n",
      "Epoch 110 | Loss: 6.3485\n",
      "alpha: 0.07553261518478394, beta0: 0.11495106667280197, beta1: -0.00015667818661313504, beta2: 0.0022217005025595427, \n",
      "gamma: 0.06381560117006302, sigma0: 0.26639220118522644, sigma1: 0.00017841219960246235, sigma2: -4.894267476629466e-05, sigmaX: 0.1550113558769226\n",
      "forward done\n",
      "tensor([0.0184, 0.1745, 0.1026, 0.7171, 0.3992], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.1157]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-455.1587]], device='cuda:0')\n",
      "sigma0 grad tensor([-513.4825], device='cuda:0')\n",
      "sigma1 grad tensor([[-431.2688]], device='cuda:0')\n",
      "gamma grad tensor([[3468.5190]], device='cuda:0')\n",
      "alpha grad tensor([[-6785.2974]], device='cuda:0')\n",
      "beta2 grad tensor([[6415.7891]], device='cuda:0')\n",
      "beta0 grad tensor([3196.2671], device='cuda:0')\n",
      "beta1 grad tensor([[4276.4302]], device='cuda:0')\n",
      "Epoch 111 | Loss: 18.6839\n",
      "alpha: 0.07545861601829529, beta0: 0.11498160660266876, beta1: -0.00010060383647214621, beta2: 0.0023334200959652662, \n",
      "gamma: 0.06385865062475204, sigma0: 0.2663899064064026, sigma1: 0.00017479730013292283, sigma2: -5.512541611096822e-05, sigmaX: 0.15501144528388977\n",
      "forward done\n",
      "tensor([0.0119, 0.0711, 0.0977, 0.6350, 0.3502], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.1263]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-606.7686]], device='cuda:0')\n",
      "sigma0 grad tensor([-551.7043], device='cuda:0')\n",
      "sigma1 grad tensor([[-519.8693]], device='cuda:0')\n",
      "gamma grad tensor([[3687.3442]], device='cuda:0')\n",
      "alpha grad tensor([[-7229.1318]], device='cuda:0')\n",
      "beta2 grad tensor([[7577.8452]], device='cuda:0')\n",
      "beta0 grad tensor([3418.1182], device='cuda:0')\n",
      "beta1 grad tensor([[4811.0020]], device='cuda:0')\n",
      "Epoch 112 | Loss: 8.2046\n",
      "alpha: 0.07547170668840408, beta0: 0.11497185379266739, beta1: -0.00010385437053628266, beta2: 0.002347017405554652, \n",
      "gamma: 0.06385622173547745, sigma0: 0.26639360189437866, sigma1: 0.00017710406973492354, sigma2: -5.4003921832190827e-05, sigmaX: 0.15501153469085693\n",
      "forward done\n",
      "tensor([0.0142, 0.0375, 0.1489, 0.6773, 0.3929], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.2844]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-217.0132]], device='cuda:0')\n",
      "sigma0 grad tensor([-180.6019], device='cuda:0')\n",
      "sigma1 grad tensor([[-178.4731]], device='cuda:0')\n",
      "gamma grad tensor([[429.9493]], device='cuda:0')\n",
      "alpha grad tensor([[-1123.0546]], device='cuda:0')\n",
      "beta2 grad tensor([[1561.4749]], device='cuda:0')\n",
      "beta0 grad tensor([674.8842], device='cuda:0')\n",
      "beta1 grad tensor([[973.3014]], device='cuda:0')\n",
      "Epoch 113 | Loss: 4.9849\n",
      "alpha: 0.07549341022968292, beta0: 0.1149573028087616, beta1: -0.00011618781718425453, beta2: 0.0023422804661095142, \n",
      "gamma: 0.06384997814893723, sigma0: 0.2663983702659607, sigma1: 0.0001807342196116224, sigma2: -5.093659638077952e-05, sigmaX: 0.1550116091966629\n",
      "forward done\n",
      "tensor([0.0097, 0.0352, 0.5130, 0.6474, 0.3707], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.8289]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-43.3454]], device='cuda:0')\n",
      "sigma0 grad tensor([-20.4228], device='cuda:0')\n",
      "sigma1 grad tensor([[-24.1778]], device='cuda:0')\n",
      "gamma grad tensor([[-835.5782]], device='cuda:0')\n",
      "alpha grad tensor([[1319.1558]], device='cuda:0')\n",
      "beta2 grad tensor([[-1009.3384]], device='cuda:0')\n",
      "beta0 grad tensor([-441.9750], device='cuda:0')\n",
      "beta1 grad tensor([[-631.0243]], device='cuda:0')\n",
      "Epoch 114 | Loss: 5.0638\n",
      "alpha: 0.0754975825548172, beta0: 0.11495008319616318, beta1: -0.00011974432709394023, beta2: 0.0023485843557864428, \n",
      "gamma: 0.06385333836078644, sigma0: 0.26640239357948303, sigma1: 0.00018388011085335165, sigma2: -4.804928175872192e-05, sigmaX: 0.15501168370246887\n",
      "forward done\n",
      "tensor([0.0196, 0.1457, 0.1953, 0.6104, 0.3690], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.6843]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-542.2501]], device='cuda:0')\n",
      "sigma0 grad tensor([-504.7629], device='cuda:0')\n",
      "sigma1 grad tensor([[-462.8300]], device='cuda:0')\n",
      "gamma grad tensor([[3482.3635]], device='cuda:0')\n",
      "alpha grad tensor([[-6797.8774]], device='cuda:0')\n",
      "beta2 grad tensor([[7025.6709]], device='cuda:0')\n",
      "beta0 grad tensor([3197.5195], device='cuda:0')\n",
      "beta1 grad tensor([[4469.9453]], device='cuda:0')\n",
      "Epoch 115 | Loss: 15.7613\n",
      "alpha: 0.07556889951229095, beta0: 0.11491233110427856, beta1: -0.00016728899208828807, beta2: 0.0022833705879747868, \n",
      "gamma: 0.0638212040066719, sigma0: 0.2664106488227844, sigma1: 0.00019102513033431023, sigma2: -4.0316928789252415e-05, sigmaX: 0.15501177310943604\n",
      "forward done\n",
      "tensor([0.0311, 0.2799, 0.1057, 0.7046, 0.4729], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.0365]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-287.0098]], device='cuda:0')\n",
      "sigma0 grad tensor([-444.1762], device='cuda:0')\n",
      "sigma1 grad tensor([[-322.9896]], device='cuda:0')\n",
      "gamma grad tensor([[3017.1243]], device='cuda:0')\n",
      "alpha grad tensor([[-5915.5967]], device='cuda:0')\n",
      "beta2 grad tensor([[5154.0649]], device='cuda:0')\n",
      "beta0 grad tensor([2799.6072], device='cuda:0')\n",
      "beta1 grad tensor([[3589.0261]], device='cuda:0')\n",
      "Epoch 116 | Loss: 29.3030\n",
      "alpha: 0.07568510621786118, beta0: 0.11485413461923599, beta1: -0.00024121497699525207, beta2: 0.0021796589717268944, \n",
      "gamma: 0.06376532465219498, sigma0: 0.26642170548439026, sigma1: 0.00019997103663627058, sigma2: -3.126094816252589e-05, sigmaX: 0.1550118327140808\n",
      "forward done\n",
      "tensor([0.0192, 0.1601, 0.2833, 0.6507, 0.3578], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.4445]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-454.5237]], device='cuda:0')\n",
      "sigma0 grad tensor([-512.1158], device='cuda:0')\n",
      "sigma1 grad tensor([[-440.6823]], device='cuda:0')\n",
      "gamma grad tensor([[3713.7219]], device='cuda:0')\n",
      "alpha grad tensor([[-7163.2437]], device='cuda:0')\n",
      "beta2 grad tensor([[6957.9565]], device='cuda:0')\n",
      "beta0 grad tensor([3339.9424], device='cuda:0')\n",
      "beta1 grad tensor([[4562.1719]], device='cuda:0')\n",
      "Epoch 117 | Loss: 17.3197\n",
      "alpha: 0.07584970444440842, beta0: 0.1147741749882698, beta1: -0.0003459774889051914, beta2: 0.0020271101966500282, \n",
      "gamma: 0.06368348747491837, sigma0: 0.2664356529712677, sigma1: 0.00021153458510525525, sigma2: -1.9470926417852752e-05, sigmaX: 0.15501190721988678\n",
      "forward done\n",
      "tensor([0.0101, 0.0649, 0.0855, 0.7007, 0.4009], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.2082]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-402.0293]], device='cuda:0')\n",
      "sigma0 grad tensor([-406.4192], device='cuda:0')\n",
      "sigma1 grad tensor([[-363.0485]], device='cuda:0')\n",
      "gamma grad tensor([[2345.9431]], device='cuda:0')\n",
      "alpha grad tensor([[-4795.6113]], device='cuda:0')\n",
      "beta2 grad tensor([[5011.6455]], device='cuda:0')\n",
      "beta0 grad tensor([2348.5337], device='cuda:0')\n",
      "beta1 grad tensor([[3239.2300]], device='cuda:0')\n",
      "Epoch 118 | Loss: 7.6852\n",
      "alpha: 0.07602933794260025, beta0: 0.11468672752380371, beta1: -0.0004621797997970134, beta2: 0.0018549546366557479, \n",
      "gamma: 0.06359455734491348, sigma0: 0.2664508819580078, sigma1: 0.00022441591136157513, sigma2: -6.01861574978102e-06, sigmaX: 0.15501198172569275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0090, 0.0788, 0.2313, 0.6287, 0.3647], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.9156]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-592.3128]], device='cuda:0')\n",
      "sigma0 grad tensor([-574.9254], device='cuda:0')\n",
      "sigma1 grad tensor([[-527.6480]], device='cuda:0')\n",
      "gamma grad tensor([[4219.3853]], device='cuda:0')\n",
      "alpha grad tensor([[-8136.9751]], device='cuda:0')\n",
      "beta2 grad tensor([[8342.2324]], device='cuda:0')\n",
      "beta0 grad tensor([3798.5435], device='cuda:0')\n",
      "beta1 grad tensor([[5329.8496]], device='cuda:0')\n",
      "Epoch 119 | Loss: 9.1133\n",
      "alpha: 0.07625441253185272, beta0: 0.11457878351211548, beta1: -0.0006084401393309236, beta2: 0.0016338079003617167, \n",
      "gamma: 0.06348121911287308, sigma0: 0.2664688229560852, sigma1: 0.00023999744735192508, sigma2: 1.0666361959010828e-05, sigmaX: 0.15501205623149872\n",
      "forward done\n",
      "tensor([0.0188, 0.1608, 0.2499, 0.6672, 0.3772], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.9973]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-477.6022]], device='cuda:0')\n",
      "sigma0 grad tensor([-550.0509], device='cuda:0')\n",
      "sigma1 grad tensor([[-463.6956]], device='cuda:0')\n",
      "gamma grad tensor([[3219.5586]], device='cuda:0')\n",
      "alpha grad tensor([[-6579.5488]], device='cuda:0')\n",
      "beta2 grad tensor([[6886.1602]], device='cuda:0')\n",
      "beta0 grad tensor([3207.3188], device='cuda:0')\n",
      "beta1 grad tensor([[4435.7090]], device='cuda:0')\n",
      "Epoch 120 | Loss: 17.3927\n",
      "alpha: 0.07650027424097061, beta0: 0.11446035653352737, beta1: -0.0007698055123910308, beta2: 0.0013880289625376463, \n",
      "gamma: 0.0633583515882492, sigma0: 0.2664886713027954, sigma1: 0.0002570996293798089, sigma2: 2.879036583181005e-05, sigmaX: 0.15501214563846588\n",
      "forward done\n",
      "tensor([0.0097, 0.0620, 0.1941, 0.6603, 0.3708], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.3599]]], device='cuda:0')\n",
      "sigma2 grad tensor([[450.8903]], device='cuda:0')\n",
      "sigma0 grad tensor([386.6279], device='cuda:0')\n",
      "sigma1 grad tensor([[377.7738]], device='cuda:0')\n",
      "gamma grad tensor([[-3631.8323]], device='cuda:0')\n",
      "alpha grad tensor([[6825.1221]], device='cuda:0')\n",
      "beta2 grad tensor([[-7704.5122]], device='cuda:0')\n",
      "beta0 grad tensor([-3072.7598], device='cuda:0')\n",
      "beta1 grad tensor([[-4611.5581]], device='cuda:0')\n",
      "Epoch 121 | Loss: 7.4329\n",
      "alpha: 0.07662870734930038, beta0: 0.1143963411450386, beta1: -0.0008527822210453451, beta2: 0.0012684508692473173, \n",
      "gamma: 0.063296377658844, sigma0: 0.26650068163871765, sigma1: 0.0002670036337804049, sigma2: 3.878066490869969e-05, sigmaX: 0.15501223504543304\n",
      "forward done\n",
      "tensor([0.0141, 0.0394, 0.2130, 0.5870, 0.3491], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.8267]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-87.1982]], device='cuda:0')\n",
      "sigma0 grad tensor([-63.7738], device='cuda:0')\n",
      "sigma1 grad tensor([[-65.0693]], device='cuda:0')\n",
      "gamma grad tensor([[-522.8582]], device='cuda:0')\n",
      "alpha grad tensor([[716.8704]], device='cuda:0')\n",
      "beta2 grad tensor([[-358.8548]], device='cuda:0')\n",
      "beta0 grad tensor([-168.6989], device='cuda:0')\n",
      "beta1 grad tensor([[-231.9188]], device='cuda:0')\n",
      "Epoch 122 | Loss: 5.1054\n",
      "alpha: 0.07672428339719772, beta0: 0.11434681713581085, beta1: -0.000916844408493489, beta2: 0.0011763769434764981, \n",
      "gamma: 0.0632520243525505, sigma0: 0.266510933637619, sigma1: 0.0002755775349214673, sigma2: 4.764488767250441e-05, sigmaX: 0.1550123393535614\n",
      "forward done\n",
      "tensor([0.0223, 0.0403, 0.3191, 0.5942, 0.3471], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.5951]]], device='cuda:0')\n",
      "sigma2 grad tensor([[6.6818]], device='cuda:0')\n",
      "sigma0 grad tensor([10.7709], device='cuda:0')\n",
      "sigma1 grad tensor([[9.4281]], device='cuda:0')\n",
      "gamma grad tensor([[-1245.9414]], device='cuda:0')\n",
      "alpha grad tensor([[2065.3391]], device='cuda:0')\n",
      "beta2 grad tensor([[-1968.3921]], device='cuda:0')\n",
      "beta0 grad tensor([-777.8286], device='cuda:0')\n",
      "beta1 grad tensor([[-1166.4271]], device='cuda:0')\n",
      "Epoch 123 | Loss: 5.3172\n",
      "alpha: 0.07678009569644928, beta0: 0.1143149733543396, beta1: -0.0009564298670738935, beta2: 0.0011224017944186926, \n",
      "gamma: 0.06322900205850601, sigma0: 0.2665190100669861, sigma1: 0.00028234237106516957, sigma2: 5.466944639920257e-05, sigmaX: 0.15501244366168976\n",
      "forward done\n",
      "tensor([0.0180, 0.3107, 0.4420, 0.5643, 0.3081], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.6030]]], device='cuda:0')\n",
      "sigma2 grad tensor([[1001.7690]], device='cuda:0')\n",
      "sigma0 grad tensor([860.8566], device='cuda:0')\n",
      "sigma1 grad tensor([[850.9371]], device='cuda:0')\n",
      "gamma grad tensor([[-7133.5898]], device='cuda:0')\n",
      "alpha grad tensor([[13438.4590]], device='cuda:0')\n",
      "beta2 grad tensor([[-16778.7461]], device='cuda:0')\n",
      "beta0 grad tensor([-6184.9062], device='cuda:0')\n",
      "beta1 grad tensor([[-9649.8057]], device='cuda:0')\n",
      "Epoch 124 | Loss: 32.4000\n",
      "alpha: 0.07669036090373993, beta0: 0.11435134708881378, beta1: -0.0008916002116166055, beta2: 0.001247009146027267, \n",
      "gamma: 0.06328192353248596, sigma0: 0.26651686429977417, sigma1: 0.00027924487949348986, sigma2: 5.027140286983922e-05, sigmaX: 0.15501253306865692\n",
      "forward done\n",
      "tensor([0.0145, 0.1136, 0.2577, 0.6331, 0.3545], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-4.2247]]], device='cuda:0')\n",
      "sigma2 grad tensor([[744.0270]], device='cuda:0')\n",
      "sigma0 grad tensor([704.5525], device='cuda:0')\n",
      "sigma1 grad tensor([[655.7246]], device='cuda:0')\n",
      "gamma grad tensor([[-5603.1948]], device='cuda:0')\n",
      "alpha grad tensor([[10697.0781]], device='cuda:0')\n",
      "beta2 grad tensor([[-12229.8096]], device='cuda:0')\n",
      "beta0 grad tensor([-4959.6011], device='cuda:0')\n",
      "beta1 grad tensor([[-7363.3550]], device='cuda:0')\n",
      "Epoch 125 | Loss: 12.6155\n",
      "alpha: 0.07651159912347794, beta0: 0.11443004012107849, beta1: -0.0007661029230803251, beta2: 0.0014689931413158774, \n",
      "gamma: 0.06338029354810715, sigma0: 0.2665081024169922, sigma1: 0.00027020962443202734, sigma2: 3.931270111934282e-05, sigmaX: 0.15501265227794647\n",
      "forward done\n",
      "tensor([0.0116, 0.1144, 0.1814, 0.6222, 0.3526], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-4.5030]]], device='cuda:0')\n",
      "sigma2 grad tensor([[775.0674]], device='cuda:0')\n",
      "sigma0 grad tensor([687.5516], device='cuda:0')\n",
      "sigma1 grad tensor([[655.0029]], device='cuda:0')\n",
      "gamma grad tensor([[-5409.1724]], device='cuda:0')\n",
      "alpha grad tensor([[10335.5098]], device='cuda:0')\n",
      "beta2 grad tensor([[-11515.0557]], device='cuda:0')\n",
      "beta0 grad tensor([-4790.9854], device='cuda:0')\n",
      "beta1 grad tensor([[-7027.4570]], device='cuda:0')\n",
      "Epoch 126 | Loss: 12.6089\n",
      "alpha: 0.07626523822546005, beta0: 0.11454090476036072, beta1: -0.0005954304942861199, beta2: 0.001761730876751244, \n",
      "gamma: 0.06351307779550552, sigma0: 0.2664942145347595, sigma1: 0.0002564314054325223, sigma2: 2.2795064069214277e-05, sigmaX: 0.15501278638839722\n",
      "forward done\n",
      "tensor([0.0196, 0.0434, 0.0993, 0.6573, 0.3435], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.3608]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-237.5167]], device='cuda:0')\n",
      "sigma0 grad tensor([-210.3766], device='cuda:0')\n",
      "sigma1 grad tensor([[-197.7306]], device='cuda:0')\n",
      "gamma grad tensor([[719.7936]], device='cuda:0')\n",
      "alpha grad tensor([[-1661.6146]], device='cuda:0')\n",
      "beta2 grad tensor([[2182.6907]], device='cuda:0')\n",
      "beta0 grad tensor([916.8332], device='cuda:0')\n",
      "beta1 grad tensor([[1336.6926]], device='cuda:0')\n",
      "Epoch 127 | Loss: 5.4622\n",
      "alpha: 0.07608476281166077, beta0: 0.11462043225765228, beta1: -0.0004722595040220767, beta2: 0.001974094193428755, \n",
      "gamma: 0.06361211091279984, sigma0: 0.26648521423339844, sigma1: 0.00024738613865338266, sigma2: 1.1956120943068527e-05, sigmaX: 0.15501292049884796\n",
      "forward done\n",
      "tensor([0.0111, 0.0545, 0.1325, 0.6660, 0.3683], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.8805]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-235.3354]], device='cuda:0')\n",
      "sigma0 grad tensor([-248.8529], device='cuda:0')\n",
      "sigma1 grad tensor([[-219.3140]], device='cuda:0')\n",
      "gamma grad tensor([[1138.8331]], device='cuda:0')\n",
      "alpha grad tensor([[-2422.0955]], device='cuda:0')\n",
      "beta2 grad tensor([[2668.7205]], device='cuda:0')\n",
      "beta0 grad tensor([1247.9957], device='cuda:0')\n",
      "beta1 grad tensor([[1731.8429]], device='cuda:0')\n",
      "Epoch 128 | Loss: 6.6320\n",
      "alpha: 0.07596460729837418, beta0: 0.11467157304286957, beta1: -0.00039104113238863647, beta2: 0.002117297612130642, \n",
      "gamma: 0.06367994844913483, sigma0: 0.2664805054664612, sigma1: 0.0002423430560156703, sigma2: 5.6383205446763895e-06, sigmaX: 0.1550130397081375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0138, 0.1469, 0.1371, 0.6959, 0.3903], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.8568]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-463.3757]], device='cuda:0')\n",
      "sigma0 grad tensor([-524.0303], device='cuda:0')\n",
      "sigma1 grad tensor([[-442.6830]], device='cuda:0')\n",
      "gamma grad tensor([[3835.9375]], device='cuda:0')\n",
      "alpha grad tensor([[-7402.0571]], device='cuda:0')\n",
      "beta2 grad tensor([[7001.4482]], device='cuda:0')\n",
      "beta0 grad tensor([3458.2954], device='cuda:0')\n",
      "beta1 grad tensor([[4653.6460]], device='cuda:0')\n",
      "Epoch 129 | Loss: 15.9246\n",
      "alpha: 0.0759425014257431, beta0: 0.11467789858579636, beta1: -0.0003726028953678906, beta2: 0.0021618457976728678, \n",
      "gamma: 0.06369585543870926, sigma0: 0.2664819657802582, sigma1: 0.00024273541930597275, sigma2: 5.217837042437168e-06, sigmaX: 0.15501314401626587\n",
      "forward done\n",
      "tensor([0.0205, 0.1088, 0.2205, 0.6567, 0.3848], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.5157]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-478.0270]], device='cuda:0')\n",
      "sigma0 grad tensor([-536.5804], device='cuda:0')\n",
      "sigma1 grad tensor([[-442.8126]], device='cuda:0')\n",
      "gamma grad tensor([[3919.2188]], device='cuda:0')\n",
      "alpha grad tensor([[-7543.9883]], device='cuda:0')\n",
      "beta2 grad tensor([[7860.3120]], device='cuda:0')\n",
      "beta0 grad tensor([3518.7556], device='cuda:0')\n",
      "beta1 grad tensor([[4940.5444]], device='cuda:0')\n",
      "Epoch 130 | Loss: 12.1590\n",
      "alpha: 0.07600025832653046, beta0: 0.114647775888443, beta1: -0.00040725775761529803, beta2: 0.0021188813261687756, \n",
      "gamma: 0.06366939097642899, sigma0: 0.26648852229118347, sigma1: 0.00024747743736952543, sigma2: 9.661720469011925e-06, sigmaX: 0.15501324832439423\n",
      "forward done\n",
      "tensor([0.0229, 0.1777, 0.2562, 0.6306, 0.3539], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.3453]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-399.1790]], device='cuda:0')\n",
      "sigma0 grad tensor([-510.1315], device='cuda:0')\n",
      "sigma1 grad tensor([[-407.0315]], device='cuda:0')\n",
      "gamma grad tensor([[3588.1699]], device='cuda:0')\n",
      "alpha grad tensor([[-6972.0356]], device='cuda:0')\n",
      "beta2 grad tensor([[6629.5654]], device='cuda:0')\n",
      "beta0 grad tensor([3279.1252], device='cuda:0')\n",
      "beta1 grad tensor([[4401.0630]], device='cuda:0')\n",
      "Epoch 131 | Loss: 19.0382\n",
      "alpha: 0.076116181910038, beta0: 0.11459088325500488, beta1: -0.0004789922677446157, beta2: 0.0020182139705866575, \n",
      "gamma: 0.06361233443021774, sigma0: 0.266498863697052, sigma1: 0.00025534137967042625, sigma2: 1.7208616554853506e-05, sigmaX: 0.15501335263252258\n",
      "forward done\n",
      "tensor([0.0211, 0.0941, 0.3106, 0.6610, 0.3634], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.6447]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-650.8182]], device='cuda:0')\n",
      "sigma0 grad tensor([-556.9656], device='cuda:0')\n",
      "sigma1 grad tensor([[-533.5046]], device='cuda:0')\n",
      "gamma grad tensor([[3895.7532]], device='cuda:0')\n",
      "alpha grad tensor([[-7598.2847]], device='cuda:0')\n",
      "beta2 grad tensor([[8476.0234]], device='cuda:0')\n",
      "beta0 grad tensor([3565.3765], device='cuda:0')\n",
      "beta1 grad tensor([[5176.1943]], device='cuda:0')\n",
      "Epoch 132 | Loss: 10.7677\n",
      "alpha: 0.07628490775823593, beta0: 0.114509716629982, beta1: -0.0005881417891941965, beta2: 0.0018529199296608567, \n",
      "gamma: 0.06352773308753967, sigma0: 0.2665126919746399, sigma1: 0.00026696757413446903, sigma2: 2.975431561935693e-05, sigmaX: 0.15501347184181213\n",
      "forward done\n",
      "tensor([0.0079, 0.0596, 0.1458, 0.6917, 0.3872], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.2697]]], device='cuda:0')\n",
      "sigma2 grad tensor([[70.1001]], device='cuda:0')\n",
      "sigma0 grad tensor([148.7849], device='cuda:0')\n",
      "sigma1 grad tensor([[102.4173]], device='cuda:0')\n",
      "gamma grad tensor([[-2166.6042]], device='cuda:0')\n",
      "alpha grad tensor([[3866.4338]], device='cuda:0')\n",
      "beta2 grad tensor([[-3630.8213]], device='cuda:0')\n",
      "beta0 grad tensor([-1622.0759], device='cuda:0')\n",
      "beta1 grad tensor([[-2298.0784]], device='cuda:0')\n",
      "Epoch 133 | Loss: 7.1897\n",
      "alpha: 0.07638122141361237, beta0: 0.1144610047340393, beta1: -0.0006524806376546621, beta2: 0.0017569928895682096, \n",
      "gamma: 0.06348171830177307, sigma0: 0.26652228832244873, sigma1: 0.0002752443542703986, sigma2: 3.908987491740845e-05, sigmaX: 0.1550135612487793\n",
      "forward done\n",
      "tensor([0.0117, 0.1106, 0.2542, 0.5780, 0.2987], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-4.2490]]], device='cuda:0')\n",
      "sigma2 grad tensor([[838.6296]], device='cuda:0')\n",
      "sigma0 grad tensor([653.3809], device='cuda:0')\n",
      "sigma1 grad tensor([[647.1822]], device='cuda:0')\n",
      "gamma grad tensor([[-5263.3921]], device='cuda:0')\n",
      "alpha grad tensor([[9951.4990]], device='cuda:0')\n",
      "beta2 grad tensor([[-11612.3076]], device='cuda:0')\n",
      "beta0 grad tensor([-4579.1562], device='cuda:0')\n",
      "beta1 grad tensor([[-6862.0303]], device='cuda:0')\n",
      "Epoch 134 | Loss: 12.1997\n",
      "alpha: 0.07635875791311264, beta0: 0.11446782946586609, beta1: -0.0006353314383886755, beta2: 0.0017963743302971125, \n",
      "gamma: 0.06349754333496094, sigma0: 0.26652342081069946, sigma1: 0.00027539394795894623, sigma2: 3.817202741629444e-05, sigmaX: 0.15501368045806885\n",
      "forward done\n",
      "tensor([0.0133, 0.0249, 0.2439, 0.6327, 0.3402], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-3.4593]]], device='cuda:0')\n",
      "sigma2 grad tensor([[142.2167]], device='cuda:0')\n",
      "sigma0 grad tensor([105.5686], device='cuda:0')\n",
      "sigma1 grad tensor([[106.9100]], device='cuda:0')\n",
      "gamma grad tensor([[-1348.6667]], device='cuda:0')\n",
      "alpha grad tensor([[2432.5469]], device='cuda:0')\n",
      "beta2 grad tensor([[-2708.9060]], device='cuda:0')\n",
      "beta0 grad tensor([-1028.3162], device='cuda:0')\n",
      "beta1 grad tensor([[-1574.3981]], device='cuda:0')\n",
      "Epoch 135 | Loss: 3.7208\n",
      "alpha: 0.0763164609670639, beta0: 0.11448357254266739, beta1: -0.0006058680592104793, beta2: 0.0018549684900790453, \n",
      "gamma: 0.06352368742227554, sigma0: 0.2665232717990875, sigma1: 0.00027444452280178666, sigma2: 3.6015582736581564e-05, sigmaX: 0.1550138145685196\n",
      "forward done\n",
      "tensor([0.0153, 0.1771, 0.1072, 0.6685, 0.3813], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.0723]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-400.7278]], device='cuda:0')\n",
      "sigma0 grad tensor([-513.2339], device='cuda:0')\n",
      "sigma1 grad tensor([[-404.7876]], device='cuda:0')\n",
      "gamma grad tensor([[3916.6003]], device='cuda:0')\n",
      "alpha grad tensor([[-7541.2686]], device='cuda:0')\n",
      "beta2 grad tensor([[7248.4795]], device='cuda:0')\n",
      "beta0 grad tensor([3511.6348], device='cuda:0')\n",
      "beta1 grad tensor([[4757.4443]], device='cuda:0')\n",
      "Epoch 136 | Loss: 18.8857\n",
      "alpha: 0.07635803520679474, beta0: 0.11446104943752289, beta1: -0.0006298717926256359, beta2: 0.0018293590983375907, \n",
      "gamma: 0.06350543349981308, sigma0: 0.26652827858924866, sigma1: 0.00027773287729360163, sigma2: 3.829770503216423e-05, sigmaX: 0.15501393377780914\n",
      "forward done\n",
      "tensor([0.0154, 0.0360, 0.2761, 0.5985, 0.3494], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.1097]]], device='cuda:0')\n",
      "sigma2 grad tensor([[608.7112]], device='cuda:0')\n",
      "sigma0 grad tensor([495.7944], device='cuda:0')\n",
      "sigma1 grad tensor([[486.1156]], device='cuda:0')\n",
      "gamma grad tensor([[-3675.3027]], device='cuda:0')\n",
      "alpha grad tensor([[7093.2559]], device='cuda:0')\n",
      "beta2 grad tensor([[-8272.2461]], device='cuda:0')\n",
      "beta0 grad tensor([-3296.3921], device='cuda:0')\n",
      "beta1 grad tensor([[-4923.8335]], device='cuda:0')\n",
      "Epoch 137 | Loss: 4.8357\n",
      "alpha: 0.07632036507129669, beta0: 0.11447599530220032, beta1: -0.0005998364649713039, beta2: 0.001891594030894339, \n",
      "gamma: 0.06352758407592773, sigma0: 0.26652732491493225, sigma1: 0.000275502388831228, sigma2: 3.403628943488002e-05, sigmaX: 0.1550140529870987\n",
      "forward done\n",
      "tensor([0.0173, 0.1291, 0.2763, 0.5926, 0.3312], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-4.3941]]], device='cuda:0')\n",
      "sigma2 grad tensor([[810.0047]], device='cuda:0')\n",
      "sigma0 grad tensor([661.9176], device='cuda:0')\n",
      "sigma1 grad tensor([[655.4243]], device='cuda:0')\n",
      "gamma grad tensor([[-5236.0264]], device='cuda:0')\n",
      "alpha grad tensor([[9946.5908]], device='cuda:0')\n",
      "beta2 grad tensor([[-11703.3750]], device='cuda:0')\n",
      "beta0 grad tensor([-4576.8848], device='cuda:0')\n",
      "beta1 grad tensor([[-6926.1499]], device='cuda:0')\n",
      "Epoch 138 | Loss: 14.1277\n",
      "alpha: 0.0761907622218132, beta0: 0.11453372240066528, beta1: -0.0005065466975793242, beta2: 0.002058415673673153, \n",
      "gamma: 0.0635976642370224, sigma0: 0.2665199339389801, sigma1: 0.0002671637630555779, sigma2: 2.252711055916734e-05, sigmaX: 0.15501418709754944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0195, 0.2154, 0.1031, 0.7089, 0.4246], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.8128]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-395.6589]], device='cuda:0')\n",
      "sigma0 grad tensor([-477.4849], device='cuda:0')\n",
      "sigma1 grad tensor([[-385.9242]], device='cuda:0')\n",
      "gamma grad tensor([[3655.0486]], device='cuda:0')\n",
      "alpha grad tensor([[-7041.3213]], device='cuda:0')\n",
      "beta2 grad tensor([[6728.8701]], device='cuda:0')\n",
      "beta0 grad tensor([3274.5247], device='cuda:0')\n",
      "beta1 grad tensor([[4423.4248]], device='cuda:0')\n",
      "Epoch 139 | Loss: 22.7919\n",
      "alpha: 0.07615749537944794, beta0: 0.11454715579748154, beta1: -0.0004761491436511278, beta2: 0.0021245842799544334, \n",
      "gamma: 0.06361717730760574, sigma0: 0.26651880145072937, sigma1: 0.00026435210020281374, sigma2: 1.7276355720241554e-05, sigmaX: 0.155014306306839\n",
      "forward done\n",
      "tensor([0.0164, 0.1272, 0.1738, 0.7106, 0.4470], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.5947]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-422.2833]], device='cuda:0')\n",
      "sigma0 grad tensor([-539.6674], device='cuda:0')\n",
      "sigma1 grad tensor([[-429.4387]], device='cuda:0')\n",
      "gamma grad tensor([[3780.2651]], device='cuda:0')\n",
      "alpha grad tensor([[-7393.4517]], device='cuda:0')\n",
      "beta2 grad tensor([[7226.8804]], device='cuda:0')\n",
      "beta0 grad tensor([3480.0632], device='cuda:0')\n",
      "beta1 grad tensor([[4744.8770]], device='cuda:0')\n",
      "Epoch 140 | Loss: 14.0721\n",
      "alpha: 0.076204814016819, beta0: 0.11452310532331467, beta1: -0.0004992798785679042, beta2: 0.0021052504889667034, \n",
      "gamma: 0.0635949894785881, sigma0: 0.2665233016014099, sigma1: 0.0002663971681613475, sigma2: 1.7298585589742288e-05, sigmaX: 0.15501441061496735\n",
      "forward done\n",
      "tensor([0.0059, 0.0566, 0.1353, 0.6878, 0.3912], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.9918]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-322.1456]], device='cuda:0')\n",
      "sigma0 grad tensor([-366.3089], device='cuda:0')\n",
      "sigma1 grad tensor([[-304.7257]], device='cuda:0')\n",
      "gamma grad tensor([[2027.8385]], device='cuda:0')\n",
      "alpha grad tensor([[-4182.8760]], device='cuda:0')\n",
      "beta2 grad tensor([[4334.7241]], device='cuda:0')\n",
      "beta0 grad tensor([2066.2651], device='cuda:0')\n",
      "beta1 grad tensor([[2828.4460]], device='cuda:0')\n",
      "Epoch 141 | Loss: 6.8798\n",
      "alpha: 0.0762844979763031, beta0: 0.11448320001363754, beta1: -0.0005460689426399767, beta2: 0.002046436071395874, \n",
      "gamma: 0.0635569617152214, sigma0: 0.2665305733680725, sigma1: 0.0002710804692469537, sigma2: 2.0537823729682714e-05, sigmaX: 0.1550145149230957\n",
      "forward done\n",
      "tensor([0.0147, 0.0822, 0.2037, 0.6525, 0.3917], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.6618]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-575.4520]], device='cuda:0')\n",
      "sigma0 grad tensor([-574.2814], device='cuda:0')\n",
      "sigma1 grad tensor([[-517.3513]], device='cuda:0')\n",
      "gamma grad tensor([[3820.3354]], device='cuda:0')\n",
      "alpha grad tensor([[-7507.3926]], device='cuda:0')\n",
      "beta2 grad tensor([[8046.6895]], device='cuda:0')\n",
      "beta0 grad tensor([3556.9153], device='cuda:0')\n",
      "beta1 grad tensor([[5058.5840]], device='cuda:0')\n",
      "Epoch 142 | Loss: 9.4836\n",
      "alpha: 0.07642331719398499, beta0: 0.11441570520401001, beta1: -0.0006340860272757709, beta2: 0.0019189176382496953, \n",
      "gamma: 0.06348833441734314, sigma0: 0.26654213666915894, sigma1: 0.00028000061865895987, sigma2: 2.888373455789406e-05, sigmaX: 0.15501461923122406\n",
      "forward done\n",
      "tensor([0.0166, 0.0793, 0.2503, 0.5895, 0.3307], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.4095]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-623.0517]], device='cuda:0')\n",
      "sigma0 grad tensor([-563.8243], device='cuda:0')\n",
      "sigma1 grad tensor([[-506.5264]], device='cuda:0')\n",
      "gamma grad tensor([[3916.6868]], device='cuda:0')\n",
      "alpha grad tensor([[-7709.3628]], device='cuda:0')\n",
      "beta2 grad tensor([[8532.8877]], device='cuda:0')\n",
      "beta0 grad tensor([3642.8865], device='cuda:0')\n",
      "beta1 grad tensor([[5222.7852]], device='cuda:0')\n",
      "Epoch 143 | Loss: 9.1127\n",
      "alpha: 0.0766114667057991, beta0: 0.11432528495788574, beta1: -0.0007567275315523148, beta2: 0.0017315740697085857, \n",
      "gamma: 0.06339426338672638, sigma0: 0.2665570080280304, sigma1: 0.0002922019921243191, sigma2: 4.1790979594225064e-05, sigmaX: 0.15501472353935242\n",
      "forward done\n",
      "tensor([0.0126, 0.0887, 0.2748, 0.6774, 0.3973], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.8646]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-448.5286]], device='cuda:0')\n",
      "sigma0 grad tensor([-576.9166], device='cuda:0')\n",
      "sigma1 grad tensor([[-462.5277]], device='cuda:0')\n",
      "gamma grad tensor([[4513.2344]], device='cuda:0')\n",
      "alpha grad tensor([[-8628.9590]], device='cuda:0')\n",
      "beta2 grad tensor([[8537.6680]], device='cuda:0')\n",
      "beta0 grad tensor([4001.4050], device='cuda:0')\n",
      "beta1 grad tensor([[5528.1860]], device='cuda:0')\n",
      "Epoch 144 | Loss: 10.2283\n",
      "alpha: 0.07684827595949173, beta0: 0.11421293020248413, beta1: -0.0009101225878112018, beta2: 0.0014963224530220032, \n",
      "gamma: 0.06327387690544128, sigma0: 0.2665746808052063, sigma1: 0.000306588364765048, sigma2: 5.660206443280913e-05, sigmaX: 0.15501481294631958\n",
      "forward done\n",
      "tensor([0.0173, 0.1918, 0.3413, 0.6626, 0.3703], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.7429]]], device='cuda:0')\n",
      "sigma2 grad tensor([[995.1806]], device='cuda:0')\n",
      "sigma0 grad tensor([745.1295], device='cuda:0')\n",
      "sigma1 grad tensor([[764.6265]], device='cuda:0')\n",
      "gamma grad tensor([[-6423.2129]], device='cuda:0')\n",
      "alpha grad tensor([[11964.9990]], device='cuda:0')\n",
      "beta2 grad tensor([[-15474.7119]], device='cuda:0')\n",
      "beta0 grad tensor([-5437.7563], device='cuda:0')\n",
      "beta1 grad tensor([[-8660.7852]], device='cuda:0')\n",
      "Epoch 145 | Loss: 20.5726\n",
      "alpha: 0.07691807299852371, beta0: 0.11417742818593979, beta1: -0.0009462307789362967, beta2: 0.0014628682984039187, \n",
      "gamma: 0.06324180215597153, sigma0: 0.26658135652542114, sigma1: 0.00031045119976624846, sigma2: 5.8499124861555174e-05, sigmaX: 0.15501488745212555\n",
      "forward done\n",
      "tensor([0.0244, 0.4056, 0.3518, 0.5661, 0.3393], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.6724]]], device='cuda:0')\n",
      "sigma2 grad tensor([[1189.0166]], device='cuda:0')\n",
      "sigma0 grad tensor([871.6276], device='cuda:0')\n",
      "sigma1 grad tensor([[906.1734]], device='cuda:0')\n",
      "gamma grad tensor([[-7951.3691]], device='cuda:0')\n",
      "alpha grad tensor([[14670.5146]], device='cuda:0')\n",
      "beta2 grad tensor([[-18808.5527]], device='cuda:0')\n",
      "beta0 grad tensor([-6621.2788], device='cuda:0')\n",
      "beta1 grad tensor([[-10504.9961]], device='cuda:0')\n",
      "Epoch 146 | Loss: 41.8450\n",
      "alpha: 0.07682720571756363, beta0: 0.11421523988246918, beta1: -0.0008700673934072256, beta2: 0.0016241904813796282, \n",
      "gamma: 0.06329565495252609, sigma0: 0.26657798886299133, sigma1: 0.00030447973404079676, sigma2: 4.812660699826665e-05, sigmaX: 0.15501496195793152\n",
      "forward done\n",
      "tensor([0.0233, 0.3022, 0.3964, 0.5149, 0.3397], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[0.3987]]], device='cuda:0')\n",
      "sigma2 grad tensor([[1088.9861]], device='cuda:0')\n",
      "sigma0 grad tensor([790.8281], device='cuda:0')\n",
      "sigma1 grad tensor([[822.4231]], device='cuda:0')\n",
      "gamma grad tensor([[-7085.4800]], device='cuda:0')\n",
      "alpha grad tensor([[13162.5615]], device='cuda:0')\n",
      "beta2 grad tensor([[-16200.9434]], device='cuda:0')\n",
      "beta0 grad tensor([-5960.5083], device='cuda:0')\n",
      "beta1 grad tensor([[-9278.8701]], device='cuda:0')\n",
      "Epoch 147 | Loss: 31.4970\n",
      "alpha: 0.07662288844585419, beta0: 0.11430509388446808, beta1: -0.0007163479458540678, beta2: 0.0019152576569467783, \n",
      "gamma: 0.06340958923101425, sigma0: 0.2665673792362213, sigma1: 0.0002914783253800124, sigma2: 2.8938731702510267e-05, sigmaX: 0.1550150215625763\n",
      "forward done\n",
      "tensor([0.0110, 0.0508, 0.2794, 0.6556, 0.3589], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.1674]]], device='cuda:0')\n",
      "sigma2 grad tensor([[578.5306]], device='cuda:0')\n",
      "sigma0 grad tensor([603.6167], device='cuda:0')\n",
      "sigma1 grad tensor([[535.2651]], device='cuda:0')\n",
      "gamma grad tensor([[-4466.5991]], device='cuda:0')\n",
      "alpha grad tensor([[8693.0820]], device='cuda:0')\n",
      "beta2 grad tensor([[-9272.2256]], device='cuda:0')\n",
      "beta0 grad tensor([-4064.9329], device='cuda:0')\n",
      "beta1 grad tensor([[-5818.4038]], device='cuda:0')\n",
      "Epoch 148 | Loss: 6.3874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.07637250423431396, beta0: 0.11441762745380402, beta1: -0.000535188359208405, beta2: 0.002240833593532443, \n",
      "gamma: 0.06354540586471558, sigma0: 0.2665528655052185, sigma1: 0.0002757245674729347, sigma2: 7.803126209182665e-06, sigmaX: 0.15501508116722107\n",
      "forward done\n",
      "tensor([0.0115, 0.0420, 0.1530, 0.6352, 0.3954], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.8229]]], device='cuda:0')\n",
      "sigma2 grad tensor([[20.5182]], device='cuda:0')\n",
      "sigma0 grad tensor([52.8047], device='cuda:0')\n",
      "sigma1 grad tensor([[34.4128]], device='cuda:0')\n",
      "gamma grad tensor([[-1573.5345]], device='cuda:0')\n",
      "alpha grad tensor([[2689.5237]], device='cuda:0')\n",
      "beta2 grad tensor([[-2455.3916]], device='cuda:0')\n",
      "beta0 grad tensor([-1050.9316], device='cuda:0')\n",
      "beta1 grad tensor([[-1521.7042]], device='cuda:0')\n",
      "Epoch 149 | Loss: 5.3946\n",
      "alpha: 0.07614529877901077, beta0: 0.11451815813779831, beta1: -0.00037504362990148365, beta2: 0.002525848336517811, \n",
      "gamma: 0.06366979330778122, sigma0: 0.2665407359600067, sigma1: 0.00026277743745595217, sigma2: -9.310540917795151e-06, sigmaX: 0.15501515567302704\n",
      "forward done\n",
      "tensor([0.0070, 0.0500, 0.3389, 0.6510, 0.3639], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.9102]]], device='cuda:0')\n",
      "sigma2 grad tensor([[25.9560]], device='cuda:0')\n",
      "sigma0 grad tensor([58.8212], device='cuda:0')\n",
      "sigma1 grad tensor([[35.1204]], device='cuda:0')\n",
      "gamma grad tensor([[-1371.9244]], device='cuda:0')\n",
      "alpha grad tensor([[2380.3586]], device='cuda:0')\n",
      "beta2 grad tensor([[-2046.7715]], device='cuda:0')\n",
      "beta0 grad tensor([-945.5870], device='cuda:0')\n",
      "beta1 grad tensor([[-1308.0804]], device='cuda:0')\n",
      "Epoch 150 | Loss: 6.3654\n",
      "alpha: 0.07593972980976105, beta0: 0.1146080419421196, beta1: -0.00023384705127682537, beta2: 0.0027743277605623007, \n",
      "gamma: 0.06378301978111267, sigma0: 0.26653042435646057, sigma1: 0.00025206850841641426, sigma2: -2.326103458472062e-05, sigmaX: 0.155015230178833\n",
      "forward done\n",
      "tensor([0.0114, 0.0850, 0.1750, 0.6227, 0.3908], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.4818]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-593.4340]], device='cuda:0')\n",
      "sigma0 grad tensor([-515.8520], device='cuda:0')\n",
      "sigma1 grad tensor([[-488.8822]], device='cuda:0')\n",
      "gamma grad tensor([[3739.1035]], device='cuda:0')\n",
      "alpha grad tensor([[-7226.9683]], device='cuda:0')\n",
      "beta2 grad tensor([[7518.4922]], device='cuda:0')\n",
      "beta0 grad tensor([3369.9453], device='cuda:0')\n",
      "beta1 grad tensor([[4740.1274]], device='cuda:0')\n",
      "Epoch 151 | Loss: 9.6951\n",
      "alpha: 0.07584754377603531, beta0: 0.11464624851942062, beta1: -0.00016829106607474387, beta2: 0.0028979263734072447, \n",
      "gamma: 0.06383620947599411, sigma0: 0.26652735471725464, sigma1: 0.0002483901917003095, sigma2: -2.8487089366535656e-05, sigmaX: 0.15501531958580017\n",
      "forward done\n",
      "tensor([0.0181, 0.1111, 0.1957, 0.6759, 0.3851], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.1351]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-465.4265]], device='cuda:0')\n",
      "sigma0 grad tensor([-513.4690], device='cuda:0')\n",
      "sigma1 grad tensor([[-433.1124]], device='cuda:0')\n",
      "gamma grad tensor([[3633.7021]], device='cuda:0')\n",
      "alpha grad tensor([[-7021.4180]], device='cuda:0')\n",
      "beta2 grad tensor([[6844.9258]], device='cuda:0')\n",
      "beta0 grad tensor([3275.2383], device='cuda:0')\n",
      "beta1 grad tensor([[4475.2324]], device='cuda:0')\n",
      "Epoch 152 | Loss: 12.3857\n",
      "alpha: 0.07584401220083237, beta0: 0.11464406549930573, beta1: -0.00016059860354289412, beta2: 0.002928356174379587, \n",
      "gamma: 0.06384242326021194, sigma0: 0.26653003692626953, sigma1: 0.00024977867724373937, sigma2: -2.801366827043239e-05, sigmaX: 0.15501540899276733\n",
      "forward done\n",
      "tensor([0.0288, 0.2265, 0.0977, 0.6840, 0.3856], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.6030]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-461.3384]], device='cuda:0')\n",
      "sigma0 grad tensor([-443.7960], device='cuda:0')\n",
      "sigma1 grad tensor([[-399.7537]], device='cuda:0')\n",
      "gamma grad tensor([[3018.9443]], device='cuda:0')\n",
      "alpha grad tensor([[-5937.3179]], device='cuda:0')\n",
      "beta2 grad tensor([[5825.9990]], device='cuda:0')\n",
      "beta0 grad tensor([2797.9119], device='cuda:0')\n",
      "beta1 grad tensor([[3812.0901]], device='cuda:0')\n",
      "Epoch 153 | Loss: 23.8438\n",
      "alpha: 0.07590056210756302, beta0: 0.114614337682724, beta1: -0.00019256553787272424, beta2: 0.0028944399673491716, \n",
      "gamma: 0.06381721049547195, sigma0: 0.2665366232395172, sigma1: 0.00025488698156550527, sigma2: -2.302154643984977e-05, sigmaX: 0.1550154834985733\n",
      "forward done\n",
      "tensor([0.0237, 0.2312, 0.1378, 0.6812, 0.3854], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.2167]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-408.9000]], device='cuda:0')\n",
      "sigma0 grad tensor([-450.9691], device='cuda:0')\n",
      "sigma1 grad tensor([[-381.0945]], device='cuda:0')\n",
      "gamma grad tensor([[3005.1335]], device='cuda:0')\n",
      "alpha grad tensor([[-5921.5283]], device='cuda:0')\n",
      "beta2 grad tensor([[5679.6152]], device='cuda:0')\n",
      "beta0 grad tensor([2796.6067], device='cuda:0')\n",
      "beta1 grad tensor([[3758.3684]], device='cuda:0')\n",
      "Epoch 154 | Loss: 24.3445\n",
      "alpha: 0.0760050117969513, beta0: 0.11456258594989777, beta1: -0.0002557227562647313, beta2: 0.0028105108067393303, \n",
      "gamma: 0.06376698613166809, sigma0: 0.2665463984012604, sigma1: 0.00026278456789441407, sigma2: -1.4938849744794425e-05, sigmaX: 0.15501555800437927\n",
      "forward done\n",
      "tensor([0.0128, 0.0580, 0.1239, 0.7072, 0.4106], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.3556]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-323.9243]], device='cuda:0')\n",
      "sigma0 grad tensor([-295.7278], device='cuda:0')\n",
      "sigma1 grad tensor([[-273.5432]], device='cuda:0')\n",
      "gamma grad tensor([[1701.6083]], device='cuda:0')\n",
      "alpha grad tensor([[-3429.4666]], device='cuda:0')\n",
      "beta2 grad tensor([[3665.0073]], device='cuda:0')\n",
      "beta0 grad tensor([1673.2853], device='cuda:0')\n",
      "beta1 grad tensor([[2336.3455]], device='cuda:0')\n",
      "Epoch 155 | Loss: 7.0591\n",
      "alpha: 0.07612286508083344, beta0: 0.11450445652008057, beta1: -0.00032961199758574367, beta2: 0.0027067174669355154, \n",
      "gamma: 0.0637097880244255, sigma0: 0.26655715703964233, sigma1: 0.00027183807105757296, sigma2: -5.233449883235153e-06, sigmaX: 0.15501563251018524\n",
      "forward done\n",
      "tensor([0.0111, 0.0552, 0.2387, 0.6826, 0.3941], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.4688]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-154.9846]], device='cuda:0')\n",
      "sigma0 grad tensor([-143.4425], device='cuda:0')\n",
      "sigma1 grad tensor([[-132.7661]], device='cuda:0')\n",
      "gamma grad tensor([[256.9434]], device='cuda:0')\n",
      "alpha grad tensor([[-783.2871]], device='cuda:0')\n",
      "beta2 grad tensor([[1132.3060]], device='cuda:0')\n",
      "beta0 grad tensor([501.5268], device='cuda:0')\n",
      "beta1 grad tensor([[712.7001]], device='cuda:0')\n",
      "Epoch 156 | Loss: 6.8509\n",
      "alpha: 0.07622498273849487, beta0: 0.11445293575525284, beta1: -0.00039585039485245943, beta2: 0.0026123598217964172, \n",
      "gamma: 0.06366146355867386, sigma0: 0.266567200422287, sigma1: 0.00028040853794664145, sigma2: 4.0807162804412656e-06, sigmaX: 0.1550157070159912\n",
      "forward done\n",
      "tensor([0.0099, 0.0407, 0.4009, 0.6290, 0.4228], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.3201]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-32.0336]], device='cuda:0')\n",
      "sigma0 grad tensor([-17.2462], device='cuda:0')\n",
      "sigma1 grad tensor([[-24.9394]], device='cuda:0')\n",
      "gamma grad tensor([[-828.6517]], device='cuda:0')\n",
      "alpha grad tensor([[1309.8431]], device='cuda:0')\n",
      "beta2 grad tensor([[-990.6609]], device='cuda:0')\n",
      "beta0 grad tensor([-444.5529], device='cuda:0')\n",
      "beta1 grad tensor([[-622.5855]], device='cuda:0')\n",
      "Epoch 157 | Loss: 5.5328\n",
      "alpha: 0.07629358023405075, beta0: 0.11441616714000702, beta1: -0.00044261524453759193, beta2: 0.002546780277043581, \n",
      "gamma: 0.0636310875415802, sigma0: 0.266575425863266, sigma1: 0.0002875142963603139, sigma2: 1.1852384886879008e-05, sigmaX: 0.15501578152179718\n",
      "forward done\n",
      "tensor([0.0127, 0.0876, 0.0796, 0.6946, 0.4051], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmaX grad tensor([[[-1.6976]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-488.8665]], device='cuda:0')\n",
      "sigma0 grad tensor([-534.4453], device='cuda:0')\n",
      "sigma1 grad tensor([[-464.0561]], device='cuda:0')\n",
      "gamma grad tensor([[3926.2957]], device='cuda:0')\n",
      "alpha grad tensor([[-7570.3799]], device='cuda:0')\n",
      "beta2 grad tensor([[7749.5820]], device='cuda:0')\n",
      "beta0 grad tensor([3522.7466], device='cuda:0')\n",
      "beta1 grad tensor([[4951.7290]], device='cuda:0')\n",
      "Epoch 158 | Loss: 9.9478\n",
      "alpha: 0.07642415910959244, beta0: 0.11435152590274811, beta1: -0.0005295444279909134, beta2: 0.0024168207310140133, \n",
      "gamma: 0.06356752663850784, sigma0: 0.26658734679222107, sigma1: 0.0002978394622914493, sigma2: 2.295838567079045e-05, sigmaX: 0.15501585602760315\n",
      "forward done\n",
      "tensor([0.0077, 0.0749, 0.2923, 0.6519, 0.3735], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.3783]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-521.4673]], device='cuda:0')\n",
      "sigma0 grad tensor([-537.9855], device='cuda:0')\n",
      "sigma1 grad tensor([[-472.4897]], device='cuda:0')\n",
      "gamma grad tensor([[4443.5225]], device='cuda:0')\n",
      "alpha grad tensor([[-8365.3945]], device='cuda:0')\n",
      "beta2 grad tensor([[8432.4346]], device='cuda:0')\n",
      "beta0 grad tensor([3822.9084], device='cuda:0')\n",
      "beta1 grad tensor([[5357.6553]], device='cuda:0')\n",
      "Epoch 159 | Loss: 8.8118\n",
      "alpha: 0.07661227881908417, beta0: 0.11426158249378204, beta1: -0.000652664341032505, beta2: 0.0022285287268459797, \n",
      "gamma: 0.06347224116325378, sigma0: 0.2666022479534149, sigma1: 0.000310824514599517, sigma2: 3.705786002683453e-05, sigmaX: 0.15501593053340912\n",
      "forward done\n",
      "tensor([0.0200, 0.2416, 0.1097, 0.6887, 0.4026], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.6108]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-412.5085]], device='cuda:0')\n",
      "sigma0 grad tensor([-466.7723], device='cuda:0')\n",
      "sigma1 grad tensor([[-399.6659]], device='cuda:0')\n",
      "gamma grad tensor([[3084.0161]], device='cuda:0')\n",
      "alpha grad tensor([[-6172.7153]], device='cuda:0')\n",
      "beta2 grad tensor([[5955.9521]], device='cuda:0')\n",
      "beta0 grad tensor([2948.4065], device='cuda:0')\n",
      "beta1 grad tensor([[3959.9209]], device='cuda:0')\n",
      "Epoch 160 | Loss: 25.3805\n",
      "alpha: 0.07682450115680695, beta0: 0.11416014283895493, beta1: -0.0007907594554126263, beta2: 0.0020183357410132885, \n",
      "gamma: 0.06336517632007599, sigma0: 0.26661884784698486, sigma1: 0.00032520919921807945, sigma2: 5.2462524763541296e-05, sigmaX: 0.1550159901380539\n",
      "forward done\n",
      "tensor([0.0084, 0.0414, 0.1918, 0.6375, 0.3836], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.9407]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-59.6656]], device='cuda:0')\n",
      "sigma0 grad tensor([-13.6669], device='cuda:0')\n",
      "sigma1 grad tensor([[-30.8217]], device='cuda:0')\n",
      "gamma grad tensor([[-961.7780]], device='cuda:0')\n",
      "alpha grad tensor([[1534.2637]], device='cuda:0')\n",
      "beta2 grad tensor([[-1151.1924]], device='cuda:0')\n",
      "beta0 grad tensor([-537.0803], device='cuda:0')\n",
      "beta1 grad tensor([[-742.6854]], device='cuda:0')\n",
      "Epoch 161 | Loss: 5.3585\n",
      "alpha: 0.07697893679141998, beta0: 0.11408436298370361, beta1: -0.0008938087266869843, beta2: 0.0018616932211443782, \n",
      "gamma: 0.06328914314508438, sigma0: 0.2666322588920593, sigma1: 0.0003370251797605306, sigma2: 6.538291199831292e-05, sigmaX: 0.15501606464385986\n",
      "forward done\n",
      "tensor([0.0185, 0.2411, 0.2289, 0.5963, 0.4061], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.6494]]], device='cuda:0')\n",
      "sigma2 grad tensor([[923.2144]], device='cuda:0')\n",
      "sigma0 grad tensor([751.9149], device='cuda:0')\n",
      "sigma1 grad tensor([[753.4123]], device='cuda:0')\n",
      "gamma grad tensor([[-5864.1353]], device='cuda:0')\n",
      "alpha grad tensor([[11217.8408]], device='cuda:0')\n",
      "beta2 grad tensor([[-13690.9033]], device='cuda:0')\n",
      "beta0 grad tensor([-5195.2988], device='cuda:0')\n",
      "beta1 grad tensor([[-8002.0986]], device='cuda:0')\n",
      "Epoch 162 | Loss: 25.3643\n",
      "alpha: 0.07699030637741089, beta0: 0.1140756905078888, beta1: -0.000896227138582617, beta2: 0.001873288187198341, \n",
      "gamma: 0.06328695267438889, sigma0: 0.2666354775428772, sigma1: 0.0003389438206795603, sigma2: 6.648708222201094e-05, sigmaX: 0.15501612424850464\n",
      "forward done\n",
      "tensor([0.0121, 0.1051, 0.1969, 0.6220, 0.3537], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-4.8446]]], device='cuda:0')\n",
      "sigma2 grad tensor([[722.6795]], device='cuda:0')\n",
      "sigma0 grad tensor([655.8015], device='cuda:0')\n",
      "sigma1 grad tensor([[621.2660]], device='cuda:0')\n",
      "gamma grad tensor([[-4692.5117]], device='cuda:0')\n",
      "alpha grad tensor([[9186.3428]], device='cuda:0')\n",
      "beta2 grad tensor([[-10571.9443]], device='cuda:0')\n",
      "beta0 grad tensor([-4332.9380], device='cuda:0')\n",
      "beta1 grad tensor([[-6396.7983]], device='cuda:0')\n",
      "Epoch 163 | Loss: 11.6975\n",
      "alpha: 0.07690753787755966, beta0: 0.11411207914352417, beta1: -0.0008341938955709338, beta2: 0.0019882835913449526, \n",
      "gamma: 0.06333212554454803, sigma0: 0.26663148403167725, sigma1: 0.0003342660784255713, sigma2: 6.0143622249597684e-05, sigmaX: 0.155016228556633\n",
      "forward done\n",
      "tensor([0.0268, 0.3490, 0.2039, 0.6091, 0.3297], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.2582]]], device='cuda:0')\n",
      "sigma2 grad tensor([[933.1707]], device='cuda:0')\n",
      "sigma0 grad tensor([789.0544], device='cuda:0')\n",
      "sigma1 grad tensor([[763.4081]], device='cuda:0')\n",
      "gamma grad tensor([[-7607.0562]], device='cuda:0')\n",
      "alpha grad tensor([[13862.4268]], device='cuda:0')\n",
      "beta2 grad tensor([[-16084.7188]], device='cuda:0')\n",
      "beta0 grad tensor([-6180.1426], device='cuda:0')\n",
      "beta1 grad tensor([[-9419.5605]], device='cuda:0')\n",
      "Epoch 164 | Loss: 36.0736\n",
      "alpha: 0.07670269906520844, beta0: 0.11420299112796783, beta1: -0.0006903716712258756, beta2: 0.0022411271929740906, \n",
      "gamma: 0.0634443387389183, sigma0: 0.266620397567749, sigma1: 0.0003228897985536605, sigma2: 4.5737146137980744e-05, sigmaX: 0.15501631796360016\n",
      "forward done\n",
      "tensor([0.0152, 0.0745, 0.2465, 0.6181, 0.3636], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.5343]]], device='cuda:0')\n",
      "sigma2 grad tensor([[54.2790]], device='cuda:0')\n",
      "sigma0 grad tensor([70.1581], device='cuda:0')\n",
      "sigma1 grad tensor([[56.7485]], device='cuda:0')\n",
      "gamma grad tensor([[-1692.4946]], device='cuda:0')\n",
      "alpha grad tensor([[2885.5125]], device='cuda:0')\n",
      "beta2 grad tensor([[-2779.1555]], device='cuda:0')\n",
      "beta0 grad tensor([-1148.0411], device='cuda:0')\n",
      "beta1 grad tensor([[-1688.2450]], device='cuda:0')\n",
      "Epoch 165 | Loss: 8.6903\n",
      "alpha: 0.0765099748969078, beta0: 0.11428720504045486, beta1: -0.0005584314349107444, beta2: 0.0024711936712265015, \n",
      "gamma: 0.06355103105306625, sigma0: 0.2666108310222626, sigma1: 0.0003132213023491204, sigma2: 3.3669177355477586e-05, sigmaX: 0.15501640737056732\n",
      "forward done\n",
      "tensor([0.0123, 0.0302, 0.3279, 0.5976, 0.3057], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.5943]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-18.7873]], device='cuda:0')\n",
      "sigma0 grad tensor([-3.2619], device='cuda:0')\n",
      "sigma1 grad tensor([[-10.2919]], device='cuda:0')\n",
      "gamma grad tensor([[-1081.7842]], device='cuda:0')\n",
      "alpha grad tensor([[1761.8247]], device='cuda:0')\n",
      "beta2 grad tensor([[-1470.7679]], device='cuda:0')\n",
      "beta0 grad tensor([-630.8104], device='cuda:0')\n",
      "beta1 grad tensor([[-906.5829]], device='cuda:0')\n",
      "Epoch 166 | Loss: 4.2615\n",
      "alpha: 0.07633817940950394, beta0: 0.11436088383197784, beta1: -0.0004438134201336652, beta2: 0.002669954439625144, \n",
      "gamma: 0.06364720314741135, sigma0: 0.2666032016277313, sigma1: 0.00030558943399228156, sigma2: 2.420267446723301e-05, sigmaX: 0.15501651167869568\n",
      "forward done\n",
      "tensor([0.0075, 0.0592, 0.1024, 0.6657, 0.3943], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.7070]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-47.7136]], device='cuda:0')\n",
      "sigma0 grad tensor([-5.0195], device='cuda:0')\n",
      "sigma1 grad tensor([[-23.0789]], device='cuda:0')\n",
      "gamma grad tensor([[-904.2712]], device='cuda:0')\n",
      "alpha grad tensor([[1451.4474]], device='cuda:0')\n",
      "beta2 grad tensor([[-1039.8774]], device='cuda:0')\n",
      "beta0 grad tensor([-513.0536], device='cuda:0')\n",
      "beta1 grad tensor([[-693.6360]], device='cuda:0')\n",
      "Epoch 167 | Loss: 7.0911\n",
      "alpha: 0.07618622481822968, beta0: 0.11442495882511139, beta1: -0.000345182663295418, beta2: 0.002839361783117056, \n",
      "gamma: 0.06373318284749985, sigma0: 0.2665971517562866, sigma1: 0.00029971470939926803, sigma2: 1.7106609448092058e-05, sigmaX: 0.15501660108566284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0208, 0.1475, 0.0877, 0.7018, 0.4324], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.4917]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-414.2574]], device='cuda:0')\n",
      "sigma0 grad tensor([-504.0744], device='cuda:0')\n",
      "sigma1 grad tensor([[-411.4358]], device='cuda:0')\n",
      "gamma grad tensor([[3516.1482]], device='cuda:0')\n",
      "alpha grad tensor([[-6835.1235]], device='cuda:0')\n",
      "beta2 grad tensor([[6573.3657]], device='cuda:0')\n",
      "beta0 grad tensor([3201.3779], device='cuda:0')\n",
      "beta1 grad tensor([[4352.1655]], device='cuda:0')\n",
      "Epoch 168 | Loss: 15.9946\n",
      "alpha: 0.07613301277160645, beta0: 0.11444420367479324, beta1: -0.0003097997105214745, beta2: 0.0029091541655361652, \n",
      "gamma: 0.06376680731773376, sigma0: 0.26659736037254333, sigma1: 0.00029912928584963083, sigma2: 1.5572330084978603e-05, sigmaX: 0.15501669049263\n",
      "forward done\n",
      "tensor([0.0186, 0.2213, 0.2669, 0.6406, 0.4380], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[0.0420]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-396.7968]], device='cuda:0')\n",
      "sigma0 grad tensor([-467.7326], device='cuda:0')\n",
      "sigma1 grad tensor([[-389.3086]], device='cuda:0')\n",
      "gamma grad tensor([[2712.2275]], device='cuda:0')\n",
      "alpha grad tensor([[-5558.0381]], device='cuda:0')\n",
      "beta2 grad tensor([[5394.4038]], device='cuda:0')\n",
      "beta0 grad tensor([2695.8872], device='cuda:0')\n",
      "beta1 grad tensor([[3616.6213]], device='cuda:0')\n",
      "Epoch 169 | Loss: 23.4946\n",
      "alpha: 0.07614602148532867, beta0: 0.11443264037370682, beta1: -0.0003176595491822809, beta2: 0.0029110440518707037, \n",
      "gamma: 0.06376658380031586, sigma0: 0.26660218834877014, sigma1: 0.0003025540499947965, sigma2: 1.8312874090042897e-05, sigmaX: 0.15501676499843597\n",
      "forward done\n",
      "tensor([0.0271, 0.1802, 0.1603, 0.6276, 0.3666], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.1336]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-482.3140]], device='cuda:0')\n",
      "sigma0 grad tensor([-469.6087], device='cuda:0')\n",
      "sigma1 grad tensor([[-423.4363]], device='cuda:0')\n",
      "gamma grad tensor([[3269.9729]], device='cuda:0')\n",
      "alpha grad tensor([[-6364.8271]], device='cuda:0')\n",
      "beta2 grad tensor([[6545.0601]], device='cuda:0')\n",
      "beta0 grad tensor([2978.7271], device='cuda:0')\n",
      "beta1 grad tensor([[4163.3203]], device='cuda:0')\n",
      "Epoch 170 | Loss: 19.1995\n",
      "alpha: 0.0762200802564621, beta0: 0.11439359933137894, beta1: -0.0003655806358437985, beta2: 0.0028471052646636963, \n",
      "gamma: 0.06373370438814163, sigma0: 0.2666107714176178, sigma1: 0.00030952822999097407, sigma2: 2.5328448828076944e-05, sigmaX: 0.15501683950424194\n",
      "forward done\n",
      "tensor([0.0173, 0.1925, 0.2913, 0.6841, 0.4084], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.7603]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-357.2718]], device='cuda:0')\n",
      "sigma0 grad tensor([-480.4658], device='cuda:0')\n",
      "sigma1 grad tensor([[-367.9659]], device='cuda:0')\n",
      "gamma grad tensor([[3336.9290]], device='cuda:0')\n",
      "alpha grad tensor([[-6514.8291]], device='cuda:0')\n",
      "beta2 grad tensor([[6084.5508]], device='cuda:0')\n",
      "beta0 grad tensor([3056.2937], device='cuda:0')\n",
      "beta1 grad tensor([[4064.0459]], device='cuda:0')\n",
      "Epoch 171 | Loss: 20.6532\n",
      "alpha: 0.07634447515010834, beta0: 0.11433180421590805, beta1: -0.00044455795432440937, beta2: 0.0027351088356226683, \n",
      "gamma: 0.06367403268814087, sigma0: 0.2666224241256714, sigma1: 0.00031878723530098796, sigma2: 3.451362863415852e-05, sigmaX: 0.1550169140100479\n",
      "forward done\n",
      "tensor([0.0247, 0.1561, 0.1832, 0.6842, 0.4025], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.1044]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-448.3988]], device='cuda:0')\n",
      "sigma0 grad tensor([-488.7178], device='cuda:0')\n",
      "sigma1 grad tensor([[-416.4391]], device='cuda:0')\n",
      "gamma grad tensor([[3668.0164]], device='cuda:0')\n",
      "alpha grad tensor([[-7023.1621]], device='cuda:0')\n",
      "beta2 grad tensor([[7046.0400]], device='cuda:0')\n",
      "beta0 grad tensor([3255.1978], device='cuda:0')\n",
      "beta1 grad tensor([[4512.8828]], device='cuda:0')\n",
      "Epoch 172 | Loss: 16.9083\n",
      "alpha: 0.07651422172784805, beta0: 0.1142498180270195, beta1: -0.0005528686451725662, beta2: 0.002575051272287965, \n",
      "gamma: 0.06358961760997772, sigma0: 0.2666366398334503, sigma1: 0.0003303588309790939, sigma2: 4.6345758164534345e-05, sigmaX: 0.15501698851585388\n",
      "forward done\n",
      "tensor([0.0185, 0.1594, 0.3098, 0.6528, 0.3659], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.2190]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-450.8278]], device='cuda:0')\n",
      "sigma0 grad tensor([-482.9938], device='cuda:0')\n",
      "sigma1 grad tensor([[-415.9445]], device='cuda:0')\n",
      "gamma grad tensor([[3922.5950]], device='cuda:0')\n",
      "alpha grad tensor([[-7442.9785]], device='cuda:0')\n",
      "beta2 grad tensor([[7279.2466]], device='cuda:0')\n",
      "beta0 grad tensor([3419.6741], device='cuda:0')\n",
      "beta1 grad tensor([[4703.0776]], device='cuda:0')\n",
      "Epoch 173 | Loss: 17.2849\n",
      "alpha: 0.07672444730997086, beta0: 0.1141500324010849, beta1: -0.000686547951772809, beta2: 0.002374212723225355, \n",
      "gamma: 0.0634828582406044, sigma0: 0.2666528522968292, sigma1: 0.00034377555130049586, sigma2: 6.03197404416278e-05, sigmaX: 0.15501706302165985\n",
      "forward done\n",
      "tensor([0.0145, 0.2241, 0.3787, 0.5428, 0.2329], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.1113]]], device='cuda:0')\n",
      "sigma2 grad tensor([[911.3047]], device='cuda:0')\n",
      "sigma0 grad tensor([693.6884], device='cuda:0')\n",
      "sigma1 grad tensor([[697.5735]], device='cuda:0')\n",
      "gamma grad tensor([[-5644.6665]], device='cuda:0')\n",
      "alpha grad tensor([[10662.0342]], device='cuda:0')\n",
      "beta2 grad tensor([[-12709.4072]], device='cuda:0')\n",
      "beta0 grad tensor([-4879.7275], device='cuda:0')\n",
      "beta1 grad tensor([[-7418.5195]], device='cuda:0')\n",
      "Epoch 174 | Loss: 23.5782\n",
      "alpha: 0.07678601145744324, beta0: 0.11411900073289871, beta1: -0.000719306233804673, beta2: 0.002340635983273387, \n",
      "gamma: 0.06345389783382416, sigma0: 0.26665887236595154, sigma1: 0.0003475331759545952, sigma2: 6.238587957341224e-05, sigmaX: 0.15501713752746582\n",
      "forward done\n",
      "tensor([0.0082, 0.0957, 0.3154, 0.6811, 0.4804], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.5326]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-424.7255]], device='cuda:0')\n",
      "sigma0 grad tensor([-549.5369], device='cuda:0')\n",
      "sigma1 grad tensor([[-438.4502]], device='cuda:0')\n",
      "gamma grad tensor([[4017.5957]], device='cuda:0')\n",
      "alpha grad tensor([[-7796.5103]], device='cuda:0')\n",
      "beta2 grad tensor([[7559.6069]], device='cuda:0')\n",
      "beta0 grad tensor([3646.2097], device='cuda:0')\n",
      "beta1 grad tensor([[4977.1763]], device='cuda:0')\n",
      "Epoch 175 | Loss: 11.0593\n",
      "alpha: 0.07691322267055511, beta0: 0.11405771225690842, beta1: -0.0007952845771797001, beta2: 0.0022381783928722143, \n",
      "gamma: 0.06339055299758911, sigma0: 0.2666691839694977, sigma1: 0.0003549237735569477, sigma2: 6.828604819020256e-05, sigmaX: 0.1550171971321106\n",
      "forward done\n",
      "tensor([0.0149, 0.2163, 0.2435, 0.5792, 0.3066], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.9708]]], device='cuda:0')\n",
      "sigma2 grad tensor([[860.7803]], device='cuda:0')\n",
      "sigma0 grad tensor([718.2214], device='cuda:0')\n",
      "sigma1 grad tensor([[709.4788]], device='cuda:0')\n",
      "gamma grad tensor([[-5112.4844]], device='cuda:0')\n",
      "alpha grad tensor([[9960.1055]], device='cuda:0')\n",
      "beta2 grad tensor([[-11631.6348]], device='cuda:0')\n",
      "beta0 grad tensor([-4679.8379], device='cuda:0')\n",
      "beta1 grad tensor([[-6986.0654]], device='cuda:0')\n",
      "Epoch 176 | Loss: 22.7756\n",
      "alpha: 0.07691539078950882, beta0: 0.11405547708272934, beta1: -0.0007862066267989576, beta2: 0.0022725288290530443, \n",
      "gamma: 0.06339100003242493, sigma0: 0.26667025685310364, sigma1: 0.00035374145954847336, sigma2: 6.439838034566492e-05, sigmaX: 0.15501725673675537\n",
      "forward done\n",
      "tensor([0.0106, 0.0775, 0.2744, 0.6327, 0.3496], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-4.2421]]], device='cuda:0')\n",
      "sigma2 grad tensor([[606.6494]], device='cuda:0')\n",
      "sigma0 grad tensor([623.3657], device='cuda:0')\n",
      "sigma1 grad tensor([[548.9548]], device='cuda:0')\n",
      "gamma grad tensor([[-4992.0063]], device='cuda:0')\n",
      "alpha grad tensor([[9505.4023]], device='cuda:0')\n",
      "beta2 grad tensor([[-9930.5068]], device='cuda:0')\n",
      "beta0 grad tensor([-4373.2480], device='cuda:0')\n",
      "beta1 grad tensor([[-6227.2100]], device='cuda:0')\n",
      "Epoch 177 | Loss: 9.0157\n",
      "alpha: 0.07682207226753235, beta0: 0.11409742385149002, beta1: -0.0007166721625253558, beta2: 0.002399314194917679, \n",
      "gamma: 0.06344127655029297, sigma0: 0.26666489243507385, sigma1: 0.0003473060787655413, sigma2: 5.5221749789780006e-05, sigmaX: 0.15501734614372253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0137, 0.0993, 0.3735, 0.6230, 0.3826], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.3356]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-442.6959]], device='cuda:0')\n",
      "sigma0 grad tensor([-530.6674], device='cuda:0')\n",
      "sigma1 grad tensor([[-436.2242]], device='cuda:0')\n",
      "gamma grad tensor([[4310.6445]], device='cuda:0')\n",
      "alpha grad tensor([[-8216.0146]], device='cuda:0')\n",
      "beta2 grad tensor([[7962.8022]], device='cuda:0')\n",
      "beta0 grad tensor([3779.0803], device='cuda:0')\n",
      "beta1 grad tensor([[5188.4058]], device='cuda:0')\n",
      "Epoch 178 | Loss: 11.3215\n",
      "alpha: 0.07682957500219345, beta0: 0.11409319192171097, beta1: -0.000712928653229028, beta2: 0.0024211143609136343, \n",
      "gamma: 0.06343839317560196, sigma0: 0.26666590571403503, sigma1: 0.0003465200134087354, sigma2: 5.230740498518571e-05, sigmaX: 0.1550174355506897\n",
      "forward done\n",
      "tensor([0.0133, 0.0475, 0.2914, 0.6089, 0.3479], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.1130]]], device='cuda:0')\n",
      "sigma2 grad tensor([[14.2463]], device='cuda:0')\n",
      "sigma0 grad tensor([59.7124], device='cuda:0')\n",
      "sigma1 grad tensor([[29.2481]], device='cuda:0')\n",
      "gamma grad tensor([[-1493.0574]], device='cuda:0')\n",
      "alpha grad tensor([[2564.3252]], device='cuda:0')\n",
      "beta2 grad tensor([[-2261.3157]], device='cuda:0')\n",
      "beta0 grad tensor([-1014.0570], device='cuda:0')\n",
      "beta1 grad tensor([[-1426.4445]], device='cuda:0')\n",
      "Epoch 179 | Loss: 6.0123\n",
      "alpha: 0.07680993527173996, beta0: 0.11409994959831238, beta1: -0.0006956693832762539, beta2: 0.002461167750880122, \n",
      "gamma: 0.06345101445913315, sigma0: 0.26666611433029175, sigma1: 0.0003455986734479666, sigma2: 4.983346661902033e-05, sigmaX: 0.15501752495765686\n",
      "forward done\n",
      "tensor([0.0116, 0.1158, 0.1303, 0.6949, 0.4232], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.4490]]], device='cuda:0')\n",
      "sigma2 grad tensor([[631.2973]], device='cuda:0')\n",
      "sigma0 grad tensor([594.9955], device='cuda:0')\n",
      "sigma1 grad tensor([[553.4186]], device='cuda:0')\n",
      "gamma grad tensor([[-5156.5967]], device='cuda:0')\n",
      "alpha grad tensor([[9676.4414]], device='cuda:0')\n",
      "beta2 grad tensor([[-10323.0615]], device='cuda:0')\n",
      "beta0 grad tensor([-4387.8530], device='cuda:0')\n",
      "beta1 grad tensor([[-6387.7329]], device='cuda:0')\n",
      "Epoch 180 | Loss: 12.8449\n",
      "alpha: 0.0766974613070488, beta0: 0.11414923518896103, beta1: -0.0006179846241138875, beta2: 0.0025964409578591585, \n",
      "gamma: 0.06351268291473389, sigma0: 0.26666033267974854, sigma1: 0.00033932740916498005, sigma2: 4.154134148848243e-05, sigmaX: 0.15501761436462402\n",
      "forward done\n",
      "tensor([0.0096, 0.0527, 0.0750, 0.6787, 0.4098], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.1889]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-167.4101]], device='cuda:0')\n",
      "sigma0 grad tensor([-172.7050], device='cuda:0')\n",
      "sigma1 grad tensor([[-153.5329]], device='cuda:0')\n",
      "gamma grad tensor([[453.9792]], device='cuda:0')\n",
      "alpha grad tensor([[-1143.8604]], device='cuda:0')\n",
      "beta2 grad tensor([[1436.0066]], device='cuda:0')\n",
      "beta0 grad tensor([671.3273], device='cuda:0')\n",
      "beta1 grad tensor([[932.0867]], device='cuda:0')\n",
      "Epoch 181 | Loss: 6.4395\n",
      "alpha: 0.07661891728639603, beta0: 0.11418195068836212, beta1: -0.0005651576793752611, beta2: 0.0026902996469289064, \n",
      "gamma: 0.06355747580528259, sigma0: 0.26665744185447693, sigma1: 0.00033584574703127146, sigma2: 3.658174318843521e-05, sigmaX: 0.1550177037715912\n",
      "forward done\n",
      "tensor([0.0095, 0.1842, 0.2980, 0.7106, 0.4038], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[1.3890]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-370.8048]], device='cuda:0')\n",
      "sigma0 grad tensor([-476.2595], device='cuda:0')\n",
      "sigma1 grad tensor([[-381.6025]], device='cuda:0')\n",
      "gamma grad tensor([[3856.5569]], device='cuda:0')\n",
      "alpha grad tensor([[-7332.2134]], device='cuda:0')\n",
      "beta2 grad tensor([[6598.0186]], device='cuda:0')\n",
      "beta0 grad tensor([3369.5757], device='cuda:0')\n",
      "beta1 grad tensor([[4460.6182]], device='cuda:0')\n",
      "Epoch 182 | Loss: 19.8460\n",
      "alpha: 0.0766294077038765, beta0: 0.11417442560195923, beta1: -0.0005675023421645164, beta2: 0.0026994063518941402, \n",
      "gamma: 0.06355474144220352, sigma0: 0.2666598856449127, sigma1: 0.0003368764300830662, sigma2: 3.63221115549095e-05, sigmaX: 0.15501776337623596\n",
      "forward done\n",
      "tensor([0.0062, 0.0553, 0.1491, 0.6901, 0.4030], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.6187]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-75.7768]], device='cuda:0')\n",
      "sigma0 grad tensor([-53.3811], device='cuda:0')\n",
      "sigma1 grad tensor([[-57.5285]], device='cuda:0')\n",
      "gamma grad tensor([[-532.5016]], device='cuda:0')\n",
      "alpha grad tensor([[721.2045]], device='cuda:0')\n",
      "beta2 grad tensor([[-372.9370]], device='cuda:0')\n",
      "beta0 grad tensor([-176.1545], device='cuda:0')\n",
      "beta1 grad tensor([[-243.3235]], device='cuda:0')\n",
      "Epoch 183 | Loss: 6.7819\n",
      "alpha: 0.07663058489561081, beta0: 0.11417016386985779, beta1: -0.0005669448291882873, beta2: 0.0027104211039841175, \n",
      "gamma: 0.06355787813663483, sigma0: 0.2666623592376709, sigma1: 0.0003382762661203742, sigma2: 3.6872173950541764e-05, sigmaX: 0.15501782298088074\n",
      "forward done\n",
      "tensor([0.0080, 0.0564, 0.1983, 0.6333, 0.3562], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.7886]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-516.0593]], device='cuda:0')\n",
      "sigma0 grad tensor([-534.9955], device='cuda:0')\n",
      "sigma1 grad tensor([[-468.6378]], device='cuda:0')\n",
      "gamma grad tensor([[3786.3999]], device='cuda:0')\n",
      "alpha grad tensor([[-7366.4072]], device='cuda:0')\n",
      "beta2 grad tensor([[7531.0649]], device='cuda:0')\n",
      "beta0 grad tensor([3440.3977], device='cuda:0')\n",
      "beta1 grad tensor([[4799.9619]], device='cuda:0')\n",
      "Epoch 184 | Loss: 6.8380\n",
      "alpha: 0.0767051950097084, beta0: 0.1141323521733284, beta1: -0.0006144984508864582, beta2: 0.002643922343850136, \n",
      "gamma: 0.06352252513170242, sigma0: 0.26666969060897827, sigma1: 0.00034408250940032303, sigma2: 4.247281685820781e-05, sigmaX: 0.1550178974866867\n",
      "forward done\n",
      "tensor([0.0160, 0.0539, 0.0786, 0.6854, 0.3893], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.8805]]], device='cuda:0')\n",
      "sigma2 grad tensor([[451.7256]], device='cuda:0')\n",
      "sigma0 grad tensor([478.4576], device='cuda:0')\n",
      "sigma1 grad tensor([[423.3675]], device='cuda:0')\n",
      "gamma grad tensor([[-4159.8149]], device='cuda:0')\n",
      "alpha grad tensor([[7873.6025]], device='cuda:0')\n",
      "beta2 grad tensor([[-8089.2515]], device='cuda:0')\n",
      "beta0 grad tensor([-3571.4912], device='cuda:0')\n",
      "beta1 grad tensor([[-5097.3398]], device='cuda:0')\n",
      "Epoch 185 | Loss: 6.5598\n",
      "alpha: 0.07668614387512207, beta0: 0.11413782089948654, beta1: -0.0006015679100528359, beta2: 0.0026716156862676144, \n",
      "gamma: 0.06353583931922913, sigma0: 0.26667076349258423, sigma1: 0.00034449383383616805, sigma2: 4.243607327225618e-05, sigmaX: 0.15501797199249268\n",
      "forward done\n",
      "tensor([0.0125, 0.1115, 0.1360, 0.6953, 0.4107], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.8377]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-359.9794]], device='cuda:0')\n",
      "sigma0 grad tensor([-515.7399], device='cuda:0')\n",
      "sigma1 grad tensor([[-392.7865]], device='cuda:0')\n",
      "gamma grad tensor([[4374.7583]], device='cuda:0')\n",
      "alpha grad tensor([[-8188.0552]], device='cuda:0')\n",
      "beta2 grad tensor([[7565.9771]], device='cuda:0')\n",
      "beta0 grad tensor([3726.6182], device='cuda:0')\n",
      "beta1 grad tensor([[5029.6904]], device='cuda:0')\n",
      "Epoch 186 | Loss: 12.4073\n",
      "alpha: 0.07675278186798096, beta0: 0.11410492658615112, beta1: -0.0006415204261429608, beta2: 0.002618110738694668, \n",
      "gamma: 0.06350274384021759, sigma0: 0.26667678356170654, sigma1: 0.0003487507638055831, sigma2: 4.600647298502736e-05, sigmaX: 0.15501803159713745\n",
      "forward done\n",
      "tensor([0.0099, 0.0637, 0.4119, 0.5691, 0.3207], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.7297]]], device='cuda:0')\n",
      "sigma2 grad tensor([[26.5041]], device='cuda:0')\n",
      "sigma0 grad tensor([66.0984], device='cuda:0')\n",
      "sigma1 grad tensor([[41.1000]], device='cuda:0')\n",
      "gamma grad tensor([[-1519.2799]], device='cuda:0')\n",
      "alpha grad tensor([[2620.7649]], device='cuda:0')\n",
      "beta2 grad tensor([[-2310.9607]], device='cuda:0')\n",
      "beta0 grad tensor([-1044.8883], device='cuda:0')\n",
      "beta1 grad tensor([[-1459.1597]], device='cuda:0')\n",
      "Epoch 187 | Loss: 7.6789\n",
      "alpha: 0.07677988708019257, beta0: 0.11408906430006027, beta1: -0.0006588908145204186, beta2: 0.002598416293039918, \n",
      "gamma: 0.06349146366119385, sigma0: 0.2666809558868408, sigma1: 0.0003517452860251069, sigma2: 4.859775071963668e-05, sigmaX: 0.15501810610294342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0248, 0.0612, 0.1880, 0.6794, 0.3803], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.3218]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-184.9695]], device='cuda:0')\n",
      "sigma0 grad tensor([-164.8337], device='cuda:0')\n",
      "sigma1 grad tensor([[-153.6181]], device='cuda:0')\n",
      "gamma grad tensor([[462.7161]], device='cuda:0')\n",
      "alpha grad tensor([[-1149.1312]], device='cuda:0')\n",
      "beta2 grad tensor([[1536.3654]], device='cuda:0')\n",
      "beta0 grad tensor([663.2003], device='cuda:0')\n",
      "beta1 grad tensor([[950.4100]], device='cuda:0')\n",
      "Epoch 188 | Loss: 7.3938\n",
      "alpha: 0.07681306451559067, beta0: 0.11406973749399185, beta1: -0.0006822912255302072, beta2: 0.0025672970805317163, \n",
      "gamma: 0.06347780674695969, sigma0: 0.26668593287467957, sigma1: 0.0003556770971044898, sigma2: 5.2520466852001846e-05, sigmaX: 0.15501819550991058\n",
      "forward done\n",
      "tensor([0.0172, 0.1946, 0.3236, 0.5966, 0.3013], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.2555]]], device='cuda:0')\n",
      "sigma2 grad tensor([[873.5432]], device='cuda:0')\n",
      "sigma0 grad tensor([664.3005], device='cuda:0')\n",
      "sigma1 grad tensor([[667.2853]], device='cuda:0')\n",
      "gamma grad tensor([[-5423.8228]], device='cuda:0')\n",
      "alpha grad tensor([[10196.7236]], device='cuda:0')\n",
      "beta2 grad tensor([[-12372.1367]], device='cuda:0')\n",
      "beta0 grad tensor([-4644.0400], device='cuda:0')\n",
      "beta1 grad tensor([[-7139.6816]], device='cuda:0')\n",
      "Epoch 189 | Loss: 20.6962\n",
      "alpha: 0.07673763483762741, beta0: 0.11410071700811386, beta1: -0.000629614747595042, beta2: 0.0026661232113838196, \n",
      "gamma: 0.0635211244225502, sigma0: 0.26668328046798706, sigma1: 0.0003521496837493032, sigma2: 4.6923210902605206e-05, sigmaX: 0.15501827001571655\n",
      "forward done\n",
      "tensor([0.0125, 0.0564, 0.2977, 0.6167, 0.3551], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.9366]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-27.0406]], device='cuda:0')\n",
      "sigma0 grad tensor([-8.6993], device='cuda:0')\n",
      "sigma1 grad tensor([[-15.5958]], device='cuda:0')\n",
      "gamma grad tensor([[-883.4568]], device='cuda:0')\n",
      "alpha grad tensor([[1405.0151]], device='cuda:0')\n",
      "beta2 grad tensor([[-1125.8844]], device='cuda:0')\n",
      "beta0 grad tensor([-492.2133], device='cuda:0')\n",
      "beta1 grad tensor([[-703.7656]], device='cuda:0')\n",
      "Epoch 190 | Loss: 6.9216\n",
      "alpha: 0.07666324079036713, beta0: 0.1141304224729538, beta1: -0.0005804359097965062, beta2: 0.0027564428746700287, \n",
      "gamma: 0.06356461346149445, sigma0: 0.2666812241077423, sigma1: 0.0003494837146718055, sigma2: 4.271581201464869e-05, sigmaX: 0.15501835942268372\n",
      "forward done\n",
      "tensor([0.0159, 0.1636, 0.2840, 0.6373, 0.3595], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-3.5194]]], device='cuda:0')\n",
      "sigma2 grad tensor([[685.1383]], device='cuda:0')\n",
      "sigma0 grad tensor([620.9922], device='cuda:0')\n",
      "sigma1 grad tensor([[586.1469]], device='cuda:0')\n",
      "gamma grad tensor([[-5394.8340]], device='cuda:0')\n",
      "alpha grad tensor([[10070.7607]], device='cuda:0')\n",
      "beta2 grad tensor([[-10630.4014]], device='cuda:0')\n",
      "beta0 grad tensor([-4557.7095], device='cuda:0')\n",
      "beta1 grad tensor([[-6596.7549]], device='cuda:0')\n",
      "Epoch 191 | Loss: 17.6559\n",
      "alpha: 0.07650301605463028, beta0: 0.11419976502656937, beta1: -0.0004751252708956599, beta2: 0.0029350025579333305, \n",
      "gamma: 0.06365334987640381, sigma0: 0.26667338609695435, sigma1: 0.0003414894745219499, sigma2: 3.249850851716474e-05, sigmaX: 0.15501846373081207\n",
      "forward done\n",
      "tensor([0.0157, 0.0885, 0.2847, 0.6643, 0.4031], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.4359]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-330.7057]], device='cuda:0')\n",
      "sigma0 grad tensor([-342.2433], device='cuda:0')\n",
      "sigma1 grad tensor([[-297.3268]], device='cuda:0')\n",
      "gamma grad tensor([[2392.5583]], device='cuda:0')\n",
      "alpha grad tensor([[-4646.1421]], device='cuda:0')\n",
      "beta2 grad tensor([[4682.8223]], device='cuda:0')\n",
      "beta0 grad tensor([2182.8713], device='cuda:0')\n",
      "beta1 grad tensor([[3019.8904]], device='cuda:0')\n",
      "Epoch 192 | Loss: 10.2226\n",
      "alpha: 0.07642129808664322, beta0: 0.11423341184854507, beta1: -0.00042107567423954606, beta2: 0.00303102214820683, \n",
      "gamma: 0.06370041519403458, sigma0: 0.2666705250740051, sigma1: 0.00033806735882535577, sigma2: 2.7631724151433446e-05, sigmaX: 0.15501855313777924\n",
      "forward done\n",
      "tensor([0.0177, 0.1805, 0.2798, 0.7092, 0.4154], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.6203]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-409.6373]], device='cuda:0')\n",
      "sigma0 grad tensor([-465.2632], device='cuda:0')\n",
      "sigma1 grad tensor([[-394.9930]], device='cuda:0')\n",
      "gamma grad tensor([[3415.8853]], device='cuda:0')\n",
      "alpha grad tensor([[-6626.3047]], device='cuda:0')\n",
      "beta2 grad tensor([[6317.4521]], device='cuda:0')\n",
      "beta0 grad tensor([3085.9995], device='cuda:0')\n",
      "beta1 grad tensor([[4184.6035]], device='cuda:0')\n",
      "Epoch 193 | Loss: 19.4743\n",
      "alpha: 0.07642219215631485, beta0: 0.1142294704914093, beta1: -0.00041968203731812537, beta2: 0.003044663229957223, \n",
      "gamma: 0.06370390951633453, sigma0: 0.26667290925979614, sigma1: 0.00033927959157153964, sigma2: 2.7834668799187057e-05, sigmaX: 0.1550186425447464\n",
      "forward done\n",
      "tensor([0.0201, 0.1133, 0.1577, 0.7041, 0.4090], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.5025]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-404.5205]], device='cuda:0')\n",
      "sigma0 grad tensor([-490.8243], device='cuda:0')\n",
      "sigma1 grad tensor([[-396.1843]], device='cuda:0')\n",
      "gamma grad tensor([[4112.5874]], device='cuda:0')\n",
      "alpha grad tensor([[-7712.5884]], device='cuda:0')\n",
      "beta2 grad tensor([[7340.3164]], device='cuda:0')\n",
      "beta0 grad tensor([3509.7852], device='cuda:0')\n",
      "beta1 grad tensor([[4795.0874]], device='cuda:0')\n",
      "Epoch 194 | Loss: 12.6229\n",
      "alpha: 0.07650002837181091, beta0: 0.1141912192106247, beta1: -0.00046651798766106367, beta2: 0.0029821728821843863, \n",
      "gamma: 0.06366557627916336, sigma0: 0.26667970418930054, sigma1: 0.0003442112065386027, sigma2: 3.204222957720049e-05, sigmaX: 0.15501873195171356\n",
      "forward done\n",
      "tensor([0.0089, 0.0379, 0.1609, 0.6330, 0.3566], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.7423]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-124.6281]], device='cuda:0')\n",
      "sigma0 grad tensor([-110.1236], device='cuda:0')\n",
      "sigma1 grad tensor([[-104.4292]], device='cuda:0')\n",
      "gamma grad tensor([[-118.9906]], device='cuda:0')\n",
      "alpha grad tensor([[-66.8592]], device='cuda:0')\n",
      "beta2 grad tensor([[426.4177]], device='cuda:0')\n",
      "beta0 grad tensor([189.8690], device='cuda:0')\n",
      "beta1 grad tensor([[269.8640]], device='cuda:0')\n",
      "Epoch 195 | Loss: 4.9480\n",
      "alpha: 0.07656297087669373, beta0: 0.11415871977806091, beta1: -0.000506685406435281, beta2: 0.0029279165901243687, \n",
      "gamma: 0.06363610178232193, sigma0: 0.26668626070022583, sigma1: 0.0003492007963359356, sigma2: 3.665455733425915e-05, sigmaX: 0.15501882135868073\n",
      "forward done\n",
      "tensor([0.0130, 0.1148, 0.4236, 0.6670, 0.3749], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.7034]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-416.7686]], device='cuda:0')\n",
      "sigma0 grad tensor([-506.7007], device='cuda:0')\n",
      "sigma1 grad tensor([[-409.7025]], device='cuda:0')\n",
      "gamma grad tensor([[3666.8291]], device='cuda:0')\n",
      "alpha grad tensor([[-7136.2817]], device='cuda:0')\n",
      "beta2 grad tensor([[6896.3496]], device='cuda:0')\n",
      "beta0 grad tensor([3335.4116], device='cuda:0')\n",
      "beta1 grad tensor([[4535.5444]], device='cuda:0')\n",
      "Epoch 196 | Loss: 12.9549\n",
      "alpha: 0.07668468356132507, beta0: 0.11409936845302582, beta1: -0.0005841747624799609, beta2: 0.0028155480977147818, \n",
      "gamma: 0.0635758563876152, sigma0: 0.266696572303772, sigma1: 0.00035728950751945376, sigma2: 4.451210770639591e-05, sigmaX: 0.1550189107656479\n",
      "forward done\n",
      "tensor([0.0097, 0.0629, 0.2402, 0.6197, 0.3472], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.1159]]], device='cuda:0')\n",
      "sigma2 grad tensor([[71.3313]], device='cuda:0')\n",
      "sigma0 grad tensor([79.4666], device='cuda:0')\n",
      "sigma1 grad tensor([[69.4428]], device='cuda:0')\n",
      "gamma grad tensor([[-1652.3301]], device='cuda:0')\n",
      "alpha grad tensor([[2869.5681]], device='cuda:0')\n",
      "beta2 grad tensor([[-2807.8103]], device='cuda:0')\n",
      "beta0 grad tensor([-1152.6147], device='cuda:0')\n",
      "beta1 grad tensor([[-1702.4354]], device='cuda:0')\n",
      "Epoch 197 | Loss: 7.5114\n",
      "alpha: 0.07675336301326752, beta0: 0.11406341195106506, beta1: -0.0006291419267654419, beta2: 0.0027537313289940357, \n",
      "gamma: 0.06354418396949768, sigma0: 0.2667040228843689, sigma1: 0.00036306603578850627, sigma2: 5.008483640267514e-05, sigmaX: 0.15501900017261505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0085, 0.0384, 0.3031, 0.6540, 0.3641], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.3176]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-395.9874]], device='cuda:0')\n",
      "sigma0 grad tensor([-442.1170], device='cuda:0')\n",
      "sigma1 grad tensor([[-372.2718]], device='cuda:0')\n",
      "gamma grad tensor([[3077.9419]], device='cuda:0')\n",
      "alpha grad tensor([[-6025.6289]], device='cuda:0')\n",
      "beta2 grad tensor([[6000.5498]], device='cuda:0')\n",
      "beta0 grad tensor([2846.1628], device='cuda:0')\n",
      "beta1 grad tensor([[3907.1533]], device='cuda:0')\n",
      "Epoch 198 | Loss: 5.1679\n",
      "alpha: 0.07686855643987656, beta0: 0.11400618404150009, beta1: -0.0007041872013360262, beta2: 0.0026442725211381912, \n",
      "gamma: 0.06348806619644165, sigma0: 0.2667143940925598, sigma1: 0.00037140998756513, sigma2: 5.8502890169620514e-05, sigmaX: 0.15501908957958221\n",
      "forward done\n",
      "tensor([0.0107, 0.1522, 0.4639, 0.5568, 0.2823], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-3.9116]]], device='cuda:0')\n",
      "sigma2 grad tensor([[720.8550]], device='cuda:0')\n",
      "sigma0 grad tensor([614.1422], device='cuda:0')\n",
      "sigma1 grad tensor([[571.1319]], device='cuda:0')\n",
      "gamma grad tensor([[-5341.1421]], device='cuda:0')\n",
      "alpha grad tensor([[10006.5303]], device='cuda:0')\n",
      "beta2 grad tensor([[-10952.6367]], device='cuda:0')\n",
      "beta0 grad tensor([-4544.1582], device='cuda:0')\n",
      "beta1 grad tensor([[-6623.6064]], device='cuda:0')\n",
      "Epoch 199 | Loss: 16.5314\n",
      "alpha: 0.07686065137386322, beta0: 0.11400584131479263, beta1: -0.00069798732874915, beta2: 0.0026662317104637623, \n",
      "gamma: 0.06349658221006393, sigma0: 0.2667165696620941, sigma1: 0.00037237381911836565, sigma2: 5.8028785133501515e-05, sigmaX: 0.15501920878887177\n",
      "forward done\n",
      "tensor([0.0186, 0.2447, 0.3735, 0.6576, 0.3603], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.5234]]], device='cuda:0')\n",
      "sigma2 grad tensor([[887.4273]], device='cuda:0')\n",
      "sigma0 grad tensor([695.1819], device='cuda:0')\n",
      "sigma1 grad tensor([[705.8113]], device='cuda:0')\n",
      "gamma grad tensor([[-5922.1504]], device='cuda:0')\n",
      "alpha grad tensor([[11065.1973]], device='cuda:0')\n",
      "beta2 grad tensor([[-12423.8867]], device='cuda:0')\n",
      "beta0 grad tensor([-5014.0054], device='cuda:0')\n",
      "beta1 grad tensor([[-7471.5962]], device='cuda:0')\n",
      "Epoch 200 | Loss: 25.8837\n",
      "alpha: 0.07674366980791092, beta0: 0.11405570805072784, beta1: -0.0006183114601299167, beta2: 0.0028080379124730825, \n",
      "gamma: 0.06356261670589447, sigma0: 0.26671135425567627, sigma1: 0.0003660867805592716, sigma2: 4.877522587776184e-05, sigmaX: 0.15501929819583893\n",
      "forward done\n",
      "tensor([0.0144, 0.0631, 0.2704, 0.6309, 0.3628], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.3657]]], device='cuda:0')\n",
      "sigma2 grad tensor([[253.7456]], device='cuda:0')\n",
      "sigma0 grad tensor([264.1704], device='cuda:0')\n",
      "sigma1 grad tensor([[233.7754]], device='cuda:0')\n",
      "gamma grad tensor([[-3023.2341]], device='cuda:0')\n",
      "alpha grad tensor([[5447.3672]], device='cuda:0')\n",
      "beta2 grad tensor([[-5391.5000]], device='cuda:0')\n",
      "beta0 grad tensor([-2355.1914], device='cuda:0')\n",
      "beta1 grad tensor([[-3367.4131]], device='cuda:0')\n",
      "Epoch 201 | Loss: 7.5843\n",
      "alpha: 0.07659561187028885, beta0: 0.11411915719509125, beta1: -0.0005208966322243214, beta2: 0.002975397976115346, \n",
      "gamma: 0.06364567577838898, sigma0: 0.2667045295238495, sigma1: 0.0003587193787097931, sigma2: 3.8834925362607464e-05, sigmaX: 0.15501940250396729\n",
      "forward done\n",
      "tensor([0.0099, 0.0700, 0.2971, 0.6087, 0.3540], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.8010]]], device='cuda:0')\n",
      "sigma2 grad tensor([[103.3872]], device='cuda:0')\n",
      "sigma0 grad tensor([133.2192], device='cuda:0')\n",
      "sigma1 grad tensor([[106.4662]], device='cuda:0')\n",
      "gamma grad tensor([[-1947.5387]], device='cuda:0')\n",
      "alpha grad tensor([[3488.9802]], device='cuda:0')\n",
      "beta2 grad tensor([[-3110.6497]], device='cuda:0')\n",
      "beta0 grad tensor([-1461.6178], device='cuda:0')\n",
      "beta1 grad tensor([[-2015.6201]], device='cuda:0')\n",
      "Epoch 202 | Loss: 8.2673\n",
      "alpha: 0.07644227892160416, beta0: 0.11418452858924866, beta1: -0.0004228085745126009, beta2: 0.003140392480418086, \n",
      "gamma: 0.0637315958738327, sigma0: 0.2666977345943451, sigma1: 0.00035176079836674035, sigma2: 2.9848812118871137e-05, sigmaX: 0.15501950681209564\n",
      "forward done\n",
      "tensor([0.0133, 0.1392, 0.2989, 0.5496, 0.3425], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.8369]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-506.3178]], device='cuda:0')\n",
      "sigma0 grad tensor([-471.6081], device='cuda:0')\n",
      "sigma1 grad tensor([[-427.7246]], device='cuda:0')\n",
      "gamma grad tensor([[3577.7241]], device='cuda:0')\n",
      "alpha grad tensor([[-6915.9878]], device='cuda:0')\n",
      "beta2 grad tensor([[6869.0410]], device='cuda:0')\n",
      "beta0 grad tensor([3205.0996], device='cuda:0')\n",
      "beta1 grad tensor([[4421.4331]], device='cuda:0')\n",
      "Epoch 203 | Loss: 15.1232\n",
      "alpha: 0.07638876885175705, beta0: 0.1142047792673111, beta1: -0.00038855246384628117, beta2: 0.0032036977354437113, \n",
      "gamma: 0.0637645572423935, sigma0: 0.2666970193386078, sigma1: 0.000350471178535372, sigma2: 2.7723099265131168e-05, sigmaX: 0.155019611120224\n",
      "forward done\n",
      "tensor([0.0120, 0.0774, 0.1892, 0.6571, 0.3987], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.2052]]], device='cuda:0')\n",
      "sigma2 grad tensor([[422.5649]], device='cuda:0')\n",
      "sigma0 grad tensor([454.2295], device='cuda:0')\n",
      "sigma1 grad tensor([[396.6221]], device='cuda:0')\n",
      "gamma grad tensor([[-3822.9573]], device='cuda:0')\n",
      "alpha grad tensor([[7224.7104]], device='cuda:0')\n",
      "beta2 grad tensor([[-7160.0010]], device='cuda:0')\n",
      "beta0 grad tensor([-3275.0002], device='cuda:0')\n",
      "beta1 grad tensor([[-4591.8335]], device='cuda:0')\n",
      "Epoch 204 | Loss: 9.0015\n",
      "alpha: 0.07627371698617935, beta0: 0.11425372958183289, beta1: -0.00031522923381999135, beta2: 0.0033259419724345207, \n",
      "gamma: 0.06382915377616882, sigma0: 0.2666918933391571, sigma1: 0.0003454732650425285, sigma2: 2.1796880901092663e-05, sigmaX: 0.15501971542835236\n",
      "forward done\n",
      "tensor([0.0195, 0.2209, 0.1639, 0.6943, 0.4060], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.7155]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-358.0660]], device='cuda:0')\n",
      "sigma0 grad tensor([-443.7611], device='cuda:0')\n",
      "sigma1 grad tensor([[-355.8919]], device='cuda:0')\n",
      "gamma grad tensor([[3153.7339]], device='cuda:0')\n",
      "alpha grad tensor([[-6168.3613]], device='cuda:0')\n",
      "beta2 grad tensor([[5523.1909]], device='cuda:0')\n",
      "beta0 grad tensor([2884.9678], device='cuda:0')\n",
      "beta1 grad tensor([[3773.6726]], device='cuda:0')\n",
      "Epoch 205 | Loss: 23.3699\n",
      "alpha: 0.07624335587024689, beta0: 0.11426404118537903, beta1: -0.00029430739232338965, beta2: 0.003368505509570241, \n",
      "gamma: 0.06384929269552231, sigma0: 0.26669225096702576, sigma1: 0.00034503385541029274, sigma2: 2.0636565750464797e-05, sigmaX: 0.15501980483531952\n",
      "forward done\n",
      "tensor([0.0087, 0.0660, 0.1982, 0.6885, 0.3856], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.2094]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-464.0359]], device='cuda:0')\n",
      "sigma0 grad tensor([-473.3359], device='cuda:0')\n",
      "sigma1 grad tensor([[-421.2883]], device='cuda:0')\n",
      "gamma grad tensor([[3402.3223]], device='cuda:0')\n",
      "alpha grad tensor([[-6584.3071]], device='cuda:0')\n",
      "beta2 grad tensor([[6462.3335]], device='cuda:0')\n",
      "beta0 grad tensor([3065.4937], device='cuda:0')\n",
      "beta1 grad tensor([[4208.4668]], device='cuda:0')\n",
      "Epoch 206 | Loss: 7.8849\n",
      "alpha: 0.07628491520881653, beta0: 0.11424162983894348, beta1: -0.00031965458765625954, beta2: 0.0033379329834133387, \n",
      "gamma: 0.0638313814997673, sigma0: 0.2666972577571869, sigma1: 0.0003488952061161399, sigma2: 2.4348673832719214e-05, sigmaX: 0.15501989424228668\n",
      "forward done\n",
      "tensor([0.0150, 0.1374, 0.4471, 0.6607, 0.3705], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.3230]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-460.0114]], device='cuda:0')\n",
      "sigma0 grad tensor([-478.3373], device='cuda:0')\n",
      "sigma1 grad tensor([[-426.1125]], device='cuda:0')\n",
      "gamma grad tensor([[3623.8374]], device='cuda:0')\n",
      "alpha grad tensor([[-6960.5273]], device='cuda:0')\n",
      "beta2 grad tensor([[6640.4014]], device='cuda:0')\n",
      "beta0 grad tensor([3212.0476], device='cuda:0')\n",
      "beta1 grad tensor([[4372.8320]], device='cuda:0')\n",
      "Epoch 207 | Loss: 15.2342\n",
      "alpha: 0.07638776302337646, beta0: 0.11419158428907394, beta1: -0.0003836606629192829, beta2: 0.003247070824727416, \n",
      "gamma: 0.06378081440925598, sigma0: 0.26670604944229126, sigma1: 0.00035624540760181844, sigma2: 3.191847645211965e-05, sigmaX: 0.15501998364925385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0089, 0.0527, 0.2939, 0.6390, 0.3571], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.1007]]], device='cuda:0')\n",
      "sigma2 grad tensor([[96.3013]], device='cuda:0')\n",
      "sigma0 grad tensor([119.4142], device='cuda:0')\n",
      "sigma1 grad tensor([[101.2245]], device='cuda:0')\n",
      "gamma grad tensor([[-1909.5548]], device='cuda:0')\n",
      "alpha grad tensor([[3376.4226]], device='cuda:0')\n",
      "beta2 grad tensor([[-2989.0969]], device='cuda:0')\n",
      "beta0 grad tensor([-1389.4679], device='cuda:0')\n",
      "beta1 grad tensor([[-1935.8680]], device='cuda:0')\n",
      "Epoch 208 | Loss: 6.5691\n",
      "alpha: 0.07643628120422363, beta0: 0.11416544020175934, beta1: -0.0004155068309046328, beta2: 0.0032042721286416054, \n",
      "gamma: 0.0637594535946846, sigma0: 0.26671189069747925, sigma1: 0.0003611133433878422, sigma2: 3.701130481204018e-05, sigmaX: 0.155020073056221\n",
      "forward done\n",
      "tensor([0.0192, 0.0627, 0.3412, 0.6061, 0.3410], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-3.1721]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-390.4702]], device='cuda:0')\n",
      "sigma0 grad tensor([-332.6708], device='cuda:0')\n",
      "sigma1 grad tensor([[-309.5415]], device='cuda:0')\n",
      "gamma grad tensor([[1827.3622]], device='cuda:0')\n",
      "alpha grad tensor([[-3745.1172]], device='cuda:0')\n",
      "beta2 grad tensor([[4197.4893]], device='cuda:0')\n",
      "beta0 grad tensor([1835.5582], device='cuda:0')\n",
      "beta1 grad tensor([[2595.3579]], device='cuda:0')\n",
      "Epoch 209 | Loss: 7.5785\n",
      "alpha: 0.07651254534721375, beta0: 0.11412616819143295, beta1: -0.00046693734475411475, beta2: 0.0031280582770705223, \n",
      "gamma: 0.0637240931391716, sigma0: 0.26671987771987915, sigma1: 0.0003681030939333141, sigma2: 4.4990269088884816e-05, sigmaX: 0.15502017736434937\n",
      "forward done\n",
      "tensor([0.0104, 0.0436, 0.3811, 0.6318, 0.3552], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.4410]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-83.7440]], device='cuda:0')\n",
      "sigma0 grad tensor([-60.8084], device='cuda:0')\n",
      "sigma1 grad tensor([[-62.9515]], device='cuda:0')\n",
      "gamma grad tensor([[-454.9580]], device='cuda:0')\n",
      "alpha grad tensor([[600.1621]], device='cuda:0')\n",
      "beta2 grad tensor([[-244.5052]], device='cuda:0')\n",
      "beta0 grad tensor([-124.0444], device='cuda:0')\n",
      "beta1 grad tensor([[-166.1845]], device='cuda:0')\n",
      "Epoch 210 | Loss: 5.7401\n",
      "alpha: 0.07656755298376083, beta0: 0.11409599334001541, beta1: -0.0005064199212938547, beta2: 0.00306953233666718, \n",
      "gamma: 0.0637003555893898, sigma0: 0.26672688126564026, sigma1: 0.00037432441604323685, sigma2: 5.2210882131475955e-05, sigmaX: 0.15502028167247772\n",
      "forward done\n",
      "tensor([0.0116, 0.1272, 0.1207, 0.6621, 0.3796], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.5032]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-383.4305]], device='cuda:0')\n",
      "sigma0 grad tensor([-501.5101], device='cuda:0')\n",
      "sigma1 grad tensor([[-404.2140]], device='cuda:0')\n",
      "gamma grad tensor([[3632.2632]], device='cuda:0')\n",
      "alpha grad tensor([[-7057.2876]], device='cuda:0')\n",
      "beta2 grad tensor([[6660.1465]], device='cuda:0')\n",
      "beta0 grad tensor([3293.3987], device='cuda:0')\n",
      "beta1 grad tensor([[4433.7217]], device='cuda:0')\n",
      "Epoch 211 | Loss: 13.8948\n",
      "alpha: 0.07668213546276093, beta0: 0.11403892189264297, beta1: -0.0005823432002216578, beta2: 0.0029561100527644157, \n",
      "gamma: 0.06364504247903824, sigma0: 0.2667374908924103, sigma1: 0.00038334360579028726, sigma2: 6.182167999213561e-05, sigmaX: 0.15502037107944489\n",
      "forward done\n",
      "tensor([0.0143, 0.0735, 0.1300, 0.6733, 0.3881], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.2487]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-478.8821]], device='cuda:0')\n",
      "sigma0 grad tensor([-535.8577], device='cuda:0')\n",
      "sigma1 grad tensor([[-454.3330]], device='cuda:0')\n",
      "gamma grad tensor([[3937.7273]], device='cuda:0')\n",
      "alpha grad tensor([[-7609.1768]], device='cuda:0')\n",
      "beta2 grad tensor([[7699.1221]], device='cuda:0')\n",
      "beta0 grad tensor([3528.8123], device='cuda:0')\n",
      "beta1 grad tensor([[4928.6963]], device='cuda:0')\n",
      "Epoch 212 | Loss: 8.5573\n",
      "alpha: 0.07684989273548126, beta0: 0.1139579713344574, beta1: -0.0006923687760718167, beta2: 0.002788380952551961, \n",
      "gamma: 0.06356141716241837, sigma0: 0.26675134897232056, sigma1: 0.0003951022808905691, sigma2: 7.429913966916502e-05, sigmaX: 0.15502046048641205\n",
      "forward done\n",
      "tensor([0.0108, 0.0347, 0.3186, 0.5749, 0.3353], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.3863]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-153.1724]], device='cuda:0')\n",
      "sigma0 grad tensor([-138.3408], device='cuda:0')\n",
      "sigma1 grad tensor([[-127.0632]], device='cuda:0')\n",
      "gamma grad tensor([[60.0989]], device='cuda:0')\n",
      "alpha grad tensor([[-415.5378]], device='cuda:0')\n",
      "beta2 grad tensor([[794.9960]], device='cuda:0')\n",
      "beta0 grad tensor([353.2304], device='cuda:0')\n",
      "beta1 grad tensor([[497.0766]], device='cuda:0')\n",
      "Epoch 213 | Loss: 4.7082\n",
      "alpha: 0.07698825001716614, beta0: 0.113889679312706, beta1: -0.0007853599963709712, beta2: 0.0026462478563189507, \n",
      "gamma: 0.06349391490221024, sigma0: 0.2667638063430786, sigma1: 0.0004057798651047051, sigma2: 8.581282600061968e-05, sigmaX: 0.1550205498933792\n",
      "forward done\n",
      "tensor([0.0160, 0.0687, 0.1791, 0.6242, 0.3693], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.5130]]], device='cuda:0')\n",
      "sigma2 grad tensor([[406.9262]], device='cuda:0')\n",
      "sigma0 grad tensor([372.3596], device='cuda:0')\n",
      "sigma1 grad tensor([[352.1172]], device='cuda:0')\n",
      "gamma grad tensor([[-3299.9731]], device='cuda:0')\n",
      "alpha grad tensor([[6238.1304]], device='cuda:0')\n",
      "beta2 grad tensor([[-6790.1265]], device='cuda:0')\n",
      "beta0 grad tensor([-2812.4082], device='cuda:0')\n",
      "beta1 grad tensor([[-4141.1680]], device='cuda:0')\n",
      "Epoch 214 | Loss: 8.0599\n",
      "alpha: 0.07703655958175659, beta0: 0.11386317014694214, beta1: -0.0008183412719517946, beta2: 0.0026004426181316376, \n",
      "gamma: 0.06347291171550751, sigma0: 0.26677006483078003, sigma1: 0.0004108007706236094, sigma2: 9.095451241591945e-05, sigmaX: 0.15502065420150757\n",
      "forward done\n",
      "tensor([0.0127, 0.0530, 0.3888, 0.6536, 0.3735], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.9119]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-273.9240]], device='cuda:0')\n",
      "sigma0 grad tensor([-280.9295], device='cuda:0')\n",
      "sigma1 grad tensor([[-244.6015]], device='cuda:0')\n",
      "gamma grad tensor([[1715.6691]], device='cuda:0')\n",
      "alpha grad tensor([[-3406.0598]], device='cuda:0')\n",
      "beta2 grad tensor([[3732.2883]], device='cuda:0')\n",
      "beta0 grad tensor([1651.0933], device='cuda:0')\n",
      "beta1 grad tensor([[2341.9470]], device='cuda:0')\n",
      "Epoch 215 | Loss: 6.7274\n",
      "alpha: 0.07710926234722137, beta0: 0.11382545530796051, beta1: -0.0008681457838974893, beta2: 0.0025264755822718143, \n",
      "gamma: 0.06343895196914673, sigma0: 0.2667778730392456, sigma1: 0.0004172635090071708, sigma2: 9.780710388440639e-05, sigmaX: 0.15502075850963593\n",
      "forward done\n",
      "tensor([0.0107, 0.1438, 0.2617, 0.6120, 0.3454], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.4751]]], device='cuda:0')\n",
      "sigma2 grad tensor([[596.1148]], device='cuda:0')\n",
      "sigma0 grad tensor([604.9192], device='cuda:0')\n",
      "sigma1 grad tensor([[540.9298]], device='cuda:0')\n",
      "gamma grad tensor([[-5562.6987]], device='cuda:0')\n",
      "alpha grad tensor([[10322.6807]], device='cuda:0')\n",
      "beta2 grad tensor([[-10814.1572]], device='cuda:0')\n",
      "beta0 grad tensor([-4649.8438], device='cuda:0')\n",
      "beta1 grad tensor([[-6724.9419]], device='cuda:0')\n",
      "Epoch 216 | Loss: 15.6048\n",
      "alpha: 0.07706420123577118, beta0: 0.11384177953004837, beta1: -0.0008407399873249233, beta2: 0.002575443359091878, \n",
      "gamma: 0.06346741318702698, sigma0: 0.2667780816555023, sigma1: 0.00041702439193613827, sigma2: 9.732803300721571e-05, sigmaX: 0.1550208479166031\n",
      "forward done\n",
      "tensor([0.0095, 0.0832, 0.2766, 0.6425, 0.3660], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-4.0497]]], device='cuda:0')\n",
      "sigma2 grad tensor([[600.9274]], device='cuda:0')\n",
      "sigma0 grad tensor([602.7739], device='cuda:0')\n",
      "sigma1 grad tensor([[549.8355]], device='cuda:0')\n",
      "gamma grad tensor([[-4874.9458]], device='cuda:0')\n",
      "alpha grad tensor([[9289.3125]], device='cuda:0')\n",
      "beta2 grad tensor([[-9822.2402]], device='cuda:0')\n",
      "beta0 grad tensor([-4271.5117], device='cuda:0')\n",
      "beta1 grad tensor([[-6151.3208]], device='cuda:0')\n",
      "Epoch 217 | Loss: 9.6164\n",
      "alpha: 0.07693526148796082, beta0: 0.11389755457639694, beta1: -0.0007573021575808525, beta2: 0.0027128399815410376, \n",
      "gamma: 0.06353893131017685, sigma0: 0.26677221059799194, sigma1: 0.0004113347386009991, sigma2: 9.093550033867359e-05, sigmaX: 0.15502096712589264\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0215, 0.1860, 0.2273, 0.6318, 0.3356], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.5259]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-454.2241]], device='cuda:0')\n",
      "sigma0 grad tensor([-477.4662], device='cuda:0')\n",
      "sigma1 grad tensor([[-411.9675]], device='cuda:0')\n",
      "gamma grad tensor([[3476.5193]], device='cuda:0')\n",
      "alpha grad tensor([[-6774.4658]], device='cuda:0')\n",
      "beta2 grad tensor([[6800.8276]], device='cuda:0')\n",
      "beta0 grad tensor([3167.5811], device='cuda:0')\n",
      "beta1 grad tensor([[4369.8125]], device='cuda:0')\n",
      "Epoch 218 | Loss: 19.8142\n",
      "alpha: 0.07689984887838364, beta0: 0.1139104962348938, beta1: -0.0007342500030063093, beta2: 0.002754749031737447, \n",
      "gamma: 0.06356137990951538, sigma0: 0.2667723000049591, sigma1: 0.0004109026922378689, sigma2: 9.036371193360537e-05, sigmaX: 0.1550210863351822\n",
      "forward done\n",
      "tensor([0.0083, 0.1358, 0.2826, 0.6604, 0.3746], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-4.3206]]], device='cuda:0')\n",
      "sigma2 grad tensor([[716.5231]], device='cuda:0')\n",
      "sigma0 grad tensor([612.4080], device='cuda:0')\n",
      "sigma1 grad tensor([[588.4905]], device='cuda:0')\n",
      "gamma grad tensor([[-5195.2163]], device='cuda:0')\n",
      "alpha grad tensor([[9791.9814]], device='cuda:0')\n",
      "beta2 grad tensor([[-10422.5088]], device='cuda:0')\n",
      "beta0 grad tensor([-4454.1973], device='cuda:0')\n",
      "beta1 grad tensor([[-6426.7603]], device='cuda:0')\n",
      "Epoch 219 | Loss: 14.9026\n",
      "alpha: 0.07677359879016876, beta0: 0.11396539211273193, beta1: -0.0006515407003462315, beta2: 0.0028925014194101095, \n",
      "gamma: 0.06363128870725632, sigma0: 0.2667662501335144, sigma1: 0.00040467214421369135, sigma2: 8.27410549391061e-05, sigmaX: 0.15502122044563293\n",
      "forward done\n",
      "tensor([0.0124, 0.0711, 0.2601, 0.5943, 0.3630], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.5241]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-577.8336]], device='cuda:0')\n",
      "sigma0 grad tensor([-529.1409], device='cuda:0')\n",
      "sigma1 grad tensor([[-481.2254]], device='cuda:0')\n",
      "gamma grad tensor([[3767.4734]], device='cuda:0')\n",
      "alpha grad tensor([[-7343.0601]], device='cuda:0')\n",
      "beta2 grad tensor([[7795.8701]], device='cuda:0')\n",
      "beta0 grad tensor([3438.4636], device='cuda:0')\n",
      "beta1 grad tensor([[4876.1519]], device='cuda:0')\n",
      "Epoch 220 | Loss: 8.3423\n",
      "alpha: 0.07674603164196014, beta0: 0.113974928855896, beta1: -0.0006341347470879555, beta2: 0.0029247445054352283, \n",
      "gamma: 0.06364954262971878, sigma0: 0.2667666971683502, sigma1: 0.0004044999659527093, sigma2: 8.242126205004752e-05, sigmaX: 0.15502133965492249\n",
      "forward done\n",
      "tensor([0.0086, 0.0452, 0.0913, 0.6172, 0.3612], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.4379]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-36.1061]], device='cuda:0')\n",
      "sigma0 grad tensor([-17.6826], device='cuda:0')\n",
      "sigma1 grad tensor([[-21.6592]], device='cuda:0')\n",
      "gamma grad tensor([[-860.5562]], device='cuda:0')\n",
      "alpha grad tensor([[1365.8550]], device='cuda:0')\n",
      "beta2 grad tensor([[-1010.8398]], device='cuda:0')\n",
      "beta0 grad tensor([-466.4750], device='cuda:0')\n",
      "beta1 grad tensor([[-653.0784]], device='cuda:0')\n",
      "Epoch 221 | Loss: 5.5993\n",
      "alpha: 0.07671032100915909, beta0: 0.11398722231388092, beta1: -0.000613679236266762, beta2: 0.0029606474563479424, \n",
      "gamma: 0.0636727511882782, sigma0: 0.2667672336101532, sigma1: 0.0004045788082294166, sigma2: 8.252648694906384e-05, sigmaX: 0.15502144396305084\n",
      "forward done\n",
      "tensor([0.0235, 0.1912, 0.1432, 0.6923, 0.4069], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.8591]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-368.0782]], device='cuda:0')\n",
      "sigma0 grad tensor([-472.1053], device='cuda:0')\n",
      "sigma1 grad tensor([[-368.8504]], device='cuda:0')\n",
      "gamma grad tensor([[3500.4700]], device='cuda:0')\n",
      "alpha grad tensor([[-6744.7705]], device='cuda:0')\n",
      "beta2 grad tensor([[6249.0928]], device='cuda:0')\n",
      "beta0 grad tensor([3138.8018], device='cuda:0')\n",
      "beta1 grad tensor([[4180.5630]], device='cuda:0')\n",
      "Epoch 222 | Loss: 20.3882\n",
      "alpha: 0.07674919813871384, beta0: 0.11396566778421402, beta1: -0.0006391204078681767, beta2: 0.0029268788639456034, \n",
      "gamma: 0.06365631520748138, sigma0: 0.26677238941192627, sigma1: 0.00040833037928678095, sigma2: 8.62914530443959e-05, sigmaX: 0.155021533370018\n",
      "forward done\n",
      "tensor([0.0128, 0.0870, 0.1219, 0.6234, 0.3640], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.2075]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-423.9981]], device='cuda:0')\n",
      "sigma0 grad tensor([-516.2455], device='cuda:0')\n",
      "sigma1 grad tensor([[-424.8306]], device='cuda:0')\n",
      "gamma grad tensor([[4422.1167]], device='cuda:0')\n",
      "alpha grad tensor([[-8313.3213]], device='cuda:0')\n",
      "beta2 grad tensor([[7757.8267]], device='cuda:0')\n",
      "beta0 grad tensor([3777.5437], device='cuda:0')\n",
      "beta1 grad tensor([[5118.1182]], device='cuda:0')\n",
      "Epoch 223 | Loss: 9.8260\n",
      "alpha: 0.07686343044042587, beta0: 0.11391064524650574, beta1: -0.0007106545381247997, beta2: 0.0028222857508808374, \n",
      "gamma: 0.06359894573688507, sigma0: 0.26678165793418884, sigma1: 0.0004155799397267401, sigma2: 9.354340727441013e-05, sigmaX: 0.15502162277698517\n",
      "forward done\n",
      "tensor([0.0121, 0.1189, 0.1955, 0.5944, 0.3665], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.8574]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-415.5759]], device='cuda:0')\n",
      "sigma0 grad tensor([-509.8419], device='cuda:0')\n",
      "sigma1 grad tensor([[-412.6790]], device='cuda:0')\n",
      "gamma grad tensor([[3879.1750]], device='cuda:0')\n",
      "alpha grad tensor([[-7458.9580]], device='cuda:0')\n",
      "beta2 grad tensor([[7251.3213]], device='cuda:0')\n",
      "beta0 grad tensor([3460.8298], device='cuda:0')\n",
      "beta1 grad tensor([[4727.3784]], device='cuda:0')\n",
      "Epoch 224 | Loss: 13.0634\n",
      "alpha: 0.07702940702438354, beta0: 0.1138320192694664, beta1: -0.0008151556248776615, beta2: 0.002666098065674305, \n",
      "gamma: 0.06351425498723984, sigma0: 0.2667941749095917, sigma1: 0.0004255063831806183, sigma2: 0.00010350072989240289, sigmaX: 0.15502171218395233\n",
      "forward done\n",
      "tensor([0.0224, 0.0547, 0.1316, 0.6417, 0.3949], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.8147]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-172.3988]], device='cuda:0')\n",
      "sigma0 grad tensor([-167.8008], device='cuda:0')\n",
      "sigma1 grad tensor([[-151.6873]], device='cuda:0')\n",
      "gamma grad tensor([[497.3063]], device='cuda:0')\n",
      "alpha grad tensor([[-1207.0261]], device='cuda:0')\n",
      "beta2 grad tensor([[1550.2460]], device='cuda:0')\n",
      "beta0 grad tensor([691.0997], device='cuda:0')\n",
      "beta1 grad tensor([[979.1516]], device='cuda:0')\n",
      "Epoch 225 | Loss: 6.6611\n",
      "alpha: 0.07717426121234894, beta0: 0.11376220732927322, beta1: -0.0009085480123758316, beta2: 0.0025256455410271883, \n",
      "gamma: 0.06344152987003326, sigma0: 0.26680585741996765, sigma1: 0.0004349644004832953, sigma2: 0.00011319057375658303, sigmaX: 0.1550218015909195\n",
      "forward done\n",
      "tensor([0.0120, 0.0528, 0.3479, 0.6724, 0.3806], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.1484]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-97.5378]], device='cuda:0')\n",
      "sigma0 grad tensor([-78.8429], device='cuda:0')\n",
      "sigma1 grad tensor([[-77.4147]], device='cuda:0')\n",
      "gamma grad tensor([[-313.8454]], device='cuda:0')\n",
      "alpha grad tensor([[333.9945]], device='cuda:0')\n",
      "beta2 grad tensor([[4.8809]], device='cuda:0')\n",
      "beta0 grad tensor([-4.0938], device='cuda:0')\n",
      "beta1 grad tensor([[-1.9783]], device='cuda:0')\n",
      "Epoch 226 | Loss: 6.6890\n",
      "alpha: 0.07728680223226547, beta0: 0.11370640248060226, beta1: -0.0009832421783357859, beta2: 0.0024132346734404564, \n",
      "gamma: 0.06338649243116379, sigma0: 0.26681599020957947, sigma1: 0.00044330497621558607, sigma2: 0.00012191783025627956, sigmaX: 0.15502189099788666\n",
      "forward done\n",
      "tensor([0.0167, 0.0840, 0.2248, 0.6096, 0.3650], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.3171]]], device='cuda:0')\n",
      "sigma2 grad tensor([[646.3720]], device='cuda:0')\n",
      "sigma0 grad tensor([574.3804], device='cuda:0')\n",
      "sigma1 grad tensor([[551.3531]], device='cuda:0')\n",
      "gamma grad tensor([[-4541.4805]], device='cuda:0')\n",
      "alpha grad tensor([[8744.1768]], device='cuda:0')\n",
      "beta2 grad tensor([[-10120.9199]], device='cuda:0')\n",
      "beta0 grad tensor([-4051.6357], device='cuda:0')\n",
      "beta1 grad tensor([[-6067.4727]], device='cuda:0')\n",
      "Epoch 227 | Loss: 9.6182\n",
      "alpha: 0.0772893950343132, beta0: 0.11370227485895157, beta1: -0.0009823227301239967, beta2: 0.0024245150852948427, \n",
      "gamma: 0.06338787823915482, sigma0: 0.2668183743953705, sigma1: 0.0004444638907443732, sigma2: 0.0001224359148181975, sigmaX: 0.15502198040485382\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0181, 0.2688, 0.4584, 0.5851, 0.2527], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.4764]]], device='cuda:0')\n",
      "sigma2 grad tensor([[842.2250]], device='cuda:0')\n",
      "sigma0 grad tensor([721.5060], device='cuda:0')\n",
      "sigma1 grad tensor([[686.8369]], device='cuda:0')\n",
      "gamma grad tensor([[-6894.8271]], device='cuda:0')\n",
      "alpha grad tensor([[12629.2383]], device='cuda:0')\n",
      "beta2 grad tensor([[-13735.3945]], device='cuda:0')\n",
      "beta0 grad tensor([-5648.9512], device='cuda:0')\n",
      "beta1 grad tensor([[-8312.0117]], device='cuda:0')\n",
      "Epoch 228 | Loss: 28.1991\n",
      "alpha: 0.07716517895460129, beta0: 0.11375546455383301, beta1: -0.0008984670857898891, beta2: 0.002570893382653594, \n",
      "gamma: 0.0634579285979271, sigma0: 0.2668130695819855, sigma1: 0.00043852266389876604, sigma2: 0.00011442813411122188, sigmaX: 0.1550220549106598\n",
      "forward done\n",
      "tensor([0.0107, 0.0576, 0.1127, 0.6425, 0.4002], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.8862]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-320.5014]], device='cuda:0')\n",
      "sigma0 grad tensor([-325.5105], device='cuda:0')\n",
      "sigma1 grad tensor([[-285.2141]], device='cuda:0')\n",
      "gamma grad tensor([[2021.7351]], device='cuda:0')\n",
      "alpha grad tensor([[-4069.8057]], device='cuda:0')\n",
      "beta2 grad tensor([[4255.0381]], device='cuda:0')\n",
      "beta0 grad tensor([1973.1576], device='cuda:0')\n",
      "beta1 grad tensor([[2735.1013]], device='cuda:0')\n",
      "Epoch 229 | Loss: 6.9284\n",
      "alpha: 0.07710650563240051, beta0: 0.11377827823162079, beta1: -0.0008587335469201207, beta2: 0.002645445754751563, \n",
      "gamma: 0.0634937509894371, sigma0: 0.2668120563030243, sigma1: 0.00043662183452397585, sigma2: 0.00011122692376375198, sigmaX: 0.15502212941646576\n",
      "forward done\n",
      "tensor([0.0098, 0.0619, 0.2875, 0.6341, 0.3587], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.8422]]], device='cuda:0')\n",
      "sigma2 grad tensor([[543.5757]], device='cuda:0')\n",
      "sigma0 grad tensor([575.6395], device='cuda:0')\n",
      "sigma1 grad tensor([[499.8680]], device='cuda:0')\n",
      "gamma grad tensor([[-4298.1323]], device='cuda:0')\n",
      "alpha grad tensor([[8371.5508]], device='cuda:0')\n",
      "beta2 grad tensor([[-8604.5361]], device='cuda:0')\n",
      "beta0 grad tensor([-3905.3062], device='cuda:0')\n",
      "beta1 grad tensor([[-5480.6729]], device='cuda:0')\n",
      "Epoch 230 | Loss: 7.4773\n",
      "alpha: 0.07697584480047226, beta0: 0.11383558809757233, beta1: -0.0007721399888396263, beta2: 0.0027911330107599497, \n",
      "gamma: 0.06356539577245712, sigma0: 0.266805499792099, sigma1: 0.00043010248919017613, sigma2: 0.00010323019523639232, sigmaX: 0.15502220392227173\n",
      "forward done\n",
      "tensor([0.0099, 0.1228, 0.1606, 0.5794, 0.3987], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.1859]]], device='cuda:0')\n",
      "sigma2 grad tensor([[552.0515]], device='cuda:0')\n",
      "sigma0 grad tensor([565.7606], device='cuda:0')\n",
      "sigma1 grad tensor([[500.8511]], device='cuda:0')\n",
      "gamma grad tensor([[-5509.8926]], device='cuda:0')\n",
      "alpha grad tensor([[10136.1377]], device='cuda:0')\n",
      "beta2 grad tensor([[-10352.8652]], device='cuda:0')\n",
      "beta0 grad tensor([-4524.7007], device='cuda:0')\n",
      "beta1 grad tensor([[-6474.0068]], device='cuda:0')\n",
      "Epoch 231 | Loss: 13.4277\n",
      "alpha: 0.07676995545625687, beta0: 0.11392667889595032, beta1: -0.0006381251150742173, beta2: 0.003011211520060897, \n",
      "gamma: 0.06367781013250351, sigma0: 0.2667945921421051, sigma1: 0.0004198784881737083, sigma2: 9.131230035563931e-05, sigmaX: 0.1550222933292389\n",
      "forward done\n",
      "tensor([0.0155, 0.1756, 0.2275, 0.6221, 0.3581], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.7880]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-398.0470]], device='cuda:0')\n",
      "sigma0 grad tensor([-473.2269], device='cuda:0')\n",
      "sigma1 grad tensor([[-395.5514]], device='cuda:0')\n",
      "gamma grad tensor([[3405.4851]], device='cuda:0')\n",
      "alpha grad tensor([[-6657.7729]], device='cuda:0')\n",
      "beta2 grad tensor([[6291.4849]], device='cuda:0')\n",
      "beta0 grad tensor([3124.5635], device='cuda:0')\n",
      "beta1 grad tensor([[4194.4761]], device='cuda:0')\n",
      "Epoch 232 | Loss: 18.7805\n",
      "alpha: 0.07667182385921478, beta0: 0.11396830528974533, beta1: -0.0005728579708375037, beta2: 0.0031243592966347933, \n",
      "gamma: 0.06373368203639984, sigma0: 0.26679059863090515, sigma1: 0.00041565479477867484, sigma2: 8.575845276936889e-05, sigmaX: 0.15502238273620605\n",
      "forward done\n",
      "tensor([0.0091, 0.0577, 0.4422, 0.6415, 0.3395], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.0064]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-52.3646]], device='cuda:0')\n",
      "sigma0 grad tensor([-32.8282], device='cuda:0')\n",
      "sigma1 grad tensor([[-38.6714]], device='cuda:0')\n",
      "gamma grad tensor([[-758.4727]], device='cuda:0')\n",
      "alpha grad tensor([[1151.1256]], device='cuda:0')\n",
      "beta2 grad tensor([[-735.0717]], device='cuda:0')\n",
      "beta0 grad tensor([-367.0877], device='cuda:0')\n",
      "beta1 grad tensor([[-491.4317]], device='cuda:0')\n",
      "Epoch 233 | Loss: 7.1977\n",
      "alpha: 0.07658180594444275, beta0: 0.11400528252124786, beta1: -0.0005157299456186593, beta2: 0.0032222282607108355, \n",
      "gamma: 0.06378597021102905, sigma0: 0.26678773760795593, sigma1: 0.00041266257176175714, sigma2: 8.183901809388772e-05, sigmaX: 0.15502245724201202\n",
      "forward done\n",
      "tensor([0.0133, 0.1273, 0.1874, 0.6516, 0.3719], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.2844]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-483.5106]], device='cuda:0')\n",
      "sigma0 grad tensor([-486.2784], device='cuda:0')\n",
      "sigma1 grad tensor([[-433.3004]], device='cuda:0')\n",
      "gamma grad tensor([[3611.9146]], device='cuda:0')\n",
      "alpha grad tensor([[-6990.4043]], device='cuda:0')\n",
      "beta2 grad tensor([[6795.5151]], device='cuda:0')\n",
      "beta0 grad tensor([3251.0503], device='cuda:0')\n",
      "beta1 grad tensor([[4433.8916]], device='cuda:0')\n",
      "Epoch 234 | Loss: 13.9587\n",
      "alpha: 0.07657969743013382, beta0: 0.11400235444307327, beta1: -0.0005143664311617613, beta2: 0.003232568269595504, \n",
      "gamma: 0.0637916773557663, sigma0: 0.2667903006076813, sigma1: 0.00041460178908891976, sigma2: 8.353857992915437e-05, sigmaX: 0.155022531747818\n",
      "forward done\n",
      "tensor([0.0109, 0.0564, 0.3496, 0.6737, 0.3595], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.3182]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-17.2386]], device='cuda:0')\n",
      "sigma0 grad tensor([8.6670], device='cuda:0')\n",
      "sigma1 grad tensor([[-2.4635]], device='cuda:0')\n",
      "gamma grad tensor([[-1030.4216]], device='cuda:0')\n",
      "alpha grad tensor([[1699.7750]], device='cuda:0')\n",
      "beta2 grad tensor([[-1362.9285]], device='cuda:0')\n",
      "beta0 grad tensor([-627.1047], device='cuda:0')\n",
      "beta1 grad tensor([[-876.3371]], device='cuda:0')\n",
      "Epoch 235 | Loss: 7.0294\n",
      "alpha: 0.07656101137399673, beta0: 0.11400628089904785, beta1: -0.0005045122234150767, beta2: 0.0032544697169214487, \n",
      "gamma: 0.06380654871463776, sigma0: 0.26679226756095886, sigma1: 0.00041617779061198235, sigma2: 8.507061284035444e-05, sigmaX: 0.15502260625362396\n",
      "forward done\n",
      "tensor([0.0149, 0.1640, 0.3159, 0.6647, 0.3394], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.9781]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-444.5204]], device='cuda:0')\n",
      "sigma0 grad tensor([-467.0076], device='cuda:0')\n",
      "sigma1 grad tensor([[-393.3797]], device='cuda:0')\n",
      "gamma grad tensor([[3477.7861]], device='cuda:0')\n",
      "alpha grad tensor([[-6721.7061]], device='cuda:0')\n",
      "beta2 grad tensor([[6476.9551]], device='cuda:0')\n",
      "beta0 grad tensor([3122.6411], device='cuda:0')\n",
      "beta1 grad tensor([[4234.0244]], device='cuda:0')\n",
      "Epoch 236 | Loss: 17.7336\n",
      "alpha: 0.07661327719688416, beta0: 0.11397819221019745, beta1: -0.0005389691214077175, beta2: 0.0032072211615741253, \n",
      "gamma: 0.0637836679816246, sigma0: 0.2667985260486603, sigma1: 0.00042137238779105246, sigma2: 9.07414432731457e-05, sigmaX: 0.15502268075942993\n",
      "forward done\n",
      "tensor([0.0112, 0.0892, 0.2166, 0.6244, 0.4018], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.7502]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-391.5201]], device='cuda:0')\n",
      "sigma0 grad tensor([-504.9492], device='cuda:0')\n",
      "sigma1 grad tensor([[-403.7628]], device='cuda:0')\n",
      "gamma grad tensor([[3950.5920]], device='cuda:0')\n",
      "alpha grad tensor([[-7577.2866]], device='cuda:0')\n",
      "beta2 grad tensor([[7131.0371]], device='cuda:0')\n",
      "beta0 grad tensor([3497.5383], device='cuda:0')\n",
      "beta1 grad tensor([[4719.4717]], device='cuda:0')\n",
      "Epoch 237 | Loss: 10.1788\n",
      "alpha: 0.07673086225986481, beta0: 0.11392074823379517, beta1: -0.0006137293530628085, beta2: 0.003098112065345049, \n",
      "gamma: 0.06372585892677307, sigma0: 0.26680856943130493, sigma1: 0.00042956569814123213, sigma2: 9.9193312053103e-05, sigmaX: 0.1550227552652359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0183, 0.0857, 0.3253, 0.6198, 0.3617], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.8843]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-514.2615]], device='cuda:0')\n",
      "sigma0 grad tensor([-522.1504], device='cuda:0')\n",
      "sigma1 grad tensor([[-471.2256]], device='cuda:0')\n",
      "gamma grad tensor([[3616.3186]], device='cuda:0')\n",
      "alpha grad tensor([[-7051.1772]], device='cuda:0')\n",
      "beta2 grad tensor([[7400.0664]], device='cuda:0')\n",
      "beta0 grad tensor([3303.7451], device='cuda:0')\n",
      "beta1 grad tensor([[4687.4170]], device='cuda:0')\n",
      "Epoch 238 | Loss: 9.8999\n",
      "alpha: 0.07689544558525085, beta0: 0.11384175717830658, beta1: -0.0007204117137007415, beta2: 0.0029368239920586348, \n",
      "gamma: 0.0636434480547905, sigma0: 0.26682183146476746, sigma1: 0.00044083260581828654, sigma2: 0.00011109741899417713, sigmaX: 0.15502284467220306\n",
      "forward done\n",
      "tensor([0.0113, 0.1118, 0.2100, 0.6174, 0.3507], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.2162]]], device='cuda:0')\n",
      "sigma2 grad tensor([[651.9254]], device='cuda:0')\n",
      "sigma0 grad tensor([579.8487], device='cuda:0')\n",
      "sigma1 grad tensor([[548.2744]], device='cuda:0')\n",
      "gamma grad tensor([[-4591.6826]], device='cuda:0')\n",
      "alpha grad tensor([[8781.0332]], device='cuda:0')\n",
      "beta2 grad tensor([[-9353.6357]], device='cuda:0')\n",
      "beta0 grad tensor([-4037.4365], device='cuda:0')\n",
      "beta1 grad tensor([[-5805.6704]], device='cuda:0')\n",
      "Epoch 239 | Loss: 12.3660\n",
      "alpha: 0.07693929970264435, beta0: 0.1138189360499382, beta1: -0.0007477009203284979, beta2: 0.002901329891756177, \n",
      "gamma: 0.06362343579530716, sigma0: 0.2668266296386719, sigma1: 0.0004443633952178061, sigma2: 0.00011410145089030266, sigmaX: 0.15502293407917023\n",
      "forward done\n",
      "tensor([0.0181, 0.0485, 0.2143, 0.6020, 0.3283], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.9749]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-15.9409]], device='cuda:0')\n",
      "sigma0 grad tensor([3.3101], device='cuda:0')\n",
      "sigma1 grad tensor([[-3.1602]], device='cuda:0')\n",
      "gamma grad tensor([[-1157.0439]], device='cuda:0')\n",
      "alpha grad tensor([[1877.4968]], device='cuda:0')\n",
      "beta2 grad tensor([[-1623.6461]], device='cuda:0')\n",
      "beta0 grad tensor([-681.6652], device='cuda:0')\n",
      "beta1 grad tensor([[-994.2550]], device='cuda:0')\n",
      "Epoch 240 | Loss: 6.0135\n",
      "alpha: 0.07695560902357101, beta0: 0.11380749940872192, beta1: -0.0007595897186547518, beta2: 0.0028891710098832846, \n",
      "gamma: 0.06361899524927139, sigma0: 0.2668304443359375, sigma1: 0.0004472196160349995, sigma2: 0.00011666408681776375, sigmaX: 0.1550230234861374\n",
      "forward done\n",
      "tensor([0.0076, 0.0719, 0.2680, 0.6403, 0.3706], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-3.0233]]], device='cuda:0')\n",
      "sigma2 grad tensor([[195.8776]], device='cuda:0')\n",
      "sigma0 grad tensor([225.0086], device='cuda:0')\n",
      "sigma1 grad tensor([[188.8352]], device='cuda:0')\n",
      "gamma grad tensor([[-2680.5588]], device='cuda:0')\n",
      "alpha grad tensor([[4941.9258]], device='cuda:0')\n",
      "beta2 grad tensor([[-4544.1182]], device='cuda:0')\n",
      "beta0 grad tensor([-2144.5623], device='cuda:0')\n",
      "beta1 grad tensor([[-2957.7329]], device='cuda:0')\n",
      "Epoch 241 | Loss: 8.4763\n",
      "alpha: 0.07691923528909683, beta0: 0.11381979286670685, beta1: -0.0007395234424620867, beta2: 0.0029248851351439953, \n",
      "gamma: 0.06364224851131439, sigma0: 0.26683124899864197, sigma1: 0.00044761624303646386, sigma2: 0.00011675542191369459, sigmaX: 0.15502312779426575\n",
      "forward done\n",
      "tensor([0.0178, 0.0606, 0.3076, 0.6604, 0.3632], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.9208]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-535.8693]], device='cuda:0')\n",
      "sigma0 grad tensor([-488.1314], device='cuda:0')\n",
      "sigma1 grad tensor([[-443.7149]], device='cuda:0')\n",
      "gamma grad tensor([[3497.3796]], device='cuda:0')\n",
      "alpha grad tensor([[-6822.3154]], device='cuda:0')\n",
      "beta2 grad tensor([[7360.2178]], device='cuda:0')\n",
      "beta0 grad tensor([3192.7227], device='cuda:0')\n",
      "beta1 grad tensor([[4564.5073]], device='cuda:0')\n",
      "Epoch 242 | Loss: 7.4134\n",
      "alpha: 0.07695835828781128, beta0: 0.11379770189523697, beta1: -0.0007691154605709016, beta2: 0.002879854291677475, \n",
      "gamma: 0.06362587958574295, sigma0: 0.2668367624282837, sigma1: 0.0004523707029875368, sigma2: 0.00012218717893119901, sigmaX: 0.1550232470035553\n",
      "forward done\n",
      "tensor([0.0090, 0.1217, 0.4343, 0.6061, 0.3554], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.5069]]], device='cuda:0')\n",
      "sigma2 grad tensor([[582.2419]], device='cuda:0')\n",
      "sigma0 grad tensor([554.7987], device='cuda:0')\n",
      "sigma1 grad tensor([[494.5777]], device='cuda:0')\n",
      "gamma grad tensor([[-5528.0425]], device='cuda:0')\n",
      "alpha grad tensor([[10086.9746]], device='cuda:0')\n",
      "beta2 grad tensor([[-10829.3691]], device='cuda:0')\n",
      "beta0 grad tensor([-4472.2163], device='cuda:0')\n",
      "beta1 grad tensor([[-6552.8169]], device='cuda:0')\n",
      "Epoch 243 | Loss: 13.5735\n",
      "alpha: 0.0768887922167778, beta0: 0.1138247475028038, beta1: -0.0007272609509527683, beta2: 0.0029521232936531305, \n",
      "gamma: 0.06366806477308273, sigma0: 0.26683562994003296, sigma1: 0.0004512284940574318, sigma2: 0.00012071016681147739, sigmaX: 0.15502335131168365\n",
      "forward done\n",
      "tensor([0.0106, 0.0628, 0.2324, 0.6078, 0.3661], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.4895]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-153.0468]], device='cuda:0')\n",
      "sigma0 grad tensor([-160.8205], device='cuda:0')\n",
      "sigma1 grad tensor([[-139.5843]], device='cuda:0')\n",
      "gamma grad tensor([[524.2433]], device='cuda:0')\n",
      "alpha grad tensor([[-1209.8308]], device='cuda:0')\n",
      "beta2 grad tensor([[1469.4586]], device='cuda:0')\n",
      "beta0 grad tensor([676.0258], device='cuda:0')\n",
      "beta1 grad tensor([[942.9066]], device='cuda:0')\n",
      "Epoch 244 | Loss: 7.4924\n",
      "alpha: 0.07684523612260818, beta0: 0.11383962631225586, beta1: -0.0007032064022496343, beta2: 0.0029952439945191145, \n",
      "gamma: 0.06369657069444656, sigma0: 0.26683634519577026, sigma1: 0.00045171056990511715, sigma2: 0.00012105902715120465, sigmaX: 0.155023455619812\n",
      "forward done\n",
      "tensor([0.0137, 0.0594, 0.3251, 0.5745, 0.3005], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.9584]]], device='cuda:0')\n",
      "sigma2 grad tensor([[392.9385]], device='cuda:0')\n",
      "sigma0 grad tensor([326.6343], device='cuda:0')\n",
      "sigma1 grad tensor([[319.2161]], device='cuda:0')\n",
      "gamma grad tensor([[-3159.0066]], device='cuda:0')\n",
      "alpha grad tensor([[5872.7139]], device='cuda:0')\n",
      "beta2 grad tensor([[-6404.0771]], device='cuda:0')\n",
      "beta0 grad tensor([-2598.7324], device='cuda:0')\n",
      "beta1 grad tensor([[-3854.8418]], device='cuda:0')\n",
      "Epoch 245 | Loss: 7.1560\n",
      "alpha: 0.07675166428089142, beta0: 0.11387751996517181, beta1: -0.000645414344035089, beta2: 0.0030937811825424433, \n",
      "gamma: 0.0637509673833847, sigma0: 0.266833633184433, sigma1: 0.00044890405843034387, sigma2: 0.00011740873014787212, sigmaX: 0.15502357482910156\n",
      "forward done\n",
      "tensor([0.0119, 0.0501, 0.1840, 0.6449, 0.3699], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.1273]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-43.0443]], device='cuda:0')\n",
      "sigma0 grad tensor([-17.4377], device='cuda:0')\n",
      "sigma1 grad tensor([[-25.9221]], device='cuda:0')\n",
      "gamma grad tensor([[-932.9640]], device='cuda:0')\n",
      "alpha grad tensor([[1470.0930]], device='cuda:0')\n",
      "beta2 grad tensor([[-1164.3418]], device='cuda:0')\n",
      "beta0 grad tensor([-502.5014], device='cuda:0')\n",
      "beta1 grad tensor([[-723.9447]], device='cuda:0')\n",
      "Epoch 246 | Loss: 6.2257\n",
      "alpha: 0.0766621083021164, beta0: 0.11391285806894302, beta1: -0.0005919412360526621, beta2: 0.003184254514053464, \n",
      "gamma: 0.06380381435155869, sigma0: 0.266831636428833, sigma1: 0.00044691807124763727, sigma2: 0.00011491893383208662, sigmaX: 0.1550236940383911\n",
      "forward done\n",
      "tensor([0.0165, 0.0642, 0.4189, 0.6233, 0.3392], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.0750]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-3.9910]], device='cuda:0')\n",
      "sigma0 grad tensor([-9.1228], device='cuda:0')\n",
      "sigma1 grad tensor([[-7.5421]], device='cuda:0')\n",
      "gamma grad tensor([[-827.3511]], device='cuda:0')\n",
      "alpha grad tensor([[1307.6421]], device='cuda:0')\n",
      "beta2 grad tensor([[-1142.4017]], device='cuda:0')\n",
      "beta0 grad tensor([-454.4149], device='cuda:0')\n",
      "beta1 grad tensor([[-679.6231]], device='cuda:0')\n",
      "Epoch 247 | Loss: 7.8148\n",
      "alpha: 0.07657738775014877, beta0: 0.11394567042589188, beta1: -0.0005423665279522538, beta2: 0.0032680570147931576, \n",
      "gamma: 0.06385436654090881, sigma0: 0.2668301463127136, sigma1: 0.0004454047011677176, sigma2: 0.00011296700540697202, sigmaX: 0.15502379834651947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0243, 0.2530, 0.2639, 0.6342, 0.3658], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.3006]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-300.9955]], device='cuda:0')\n",
      "sigma0 grad tensor([-422.4910], device='cuda:0')\n",
      "sigma1 grad tensor([[-313.8715]], device='cuda:0')\n",
      "gamma grad tensor([[3282.3108]], device='cuda:0')\n",
      "alpha grad tensor([[-6278.9917]], device='cuda:0')\n",
      "beta2 grad tensor([[5735.2271]], device='cuda:0')\n",
      "beta0 grad tensor([2896.6602], device='cuda:0')\n",
      "beta1 grad tensor([[3834.6116]], device='cuda:0')\n",
      "Epoch 248 | Loss: 26.5882\n",
      "alpha: 0.07657239586114883, beta0: 0.1139429584145546, beta1: -0.0005410528974607587, beta2: 0.0032777467276901007, \n",
      "gamma: 0.06386198103427887, sigma0: 0.26683318614959717, sigma1: 0.00044733271352015436, sigma2: 0.0001144154230132699, sigmaX: 0.15502388775348663\n",
      "forward done\n",
      "tensor([0.0110, 0.0521, 0.1473, 0.6256, 0.4047], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.4449]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-335.3668]], device='cuda:0')\n",
      "sigma0 grad tensor([-312.5508], device='cuda:0')\n",
      "sigma1 grad tensor([[-281.4367]], device='cuda:0')\n",
      "gamma grad tensor([[1712.2140]], device='cuda:0')\n",
      "alpha grad tensor([[-3521.1445]], device='cuda:0')\n",
      "beta2 grad tensor([[3886.3789]], device='cuda:0')\n",
      "beta0 grad tensor([1737.0372], device='cuda:0')\n",
      "beta1 grad tensor([[2443.9583]], device='cuda:0')\n",
      "Epoch 249 | Loss: 6.3980\n",
      "alpha: 0.07660361379384995, beta0: 0.11392341554164886, beta1: -0.0005644415505230427, beta2: 0.0032466347329318523, \n",
      "gamma: 0.06385095417499542, sigma0: 0.2668387293815613, sigma1: 0.0004516894987318665, sigma2: 0.00011892781913047656, sigmaX: 0.1550239771604538\n",
      "forward done\n",
      "tensor([0.0080, 0.0400, 0.1484, 0.6574, 0.3975], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.4416]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-75.4996]], device='cuda:0')\n",
      "sigma0 grad tensor([-43.2792], device='cuda:0')\n",
      "sigma1 grad tensor([[-52.9311]], device='cuda:0')\n",
      "gamma grad tensor([[-678.5863]], device='cuda:0')\n",
      "alpha grad tensor([[1003.0267]], device='cuda:0')\n",
      "beta2 grad tensor([[-570.5078]], device='cuda:0')\n",
      "beta0 grad tensor([-299.0962], device='cuda:0')\n",
      "beta1 grad tensor([[-391.5880]], device='cuda:0')\n",
      "Epoch 250 | Loss: 5.2141\n",
      "alpha: 0.07661855965852737, beta0: 0.11391077190637589, beta1: -0.0005792365991510451, beta2: 0.0032274501863867044, \n",
      "gamma: 0.06384892016649246, sigma0: 0.2668435871601105, sigma1: 0.0004557042266242206, sigma2: 0.00012329273158684373, sigmaX: 0.15502406656742096\n",
      "forward done\n",
      "tensor([0.0133, 0.0549, 0.0941, 0.6767, 0.3829], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.2069]]], device='cuda:0')\n",
      "sigma2 grad tensor([[29.7125]], device='cuda:0')\n",
      "sigma0 grad tensor([49.7382], device='cuda:0')\n",
      "sigma1 grad tensor([[36.9732]], device='cuda:0')\n",
      "gamma grad tensor([[-1438.5179]], device='cuda:0')\n",
      "alpha grad tensor([[2454.5901]], device='cuda:0')\n",
      "beta2 grad tensor([[-2151.3501]], device='cuda:0')\n",
      "beta0 grad tensor([-961.2070], device='cuda:0')\n",
      "beta1 grad tensor([[-1363.4885]], device='cuda:0')\n",
      "Epoch 251 | Loss: 6.6593\n",
      "alpha: 0.07660596817731857, beta0: 0.11391027271747589, beta1: -0.0005774377495981753, beta2: 0.0032336160074919462, \n",
      "gamma: 0.0638616755604744, sigma0: 0.26684698462486267, sigma1: 0.00045854627387598157, sigma2: 0.00012648753181565553, sigmaX: 0.15502414107322693\n",
      "forward done\n",
      "tensor([0.0140, 0.0976, 0.3723, 0.6369, 0.3716], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.1616]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-459.3984]], device='cuda:0')\n",
      "sigma0 grad tensor([-497.3345], device='cuda:0')\n",
      "sigma1 grad tensor([[-425.1771]], device='cuda:0')\n",
      "gamma grad tensor([[3626.5073]], device='cuda:0')\n",
      "alpha grad tensor([[-7057.7739]], device='cuda:0')\n",
      "beta2 grad tensor([[7168.4854]], device='cuda:0')\n",
      "beta0 grad tensor([3293.7981], device='cuda:0')\n",
      "beta1 grad tensor([[4579.4780]], device='cuda:0')\n",
      "Epoch 252 | Loss: 11.1537\n",
      "alpha: 0.07666647434234619, beta0: 0.11387693136930466, beta1: -0.0006217934424057603, beta2: 0.003166863927617669, \n",
      "gamma: 0.06383561342954636, sigma0: 0.2668546736240387, sigma1: 0.00046507170191034675, sigma2: 0.0001336373679805547, sigmaX: 0.1550242304801941\n",
      "forward done\n",
      "tensor([0.0207, 0.1692, 0.1359, 0.6886, 0.3853], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.7008]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-471.4999]], device='cuda:0')\n",
      "sigma0 grad tensor([-454.6689], device='cuda:0')\n",
      "sigma1 grad tensor([[-407.7373]], device='cuda:0')\n",
      "gamma grad tensor([[3634.6633]], device='cuda:0')\n",
      "alpha grad tensor([[-6941.7632]], device='cuda:0')\n",
      "beta2 grad tensor([[7067.9575]], device='cuda:0')\n",
      "beta0 grad tensor([3188.5857], device='cuda:0')\n",
      "beta1 grad tensor([[4477.4248]], device='cuda:0')\n",
      "Epoch 253 | Loss: 18.1535\n",
      "alpha: 0.07678429782390594, beta0: 0.11381836980581284, beta1: -0.000702052260749042, beta2: 0.0030427826568484306, \n",
      "gamma: 0.06377841532230377, sigma0: 0.2668653726577759, sigma1: 0.0004743694153148681, sigma2: 0.00014407222624868155, sigmaX: 0.15502431988716125\n",
      "forward done\n",
      "tensor([0.0076, 0.0961, 0.1066, 0.6940, 0.4185], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.3042]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-474.7158]], device='cuda:0')\n",
      "sigma0 grad tensor([-510.7565], device='cuda:0')\n",
      "sigma1 grad tensor([[-451.4149]], device='cuda:0')\n",
      "gamma grad tensor([[3565.7153]], device='cuda:0')\n",
      "alpha grad tensor([[-7038.3911]], device='cuda:0')\n",
      "beta2 grad tensor([[7108.5596]], device='cuda:0')\n",
      "beta0 grad tensor([3321.9893], device='cuda:0')\n",
      "beta1 grad tensor([[4614.8193]], device='cuda:0')\n",
      "Epoch 254 | Loss: 10.8332\n",
      "alpha: 0.07694894075393677, beta0: 0.11373830586671829, beta1: -0.0008124074665829539, beta2: 0.002872432116419077, \n",
      "gamma: 0.06369700282812119, sigma0: 0.26687905192375183, sigma1: 0.0004863217181991786, sigma2: 0.00015716727648396045, sigmaX: 0.15502440929412842\n",
      "forward done\n",
      "tensor([0.0183, 0.1837, 0.2555, 0.6629, 0.3895], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.7023]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-360.6862]], device='cuda:0')\n",
      "sigma0 grad tensor([-480.9441], device='cuda:0')\n",
      "sigma1 grad tensor([[-373.0001]], device='cuda:0')\n",
      "gamma grad tensor([[3551.9568]], device='cuda:0')\n",
      "alpha grad tensor([[-6866.4028]], device='cuda:0')\n",
      "beta2 grad tensor([[6535.9365]], device='cuda:0')\n",
      "beta0 grad tensor([3205.0669], device='cuda:0')\n",
      "beta1 grad tensor([[4320.1421]], device='cuda:0')\n",
      "Epoch 255 | Loss: 19.6976\n",
      "alpha: 0.07714931666851044, beta0: 0.11364220082759857, beta1: -0.00094389304285869, beta2: 0.0026707921642810106, \n",
      "gamma: 0.06359635293483734, sigma0: 0.26689478754997253, sigma1: 0.0004996135830879211, sigma2: 0.00017125018348451704, sigmaX: 0.15502449870109558\n",
      "forward done\n",
      "tensor([0.0119, 0.0514, 0.1976, 0.6828, 0.3986], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.8006]]], device='cuda:0')\n",
      "sigma2 grad tensor([[362.4077]], device='cuda:0')\n",
      "sigma0 grad tensor([430.7491], device='cuda:0')\n",
      "sigma1 grad tensor([[365.2242]], device='cuda:0')\n",
      "gamma grad tensor([[-4096.9917]], device='cuda:0')\n",
      "alpha grad tensor([[7604.9136]], device='cuda:0')\n",
      "beta2 grad tensor([[-7756.8159]], device='cuda:0')\n",
      "beta0 grad tensor([-3408.9556], device='cuda:0')\n",
      "beta1 grad tensor([[-4894.3071]], device='cuda:0')\n",
      "Epoch 256 | Loss: 6.4343\n",
      "alpha: 0.07723356783390045, beta0: 0.11359940469264984, beta1: -0.0010001384653151035, beta2: 0.0025870483368635178, \n",
      "gamma: 0.06355680525302887, sigma0: 0.2669030725955963, sigma1: 0.0005065948353148997, sigma2: 0.00017889242735691369, sigmaX: 0.15502458810806274\n",
      "forward done\n",
      "tensor([0.0141, 0.1906, 0.1818, 0.6515, 0.3548], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.2417]]], device='cuda:0')\n",
      "sigma2 grad tensor([[668.0598]], device='cuda:0')\n",
      "sigma0 grad tensor([663.8894], device='cuda:0')\n",
      "sigma1 grad tensor([[607.6046]], device='cuda:0')\n",
      "gamma grad tensor([[-5600.6807]], device='cuda:0')\n",
      "alpha grad tensor([[10590.7578]], device='cuda:0')\n",
      "beta2 grad tensor([[-11801.4658]], device='cuda:0')\n",
      "beta0 grad tensor([-4852.9771], device='cuda:0')\n",
      "beta1 grad tensor([[-7185.7964]], device='cuda:0')\n",
      "Epoch 257 | Loss: 20.2672\n",
      "alpha: 0.07719506323337555, beta0: 0.11361370235681534, beta1: -0.0009732768521644175, beta2: 0.002638068050146103, \n",
      "gamma: 0.06358116865158081, sigma0: 0.2669030725955963, sigma1: 0.0005061037954874337, sigma2: 0.0001783256302587688, sigmaX: 0.1550246626138687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0118, 0.0703, 0.5758, 0.5713, 0.2778], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.9805]]], device='cuda:0')\n",
      "sigma2 grad tensor([[550.2225]], device='cuda:0')\n",
      "sigma0 grad tensor([531.6002], device='cuda:0')\n",
      "sigma1 grad tensor([[464.6333]], device='cuda:0')\n",
      "gamma grad tensor([[-4758.2300]], device='cuda:0')\n",
      "alpha grad tensor([[8929.7852]], device='cuda:0')\n",
      "beta2 grad tensor([[-9682.8047]], device='cuda:0')\n",
      "beta0 grad tensor([-4044.3750], device='cuda:0')\n",
      "beta1 grad tensor([[-5880.4194]], device='cuda:0')\n",
      "Epoch 258 | Loss: 8.4618\n",
      "alpha: 0.07707495987415314, beta0: 0.11366558074951172, beta1: -0.0008929833420552313, beta2: 0.002775711938738823, \n",
      "gamma: 0.06364824622869492, sigma0: 0.2668977379798889, sigma1: 0.000501064641866833, sigma2: 0.0001723699679132551, sigmaX: 0.15502475202083588\n",
      "forward done\n",
      "tensor([0.0180, 0.0587, 0.3554, 0.6071, 0.3391], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.9583]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-264.8604]], device='cuda:0')\n",
      "sigma0 grad tensor([-249.2603], device='cuda:0')\n",
      "sigma1 grad tensor([[-225.8495]], device='cuda:0')\n",
      "gamma grad tensor([[1397.2487]], device='cuda:0')\n",
      "alpha grad tensor([[-2844.6731]], device='cuda:0')\n",
      "beta2 grad tensor([[3227.0522]], device='cuda:0')\n",
      "beta0 grad tensor([1408.1938], device='cuda:0')\n",
      "beta1 grad tensor([[2005.6857]], device='cuda:0')\n",
      "Epoch 259 | Loss: 7.1911\n",
      "alpha: 0.07700732350349426, beta0: 0.113693006336689, beta1: -0.0008488054154440761, beta2: 0.0028535565361380577, \n",
      "gamma: 0.06368793547153473, sigma0: 0.26689597964286804, sigma1: 0.0004992918111383915, sigma2: 0.00017025403212755919, sigmaX: 0.15502484142780304\n",
      "forward done\n",
      "tensor([0.0162, 0.0707, 0.1948, 0.6620, 0.3828], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.2070]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-565.1070]], device='cuda:0')\n",
      "sigma0 grad tensor([-532.7991], device='cuda:0')\n",
      "sigma1 grad tensor([[-479.4038]], device='cuda:0')\n",
      "gamma grad tensor([[3753.7061]], device='cuda:0')\n",
      "alpha grad tensor([[-7378.8457]], device='cuda:0')\n",
      "beta2 grad tensor([[7935.7012]], device='cuda:0')\n",
      "beta0 grad tensor([3472.3354], device='cuda:0')\n",
      "beta1 grad tensor([[4940.3516]], device='cuda:0')\n",
      "Epoch 260 | Loss: 8.3209\n",
      "alpha: 0.07702700048685074, beta0: 0.11368022114038467, beta1: -0.0008628665818832815, beta2: 0.0028364751487970352, \n",
      "gamma: 0.06368214637041092, sigma0: 0.26689988374710083, sigma1: 0.000502667564433068, sigma2: 0.00017421235679648817, sigmaX: 0.1550249308347702\n",
      "forward done\n",
      "tensor([0.0143, 0.0495, 0.4106, 0.6180, 0.2983], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.3930]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-657.6718]], device='cuda:0')\n",
      "sigma0 grad tensor([-526.1556], device='cuda:0')\n",
      "sigma1 grad tensor([[-517.6271]], device='cuda:0')\n",
      "gamma grad tensor([[4167.2778]], device='cuda:0')\n",
      "alpha grad tensor([[-7991.8252]], device='cuda:0')\n",
      "beta2 grad tensor([[8923.6895]], device='cuda:0')\n",
      "beta0 grad tensor([3683.8157], device='cuda:0')\n",
      "beta1 grad tensor([[5404.4307]], device='cuda:0')\n",
      "Epoch 261 | Loss: 6.2887\n",
      "alpha: 0.07712266594171524, beta0: 0.1136331558227539, beta1: -0.0009281598031520844, beta2: 0.0027335730846971273, \n",
      "gamma: 0.06363584101200104, sigma0: 0.26690828800201416, sigma1: 0.0005105444579385221, sigma2: 0.00018395573715679348, sigmaX: 0.15502502024173737\n",
      "forward done\n",
      "tensor([0.0061, 0.0338, 0.2288, 0.6041, 0.3299], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.6338]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-120.8257]], device='cuda:0')\n",
      "sigma0 grad tensor([-90.9005], device='cuda:0')\n",
      "sigma1 grad tensor([[-94.3867]], device='cuda:0')\n",
      "gamma grad tensor([[-319.1035]], device='cuda:0')\n",
      "alpha grad tensor([[307.6026]], device='cuda:0')\n",
      "beta2 grad tensor([[81.6009]], device='cuda:0')\n",
      "beta0 grad tensor([25.4619], device='cuda:0')\n",
      "beta1 grad tensor([[44.7452]], device='cuda:0')\n",
      "Epoch 262 | Loss: 4.5525\n",
      "alpha: 0.07719612121582031, beta0: 0.11359524726867676, beta1: -0.0009808418108150363, beta2: 0.002650435548275709, \n",
      "gamma: 0.06360199302434921, sigma0: 0.2669159173965454, sigma1: 0.000517789856530726, sigma2: 0.00019295870151836425, sigmaX: 0.15502510964870453\n",
      "forward done\n",
      "tensor([0.0089, 0.0707, 0.2762, 0.6636, 0.3832], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.0782]]], device='cuda:0')\n",
      "sigma2 grad tensor([[128.7417]], device='cuda:0')\n",
      "sigma0 grad tensor([154.8262], device='cuda:0')\n",
      "sigma1 grad tensor([[126.0690]], device='cuda:0')\n",
      "gamma grad tensor([[-2470.3298]], device='cuda:0')\n",
      "alpha grad tensor([[4383.4214]], device='cuda:0')\n",
      "beta2 grad tensor([[-4216.4937]], device='cuda:0')\n",
      "beta0 grad tensor([-1831.4689], device='cuda:0')\n",
      "beta1 grad tensor([[-2623.8899]], device='cuda:0')\n",
      "Epoch 263 | Loss: 8.3996\n",
      "alpha: 0.07721105217933655, beta0: 0.11358323693275452, beta1: -0.000996748567558825, beta2: 0.0026260903105139732, \n",
      "gamma: 0.0635996162891388, sigma0: 0.2669204771518707, sigma1: 0.0005223254556767642, sigma2: 0.00019887364760506898, sigmaX: 0.1550251990556717\n",
      "forward done\n",
      "tensor([0.0098, 0.0896, 0.2467, 0.6206, 0.3690], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.7512]]], device='cuda:0')\n",
      "sigma2 grad tensor([[555.4224]], device='cuda:0')\n",
      "sigma0 grad tensor([568.0538], device='cuda:0')\n",
      "sigma1 grad tensor([[511.2931]], device='cuda:0')\n",
      "gamma grad tensor([[-5275.4009]], device='cuda:0')\n",
      "alpha grad tensor([[9824.3262]], device='cuda:0')\n",
      "beta2 grad tensor([[-10094.0459]], device='cuda:0')\n",
      "beta0 grad tensor([-4434.7671], device='cuda:0')\n",
      "beta1 grad tensor([[-6344.6069]], device='cuda:0')\n",
      "Epoch 264 | Loss: 10.2102\n",
      "alpha: 0.07712475210428238, beta0: 0.11361797153949738, beta1: -0.0009460278670303524, beta2: 0.0027075547259300947, \n",
      "gamma: 0.0636504665017128, sigma0: 0.26691845059394836, sigma1: 0.0005208409857004881, sigma2: 0.0001980513916350901, sigmaX: 0.15502528846263885\n",
      "forward done\n",
      "tensor([0.0114, 0.1371, 0.0806, 0.6630, 0.3899], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.8267]]], device='cuda:0')\n",
      "sigma2 grad tensor([[544.7672]], device='cuda:0')\n",
      "sigma0 grad tensor([621.8701], device='cuda:0')\n",
      "sigma1 grad tensor([[529.1737]], device='cuda:0')\n",
      "gamma grad tensor([[-5297.1450]], device='cuda:0')\n",
      "alpha grad tensor([[9991.6289]], device='cuda:0')\n",
      "beta2 grad tensor([[-10450.0615]], device='cuda:0')\n",
      "beta0 grad tensor([-4561.6372], device='cuda:0')\n",
      "beta1 grad tensor([[-6556.4243]], device='cuda:0')\n",
      "Epoch 265 | Loss: 14.8554\n",
      "alpha: 0.07695579528808594, beta0: 0.11369138211011887, beta1: -0.0008398870704695582, beta2: 0.002877226797863841, \n",
      "gamma: 0.06374412029981613, sigma0: 0.2669106125831604, sigma1: 0.0005143617163412273, sigma2: 0.00019194590277038515, sigmaX: 0.1550253927707672\n",
      "forward done\n",
      "tensor([0.0141, 0.0536, 0.1849, 0.6337, 0.3767], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.0557]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-353.3321]], device='cuda:0')\n",
      "sigma0 grad tensor([-340.8164], device='cuda:0')\n",
      "sigma1 grad tensor([[-307.0829]], device='cuda:0')\n",
      "gamma grad tensor([[2090.0117]], device='cuda:0')\n",
      "alpha grad tensor([[-4214.5420]], device='cuda:0')\n",
      "beta2 grad tensor([[4631.0532]], device='cuda:0')\n",
      "beta0 grad tensor([2041.8457], device='cuda:0')\n",
      "beta1 grad tensor([[2902.4639]], device='cuda:0')\n",
      "Epoch 266 | Loss: 6.5652\n",
      "alpha: 0.07686277478933334, beta0: 0.11372968554496765, beta1: -0.0007839991012588143, beta2: 0.002966654021292925, \n",
      "gamma: 0.06379814445972443, sigma0: 0.2669077515602112, sigma1: 0.0005122491274960339, sigma2: 0.00019059484475292265, sigmaX: 0.15502549707889557\n",
      "forward done\n",
      "tensor([0.0143, 0.0593, 0.3669, 0.5950, 0.3266], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.9778]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-291.9749]], device='cuda:0')\n",
      "sigma0 grad tensor([-250.9785], device='cuda:0')\n",
      "sigma1 grad tensor([[-234.0278]], device='cuda:0')\n",
      "gamma grad tensor([[1250.6429]], device='cuda:0')\n",
      "alpha grad tensor([[-2626.0352]], device='cuda:0')\n",
      "beta2 grad tensor([[3065.5867]], device='cuda:0')\n",
      "beta0 grad tensor([1324.0585], device='cuda:0')\n",
      "beta1 grad tensor([[1891.5087]], device='cuda:0')\n",
      "Epoch 267 | Loss: 7.2290\n",
      "alpha: 0.07681462168693542, beta0: 0.11374709010124207, beta1: -0.0007582037942484021, beta2: 0.0030075397808104753, \n",
      "gamma: 0.06382885575294495, sigma0: 0.2669079601764679, sigma1: 0.0005128993070684373, sigma2: 0.00019243374117650092, sigmaX: 0.15502560138702393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0120, 0.0711, 0.1036, 0.6652, 0.3754], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.3533]]], device='cuda:0')\n",
      "sigma2 grad tensor([[67.1920]], device='cuda:0')\n",
      "sigma0 grad tensor([83.8092], device='cuda:0')\n",
      "sigma1 grad tensor([[68.8190]], device='cuda:0')\n",
      "gamma grad tensor([[-1602.1824]], device='cuda:0')\n",
      "alpha grad tensor([[2826.2783]], device='cuda:0')\n",
      "beta2 grad tensor([[-2702.2024]], device='cuda:0')\n",
      "beta0 grad tensor([-1150.0042], device='cuda:0')\n",
      "beta1 grad tensor([[-1668.0924]], device='cuda:0')\n",
      "Epoch 268 | Loss: 8.2671\n",
      "alpha: 0.0767478346824646, beta0: 0.11377251148223877, beta1: -0.0007208866300061345, beta2: 0.0030672703869640827, \n",
      "gamma: 0.06386944651603699, sigma0: 0.26690730452537537, sigma1: 0.0005127312615513802, sigma2: 0.00019323293236084282, sigmaX: 0.15502570569515228\n",
      "forward done\n",
      "tensor([0.0174, 0.0536, 0.1551, 0.7002, 0.3846], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.5842]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-39.2503]], device='cuda:0')\n",
      "sigma0 grad tensor([-37.3075], device='cuda:0')\n",
      "sigma1 grad tensor([[-33.5706]], device='cuda:0')\n",
      "gamma grad tensor([[-706.5879]], device='cuda:0')\n",
      "alpha grad tensor([[1065.1729]], device='cuda:0')\n",
      "beta2 grad tensor([[-754.0886]], device='cuda:0')\n",
      "beta0 grad tensor([-328.7986], device='cuda:0')\n",
      "beta1 grad tensor([[-471.3929]], device='cuda:0')\n",
      "Epoch 269 | Loss: 6.6135\n",
      "alpha: 0.07668375223875046, beta0: 0.11379613727331161, beta1: -0.0006863189628347754, beta2: 0.003122595837339759, \n",
      "gamma: 0.06390898674726486, sigma0: 0.2669071555137634, sigma1: 0.0005129325436428189, sigma2: 0.0001942647941177711, sigmaX: 0.15502581000328064\n",
      "forward done\n",
      "tensor([0.0158, 0.1573, 0.0885, 0.6842, 0.3815], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.8478]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-367.2341]], device='cuda:0')\n",
      "sigma0 grad tensor([-457.2098], device='cuda:0')\n",
      "sigma1 grad tensor([[-372.8703]], device='cuda:0')\n",
      "gamma grad tensor([[4094.8257]], device='cuda:0')\n",
      "alpha grad tensor([[-7658.0586]], device='cuda:0')\n",
      "beta2 grad tensor([[7269.4268]], device='cuda:0')\n",
      "beta0 grad tensor([3463.1560], device='cuda:0')\n",
      "beta1 grad tensor([[4752.9502]], device='cuda:0')\n",
      "Epoch 270 | Loss: 16.8954\n",
      "alpha: 0.0767090693116188, beta0: 0.11378040909767151, beta1: -0.0007061943178996444, beta2: 0.0030941618606448174, \n",
      "gamma: 0.06389966607093811, sigma0: 0.2669115960597992, sigma1: 0.0005168222705833614, sigma2: 0.00019876263104379177, sigmaX: 0.1550258994102478\n",
      "forward done\n",
      "tensor([0.0137, 0.0666, 0.1933, 0.6668, 0.3950], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-3.0699]]], device='cuda:0')\n",
      "sigma2 grad tensor([[70.7248]], device='cuda:0')\n",
      "sigma0 grad tensor([79.1676], device='cuda:0')\n",
      "sigma1 grad tensor([[72.3547]], device='cuda:0')\n",
      "gamma grad tensor([[-1720.0358]], device='cuda:0')\n",
      "alpha grad tensor([[2975.9871]], device='cuda:0')\n",
      "beta2 grad tensor([[-2675.6912]], device='cuda:0')\n",
      "beta0 grad tensor([-1197.0903], device='cuda:0')\n",
      "beta1 grad tensor([[-1697.0618]], device='cuda:0')\n",
      "Epoch 271 | Loss: 7.9266\n",
      "alpha: 0.07669956237077713, beta0: 0.11377979815006256, beta1: -0.0007051239954307675, beta2: 0.0030981716699898243, \n",
      "gamma: 0.06390941143035889, sigma0: 0.26691436767578125, sigma1: 0.000519210530910641, sigma2: 0.00020165364549029619, sigmaX: 0.15502600371837616\n",
      "forward done\n",
      "tensor([0.0098, 0.0656, 0.1954, 0.5912, 0.3458], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.4117]]], device='cuda:0')\n",
      "sigma2 grad tensor([[29.4320]], device='cuda:0')\n",
      "sigma0 grad tensor([60.1696], device='cuda:0')\n",
      "sigma1 grad tensor([[39.5004]], device='cuda:0')\n",
      "gamma grad tensor([[-1390.1510]], device='cuda:0')\n",
      "alpha grad tensor([[2405.9287]], device='cuda:0')\n",
      "beta2 grad tensor([[-2203.5901]], device='cuda:0')\n",
      "beta0 grad tensor([-959.7267], device='cuda:0')\n",
      "beta1 grad tensor([[-1372.8928]], device='cuda:0')\n",
      "Epoch 272 | Loss: 7.6983\n",
      "alpha: 0.0766678974032402, beta0: 0.113788902759552, beta1: -0.0006905387854203582, beta2: 0.0031234154012054205, \n",
      "gamma: 0.06393110752105713, sigma0: 0.2669159770011902, sigma1: 0.0005207261419855058, sigma2: 0.00020367214165162295, sigmaX: 0.15502610802650452\n",
      "forward done\n",
      "tensor([0.0210, 0.0850, 0.3677, 0.5851, 0.3084], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.3092]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-541.4201]], device='cuda:0')\n",
      "sigma0 grad tensor([-500.9458], device='cuda:0')\n",
      "sigma1 grad tensor([[-466.5231]], device='cuda:0')\n",
      "gamma grad tensor([[4000.9414]], device='cuda:0')\n",
      "alpha grad tensor([[-7600.8794]], device='cuda:0')\n",
      "beta2 grad tensor([[7985.5259]], device='cuda:0')\n",
      "beta0 grad tensor([3489.1873], device='cuda:0')\n",
      "beta1 grad tensor([[4985.1807]], device='cuda:0')\n",
      "Epoch 273 | Loss: 9.7803\n",
      "alpha: 0.07671857625246048, beta0: 0.1137612983584404, beta1: -0.0007287224289029837, beta2: 0.0030637551099061966, \n",
      "gamma: 0.06390845775604248, sigma0: 0.266922265291214, sigma1: 0.0005266038351692259, sigma2: 0.00021070113871246576, sigmaX: 0.15502621233463287\n",
      "forward done\n",
      "tensor([0.0090, 0.1486, 0.1684, 0.6398, 0.3728], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-3.6268]]], device='cuda:0')\n",
      "sigma2 grad tensor([[660.8192]], device='cuda:0')\n",
      "sigma0 grad tensor([590.4131], device='cuda:0')\n",
      "sigma1 grad tensor([[550.1500]], device='cuda:0')\n",
      "gamma grad tensor([[-5312.7891]], device='cuda:0')\n",
      "alpha grad tensor([[9887.6455]], device='cuda:0')\n",
      "beta2 grad tensor([[-10506.4072]], device='cuda:0')\n",
      "beta0 grad tensor([-4461.2739], device='cuda:0')\n",
      "beta1 grad tensor([[-6458.5742]], device='cuda:0')\n",
      "Epoch 274 | Loss: 16.0493\n",
      "alpha: 0.07666023820638657, beta0: 0.1137838289141655, beta1: -0.0006946836365386844, beta2: 0.003121091052889824, \n",
      "gamma: 0.06394346803426743, sigma0: 0.26692140102386475, sigma1: 0.0005258044693619013, sigma2: 0.00020971614867448807, sigmaX: 0.15502633154392242\n",
      "forward done\n",
      "tensor([0.0187, 0.1968, 0.1290, 0.6149, 0.3783], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.8693]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-448.1229]], device='cuda:0')\n",
      "sigma0 grad tensor([-462.3237], device='cuda:0')\n",
      "sigma1 grad tensor([[-399.3574]], device='cuda:0')\n",
      "gamma grad tensor([[2969.8560]], device='cuda:0')\n",
      "alpha grad tensor([[-5938.1045]], device='cuda:0')\n",
      "beta2 grad tensor([[6116.2065]], device='cuda:0')\n",
      "beta0 grad tensor([2838.5288], device='cuda:0')\n",
      "beta1 grad tensor([[3922.7598]], device='cuda:0')\n",
      "Epoch 275 | Loss: 20.8177\n",
      "alpha: 0.07667294889688492, beta0: 0.11377346515655518, beta1: -0.0007066801772452891, beta2: 0.0031057975720614195, \n",
      "gamma: 0.06394177675247192, sigma0: 0.2669253349304199, sigma1: 0.000529158569406718, sigma2: 0.0002134093811037019, sigmaX: 0.15502645075321198\n",
      "forward done\n",
      "tensor([0.0071, 0.0911, 0.1327, 0.6548, 0.4070], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.4188]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-466.4000]], device='cuda:0')\n",
      "sigma0 grad tensor([-518.4373], device='cuda:0')\n",
      "sigma1 grad tensor([[-438.6356]], device='cuda:0')\n",
      "gamma grad tensor([[3968.6958]], device='cuda:0')\n",
      "alpha grad tensor([[-7641.7798]], device='cuda:0')\n",
      "beta2 grad tensor([[7331.2227]], device='cuda:0')\n",
      "beta0 grad tensor([3538.8281], device='cuda:0')\n",
      "beta1 grad tensor([[4816.7383]], device='cuda:0')\n",
      "Epoch 276 | Loss: 10.3096\n",
      "alpha: 0.07675953954458237, beta0: 0.11372978985309601, beta1: -0.0007644448196515441, beta2: 0.003020250704139471, \n",
      "gamma: 0.06390073895454407, sigma0: 0.2669336497783661, sigma1: 0.0005362281808629632, sigma2: 0.0002210279635619372, sigmaX: 0.15502656996250153\n",
      "forward done\n",
      "tensor([0.0101, 0.0123, 0.2251, 0.6422, 0.4003], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.7571]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-66.9621]], device='cuda:0')\n",
      "sigma0 grad tensor([-55.0634], device='cuda:0')\n",
      "sigma1 grad tensor([[-54.1261]], device='cuda:0')\n",
      "gamma grad tensor([[-430.4622]], device='cuda:0')\n",
      "alpha grad tensor([[543.0872]], device='cuda:0')\n",
      "beta2 grad tensor([[-256.1465]], device='cuda:0')\n",
      "beta0 grad tensor([-107.3823], device='cuda:0')\n",
      "beta1 grad tensor([[-156.9295]], device='cuda:0')\n",
      "Epoch 277 | Loss: 2.5121\n",
      "alpha: 0.07682337611913681, beta0: 0.11369591951370239, beta1: -0.0008090872433967888, beta2: 0.00295437453314662, \n",
      "gamma: 0.06387221068143845, sigma0: 0.2669408619403839, sigma1: 0.0005424251430667937, sigma2: 0.000227792450459674, sigmaX: 0.15502668917179108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0146, 0.0884, 0.2292, 0.6461, 0.3798], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.1511]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-410.4873]], device='cuda:0')\n",
      "sigma0 grad tensor([-498.1197], device='cuda:0')\n",
      "sigma1 grad tensor([[-394.6996]], device='cuda:0')\n",
      "gamma grad tensor([[3876.2627]], device='cuda:0')\n",
      "alpha grad tensor([[-7431.9800]], device='cuda:0')\n",
      "beta2 grad tensor([[7292.5708]], device='cuda:0')\n",
      "beta0 grad tensor([3438.3406], device='cuda:0')\n",
      "beta1 grad tensor([[4717.4390]], device='cuda:0')\n",
      "Epoch 278 | Loss: 10.1133\n",
      "alpha: 0.07694876939058304, beta0: 0.11363443732261658, beta1: -0.0008919755346141756, beta2: 0.0028287479653954506, \n",
      "gamma: 0.06381062418222427, sigma0: 0.26695162057876587, sigma1: 0.000551329692825675, sigma2: 0.00023730890825390816, sigmaX: 0.15502679347991943\n",
      "forward done\n",
      "tensor([0.0151, 0.0980, 0.1276, 0.6657, 0.4195], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.8277]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-455.9410]], device='cuda:0')\n",
      "sigma0 grad tensor([-528.9534], device='cuda:0')\n",
      "sigma1 grad tensor([[-435.8372]], device='cuda:0')\n",
      "gamma grad tensor([[3867.9851]], device='cuda:0')\n",
      "alpha grad tensor([[-7483.9478]], device='cuda:0')\n",
      "beta2 grad tensor([[7540.8657]], device='cuda:0')\n",
      "beta0 grad tensor([3500.9976], device='cuda:0')\n",
      "beta1 grad tensor([[4843.0405]], device='cuda:0')\n",
      "Epoch 279 | Loss: 11.0325\n",
      "alpha: 0.07712392508983612, beta0: 0.11355024576187134, beta1: -0.0010067166294902563, beta2: 0.0026528381276875734, \n",
      "gamma: 0.06372267752885818, sigma0: 0.26696550846099854, sigma1: 0.0005628117360174656, sigma2: 0.00024948149803094566, sigmaX: 0.15502691268920898\n",
      "forward done\n",
      "tensor([0.0188, 0.1842, 0.1770, 0.6723, 0.3858], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.7763]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-414.0262]], device='cuda:0')\n",
      "sigma0 grad tensor([-492.8298], device='cuda:0')\n",
      "sigma1 grad tensor([[-398.3240]], device='cuda:0')\n",
      "gamma grad tensor([[3466.9690]], device='cuda:0')\n",
      "alpha grad tensor([[-6858.5615]], device='cuda:0')\n",
      "beta2 grad tensor([[6353.7588]], device='cuda:0')\n",
      "beta0 grad tensor([3248.0503], device='cuda:0')\n",
      "beta1 grad tensor([[4274.5010]], device='cuda:0')\n",
      "Epoch 280 | Loss: 19.6709\n",
      "alpha: 0.07733263075351715, beta0: 0.11345040798187256, beta1: -0.001141254440881312, beta2: 0.0024485725443810225, \n",
      "gamma: 0.06361764669418335, sigma0: 0.2669815421104431, sigma1: 0.0005759805790148675, sigma2: 0.00026335983420722187, sigmaX: 0.15502703189849854\n",
      "forward done\n",
      "tensor([0.0166, 0.2051, 0.3107, 0.5466, 0.3440], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.0033]]], device='cuda:0')\n",
      "sigma2 grad tensor([[805.7916]], device='cuda:0')\n",
      "sigma0 grad tensor([681.5742], device='cuda:0')\n",
      "sigma1 grad tensor([[650.3757]], device='cuda:0')\n",
      "gamma grad tensor([[-5919.1685]], device='cuda:0')\n",
      "alpha grad tensor([[11111.2998]], device='cuda:0')\n",
      "beta2 grad tensor([[-12874.9736]], device='cuda:0')\n",
      "beta0 grad tensor([-5064.3921], device='cuda:0')\n",
      "beta1 grad tensor([[-7575.5479]], device='cuda:0')\n",
      "Epoch 281 | Loss: 21.7265\n",
      "alpha: 0.07738848030567169, beta0: 0.11342118680477142, beta1: -0.0011731291888281703, beta2: 0.0024139098823070526, \n",
      "gamma: 0.0635928139090538, sigma0: 0.26698756217956543, sigma1: 0.0005800119251944125, sigma2: 0.000266404589638114, sigmaX: 0.1550271362066269\n",
      "forward done\n",
      "tensor([0.0127, 0.0403, 0.3636, 0.6338, 0.3272], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.1445]]], device='cuda:0')\n",
      "sigma2 grad tensor([[547.2108]], device='cuda:0')\n",
      "sigma0 grad tensor([510.4901], device='cuda:0')\n",
      "sigma1 grad tensor([[465.3902]], device='cuda:0')\n",
      "gamma grad tensor([[-4459.6807]], device='cuda:0')\n",
      "alpha grad tensor([[8443.0840]], device='cuda:0')\n",
      "beta2 grad tensor([[-9227.2158]], device='cuda:0')\n",
      "beta0 grad tensor([-3849.0298], device='cuda:0')\n",
      "beta1 grad tensor([[-5601.5527]], device='cuda:0')\n",
      "Epoch 282 | Loss: 5.3720\n",
      "alpha: 0.0773487314581871, beta0: 0.11343629658222198, beta1: -0.0011426134733483195, beta2: 0.002478451933711767, \n",
      "gamma: 0.06361754238605499, sigma0: 0.26698726415634155, sigma1: 0.0005785831017419696, sigma2: 0.0002633682743180543, sigmaX: 0.15502724051475525\n",
      "forward done\n",
      "tensor([0.0092, 0.0598, 0.1491, 0.6384, 0.3611], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.3104]]], device='cuda:0')\n",
      "sigma2 grad tensor([[90.6576]], device='cuda:0')\n",
      "sigma0 grad tensor([132.6321], device='cuda:0')\n",
      "sigma1 grad tensor([[101.2903]], device='cuda:0')\n",
      "gamma grad tensor([[-2080.0479]], device='cuda:0')\n",
      "alpha grad tensor([[3744.8513]], device='cuda:0')\n",
      "beta2 grad tensor([[-3705.2258]], device='cuda:0')\n",
      "beta0 grad tensor([-1570.4290], device='cuda:0')\n",
      "beta1 grad tensor([[-2283.6787]], device='cuda:0')\n",
      "Epoch 283 | Loss: 7.1396\n",
      "alpha: 0.0772794857621193, beta0: 0.11346408724784851, beta1: -0.0010953641030937433, beta2: 0.002567137824371457, \n",
      "gamma: 0.06365812569856644, sigma0: 0.2669857144355774, sigma1: 0.0005764271481893957, sigma2: 0.0002600326552055776, sigmaX: 0.1550273448228836\n",
      "forward done\n",
      "tensor([0.0105, 0.0395, 0.3296, 0.6919, 0.3927], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.5139]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-43.9091]], device='cuda:0')\n",
      "sigma0 grad tensor([-19.7200], device='cuda:0')\n",
      "sigma1 grad tensor([[-27.2887]], device='cuda:0')\n",
      "gamma grad tensor([[-986.2054]], device='cuda:0')\n",
      "alpha grad tensor([[1563.2925]], device='cuda:0')\n",
      "beta2 grad tensor([[-1197.8190]], device='cuda:0')\n",
      "beta0 grad tensor([-541.3702], device='cuda:0')\n",
      "beta1 grad tensor([[-763.7792]], device='cuda:0')\n",
      "Epoch 284 | Loss: 5.3707\n",
      "alpha: 0.07720845192670822, beta0: 0.1134917363524437, beta1: -0.0010499268537387252, beta2: 0.0026500646490603685, \n",
      "gamma: 0.06370045989751816, sigma0: 0.2669846713542938, sigma1: 0.000574975274503231, sigma2: 0.0002578032435849309, sigmaX: 0.15502746403217316\n",
      "forward done\n",
      "tensor([0.0215, 0.3532, 0.3718, 0.5743, 0.2695], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.0022]]], device='cuda:0')\n",
      "sigma2 grad tensor([[1012.9338]], device='cuda:0')\n",
      "sigma0 grad tensor([756.7925], device='cuda:0')\n",
      "sigma1 grad tensor([[773.6017]], device='cuda:0')\n",
      "gamma grad tensor([[-6016.2720]], device='cuda:0')\n",
      "alpha grad tensor([[11398.3438]], device='cuda:0')\n",
      "beta2 grad tensor([[-14497.7275]], device='cuda:0')\n",
      "beta0 grad tensor([-5229.0483], device='cuda:0')\n",
      "beta1 grad tensor([[-8208.4990]], device='cuda:0')\n",
      "Epoch 285 | Loss: 36.5563\n",
      "alpha: 0.07703764736652374, beta0: 0.11356614530086517, beta1: -0.0009314920753240585, beta2: 0.002861383371055126, \n",
      "gamma: 0.06379448622465134, sigma0: 0.2669762670993805, sigma1: 0.0005660777678713202, sigma2: 0.0002458903763908893, sigmaX: 0.15502755343914032\n",
      "forward done\n",
      "tensor([0.0110, 0.0542, 0.1189, 0.6608, 0.3733], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.2764]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-39.9098]], device='cuda:0')\n",
      "sigma0 grad tensor([-12.5393], device='cuda:0')\n",
      "sigma1 grad tensor([[-21.1950]], device='cuda:0')\n",
      "gamma grad tensor([[-950.0182]], device='cuda:0')\n",
      "alpha grad tensor([[1521.4336]], device='cuda:0')\n",
      "beta2 grad tensor([[-1225.2152]], device='cuda:0')\n",
      "beta0 grad tensor([-533.1899], device='cuda:0')\n",
      "beta1 grad tensor([[-767.5850]], device='cuda:0')\n",
      "Epoch 286 | Loss: 6.5816\n",
      "alpha: 0.07688578963279724, beta0: 0.1136310026049614, beta1: -0.0008290683617815375, beta2: 0.0030426904559135437, \n",
      "gamma: 0.06387920677661896, sigma0: 0.2669696807861328, sigma1: 0.0005591717199422419, sigma2: 0.00023675918055232614, sigmaX: 0.15502764284610748\n",
      "forward done\n",
      "tensor([0.0090, 0.0556, 0.0608, 0.6866, 0.3905], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.5098]]], device='cuda:0')\n",
      "sigma2 grad tensor([[125.6817]], device='cuda:0')\n",
      "sigma0 grad tensor([210.2351], device='cuda:0')\n",
      "sigma1 grad tensor([[153.8230]], device='cuda:0')\n",
      "gamma grad tensor([[-2765.0034]], device='cuda:0')\n",
      "alpha grad tensor([[4986.9155]], device='cuda:0')\n",
      "beta2 grad tensor([[-4440.4482]], device='cuda:0')\n",
      "beta0 grad tensor([-2132.8987], device='cuda:0')\n",
      "beta1 grad tensor([[-2917.2429]], device='cuda:0')\n",
      "Epoch 287 | Loss: 6.7038\n",
      "alpha: 0.07671443372964859, beta0: 0.11370421946048737, beta1: -0.0007179569802246988, beta2: 0.0032321407925337553, \n",
      "gamma: 0.06397463381290436, sigma0: 0.26696228981018066, sigma1: 0.000552108627744019, sigma2: 0.000228197401156649, sigmaX: 0.15502771735191345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0134, 0.0395, 0.1980, 0.6006, 0.3556], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.5321]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-292.2159]], device='cuda:0')\n",
      "sigma0 grad tensor([-256.2835], device='cuda:0')\n",
      "sigma1 grad tensor([[-242.2981]], device='cuda:0')\n",
      "gamma grad tensor([[1222.7246]], device='cuda:0')\n",
      "alpha grad tensor([[-2584.2144]], device='cuda:0')\n",
      "beta2 grad tensor([[3020.8845]], device='cuda:0')\n",
      "beta0 grad tensor([1317.1786], device='cuda:0')\n",
      "beta1 grad tensor([[1882.0372]], device='cuda:0')\n",
      "Epoch 288 | Loss: 5.1147\n",
      "alpha: 0.07660318911075592, beta0: 0.11374962329864502, beta1: -0.0006478882278315723, beta2: 0.003353492124006152, \n",
      "gamma: 0.06403874605894089, sigma0: 0.26695895195007324, sigma1: 0.0005488811293616891, sigma2: 0.00022427014482673258, sigmaX: 0.15502780675888062\n",
      "forward done\n",
      "tensor([0.0083, 0.0654, 0.1577, 0.6376, 0.3809], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.4423]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-312.3435]], device='cuda:0')\n",
      "sigma0 grad tensor([-366.5186], device='cuda:0')\n",
      "sigma1 grad tensor([[-308.2029]], device='cuda:0')\n",
      "gamma grad tensor([[2627.3555]], device='cuda:0')\n",
      "alpha grad tensor([[-5083.2339]], device='cuda:0')\n",
      "beta2 grad tensor([[5032.8936]], device='cuda:0')\n",
      "beta0 grad tensor([2383.0503], device='cuda:0')\n",
      "beta1 grad tensor([[3277.9819]], device='cuda:0')\n",
      "Epoch 289 | Loss: 7.7228\n",
      "alpha: 0.07656502723693848, beta0: 0.11376211047172546, beta1: -0.0006246130797080696, beta2: 0.0034002442844212055, \n",
      "gamma: 0.06406376510858536, sigma0: 0.26695993542671204, sigma1: 0.0005493811913765967, sigma2: 0.00022425176575779915, sigmaX: 0.15502788126468658\n",
      "forward done\n",
      "tensor([0.0090, 0.0411, 0.1076, 0.7022, 0.4034], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.0820]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-49.3970]], device='cuda:0')\n",
      "sigma0 grad tensor([-21.2605], device='cuda:0')\n",
      "sigma1 grad tensor([[-33.1865]], device='cuda:0')\n",
      "gamma grad tensor([[-784.0867]], device='cuda:0')\n",
      "alpha grad tensor([[1245.7687]], device='cuda:0')\n",
      "beta2 grad tensor([[-880.2277]], device='cuda:0')\n",
      "beta0 grad tensor([-420.5624], device='cuda:0')\n",
      "beta1 grad tensor([[-575.7458]], device='cuda:0')\n",
      "Epoch 290 | Loss: 5.3363\n",
      "alpha: 0.07652203738689423, beta0: 0.1137763112783432, beta1: -0.0006002354784868658, beta2: 0.0034464483615010977, \n",
      "gamma: 0.06409162282943726, sigma0: 0.2669609487056732, sigma1: 0.0005501130945049226, sigma2: 0.0002247310330858454, sigmaX: 0.15502797067165375\n",
      "forward done\n",
      "tensor([0.0071, 0.0680, 0.2072, 0.6591, 0.3980], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.7007]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-352.6069]], device='cuda:0')\n",
      "sigma0 grad tensor([-416.5876], device='cuda:0')\n",
      "sigma1 grad tensor([[-343.2475]], device='cuda:0')\n",
      "gamma grad tensor([[2568.5129]], device='cuda:0')\n",
      "alpha grad tensor([[-5184.2729]], device='cuda:0')\n",
      "beta2 grad tensor([[5018.4443]], device='cuda:0')\n",
      "beta0 grad tensor([2504.1467], device='cuda:0')\n",
      "beta1 grad tensor([[3348.2534]], device='cuda:0')\n",
      "Epoch 291 | Loss: 8.0697\n",
      "alpha: 0.07653948664665222, beta0: 0.11376262456178665, beta1: -0.0006142159109003842, beta2: 0.0034332270734012127, \n",
      "gamma: 0.06408822536468506, sigma0: 0.26696592569351196, sigma1: 0.0005541311111301184, sigma2: 0.000228640521527268, sigmaX: 0.1550280600786209\n",
      "forward done\n",
      "tensor([0.0154, 0.1981, 0.1855, 0.6837, 0.4214], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.9000]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-375.5645]], device='cuda:0')\n",
      "sigma0 grad tensor([-439.3062], device='cuda:0')\n",
      "sigma1 grad tensor([[-367.2296]], device='cuda:0')\n",
      "gamma grad tensor([[3331.6411]], device='cuda:0')\n",
      "alpha grad tensor([[-6458.7593]], device='cuda:0')\n",
      "beta2 grad tensor([[6115.2607]], device='cuda:0')\n",
      "beta0 grad tensor([3002.3867], device='cuda:0')\n",
      "beta1 grad tensor([[4052.9756]], device='cuda:0')\n",
      "Epoch 292 | Loss: 21.1166\n",
      "alpha: 0.07661803811788559, beta0: 0.11372165381908417, beta1: -0.000665930041577667, beta2: 0.003361497540026903, \n",
      "gamma: 0.06405218690633774, sigma0: 0.2669743001461029, sigma1: 0.0005610177759081125, sigma2: 0.00023552375205326825, sigmaX: 0.15502813458442688\n",
      "forward done\n",
      "tensor([0.0238, 0.2250, 0.1641, 0.6829, 0.3816], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.0620]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-361.6606]], device='cuda:0')\n",
      "sigma0 grad tensor([-433.6034], device='cuda:0')\n",
      "sigma1 grad tensor([[-363.4094]], device='cuda:0')\n",
      "gamma grad tensor([[3293.5715]], device='cuda:0')\n",
      "alpha grad tensor([[-6372.2178]], device='cuda:0')\n",
      "beta2 grad tensor([[5832.9883]], device='cuda:0')\n",
      "beta0 grad tensor([2962.3110], device='cuda:0')\n",
      "beta1 grad tensor([[3937.8289]], device='cuda:0')\n",
      "Epoch 293 | Loss: 23.7486\n",
      "alpha: 0.07674460113048553, beta0: 0.11365925520658493, beta1: -0.0007466796087101102, beta2: 0.003245783969759941, \n",
      "gamma: 0.06399042159318924, sigma0: 0.26698532700538635, sigma1: 0.0005701612099073827, sigma2: 0.0002446469443384558, sigmaX: 0.15502820909023285\n",
      "forward done\n",
      "tensor([0.0067, 0.0647, 0.2181, 0.6793, 0.3662], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.9451]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-285.9749]], device='cuda:0')\n",
      "sigma0 grad tensor([-311.8734], device='cuda:0')\n",
      "sigma1 grad tensor([[-265.8818]], device='cuda:0')\n",
      "gamma grad tensor([[1781.5566]], device='cuda:0')\n",
      "alpha grad tensor([[-3656.7903]], device='cuda:0')\n",
      "beta2 grad tensor([[3801.6140]], device='cuda:0')\n",
      "beta0 grad tensor([1794.9119], device='cuda:0')\n",
      "beta1 grad tensor([[2467.2683]], device='cuda:0')\n",
      "Epoch 294 | Loss: 7.7377\n",
      "alpha: 0.07688242197036743, beta0: 0.11359138786792755, beta1: -0.0008359519415535033, beta2: 0.003115196945145726, \n",
      "gamma: 0.0639231950044632, sigma0: 0.2669972777366638, sigma1: 0.0005801348015666008, sigma2: 0.00025480525800958276, sigmaX: 0.15502828359603882\n",
      "forward done\n",
      "tensor([0.0116, 0.0902, 0.3040, 0.6402, 0.3548], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[0.8151]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-474.2101]], device='cuda:0')\n",
      "sigma0 grad tensor([-493.6543], device='cuda:0')\n",
      "sigma1 grad tensor([[-421.3071]], device='cuda:0')\n",
      "gamma grad tensor([[4424.3188]], device='cuda:0')\n",
      "alpha grad tensor([[-8238.9209]], device='cuda:0')\n",
      "beta2 grad tensor([[8277.1152]], device='cuda:0')\n",
      "beta0 grad tensor([3720.7747], device='cuda:0')\n",
      "beta1 grad tensor([[5227.3413]], device='cuda:0')\n",
      "Epoch 295 | Loss: 10.3326\n",
      "alpha: 0.0770750641822815, beta0: 0.11349988728761673, beta1: -0.0009596432209946215, beta2: 0.00292795617133379, \n",
      "gamma: 0.06382516771554947, sigma0: 0.26701176166534424, sigma1: 0.000592326745390892, sigma2: 0.00026767401141114533, sigmaX: 0.1550283432006836\n",
      "forward done\n",
      "tensor([0.0153, 0.0430, 0.2482, 0.5978, 0.3581], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.8010]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-19.5163]], device='cuda:0')\n",
      "sigma0 grad tensor([2.1980], device='cuda:0')\n",
      "sigma1 grad tensor([[-7.3888]], device='cuda:0')\n",
      "gamma grad tensor([[-1098.3169]], device='cuda:0')\n",
      "alpha grad tensor([[1794.1122]], device='cuda:0')\n",
      "beta2 grad tensor([[-1509.8655]], device='cuda:0')\n",
      "beta0 grad tensor([-654.2554], device='cuda:0')\n",
      "beta1 grad tensor([[-937.1438]], device='cuda:0')\n",
      "Epoch 296 | Loss: 5.5220\n",
      "alpha: 0.07721123844385147, beta0: 0.11343322694301605, beta1: -0.0010492248693481088, beta2: 0.0027932622469961643, \n",
      "gamma: 0.06375773251056671, sigma0: 0.26702332496643066, sigma1: 0.0006021541776135564, sigma2: 0.00027816416695713997, sigmaX: 0.15502841770648956\n",
      "forward done\n",
      "tensor([0.0160, 0.1526, 0.3175, 0.5937, 0.3467], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-4.0824]]], device='cuda:0')\n",
      "sigma2 grad tensor([[619.0246]], device='cuda:0')\n",
      "sigma0 grad tensor([603.6064], device='cuda:0')\n",
      "sigma1 grad tensor([[551.2519]], device='cuda:0')\n",
      "gamma grad tensor([[-5887.4946]], device='cuda:0')\n",
      "alpha grad tensor([[10849.4023]], device='cuda:0')\n",
      "beta2 grad tensor([[-11453.5342]], device='cuda:0')\n",
      "beta0 grad tensor([-4859.1265], device='cuda:0')\n",
      "beta1 grad tensor([[-7083.4575]], device='cuda:0')\n",
      "Epoch 297 | Loss: 16.5317\n",
      "alpha: 0.07721168547868729, beta0: 0.11342848837375641, beta1: -0.0010500556090846658, beta2: 0.0028000425081700087, \n",
      "gamma: 0.06376265734434128, sigma0: 0.26702654361724854, sigma1: 0.0006045036134310067, sigma2: 0.0002803660463541746, sigmaX: 0.15502852201461792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0105, 0.0972, 0.2274, 0.6317, 0.3311], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.1785]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-506.1275]], device='cuda:0')\n",
      "sigma0 grad tensor([-521.7684], device='cuda:0')\n",
      "sigma1 grad tensor([[-454.1740]], device='cuda:0')\n",
      "gamma grad tensor([[4563.0376]], device='cuda:0')\n",
      "alpha grad tensor([[-8556.7529]], device='cuda:0')\n",
      "beta2 grad tensor([[8425.4355]], device='cuda:0')\n",
      "beta0 grad tensor([3886.3643], device='cuda:0')\n",
      "beta1 grad tensor([[5383.6885]], device='cuda:0')\n",
      "Epoch 298 | Loss: 10.9220\n",
      "alpha: 0.07729760557413101, beta0: 0.11338583379983902, beta1: -0.0011045570718124509, beta2: 0.002721212338656187, \n",
      "gamma: 0.06372096389532089, sigma0: 0.2670343518257141, sigma1: 0.0006109249079599977, sigma2: 0.00028718882822431624, sigmaX: 0.15502862632274628\n",
      "forward done\n",
      "tensor([0.0080, 0.0596, 0.0990, 0.6784, 0.4162], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.0639]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-527.7109]], device='cuda:0')\n",
      "sigma0 grad tensor([-545.3804], device='cuda:0')\n",
      "sigma1 grad tensor([[-478.7031]], device='cuda:0')\n",
      "gamma grad tensor([[4602.4697]], device='cuda:0')\n",
      "alpha grad tensor([[-8740.0342]], device='cuda:0')\n",
      "beta2 grad tensor([[8514.1172]], device='cuda:0')\n",
      "beta0 grad tensor([4007.7827], device='cuda:0')\n",
      "beta1 grad tensor([[5534.2095]], device='cuda:0')\n",
      "Epoch 299 | Loss: 7.1652\n",
      "alpha: 0.07745374739170074, beta0: 0.11331163346767426, beta1: -0.001203500316478312, beta2: 0.002573007019236684, \n",
      "gamma: 0.06364158540964127, sigma0: 0.2670460343360901, sigma1: 0.0006208489648997784, sigma2: 0.0002979241544380784, sigmaX: 0.15502873063087463\n",
      "forward done\n",
      "tensor([0.0124, 0.1169, 0.1843, 0.5990, 0.3430], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-4.4471]]], device='cuda:0')\n",
      "sigma2 grad tensor([[705.6607]], device='cuda:0')\n",
      "sigma0 grad tensor([623.1825], device='cuda:0')\n",
      "sigma1 grad tensor([[594.9392]], device='cuda:0')\n",
      "gamma grad tensor([[-4756.4834]], device='cuda:0')\n",
      "alpha grad tensor([[9214.8232]], device='cuda:0')\n",
      "beta2 grad tensor([[-10428.1221]], device='cuda:0')\n",
      "beta0 grad tensor([-4299.6270], device='cuda:0')\n",
      "beta1 grad tensor([[-6335.9048]], device='cuda:0')\n",
      "Epoch 300 | Loss: 12.8300\n",
      "alpha: 0.07748650759458542, beta0: 0.11329527199268341, beta1: -0.001219295896589756, beta2: 0.002558724023401737, \n",
      "gamma: 0.06362564861774445, sigma0: 0.2670491635799408, sigma1: 0.0006228387937881052, sigma2: 0.00029945580172352493, sigmaX: 0.15502884984016418\n",
      "forward done\n",
      "tensor([0.0050, 0.0333, 0.2294, 0.6471, 0.4114], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.5718]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-56.4805]], device='cuda:0')\n",
      "sigma0 grad tensor([-26.1300], device='cuda:0')\n",
      "sigma1 grad tensor([[-35.4918]], device='cuda:0')\n",
      "gamma grad tensor([[-1039.9553]], device='cuda:0')\n",
      "alpha grad tensor([[1634.4386]], device='cuda:0')\n",
      "beta2 grad tensor([[-1332.4735]], device='cuda:0')\n",
      "beta0 grad tensor([-557.9424], device='cuda:0')\n",
      "beta1 grad tensor([[-815.8456]], device='cuda:0')\n",
      "Epoch 301 | Loss: 4.6189\n",
      "alpha: 0.07749637216329575, beta0: 0.11328776180744171, beta1: -0.0012237739283591509, beta2: 0.002560622291639447, \n",
      "gamma: 0.06362330168485641, sigma0: 0.26705193519592285, sigma1: 0.0006247856072150171, sigma2: 0.0003012459201272577, sigmaX: 0.15502896904945374\n",
      "forward done\n",
      "tensor([0.0204, 0.2325, 0.4110, 0.5864, 0.4235], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[0.7494]]], device='cuda:0')\n",
      "sigma2 grad tensor([[752.7659]], device='cuda:0')\n",
      "sigma0 grad tensor([698.4494], device='cuda:0')\n",
      "sigma1 grad tensor([[641.6445]], device='cuda:0')\n",
      "gamma grad tensor([[-6281.7222]], device='cuda:0')\n",
      "alpha grad tensor([[11696.1494]], device='cuda:0')\n",
      "beta2 grad tensor([[-13179.0244]], device='cuda:0')\n",
      "beta0 grad tensor([-5296.9321], device='cuda:0')\n",
      "beta1 grad tensor([[-7871.3950]], device='cuda:0')\n",
      "Epoch 302 | Loss: 24.6919\n",
      "alpha: 0.07738730311393738, beta0: 0.11333472281694412, beta1: -0.0011486423900350928, beta2: 0.002693931106477976, \n",
      "gamma: 0.06368423998355865, sigma0: 0.2670471668243408, sigma1: 0.0006199266063049436, sigma2: 0.0002951503556687385, sigmaX: 0.1550290584564209\n",
      "forward done\n",
      "tensor([0.0153, 0.3031, 0.2919, 0.6190, 0.3500], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.7127]]], device='cuda:0')\n",
      "sigma2 grad tensor([[945.3403]], device='cuda:0')\n",
      "sigma0 grad tensor([705.4876], device='cuda:0')\n",
      "sigma1 grad tensor([[731.5229]], device='cuda:0')\n",
      "gamma grad tensor([[-6200.3042]], device='cuda:0')\n",
      "alpha grad tensor([[11613.2363]], device='cuda:0')\n",
      "beta2 grad tensor([[-14233.3477]], device='cuda:0')\n",
      "beta0 grad tensor([-5271.0361], device='cuda:0')\n",
      "beta1 grad tensor([[-8193.0781]], device='cuda:0')\n",
      "Epoch 303 | Loss: 31.5895\n",
      "alpha: 0.07718391716480255, beta0: 0.11342500150203705, beta1: -0.0010066063841804862, beta2: 0.002942911582067609, \n",
      "gamma: 0.06379499286413193, sigma0: 0.2670362889766693, sigma1: 0.0006087241927161813, sigma2: 0.0002808205026667565, sigmaX: 0.15502914786338806\n",
      "forward done\n",
      "tensor([0.0191, 0.0497, 0.1739, 0.6631, 0.3978], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.4252]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-182.4734]], device='cuda:0')\n",
      "sigma0 grad tensor([-167.9151], device='cuda:0')\n",
      "sigma1 grad tensor([[-156.6971]], device='cuda:0')\n",
      "gamma grad tensor([[518.5308]], device='cuda:0')\n",
      "alpha grad tensor([[-1226.2311]], device='cuda:0')\n",
      "beta2 grad tensor([[1611.1597]], device='cuda:0')\n",
      "beta0 grad tensor([696.7183], device='cuda:0')\n",
      "beta1 grad tensor([[1003.0554]], device='cuda:0')\n",
      "Epoch 304 | Loss: 6.2199\n",
      "alpha: 0.07703346759080887, beta0: 0.11349025368690491, beta1: -0.0009030080982483923, beta2: 0.0031259844545274973, \n",
      "gamma: 0.06387840956449509, sigma0: 0.2670292556285858, sigma1: 0.0006013292004354298, sigma2: 0.0002711813722271472, sigmaX: 0.15502923727035522\n",
      "forward done\n",
      "tensor([0.0172, 0.1425, 0.2205, 0.6732, 0.3844], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.1263]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-427.9852]], device='cuda:0')\n",
      "sigma0 grad tensor([-472.9650], device='cuda:0')\n",
      "sigma1 grad tensor([[-400.0025]], device='cuda:0')\n",
      "gamma grad tensor([[3835.4333]], device='cuda:0')\n",
      "alpha grad tensor([[-7349.9395]], device='cuda:0')\n",
      "beta2 grad tensor([[7146.9688]], device='cuda:0')\n",
      "beta0 grad tensor([3389.5056], device='cuda:0')\n",
      "beta1 grad tensor([[4644.9575]], device='cuda:0')\n",
      "Epoch 305 | Loss: 15.5498\n",
      "alpha: 0.07698661088943481, beta0: 0.11350855976343155, beta1: -0.0008665790664963424, beta2: 0.0032009731512516737, \n",
      "gamma: 0.06390678882598877, sigma0: 0.2670283615589142, sigma1: 0.0005994132370688021, sigma2: 0.0002677499142009765, sigmaX: 0.1550293266773224\n",
      "forward done\n",
      "tensor([0.0158, 0.0549, 0.1630, 0.6335, 0.3540], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.1350]]], device='cuda:0')\n",
      "sigma2 grad tensor([[54.7401]], device='cuda:0')\n",
      "sigma0 grad tensor([78.1839], device='cuda:0')\n",
      "sigma1 grad tensor([[60.6440]], device='cuda:0')\n",
      "gamma grad tensor([[-1486.6815]], device='cuda:0')\n",
      "alpha grad tensor([[2615.1533]], device='cuda:0')\n",
      "beta2 grad tensor([[-2537.8914]], device='cuda:0')\n",
      "beta0 grad tensor([-1057.8241], device='cuda:0')\n",
      "beta1 grad tensor([[-1552.0454]], device='cuda:0')\n",
      "Epoch 306 | Loss: 6.6575\n",
      "alpha: 0.07692297548055649, beta0: 0.11353378742933273, beta1: -0.0008219153969548643, beta2: 0.003286343067884445, \n",
      "gamma: 0.06394436210393906, sigma0: 0.2670268714427948, sigma1: 0.0005972740473225713, sigma2: 0.0002644573396537453, sigmaX: 0.15502941608428955\n",
      "forward done\n",
      "tensor([0.0074, 0.1050, 0.2778, 0.6199, 0.3552], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.6559]]], device='cuda:0')\n",
      "sigma2 grad tensor([[513.3704]], device='cuda:0')\n",
      "sigma0 grad tensor([541.9537], device='cuda:0')\n",
      "sigma1 grad tensor([[467.3377]], device='cuda:0')\n",
      "gamma grad tensor([[-4971.4487]], device='cuda:0')\n",
      "alpha grad tensor([[9273.1553]], device='cuda:0')\n",
      "beta2 grad tensor([[-9359.0029]], device='cuda:0')\n",
      "beta0 grad tensor([-4179.4009], device='cuda:0')\n",
      "beta1 grad tensor([[-5922.0894]], device='cuda:0')\n",
      "Epoch 307 | Loss: 11.7585\n",
      "alpha: 0.0767793357372284, beta0: 0.11359576135873795, beta1: -0.0007269635680131614, beta2: 0.0034482290502637625, \n",
      "gamma: 0.06402413547039032, sigma0: 0.26702025532722473, sigma1: 0.000590889307204634, sigma2: 0.000256689585512504, sigmaX: 0.15502949059009552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0077, 0.0549, 0.2689, 0.6274, 0.3686], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.6261]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-379.2750]], device='cuda:0')\n",
      "sigma0 grad tensor([-455.8493], device='cuda:0')\n",
      "sigma1 grad tensor([[-374.8159]], device='cuda:0')\n",
      "gamma grad tensor([[3499.3369]], device='cuda:0')\n",
      "alpha grad tensor([[-6713.6025]], device='cuda:0')\n",
      "beta2 grad tensor([[6475.6304]], device='cuda:0')\n",
      "beta0 grad tensor([3109.3164], device='cuda:0')\n",
      "beta1 grad tensor([[4244.8003]], device='cuda:0')\n",
      "Epoch 308 | Loss: 6.7664\n",
      "alpha: 0.07673155516386032, beta0: 0.11361424624919891, beta1: -0.0006934500997886062, beta2: 0.0035129813477396965, \n",
      "gamma: 0.06405296176671982, sigma0: 0.26701951026916504, sigma1: 0.0005895296926610172, sigma2: 0.0002542681177146733, sigmaX: 0.15502957999706268\n",
      "forward done\n",
      "tensor([0.0120, 0.1018, 0.1404, 0.6352, 0.3932], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.3225]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-393.7136]], device='cuda:0')\n",
      "sigma0 grad tensor([-488.4798], device='cuda:0')\n",
      "sigma1 grad tensor([[-396.3490]], device='cuda:0')\n",
      "gamma grad tensor([[4000.8931]], device='cuda:0')\n",
      "alpha grad tensor([[-7577.8359]], device='cuda:0')\n",
      "beta2 grad tensor([[7272.8218]], device='cuda:0')\n",
      "beta0 grad tensor([3461.7456], device='cuda:0')\n",
      "beta1 grad tensor([[4757.5264]], device='cuda:0')\n",
      "Epoch 309 | Loss: 11.3643\n",
      "alpha: 0.07676911354064941, beta0: 0.1135944202542305, beta1: -0.0007142145768739283, beta2: 0.003492054995149374, \n",
      "gamma: 0.06403601169586182, sigma0: 0.26702380180358887, sigma1: 0.000592405500356108, sigma2: 0.0002562680747359991, sigmaX: 0.15502966940402985\n",
      "forward done\n",
      "tensor([0.0152, 0.0847, 0.4646, 0.6128, 0.3446], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.9239]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-466.8494]], device='cuda:0')\n",
      "sigma0 grad tensor([-503.3478], device='cuda:0')\n",
      "sigma1 grad tensor([[-436.0488]], device='cuda:0')\n",
      "gamma grad tensor([[3712.0164]], device='cuda:0')\n",
      "alpha grad tensor([[-7198.8696]], device='cuda:0')\n",
      "beta2 grad tensor([[7191.1001]], device='cuda:0')\n",
      "beta0 grad tensor([3349.0728], device='cuda:0')\n",
      "beta1 grad tensor([[4631.3052]], device='cuda:0')\n",
      "Epoch 310 | Loss: 9.9057\n",
      "alpha: 0.07687114924192429, beta0: 0.11354506760835648, beta1: -0.0007771392120048404, beta2: 0.003403402864933014, \n",
      "gamma: 0.06398533284664154, sigma0: 0.267032265663147, sigma1: 0.0005990666104480624, sigma2: 0.0002625365450512618, sigmaX: 0.155029758810997\n",
      "forward done\n",
      "tensor([0.0127, 0.0756, 0.2527, 0.6391, 0.3654], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.8090]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-510.5987]], device='cuda:0')\n",
      "sigma0 grad tensor([-504.8320], device='cuda:0')\n",
      "sigma1 grad tensor([[-442.2073]], device='cuda:0')\n",
      "gamma grad tensor([[3974.0671]], device='cuda:0')\n",
      "alpha grad tensor([[-7603.1929]], device='cuda:0')\n",
      "beta2 grad tensor([[7676.4336]], device='cuda:0')\n",
      "beta0 grad tensor([3501.1182], device='cuda:0')\n",
      "beta1 grad tensor([[4897.9336]], device='cuda:0')\n",
      "Epoch 311 | Loss: 8.8306\n",
      "alpha: 0.07702881097793579, beta0: 0.11347057670354843, beta1: -0.0008764582453295588, beta2: 0.0032557169906795025, \n",
      "gamma: 0.06390504539012909, sigma0: 0.2670440971851349, sigma1: 0.0006088175578042865, sigma2: 0.00027265731478109956, sigmaX: 0.15502984821796417\n",
      "forward done\n",
      "tensor([0.0160, 0.1406, 0.1787, 0.6693, 0.4054], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.0478]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-347.9984]], device='cuda:0')\n",
      "sigma0 grad tensor([-488.0122], device='cuda:0')\n",
      "sigma1 grad tensor([[-378.8721]], device='cuda:0')\n",
      "gamma grad tensor([[3788.2712]], device='cuda:0')\n",
      "alpha grad tensor([[-7272.8560]], device='cuda:0')\n",
      "beta2 grad tensor([[6737.7275]], device='cuda:0')\n",
      "beta0 grad tensor([3368.9609], device='cuda:0')\n",
      "beta1 grad tensor([[4499.5469]], device='cuda:0')\n",
      "Epoch 312 | Loss: 15.3328\n",
      "alpha: 0.07722766697406769, beta0: 0.11337729543447495, beta1: -0.0010009089019149542, beta2: 0.003070191014558077, \n",
      "gamma: 0.06380293518304825, sigma0: 0.26705843210220337, sigma1: 0.0006204070523381233, sigma2: 0.00028423391631804407, sigmaX: 0.15502992272377014\n",
      "forward done\n",
      "tensor([0.0140, 0.2369, 0.2202, 0.6514, 0.3405], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.1544]]], device='cuda:0')\n",
      "sigma2 grad tensor([[789.7341]], device='cuda:0')\n",
      "sigma0 grad tensor([652.2324], device='cuda:0')\n",
      "sigma1 grad tensor([[636.1901]], device='cuda:0')\n",
      "gamma grad tensor([[-6139.0083]], device='cuda:0')\n",
      "alpha grad tensor([[11260.9014]], device='cuda:0')\n",
      "beta2 grad tensor([[-12590.3779]], device='cuda:0')\n",
      "beta0 grad tensor([-5036.9067], device='cuda:0')\n",
      "beta1 grad tensor([[-7504.1074]], device='cuda:0')\n",
      "Epoch 313 | Loss: 24.9198\n",
      "alpha: 0.0772741436958313, beta0: 0.11335303634405136, beta1: -0.001025428413413465, beta2: 0.003047673963010311, \n",
      "gamma: 0.06378263980150223, sigma0: 0.2670633792877197, sigma1: 0.0006233167368918657, sigma2: 0.00028559783822856843, sigmaX: 0.1550299972295761\n",
      "forward done\n",
      "tensor([0.0115, 0.1093, 0.2607, 0.6103, 0.3432], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-4.7918]]], device='cuda:0')\n",
      "sigma2 grad tensor([[716.7858]], device='cuda:0')\n",
      "sigma0 grad tensor([578.5769], device='cuda:0')\n",
      "sigma1 grad tensor([[566.9205]], device='cuda:0')\n",
      "gamma grad tensor([[-4843.1597]], device='cuda:0')\n",
      "alpha grad tensor([[9156.1836]], device='cuda:0')\n",
      "beta2 grad tensor([[-10577.5781]], device='cuda:0')\n",
      "beta0 grad tensor([-4175.4150], device='cuda:0')\n",
      "beta1 grad tensor([[-6260.3311]], device='cuda:0')\n",
      "Epoch 314 | Loss: 12.1558\n",
      "alpha: 0.07721976190805435, beta0: 0.11337538063526154, beta1: -0.0009824406588450074, beta2: 0.0031354359816759825, \n",
      "gamma: 0.06381483376026154, sigma0: 0.2670615613460541, sigma1: 0.0006199752679094672, sigma2: 0.0002795211330521852, sigmaX: 0.15503010153770447\n",
      "forward done\n",
      "tensor([0.0118, 0.0386, 0.3288, 0.6344, 0.3791], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.0480]]], device='cuda:0')\n",
      "sigma2 grad tensor([[101.1121]], device='cuda:0')\n",
      "sigma0 grad tensor([107.7690], device='cuda:0')\n",
      "sigma1 grad tensor([[93.0964]], device='cuda:0')\n",
      "gamma grad tensor([[-1877.5780]], device='cuda:0')\n",
      "alpha grad tensor([[3318.0642]], device='cuda:0')\n",
      "beta2 grad tensor([[-3098.6265]], device='cuda:0')\n",
      "beta0 grad tensor([-1370.8761], device='cuda:0')\n",
      "beta1 grad tensor([[-1946.7775]], device='cuda:0')\n",
      "Epoch 315 | Loss: 5.2171\n",
      "alpha: 0.07714307308197021, beta0: 0.1134069636464119, beta1: -0.0009285826818086207, beta2: 0.003236631862819195, \n",
      "gamma: 0.06385936588048935, sigma0: 0.2670590281486511, sigma1: 0.0006163711659610271, sigma2: 0.0002736486494541168, sigmaX: 0.15503020584583282\n",
      "forward done\n",
      "tensor([0.0160, 0.0554, 0.2431, 0.6305, 0.3372], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.9135]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-172.4290]], device='cuda:0')\n",
      "sigma0 grad tensor([-162.0247], device='cuda:0')\n",
      "sigma1 grad tensor([[-150.0031]], device='cuda:0')\n",
      "gamma grad tensor([[454.4114]], device='cuda:0')\n",
      "alpha grad tensor([[-1129.7074]], device='cuda:0')\n",
      "beta2 grad tensor([[1499.9856]], device='cuda:0')\n",
      "beta0 grad tensor([653.9219], device='cuda:0')\n",
      "beta1 grad tensor([[938.2397]], device='cuda:0')\n",
      "Epoch 316 | Loss: 6.7685\n",
      "alpha: 0.07709302008152008, beta0: 0.11342569440603256, beta1: -0.0008948786999098957, beta2: 0.003302588826045394, \n",
      "gamma: 0.06389044225215912, sigma0: 0.2670586109161377, sigma1: 0.0006149879191070795, sigma2: 0.0002706749364733696, sigmaX: 0.1550302952528\n",
      "forward done\n",
      "tensor([0.0103, 0.0461, 0.2606, 0.6169, 0.3490], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.3497]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-58.4412]], device='cuda:0')\n",
      "sigma0 grad tensor([-40.3568], device='cuda:0')\n",
      "sigma1 grad tensor([[-44.5316]], device='cuda:0')\n",
      "gamma grad tensor([[-717.9976]], device='cuda:0')\n",
      "alpha grad tensor([[1064.1619]], device='cuda:0')\n",
      "beta2 grad tensor([[-713.3890]], device='cuda:0')\n",
      "beta0 grad tensor([-322.5958], device='cuda:0')\n",
      "beta1 grad tensor([[-454.2397]], device='cuda:0')\n",
      "Epoch 317 | Loss: 5.8430\n",
      "alpha: 0.07704233378171921, beta0: 0.11344390362501144, beta1: -0.0008633731049485505, beta2: 0.0033624882344156504, \n",
      "gamma: 0.06392248719930649, sigma0: 0.26705870032310486, sigma1: 0.0006143266218714416, sigma2: 0.0002688803942874074, sigmaX: 0.15503038465976715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0083, 0.0593, 0.2787, 0.6080, 0.3730], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.1448]]], device='cuda:0')\n",
      "sigma2 grad tensor([[373.3269]], device='cuda:0')\n",
      "sigma0 grad tensor([412.3091], device='cuda:0')\n",
      "sigma1 grad tensor([[342.1419]], device='cuda:0')\n",
      "gamma grad tensor([[-3776.8154]], device='cuda:0')\n",
      "alpha grad tensor([[7067.1191]], device='cuda:0')\n",
      "beta2 grad tensor([[-7080.7759]], device='cuda:0')\n",
      "beta0 grad tensor([-3176.6423], device='cuda:0')\n",
      "beta1 grad tensor([[-4465.3071]], device='cuda:0')\n",
      "Epoch 318 | Loss: 7.1979\n",
      "alpha: 0.07693111896514893, beta0: 0.11349023878574371, beta1: -0.000793515588156879, beta2: 0.003481215564534068, \n",
      "gamma: 0.06398589164018631, sigma0: 0.26705464720726013, sigma1: 0.0006103761843405664, sigma2: 0.0002637114957906306, sigmaX: 0.15503047406673431\n",
      "forward done\n",
      "tensor([0.0180, 0.1423, 0.1734, 0.6729, 0.3914], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.2819]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-469.5040]], device='cuda:0')\n",
      "sigma0 grad tensor([-468.8323], device='cuda:0')\n",
      "sigma1 grad tensor([[-418.0266]], device='cuda:0')\n",
      "gamma grad tensor([[3597.4678]], device='cuda:0')\n",
      "alpha grad tensor([[-6907.7212]], device='cuda:0')\n",
      "beta2 grad tensor([[7026.1748]], device='cuda:0')\n",
      "beta0 grad tensor([3188.7412], device='cuda:0')\n",
      "beta1 grad tensor([[4476.8975]], device='cuda:0')\n",
      "Epoch 319 | Loss: 15.4833\n",
      "alpha: 0.07691121846437454, beta0: 0.11349541693925858, beta1: -0.0007823985652066767, beta2: 0.0035059356596320868, \n",
      "gamma: 0.06400063633918762, sigma0: 0.26705607771873474, sigma1: 0.0006113960989750922, sigma2: 0.0002642713952809572, sigmaX: 0.15503056347370148\n",
      "forward done\n",
      "tensor([0.0090, 0.0299, 0.1767, 0.6428, 0.3731], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.9072]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-164.9053]], device='cuda:0')\n",
      "sigma0 grad tensor([-157.4200], device='cuda:0')\n",
      "sigma1 grad tensor([[-143.7949]], device='cuda:0')\n",
      "gamma grad tensor([[209.9188]], device='cuda:0')\n",
      "alpha grad tensor([[-727.5651]], device='cuda:0')\n",
      "beta2 grad tensor([[1105.6625]], device='cuda:0')\n",
      "beta0 grad tensor([502.2970], device='cuda:0')\n",
      "beta1 grad tensor([[706.3264]], device='cuda:0')\n",
      "Epoch 320 | Loss: 4.1893\n",
      "alpha: 0.07690257579088211, beta0: 0.11349453777074814, beta1: -0.0007805681671015918, beta2: 0.003514655167236924, \n",
      "gamma: 0.06401033699512482, sigma0: 0.267058789730072, sigma1: 0.0006136499578133225, sigma2: 0.0002663683844730258, sigmaX: 0.15503065288066864\n",
      "forward done\n",
      "tensor([0.0105, 0.0432, 0.2250, 0.6106, 0.3465], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.0025]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-42.6015]], device='cuda:0')\n",
      "sigma0 grad tensor([-20.4987], device='cuda:0')\n",
      "sigma1 grad tensor([[-28.7263]], device='cuda:0')\n",
      "gamma grad tensor([[-924.3470]], device='cuda:0')\n",
      "alpha grad tensor([[1457.6073]], device='cuda:0')\n",
      "beta2 grad tensor([[-1079.3723]], device='cuda:0')\n",
      "beta0 grad tensor([-494.5059], device='cuda:0')\n",
      "beta1 grad tensor([[-688.8234]], device='cuda:0')\n",
      "Epoch 321 | Loss: 5.5153\n",
      "alpha: 0.07688108831644058, beta0: 0.11349877715110779, beta1: -0.0007722156587988138, beta2: 0.003532424569129944, \n",
      "gamma: 0.064027339220047, sigma0: 0.26706117391586304, sigma1: 0.000615740311332047, sigma2: 0.00026847198023460805, sigmaX: 0.1550307422876358\n",
      "forward done\n",
      "tensor([0.0091, 0.1361, 0.1982, 0.6816, 0.4156], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[0.0236]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-284.1328]], device='cuda:0')\n",
      "sigma0 grad tensor([-466.8026], device='cuda:0')\n",
      "sigma1 grad tensor([[-344.6113]], device='cuda:0')\n",
      "gamma grad tensor([[3859.6216]], device='cuda:0')\n",
      "alpha grad tensor([[-7355.3237]], device='cuda:0')\n",
      "beta2 grad tensor([[6496.3511]], device='cuda:0')\n",
      "beta0 grad tensor([3388.8130], device='cuda:0')\n",
      "beta1 grad tensor([[4442.9810]], device='cuda:0')\n",
      "Epoch 322 | Loss: 14.9173\n",
      "alpha: 0.07693745195865631, beta0: 0.11346828192472458, beta1: -0.0008099634433165193, beta2: 0.0034816765692085028, \n",
      "gamma: 0.06400234252214432, sigma0: 0.2670677602291107, sigma1: 0.0006208586855791509, sigma2: 0.00027299619978293777, sigmaX: 0.15503081679344177\n",
      "forward done\n",
      "tensor([0.0224, 0.1550, 0.1607, 0.6586, 0.3900], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.1195]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-419.4377]], device='cuda:0')\n",
      "sigma0 grad tensor([-462.0373], device='cuda:0')\n",
      "sigma1 grad tensor([[-388.2448]], device='cuda:0')\n",
      "gamma grad tensor([[3442.0537]], device='cuda:0')\n",
      "alpha grad tensor([[-6720.7686]], device='cuda:0')\n",
      "beta2 grad tensor([[6589.6040]], device='cuda:0')\n",
      "beta0 grad tensor([3136.8164], device='cuda:0')\n",
      "beta1 grad tensor([[4287.3662]], device='cuda:0')\n",
      "Epoch 323 | Loss: 16.7330\n",
      "alpha: 0.07704974710941315, beta0: 0.1134125217795372, beta1: -0.0008830353035591543, beta2: 0.0033751821611076593, \n",
      "gamma: 0.06394792348146439, sigma0: 0.26707765460014343, sigma1: 0.0006288358708843589, sigma2: 0.0002808099379763007, sigmaX: 0.15503089129924774\n",
      "forward done\n",
      "tensor([0.0107, 0.0444, 0.0967, 0.6527, 0.4039], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.9071]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-197.2968]], device='cuda:0')\n",
      "sigma0 grad tensor([-210.9811], device='cuda:0')\n",
      "sigma1 grad tensor([[-181.7202]], device='cuda:0')\n",
      "gamma grad tensor([[909.5732]], device='cuda:0')\n",
      "alpha grad tensor([[-1959.3936]], device='cuda:0')\n",
      "beta2 grad tensor([[2242.9648]], device='cuda:0')\n",
      "beta0 grad tensor([1024.8708], device='cuda:0')\n",
      "beta1 grad tensor([[1433.7062]], device='cuda:0')\n",
      "Epoch 324 | Loss: 5.6070\n",
      "alpha: 0.07715918123722076, beta0: 0.11335766315460205, beta1: -0.0009558298625051975, beta2: 0.003267556894570589, \n",
      "gamma: 0.06389529258012772, sigma0: 0.2670876681804657, sigma1: 0.0006370348273776472, sigma2: 0.00028903389465995133, sigmaX: 0.1550309807062149\n",
      "forward done\n",
      "tensor([0.0152, 0.1020, 0.2677, 0.6211, 0.3457], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.5330]]], device='cuda:0')\n",
      "sigma2 grad tensor([[632.8376]], device='cuda:0')\n",
      "sigma0 grad tensor([542.9419], device='cuda:0')\n",
      "sigma1 grad tensor([[529.1597]], device='cuda:0')\n",
      "gamma grad tensor([[-4676.7441]], device='cuda:0')\n",
      "alpha grad tensor([[8809.9941]], device='cuda:0')\n",
      "beta2 grad tensor([[-9687.5918]], device='cuda:0')\n",
      "beta0 grad tensor([-4004.2666], device='cuda:0')\n",
      "beta1 grad tensor([[-5904.3760]], device='cuda:0')\n",
      "Epoch 325 | Loss: 11.4478\n",
      "alpha: 0.07715862989425659, beta0: 0.11335381865501404, beta1: -0.0009550217655487359, beta2: 0.003278332529589534, \n",
      "gamma: 0.06389995664358139, sigma0: 0.2670902609825134, sigma1: 0.0006383023574016988, sigma2: 0.000289284682366997, sigmaX: 0.15503107011318207\n",
      "forward done\n",
      "tensor([0.0133, 0.0639, 0.1689, 0.6249, 0.3772], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.5315]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-252.9103]], device='cuda:0')\n",
      "sigma0 grad tensor([-243.9847], device='cuda:0')\n",
      "sigma1 grad tensor([[-220.6884]], device='cuda:0')\n",
      "gamma grad tensor([[1281.7828]], device='cuda:0')\n",
      "alpha grad tensor([[-2662.8481]], device='cuda:0')\n",
      "beta2 grad tensor([[2932.5115]], device='cuda:0')\n",
      "beta0 grad tensor([1331.5549], device='cuda:0')\n",
      "beta1 grad tensor([[1866.1277]], device='cuda:0')\n",
      "Epoch 326 | Loss: 7.5700\n",
      "alpha: 0.07718481123447418, beta0: 0.1133374273777008, beta1: -0.0009730365709401667, beta2: 0.0032576280646026134, \n",
      "gamma: 0.06389086693525314, sigma0: 0.26709476113319397, sigma1: 0.0006415232783183455, sigma2: 0.00029201441793702543, sigmaX: 0.15503115952014923\n",
      "forward done\n",
      "tensor([0.0124, 0.0558, 0.4035, 0.6388, 0.3455], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.4335]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-258.6523]], device='cuda:0')\n",
      "sigma0 grad tensor([-246.1923], device='cuda:0')\n",
      "sigma1 grad tensor([[-223.4188]], device='cuda:0')\n",
      "gamma grad tensor([[1290.4979]], device='cuda:0')\n",
      "alpha grad tensor([[-2685.4854]], device='cuda:0')\n",
      "beta2 grad tensor([[3032.7214]], device='cuda:0')\n",
      "beta0 grad tensor([1344.8611], device='cuda:0')\n",
      "beta1 grad tensor([[1902.7144]], device='cuda:0')\n",
      "Epoch 327 | Loss: 6.9768\n",
      "alpha: 0.07723261415958405, beta0: 0.11331086605787277, beta1: -0.0010064755333587527, beta2: 0.0032107371371239424, \n",
      "gamma: 0.06387069076299667, sigma0: 0.26710084080696106, sigma1: 0.0006463341997005045, sigma2: 0.0002967847394756973, sigmaX: 0.1550312489271164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0160, 0.1262, 0.4626, 0.5583, 0.2808], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.9537]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-447.6938]], device='cuda:0')\n",
      "sigma0 grad tensor([-487.5889], device='cuda:0')\n",
      "sigma1 grad tensor([[-412.1697]], device='cuda:0')\n",
      "gamma grad tensor([[3694.6514]], device='cuda:0')\n",
      "alpha grad tensor([[-7157.0493]], device='cuda:0')\n",
      "beta2 grad tensor([[7268.2783]], device='cuda:0')\n",
      "beta0 grad tensor([3332.8745], device='cuda:0')\n",
      "beta1 grad tensor([[4625.1138]], device='cuda:0')\n",
      "Epoch 328 | Loss: 13.9381\n",
      "alpha: 0.0773424282670021, beta0: 0.1132562905550003, beta1: -0.0010794778354465961, beta2: 0.003100541653111577, \n",
      "gamma: 0.06381760537624359, sigma0: 0.26711055636405945, sigma1: 0.0006543046329170465, sigma2: 0.00030507793417200446, sigmaX: 0.15503133833408356\n",
      "forward done\n",
      "tensor([0.0089, 0.0487, 0.1008, 0.6629, 0.3907], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.3933]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-89.7383]], device='cuda:0')\n",
      "sigma0 grad tensor([-60.1818], device='cuda:0')\n",
      "sigma1 grad tensor([[-66.6821]], device='cuda:0')\n",
      "gamma grad tensor([[-547.9108]], device='cuda:0')\n",
      "alpha grad tensor([[745.5684]], device='cuda:0')\n",
      "beta2 grad tensor([[-361.4183]], device='cuda:0')\n",
      "beta0 grad tensor([-179.5374], device='cuda:0')\n",
      "beta1 grad tensor([[-240.5563]], device='cuda:0')\n",
      "Epoch 329 | Loss: 6.0311\n",
      "alpha: 0.07742282003164291, beta0: 0.11321442574262619, beta1: -0.001135474187321961, beta2: 0.003015999449416995, \n",
      "gamma: 0.06378061324357986, sigma0: 0.2671189308166504, sigma1: 0.000661347818095237, sigma2: 0.00031260985997505486, sigmaX: 0.15503142774105072\n",
      "forward done\n",
      "tensor([0.0122, 0.0368, 0.1991, 0.6467, 0.3625], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.2396]]], device='cuda:0')\n",
      "sigma2 grad tensor([[500.7603]], device='cuda:0')\n",
      "sigma0 grad tensor([454.7005], device='cuda:0')\n",
      "sigma1 grad tensor([[434.0974]], device='cuda:0')\n",
      "gamma grad tensor([[-3966.8838]], device='cuda:0')\n",
      "alpha grad tensor([[7519.2275]], device='cuda:0')\n",
      "beta2 grad tensor([[-8211.0498]], device='cuda:0')\n",
      "beta0 grad tensor([-3419.7107], device='cuda:0')\n",
      "beta1 grad tensor([[-5023.2500]], device='cuda:0')\n",
      "Epoch 330 | Loss: 4.9000\n",
      "alpha: 0.0774119421839714, beta0: 0.1132151260972023, beta1: -0.0011300387559458613, beta2: 0.0030304761603474617, \n",
      "gamma: 0.0637906938791275, sigma0: 0.2671211063861847, sigma1: 0.000662641366943717, sigma2: 0.0003136277955491096, sigmaX: 0.15503151714801788\n",
      "forward done\n",
      "tensor([0.0140, 0.1631, 0.1874, 0.6806, 0.3902], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.6811]]], device='cuda:0')\n",
      "sigma2 grad tensor([[494.1730]], device='cuda:0')\n",
      "sigma0 grad tensor([605.0350], device='cuda:0')\n",
      "sigma1 grad tensor([[505.9374]], device='cuda:0')\n",
      "gamma grad tensor([[-5673.0884]], device='cuda:0')\n",
      "alpha grad tensor([[10548.5107]], device='cuda:0')\n",
      "beta2 grad tensor([[-10843.1309]], device='cuda:0')\n",
      "beta0 grad tensor([-4758.7310], device='cuda:0')\n",
      "beta1 grad tensor([[-6809.0845]], device='cuda:0')\n",
      "Epoch 331 | Loss: 17.5871\n",
      "alpha: 0.07729775458574295, beta0: 0.11326327919960022, beta1: -0.0010575995547696948, beta2: 0.0031504889484494925, \n",
      "gamma: 0.06385548412799835, sigma0: 0.2671167850494385, sigma1: 0.000658616831060499, sigma2: 0.0003095004358328879, sigmaX: 0.15503162145614624\n",
      "forward done\n",
      "tensor([0.0084, 0.0635, 0.4550, 0.6170, 0.3604], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.0601]]], device='cuda:0')\n",
      "sigma2 grad tensor([[497.3557]], device='cuda:0')\n",
      "sigma0 grad tensor([543.9927], device='cuda:0')\n",
      "sigma1 grad tensor([[474.2112]], device='cuda:0')\n",
      "gamma grad tensor([[-4588.3750]], device='cuda:0')\n",
      "alpha grad tensor([[8736.4121]], device='cuda:0')\n",
      "beta2 grad tensor([[-8748.9209]], device='cuda:0')\n",
      "beta0 grad tensor([-4004.0452], device='cuda:0')\n",
      "beta1 grad tensor([[-5601.4478]], device='cuda:0')\n",
      "Epoch 332 | Loss: 7.7861\n",
      "alpha: 0.07711904495954514, beta0: 0.11334183812141418, beta1: -0.0009436337277293205, beta2: 0.003333988366648555, \n",
      "gamma: 0.06395319849252701, sigma0: 0.26710787415504456, sigma1: 0.000650655128993094, sigma2: 0.0003012249944731593, sigmaX: 0.1550317257642746\n",
      "forward done\n",
      "tensor([0.0168, 0.1473, 0.1173, 0.6617, 0.4050], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.8773]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-397.9370]], device='cuda:0')\n",
      "sigma0 grad tensor([-475.7325], device='cuda:0')\n",
      "sigma1 grad tensor([[-395.4468]], device='cuda:0')\n",
      "gamma grad tensor([[3424.0659]], device='cuda:0')\n",
      "alpha grad tensor([[-6750.1934]], device='cuda:0')\n",
      "beta2 grad tensor([[6561.2358]], device='cuda:0')\n",
      "beta0 grad tensor([3179.0962], device='cuda:0')\n",
      "beta1 grad tensor([[4327.1704]], device='cuda:0')\n",
      "Epoch 333 | Loss: 15.9325\n",
      "alpha: 0.0770435780286789, beta0: 0.11337289214134216, beta1: -0.000895732722710818, beta2: 0.0034151754807680845, \n",
      "gamma: 0.06399713456630707, sigma0: 0.2671055197715759, sigma1: 0.000648240209557116, sigma2: 0.00029858399648219347, sigmaX: 0.15503183007240295\n",
      "forward done\n",
      "tensor([0.0073, 0.0688, 0.1882, 0.6959, 0.4242], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.1529]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-168.1460]], device='cuda:0')\n",
      "sigma0 grad tensor([-196.9422], device='cuda:0')\n",
      "sigma1 grad tensor([[-166.0304]], device='cuda:0')\n",
      "gamma grad tensor([[852.2469]], device='cuda:0')\n",
      "alpha grad tensor([[-1877.4155]], device='cuda:0')\n",
      "beta2 grad tensor([[1976.7775]], device='cuda:0')\n",
      "beta0 grad tensor([982.9849], device='cuda:0')\n",
      "beta1 grad tensor([[1325.9418]], device='cuda:0')\n",
      "Epoch 334 | Loss: 8.1918\n",
      "alpha: 0.07700197398662567, beta0: 0.11338790506124496, beta1: -0.0008706713560968637, beta2: 0.003460357431322336, \n",
      "gamma: 0.06402375549077988, sigma0: 0.2671056091785431, sigma1: 0.0006479685544036329, sigma2: 0.0002981526486109942, sigmaX: 0.1550319343805313\n",
      "forward done\n",
      "tensor([0.0130, 0.0537, 0.2199, 0.6994, 0.4086], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.9054]]], device='cuda:0')\n",
      "sigma2 grad tensor([[244.0185]], device='cuda:0')\n",
      "sigma0 grad tensor([276.6149], device='cuda:0')\n",
      "sigma1 grad tensor([[239.1712]], device='cuda:0')\n",
      "gamma grad tensor([[-2670.8801]], device='cuda:0')\n",
      "alpha grad tensor([[5021.8677]], device='cuda:0')\n",
      "beta2 grad tensor([[-5033.4854]], device='cuda:0')\n",
      "beta0 grad tensor([-2230.9739], device='cuda:0')\n",
      "beta1 grad tensor([[-3178.4414]], device='cuda:0')\n",
      "Epoch 335 | Loss: 6.7077\n",
      "alpha: 0.07691847532987595, beta0: 0.11342222988605499, beta1: -0.0008188378415070474, beta2: 0.0035468379501253366, \n",
      "gamma: 0.06407176703214645, sigma0: 0.2671028971672058, sigma1: 0.0006453595124185085, sigma2: 0.00029536738293245435, sigmaX: 0.15503203868865967\n",
      "forward done\n",
      "tensor([0.0265, 0.2540, 0.1055, 0.6950, 0.4124], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.5291]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-306.8681]], device='cuda:0')\n",
      "sigma0 grad tensor([-414.3907], device='cuda:0')\n",
      "sigma1 grad tensor([[-332.0606]], device='cuda:0')\n",
      "gamma grad tensor([[3217.9153]], device='cuda:0')\n",
      "alpha grad tensor([[-6192.5591]], device='cuda:0')\n",
      "beta2 grad tensor([[5748.3438]], device='cuda:0')\n",
      "beta0 grad tensor([2864.9409], device='cuda:0')\n",
      "beta1 grad tensor([[3849.1030]], device='cuda:0')\n",
      "Epoch 336 | Loss: 26.6372\n",
      "alpha: 0.07691360265016556, beta0: 0.11342103779315948, beta1: -0.0008158620912581682, beta2: 0.003558538854122162, \n",
      "gamma: 0.06407799571752548, sigma0: 0.2671048939228058, sigma1: 0.0006465929327532649, sigma2: 0.00029620787245221436, sigmaX: 0.15503212809562683\n",
      "forward done\n",
      "tensor([0.0061, 0.0546, 0.1557, 0.6778, 0.3845], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.6433]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-201.9359]], device='cuda:0')\n",
      "sigma0 grad tensor([-204.7419], device='cuda:0')\n",
      "sigma1 grad tensor([[-182.9830]], device='cuda:0')\n",
      "gamma grad tensor([[781.2650]], device='cuda:0')\n",
      "alpha grad tensor([[-1776.8668]], device='cuda:0')\n",
      "beta2 grad tensor([[2050.3315]], device='cuda:0')\n",
      "beta0 grad tensor([952.4343], device='cuda:0')\n",
      "beta1 grad tensor([[1322.9548]], device='cuda:0')\n",
      "Epoch 337 | Loss: 6.6886\n",
      "alpha: 0.07692747563123703, beta0: 0.11341056227684021, beta1: -0.000826711009722203, beta2: 0.0035473962780088186, \n",
      "gamma: 0.06407516449689865, sigma0: 0.2671085298061371, sigma1: 0.0006494094850495458, sigma2: 0.00029889962752349675, sigmaX: 0.155032217502594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0126, 0.0728, 0.1653, 0.6677, 0.3870], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.4021]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-219.9544]], device='cuda:0')\n",
      "sigma0 grad tensor([-232.0465], device='cuda:0')\n",
      "sigma1 grad tensor([[-203.1824]], device='cuda:0')\n",
      "gamma grad tensor([[1225.1775]], device='cuda:0')\n",
      "alpha grad tensor([[-2557.3308]], device='cuda:0')\n",
      "beta2 grad tensor([[2803.1758]], device='cuda:0')\n",
      "beta0 grad tensor([1276.8389], device='cuda:0')\n",
      "beta1 grad tensor([[1794.7219]], device='cuda:0')\n",
      "Epoch 338 | Loss: 8.5125\n",
      "alpha: 0.07696414738893509, beta0: 0.11338941007852554, beta1: -0.0008533373475074768, beta2: 0.003510450478643179, \n",
      "gamma: 0.06406065076589584, sigma0: 0.26711374521255493, sigma1: 0.0006536945584230125, sigma2: 0.0003032525710295886, sigmaX: 0.15503230690956116\n",
      "forward done\n",
      "tensor([0.0158, 0.0496, 0.1088, 0.7044, 0.3965], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.6230]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-160.5450]], device='cuda:0')\n",
      "sigma0 grad tensor([-144.4716], device='cuda:0')\n",
      "sigma1 grad tensor([[-136.7206]], device='cuda:0')\n",
      "gamma grad tensor([[268.8148]], device='cuda:0')\n",
      "alpha grad tensor([[-778.9445]], device='cuda:0')\n",
      "beta2 grad tensor([[1101.5071]], device='cuda:0')\n",
      "beta0 grad tensor([498.3204], device='cuda:0')\n",
      "beta1 grad tensor([[701.8688]], device='cuda:0')\n",
      "Epoch 339 | Loss: 6.1825\n",
      "alpha: 0.07700127363204956, beta0: 0.11336750537157059, beta1: -0.0008816571207717061, beta2: 0.0034698788076639175, \n",
      "gamma: 0.06404635310173035, sigma0: 0.2671193778514862, sigma1: 0.0006584898219443858, sigma2: 0.0003083403571508825, sigmaX: 0.15503239631652832\n",
      "forward done\n",
      "tensor([0.0169, 0.1223, 0.3131, 0.6620, 0.4024], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.0416]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-421.1573]], device='cuda:0')\n",
      "sigma0 grad tensor([-478.2354], device='cuda:0')\n",
      "sigma1 grad tensor([[-404.5852]], device='cuda:0')\n",
      "gamma grad tensor([[3600.0190]], device='cuda:0')\n",
      "alpha grad tensor([[-7008.8628]], device='cuda:0')\n",
      "beta2 grad tensor([[6988.4902]], device='cuda:0')\n",
      "beta0 grad tensor([3264.4644], device='cuda:0')\n",
      "beta1 grad tensor([[4517.2930]], device='cuda:0')\n",
      "Epoch 340 | Loss: 13.6237\n",
      "alpha: 0.07710105925798416, beta0: 0.1133173406124115, beta1: -0.0009494858677498996, beta2: 0.0033675364684313536, \n",
      "gamma: 0.06399891525506973, sigma0: 0.26712867617607117, sigma1: 0.0006663718959316611, sigma2: 0.0003166221722494811, sigmaX: 0.15503248572349548\n",
      "forward done\n",
      "tensor([0.0185, 0.0866, 0.1685, 0.6389, 0.3720], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.5818]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-467.6138]], device='cuda:0')\n",
      "sigma0 grad tensor([-505.8291], device='cuda:0')\n",
      "sigma1 grad tensor([[-430.6927]], device='cuda:0')\n",
      "gamma grad tensor([[3850.1111]], device='cuda:0')\n",
      "alpha grad tensor([[-7420.3325]], device='cuda:0')\n",
      "beta2 grad tensor([[7496.6079]], device='cuda:0')\n",
      "beta0 grad tensor([3444.3132], device='cuda:0')\n",
      "beta1 grad tensor([[4789.7637]], device='cuda:0')\n",
      "Epoch 341 | Loss: 9.8625\n",
      "alpha: 0.07725509256124496, beta0: 0.11324276030063629, beta1: -0.0010516465408727527, beta2: 0.0032106966245919466, \n",
      "gamma: 0.0639224648475647, sigma0: 0.2671411633491516, sigma1: 0.0006769844912923872, sigma2: 0.0003279237716924399, sigmaX: 0.15503259003162384\n",
      "forward done\n",
      "tensor([0.0112, 0.1070, 0.1956, 0.6872, 0.3902], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.0399]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-407.9805]], device='cuda:0')\n",
      "sigma0 grad tensor([-489.5516], device='cuda:0')\n",
      "sigma1 grad tensor([[-407.4818]], device='cuda:0')\n",
      "gamma grad tensor([[4186.1216]], device='cuda:0')\n",
      "alpha grad tensor([[-7929.9648]], device='cuda:0')\n",
      "beta2 grad tensor([[7733.0796]], device='cuda:0')\n",
      "beta0 grad tensor([3626.1685], device='cuda:0')\n",
      "beta1 grad tensor([[5007.6899]], device='cuda:0')\n",
      "Epoch 342 | Loss: 11.9862\n",
      "alpha: 0.07745762169361115, beta0: 0.1131468340754509, beta1: -0.0011834519682452083, beta2: 0.003007893916219473, \n",
      "gamma: 0.06381943821907043, sigma0: 0.26715603470802307, sigma1: 0.0006895493716001511, sigma2: 0.00034104485530406237, sigmaX: 0.1550326943397522\n",
      "forward done\n",
      "tensor([0.0221, 0.2648, 0.2471, 0.5679, 0.4233], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[1.5175]]], device='cuda:0')\n",
      "sigma2 grad tensor([[814.2923]], device='cuda:0')\n",
      "sigma0 grad tensor([678.5300], device='cuda:0')\n",
      "sigma1 grad tensor([[658.0184]], device='cuda:0')\n",
      "gamma grad tensor([[-6310.1045]], device='cuda:0')\n",
      "alpha grad tensor([[11670.5420]], device='cuda:0')\n",
      "beta2 grad tensor([[-12982.3506]], device='cuda:0')\n",
      "beta0 grad tensor([-5246.2041], device='cuda:0')\n",
      "beta1 grad tensor([[-7801.2944]], device='cuda:0')\n",
      "Epoch 343 | Loss: 27.7400\n",
      "alpha: 0.07750293612480164, beta0: 0.11312256008386612, beta1: -0.0012108833761885762, beta2: 0.002975475275889039, \n",
      "gamma: 0.06380011886358261, sigma0: 0.26716116070747375, sigma1: 0.0006930211093276739, sigma2: 0.00034339880221523345, sigmaX: 0.15503275394439697\n",
      "forward done\n",
      "tensor([0.0136, 0.0841, 0.1527, 0.6849, 0.3449], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.2406]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-541.1948]], device='cuda:0')\n",
      "sigma0 grad tensor([-514.8821], device='cuda:0')\n",
      "sigma1 grad tensor([[-460.5255]], device='cuda:0')\n",
      "gamma grad tensor([[3775.7673]], device='cuda:0')\n",
      "alpha grad tensor([[-7400.1191]], device='cuda:0')\n",
      "beta2 grad tensor([[8088.8418]], device='cuda:0')\n",
      "beta0 grad tensor([3474.2190], device='cuda:0')\n",
      "beta1 grad tensor([[4991.0122]], device='cuda:0')\n",
      "Epoch 344 | Loss: 9.6067\n",
      "alpha: 0.07761318981647491, beta0: 0.11306839436292648, beta1: -0.0012827386381104589, beta2: 0.0028686518780887127, \n",
      "gamma: 0.06374690681695938, sigma0: 0.26717039942741394, sigma1: 0.0007004037615843117, sigma2: 0.0003506939101498574, sigmaX: 0.15503282845020294\n",
      "forward done\n",
      "tensor([0.0072, 0.0812, 0.1941, 0.6402, 0.3762], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.6637]]], device='cuda:0')\n",
      "sigma2 grad tensor([[492.7842]], device='cuda:0')\n",
      "sigma0 grad tensor([525.1292], device='cuda:0')\n",
      "sigma1 grad tensor([[454.4317]], device='cuda:0')\n",
      "gamma grad tensor([[-5163.5557]], device='cuda:0')\n",
      "alpha grad tensor([[9555.1914]], device='cuda:0')\n",
      "beta2 grad tensor([[-9990.7188]], device='cuda:0')\n",
      "beta0 grad tensor([-4278.3188], device='cuda:0')\n",
      "beta1 grad tensor([[-6159.4561]], device='cuda:0')\n",
      "Epoch 345 | Loss: 9.3332\n",
      "alpha: 0.07760584354400635, beta0: 0.11306785047054291, beta1: -0.0012786282459273934, beta2: 0.0028831004165112972, \n",
      "gamma: 0.06375597417354584, sigma0: 0.26717254519462585, sigma1: 0.0007017655298113823, sigma2: 0.0003516021533869207, sigmaX: 0.1550329178571701\n",
      "forward done\n",
      "tensor([0.0130, 0.1681, 0.1256, 0.6578, 0.3709], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-3.0331]]], device='cuda:0')\n",
      "sigma2 grad tensor([[529.9771]], device='cuda:0')\n",
      "sigma0 grad tensor([631.0958], device='cuda:0')\n",
      "sigma1 grad tensor([[536.3785]], device='cuda:0')\n",
      "gamma grad tensor([[-5795.4668]], device='cuda:0')\n",
      "alpha grad tensor([[10809.1221]], device='cuda:0')\n",
      "beta2 grad tensor([[-11245.5781]], device='cuda:0')\n",
      "beta0 grad tensor([-4887.7476], device='cuda:0')\n",
      "beta1 grad tensor([[-7048.5205]], device='cuda:0')\n",
      "Epoch 346 | Loss: 17.9807\n",
      "alpha: 0.0774918720126152, beta0: 0.11311628669500351, beta1: -0.0012048546923324466, beta2: 0.0030071150977164507, \n",
      "gamma: 0.06382118165493011, sigma0: 0.26716795563697815, sigma1: 0.0006974911666475236, sigma2: 0.00034702898119576275, sigmaX: 0.15503302216529846\n",
      "forward done\n",
      "tensor([0.0075, 0.0482, 0.2399, 0.6779, 0.3997], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.7341]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-32.4500]], device='cuda:0')\n",
      "sigma0 grad tensor([5.6184], device='cuda:0')\n",
      "sigma1 grad tensor([[-11.8296]], device='cuda:0')\n",
      "gamma grad tensor([[-1135.4633]], device='cuda:0')\n",
      "alpha grad tensor([[1881.1449]], device='cuda:0')\n",
      "beta2 grad tensor([[-1514.5675]], device='cuda:0')\n",
      "beta0 grad tensor([-698.4447], device='cuda:0')\n",
      "beta1 grad tensor([[-971.7231]], device='cuda:0')\n",
      "Epoch 347 | Loss: 6.1438\n",
      "alpha: 0.07738188654184341, beta0: 0.11316202580928802, beta1: -0.0011361186625435948, beta2: 0.003121472429484129, \n",
      "gamma: 0.06388470530509949, sigma0: 0.2671642303466797, sigma1: 0.0006941899773664773, sigma2: 0.0003436949336901307, sigmaX: 0.15503311157226562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0079, 0.0679, 0.3666, 0.6268, 0.3499], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-3.1523]]], device='cuda:0')\n",
      "sigma2 grad tensor([[102.1390]], device='cuda:0')\n",
      "sigma0 grad tensor([169.4313], device='cuda:0')\n",
      "sigma1 grad tensor([[118.3241]], device='cuda:0')\n",
      "gamma grad tensor([[-2575.0718]], device='cuda:0')\n",
      "alpha grad tensor([[4549.6851]], device='cuda:0')\n",
      "beta2 grad tensor([[-4205.9688]], device='cuda:0')\n",
      "beta0 grad tensor([-1907.6617], device='cuda:0')\n",
      "beta1 grad tensor([[-2666.2686]], device='cuda:0')\n",
      "Epoch 348 | Loss: 8.1432\n",
      "alpha: 0.07724840193986893, beta0: 0.11321768909692764, beta1: -0.0010544671677052975, beta2: 0.0032550180330872536, \n",
      "gamma: 0.06396127492189407, sigma0: 0.2671595513820648, sigma1: 0.0006903657922521234, sigma2: 0.0003400063142180443, sigmaX: 0.15503321588039398\n",
      "forward done\n",
      "tensor([0.0104, 0.0475, 0.1647, 0.6716, 0.3674], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.9776]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-84.9832]], device='cuda:0')\n",
      "sigma0 grad tensor([-62.3488], device='cuda:0')\n",
      "sigma1 grad tensor([[-62.9910]], device='cuda:0')\n",
      "gamma grad tensor([[-535.0207]], device='cuda:0')\n",
      "alpha grad tensor([[723.7391]], device='cuda:0')\n",
      "beta2 grad tensor([[-332.3805]], device='cuda:0')\n",
      "beta0 grad tensor([-170.2252], device='cuda:0')\n",
      "beta1 grad tensor([[-226.6796]], device='cuda:0')\n",
      "Epoch 349 | Loss: 5.9653\n",
      "alpha: 0.0771343782544136, beta0: 0.11326391994953156, beta1: -0.0009868791094049811, beta2: 0.003365178359672427, \n",
      "gamma: 0.06402787566184998, sigma0: 0.2671564221382141, sigma1: 0.000687936320900917, sigma2: 0.00033790525048971176, sigmaX: 0.15503332018852234\n",
      "forward done\n",
      "tensor([0.0079, 0.0380, 0.3027, 0.6751, 0.4020], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.3971]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-69.3016]], device='cuda:0')\n",
      "sigma0 grad tensor([-44.2128], device='cuda:0')\n",
      "sigma1 grad tensor([[-52.4141]], device='cuda:0')\n",
      "gamma grad tensor([[-705.6017]], device='cuda:0')\n",
      "alpha grad tensor([[1052.9929]], device='cuda:0')\n",
      "beta2 grad tensor([[-632.1024]], device='cuda:0')\n",
      "beta0 grad tensor([-316.6646], device='cuda:0')\n",
      "beta1 grad tensor([[-419.4001]], device='cuda:0')\n",
      "Epoch 350 | Loss: 5.1840\n",
      "alpha: 0.07703262567520142, beta0: 0.11330407112836838, beta1: -0.0009286146960221231, beta2: 0.0034596275072544813, \n",
      "gamma: 0.06408821791410446, sigma0: 0.26715436577796936, sigma1: 0.0006865169270895422, sigma2: 0.0003369174082763493, sigmaX: 0.1550334244966507\n",
      "forward done\n",
      "tensor([0.0119, 0.0527, 0.1379, 0.6703, 0.3776], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.7327]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-78.4080]], device='cuda:0')\n",
      "sigma0 grad tensor([-59.8557], device='cuda:0')\n",
      "sigma1 grad tensor([[-61.2768]], device='cuda:0')\n",
      "gamma grad tensor([[-534.3113]], device='cuda:0')\n",
      "alpha grad tensor([[720.6876]], device='cuda:0')\n",
      "beta2 grad tensor([[-376.8080]], device='cuda:0')\n",
      "beta0 grad tensor([-170.8417], device='cuda:0')\n",
      "beta1 grad tensor([[-239.6830]], device='cuda:0')\n",
      "Epoch 351 | Loss: 6.4673\n",
      "alpha: 0.0769440159201622, beta0: 0.11333790421485901, beta1: -0.0008796063484624028, beta2: 0.0035389550030231476, \n",
      "gamma: 0.06414183229207993, sigma0: 0.2671533226966858, sigma1: 0.0006859941640868783, sigma2: 0.000336911209160462, sigmaX: 0.15503352880477905\n",
      "forward done\n",
      "tensor([0.0064, 0.0375, 0.3162, 0.5638, 0.3244], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.4563]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-39.7014]], device='cuda:0')\n",
      "sigma0 grad tensor([-26.1484], device='cuda:0')\n",
      "sigma1 grad tensor([[-29.9057]], device='cuda:0')\n",
      "gamma grad tensor([[-806.8823]], device='cuda:0')\n",
      "alpha grad tensor([[1266.6039]], device='cuda:0')\n",
      "beta2 grad tensor([[-1014.2858]], device='cuda:0')\n",
      "beta0 grad tensor([-417.4486], device='cuda:0')\n",
      "beta1 grad tensor([[-612.0555]], device='cuda:0')\n",
      "Epoch 352 | Loss: 4.9654\n",
      "alpha: 0.0768604651093483, beta0: 0.11336914449930191, beta1: -0.0008342791115865111, beta2: 0.0036125597544014454, \n",
      "gamma: 0.06419279426336288, sigma0: 0.2671527564525604, sigma1: 0.0006858750130049884, sigma2: 0.0003373032668605447, sigmaX: 0.1550336331129074\n",
      "forward done\n",
      "tensor([0.0196, 0.1099, 0.1525, 0.6473, 0.3614], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.4622]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-395.4745]], device='cuda:0')\n",
      "sigma0 grad tensor([-480.7072], device='cuda:0')\n",
      "sigma1 grad tensor([[-400.0091]], device='cuda:0')\n",
      "gamma grad tensor([[3648.7705]], device='cuda:0')\n",
      "alpha grad tensor([[-7029.7275]], device='cuda:0')\n",
      "beta2 grad tensor([[6997.1348]], device='cuda:0')\n",
      "beta0 grad tensor([3266.2722], device='cuda:0')\n",
      "beta1 grad tensor([[4531.4102]], device='cuda:0')\n",
      "Epoch 353 | Loss: 12.1742\n",
      "alpha: 0.07686392217874527, beta0: 0.11336147040128708, beta1: -0.0008433313923887908, beta2: 0.003601472359150648, \n",
      "gamma: 0.06419707834720612, sigma0: 0.26715710759162903, sigma1: 0.0006897797575220466, sigma2: 0.0003415716637391597, sigmaX: 0.15503373742103577\n",
      "forward done\n",
      "tensor([0.0081, 0.0454, 0.1080, 0.6837, 0.3993], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.7166]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-299.6761]], device='cuda:0')\n",
      "sigma0 grad tensor([-397.5455], device='cuda:0')\n",
      "sigma1 grad tensor([[-319.5741]], device='cuda:0')\n",
      "gamma grad tensor([[2697.1289]], device='cuda:0')\n",
      "alpha grad tensor([[-5295.7124]], device='cuda:0')\n",
      "beta2 grad tensor([[5283.1387]], device='cuda:0')\n",
      "beta0 grad tensor([2513.7783], device='cuda:0')\n",
      "beta1 grad tensor([[3470.2727]], device='cuda:0')\n",
      "Epoch 354 | Loss: 5.7433\n",
      "alpha: 0.07691964507102966, beta0: 0.11333019286394119, beta1: -0.0008852759492583573, beta2: 0.0035397710744291544, \n",
      "gamma: 0.06417353451251984, sigma0: 0.26716455817222595, sigma1: 0.0006960993050597608, sigma2: 0.00034798315027728677, sigmaX: 0.15503382682800293\n",
      "forward done\n",
      "tensor([0.0134, 0.0450, 0.6563, 0.5441, 0.3318], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.5627]]], device='cuda:0')\n",
      "sigma2 grad tensor([[441.1501]], device='cuda:0')\n",
      "sigma0 grad tensor([450.3428], device='cuda:0')\n",
      "sigma1 grad tensor([[387.6658]], device='cuda:0')\n",
      "gamma grad tensor([[-3988.3862]], device='cuda:0')\n",
      "alpha grad tensor([[7479.6904]], device='cuda:0')\n",
      "beta2 grad tensor([[-7413.9741]], device='cuda:0')\n",
      "beta0 grad tensor([-3378.6077], device='cuda:0')\n",
      "beta1 grad tensor([[-4719.7671]], device='cuda:0')\n",
      "Epoch 355 | Loss: 6.0440\n",
      "alpha: 0.07688942551612854, beta0: 0.11333896219730377, beta1: -0.0008716339361853898, beta2: 0.00356454961001873, \n",
      "gamma: 0.06419458240270615, sigma0: 0.26716601848602295, sigma1: 0.0006972783012315631, sigma2: 0.00034870082163251936, sigmaX: 0.1550339013338089\n",
      "forward done\n",
      "tensor([0.0105, 0.0787, 0.4242, 0.6055, 0.3562], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.0100]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-446.2424]], device='cuda:0')\n",
      "sigma0 grad tensor([-507.0444], device='cuda:0')\n",
      "sigma1 grad tensor([[-424.9623]], device='cuda:0')\n",
      "gamma grad tensor([[3594.9087]], device='cuda:0')\n",
      "alpha grad tensor([[-7058.2866]], device='cuda:0')\n",
      "beta2 grad tensor([[7018.0791]], device='cuda:0')\n",
      "beta0 grad tensor([3322.3770], device='cuda:0')\n",
      "beta1 grad tensor([[4575.5791]], device='cuda:0')\n",
      "Epoch 356 | Loss: 9.2655\n",
      "alpha: 0.07693583518266678, beta0: 0.1133127510547638, beta1: -0.0009064761106856167, beta2: 0.003514191834256053, \n",
      "gamma: 0.06417547166347504, sigma0: 0.267172247171402, sigma1: 0.0007024711230769753, sigma2: 0.0003537373850122094, sigmaX: 0.15503397583961487\n",
      "forward done\n",
      "tensor([0.0109, 0.0501, 0.2175, 0.6251, 0.3217], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.7435]]], device='cuda:0')\n",
      "sigma2 grad tensor([[54.2135]], device='cuda:0')\n",
      "sigma0 grad tensor([69.8039], device='cuda:0')\n",
      "sigma1 grad tensor([[52.6059]], device='cuda:0')\n",
      "gamma grad tensor([[-1420.2777]], device='cuda:0')\n",
      "alpha grad tensor([[2524.9436]], device='cuda:0')\n",
      "beta2 grad tensor([[-2238.7192]], device='cuda:0')\n",
      "beta0 grad tensor([-1027.2173], device='cuda:0')\n",
      "beta1 grad tensor([[-1427.7225]], device='cuda:0')\n",
      "Epoch 357 | Loss: 6.1846\n",
      "alpha: 0.07694771140813828, beta0: 0.11330205202102661, beta1: -0.0009200726053677499, beta2: 0.003496292745694518, \n",
      "gamma: 0.06417438387870789, sigma0: 0.2671765387058258, sigma1: 0.0007060993229970336, sigma2: 0.0003572245186660439, sigmaX: 0.15503405034542084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0142, 0.0673, 0.1410, 0.6688, 0.3773], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.2070]]], device='cuda:0')\n",
      "sigma2 grad tensor([[89.6949]], device='cuda:0')\n",
      "sigma0 grad tensor([110.9513], device='cuda:0')\n",
      "sigma1 grad tensor([[93.6951]], device='cuda:0')\n",
      "gamma grad tensor([[-2100.6448]], device='cuda:0')\n",
      "alpha grad tensor([[3689.6987]], device='cuda:0')\n",
      "beta2 grad tensor([[-3410.4834]], device='cuda:0')\n",
      "beta0 grad tensor([-1512.4437], device='cuda:0')\n",
      "beta1 grad tensor([[-2152.6594]], device='cuda:0')\n",
      "Epoch 358 | Loss: 7.9302\n",
      "alpha: 0.07692031562328339, beta0: 0.1133086159825325, beta1: -0.0009094232227653265, beta2: 0.0035160782281309366, \n",
      "gamma: 0.06419452279806137, sigma0: 0.26717886328697205, sigma1: 0.0007080649374984205, sigma2: 0.0003591172571759671, sigmaX: 0.155034139752388\n",
      "forward done\n",
      "tensor([0.0110, 0.0784, 0.3086, 0.6555, 0.3796], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.7922]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-439.6831]], device='cuda:0')\n",
      "sigma0 grad tensor([-506.5131], device='cuda:0')\n",
      "sigma1 grad tensor([[-433.0815]], device='cuda:0')\n",
      "gamma grad tensor([[3700.3755]], device='cuda:0')\n",
      "alpha grad tensor([[-7250.2861]], device='cuda:0')\n",
      "beta2 grad tensor([[7057.0737]], device='cuda:0')\n",
      "beta0 grad tensor([3400.7092], device='cuda:0')\n",
      "beta1 grad tensor([[4646.1914]], device='cuda:0')\n",
      "Epoch 359 | Loss: 9.1986\n",
      "alpha: 0.0769709050655365, beta0: 0.11327986419200897, beta1: -0.0009473656537011266, beta2: 0.0034613360185176134, \n",
      "gamma: 0.0641736313700676, sigma0: 0.267185777425766, sigma1: 0.0007139682420529425, sigma2: 0.00036502827424556017, sigmaX: 0.15503422915935516\n",
      "forward done\n",
      "tensor([0.0122, 0.0753, 0.3751, 0.6140, 0.4097], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.3786]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-527.4288]], device='cuda:0')\n",
      "sigma0 grad tensor([-501.4905], device='cuda:0')\n",
      "sigma1 grad tensor([[-452.7916]], device='cuda:0')\n",
      "gamma grad tensor([[3796.9580]], device='cuda:0')\n",
      "alpha grad tensor([[-7363.3271]], device='cuda:0')\n",
      "beta2 grad tensor([[7496.0371]], device='cuda:0')\n",
      "beta0 grad tensor([3430.2952], device='cuda:0')\n",
      "beta1 grad tensor([[4782.1650]], device='cuda:0')\n",
      "Epoch 360 | Loss: 8.9430\n",
      "alpha: 0.07708501070737839, beta0: 0.11322256177663803, beta1: -0.0010255412198603153, beta2: 0.0033425819128751755, \n",
      "gamma: 0.06411894410848618, sigma0: 0.26719632744789124, sigma1: 0.0007232187781482935, sigma2: 0.00037503137718886137, sigmaX: 0.15503431856632233\n",
      "forward done\n",
      "tensor([0.0091, 0.0657, 0.2041, 0.5865, 0.3175], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.4372]]], device='cuda:0')\n",
      "sigma2 grad tensor([[491.0498]], device='cuda:0')\n",
      "sigma0 grad tensor([530.0018], device='cuda:0')\n",
      "sigma1 grad tensor([[461.2620]], device='cuda:0')\n",
      "gamma grad tensor([[-4788.3184]], device='cuda:0')\n",
      "alpha grad tensor([[8981.1074]], device='cuda:0')\n",
      "beta2 grad tensor([[-9006.0781]], device='cuda:0')\n",
      "beta0 grad tensor([-4062.4456], device='cuda:0')\n",
      "beta1 grad tensor([[-5723.4126]], device='cuda:0')\n",
      "Epoch 361 | Loss: 7.6827\n",
      "alpha: 0.07708647847175598, beta0: 0.11321733891963959, beta1: -0.0010308475466445088, beta2: 0.003337639383971691, \n",
      "gamma: 0.06412307918071747, sigma0: 0.26719945669174194, sigma1: 0.0007260065758600831, sigma2: 0.00037812336813658476, sigmaX: 0.15503442287445068\n",
      "forward done\n",
      "tensor([0.0135, 0.0483, 0.4556, 0.5364, 0.2955], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.3527]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-13.7079]], device='cuda:0')\n",
      "sigma0 grad tensor([1.5921], device='cuda:0')\n",
      "sigma1 grad tensor([[-7.3251]], device='cuda:0')\n",
      "gamma grad tensor([[-978.8454]], device='cuda:0')\n",
      "alpha grad tensor([[1605.4535]], device='cuda:0')\n",
      "beta2 grad tensor([[-1414.4036]], device='cuda:0')\n",
      "beta0 grad tensor([-585.9830], device='cuda:0')\n",
      "beta1 grad tensor([[-853.3806]], device='cuda:0')\n",
      "Epoch 362 | Loss: 6.1321\n",
      "alpha: 0.07707159966230392, beta0: 0.11321902275085449, beta1: -0.0010265588061884046, beta2: 0.0033478294499218464, \n",
      "gamma: 0.06413617730140686, sigma0: 0.2672019600868225, sigma1: 0.0007283100858330727, sigma2: 0.0003807340399362147, sigmaX: 0.15503452718257904\n",
      "forward done\n",
      "tensor([0.0120, 0.0387, 0.2425, 0.6675, 0.4746], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.9013]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-221.5107]], device='cuda:0')\n",
      "sigma0 grad tensor([-239.6912], device='cuda:0')\n",
      "sigma1 grad tensor([[-212.7979]], device='cuda:0')\n",
      "gamma grad tensor([[1046.7939]], device='cuda:0')\n",
      "alpha grad tensor([[-2287.6404]], device='cuda:0')\n",
      "beta2 grad tensor([[2491.3503]], device='cuda:0')\n",
      "beta0 grad tensor([1194.0642], device='cuda:0')\n",
      "beta1 grad tensor([[1643.0758]], device='cuda:0')\n",
      "Epoch 363 | Loss: 5.2659\n",
      "alpha: 0.0770825743675232, beta0: 0.11320842802524567, beta1: -0.0010395585559308529, beta2: 0.0033310679718852043, \n",
      "gamma: 0.06413618475198746, sigma0: 0.2672063708305359, sigma1: 0.0007322808960452676, sigma2: 0.0003850376815535128, sigmaX: 0.1550346165895462\n",
      "forward done\n",
      "tensor([0.0083, 0.0499, 0.0991, 0.6579, 0.3564], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.0403]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-100.1226]], device='cuda:0')\n",
      "sigma0 grad tensor([-83.7110], device='cuda:0')\n",
      "sigma1 grad tensor([[-81.7893]], device='cuda:0')\n",
      "gamma grad tensor([[-395.0178]], device='cuda:0')\n",
      "alpha grad tensor([[444.5581]], device='cuda:0')\n",
      "beta2 grad tensor([[-65.7376]], device='cuda:0')\n",
      "beta0 grad tensor([-36.8840], device='cuda:0')\n",
      "beta1 grad tensor([[-48.1060]], device='cuda:0')\n",
      "Epoch 364 | Loss: 6.1151\n",
      "alpha: 0.0770869106054306, beta0: 0.11320032179355621, beta1: -0.0010494772577658296, beta2: 0.0033183160703629255, \n",
      "gamma: 0.06414014101028442, sigma0: 0.2672107219696045, sigma1: 0.0007362753967754543, sigma2: 0.00038948183646425605, sigmaX: 0.15503470599651337\n",
      "forward done\n",
      "tensor([0.0150, 0.0768, 0.2712, 0.6317, 0.3572], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.0389]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-447.8843]], device='cuda:0')\n",
      "sigma0 grad tensor([-501.6651], device='cuda:0')\n",
      "sigma1 grad tensor([[-419.3148]], device='cuda:0')\n",
      "gamma grad tensor([[4183.5234]], device='cuda:0')\n",
      "alpha grad tensor([[-7957.6816]], device='cuda:0')\n",
      "beta2 grad tensor([[8021.8613]], device='cuda:0')\n",
      "beta0 grad tensor([3649.5684], device='cuda:0')\n",
      "beta1 grad tensor([[5094.6504]], device='cuda:0')\n",
      "Epoch 365 | Loss: 8.9578\n",
      "alpha: 0.07716995477676392, beta0: 0.11315733939409256, beta1: -0.0011083587305620313, beta2: 0.0032278960570693016, \n",
      "gamma: 0.06410147249698639, sigma0: 0.267219215631485, sigma1: 0.000743664160836488, sigma2: 0.0003975160070694983, sigmaX: 0.15503479540348053\n",
      "forward done\n",
      "tensor([0.0239, 0.2187, 0.1780, 0.6469, 0.3457], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.6025]]], device='cuda:0')\n",
      "sigma2 grad tensor([[725.3874]], device='cuda:0')\n",
      "sigma0 grad tensor([644.9553], device='cuda:0')\n",
      "sigma1 grad tensor([[620.7872]], device='cuda:0')\n",
      "gamma grad tensor([[-5452.7163]], device='cuda:0')\n",
      "alpha grad tensor([[10275.8945]], device='cuda:0')\n",
      "beta2 grad tensor([[-11597.0508]], device='cuda:0')\n",
      "beta0 grad tensor([-4694.6318], device='cuda:0')\n",
      "beta1 grad tensor([[-7006.8286]], device='cuda:0')\n",
      "Epoch 366 | Loss: 23.0647\n",
      "alpha: 0.07713363319635391, beta0: 0.11316990107297897, beta1: -0.0010853956919163465, beta2: 0.003271530382335186, \n",
      "gamma: 0.06412506103515625, sigma0: 0.26721957325935364, sigma1: 0.0007433673017658293, sigma2: 0.00039668945828452706, sigmaX: 0.1550348848104477\n",
      "forward done\n",
      "tensor([0.0175, 0.1436, 0.2068, 0.6252, 0.3511], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-4.2846]]], device='cuda:0')\n",
      "sigma2 grad tensor([[672.6844]], device='cuda:0')\n",
      "sigma0 grad tensor([592.4180], device='cuda:0')\n",
      "sigma1 grad tensor([[559.8950]], device='cuda:0')\n",
      "gamma grad tensor([[-4926.7139]], device='cuda:0')\n",
      "alpha grad tensor([[9317.0498]], device='cuda:0')\n",
      "beta2 grad tensor([[-10305.6455]], device='cuda:0')\n",
      "beta0 grad tensor([-4263.6841], device='cuda:0')\n",
      "beta1 grad tensor([[-6273.0996]], device='cuda:0')\n",
      "Epoch 367 | Loss: 15.5575\n",
      "alpha: 0.07701140642166138, beta0: 0.11322258412837982, beta1: -0.0010042942594736814, beta2: 0.00340949441306293, \n",
      "gamma: 0.06419320404529572, sigma0: 0.26721394062042236, sigma1: 0.0007375308778136969, sigma2: 0.00038930136361159384, sigmaX: 0.15503498911857605\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0133, 0.0384, 0.1959, 0.6840, 0.3890], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.3910]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-258.0985]], device='cuda:0')\n",
      "sigma0 grad tensor([-259.8584], device='cuda:0')\n",
      "sigma1 grad tensor([[-231.3775]], device='cuda:0')\n",
      "gamma grad tensor([[1185.4066]], device='cuda:0')\n",
      "alpha grad tensor([[-2561.8232]], device='cuda:0')\n",
      "beta2 grad tensor([[2924.1370]], device='cuda:0')\n",
      "beta0 grad tensor([1320.7802], device='cuda:0')\n",
      "beta1 grad tensor([[1857.7069]], device='cuda:0')\n",
      "Epoch 368 | Loss: 5.1198\n",
      "alpha: 0.07693924009799957, beta0: 0.11325152218341827, beta1: -0.00095799018163234, beta2: 0.003490624250844121, \n",
      "gamma: 0.0642358660697937, sigma0: 0.26721203327178955, sigma1: 0.0007351755048148334, sigma2: 0.0003859718854073435, sigmaX: 0.1550350934267044\n",
      "forward done\n",
      "tensor([0.0085, 0.0729, 0.1185, 0.6774, 0.3873], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.4802]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-460.1288]], device='cuda:0')\n",
      "sigma0 grad tensor([-508.0836], device='cuda:0')\n",
      "sigma1 grad tensor([[-439.7231]], device='cuda:0')\n",
      "gamma grad tensor([[3707.7500]], device='cuda:0')\n",
      "alpha grad tensor([[-7220.1040]], device='cuda:0')\n",
      "beta2 grad tensor([[7314.2266]], device='cuda:0')\n",
      "beta0 grad tensor([3384.6140], device='cuda:0')\n",
      "beta1 grad tensor([[4711.7930]], device='cuda:0')\n",
      "Epoch 369 | Loss: 8.4768\n",
      "alpha: 0.0769537091255188, beta0: 0.11324083060026169, beta1: -0.0009680648217909038, beta2: 0.0034823857713490725, \n",
      "gamma: 0.06423291563987732, sigma0: 0.2672155797481537, sigma1: 0.0007376884459517896, sigma2: 0.0003879095893353224, sigmaX: 0.15503519773483276\n",
      "forward done\n",
      "tensor([0.0098, 0.1039, 0.1308, 0.6391, 0.3911], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.4474]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-441.7094]], device='cuda:0')\n",
      "sigma0 grad tensor([-490.7563], device='cuda:0')\n",
      "sigma1 grad tensor([[-405.4127]], device='cuda:0')\n",
      "gamma grad tensor([[3933.1731]], device='cuda:0')\n",
      "alpha grad tensor([[-7552.9297]], device='cuda:0')\n",
      "beta2 grad tensor([[7327.8633]], device='cuda:0')\n",
      "beta0 grad tensor([3481.4949], device='cuda:0')\n",
      "beta1 grad tensor([[4758.8599]], device='cuda:0')\n",
      "Epoch 370 | Loss: 11.5633\n",
      "alpha: 0.07704081386327744, beta0: 0.113197460770607, beta1: -0.001023713150061667, beta2: 0.0034025164786726236, \n",
      "gamma: 0.06419122219085693, sigma0: 0.2672233283519745, sigma1: 0.000743752927519381, sigma2: 0.00039387683500535786, sigmaX: 0.15503530204296112\n",
      "forward done\n",
      "tensor([0.0134, 0.0586, 0.1634, 0.6788, 0.3760], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.0479]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-431.2470]], device='cuda:0')\n",
      "sigma0 grad tensor([-487.2797], device='cuda:0')\n",
      "sigma1 grad tensor([[-408.4026]], device='cuda:0')\n",
      "gamma grad tensor([[3772.0310]], device='cuda:0')\n",
      "alpha grad tensor([[-7270.3062]], device='cuda:0')\n",
      "beta2 grad tensor([[7608.5386]], device='cuda:0')\n",
      "beta0 grad tensor([3376.0627], device='cuda:0')\n",
      "beta1 grad tensor([[4784.0352]], device='cuda:0')\n",
      "Epoch 371 | Loss: 7.0962\n",
      "alpha: 0.07718320190906525, beta0: 0.11312900483608246, beta1: -0.0011160721769556403, beta2: 0.0032625356689095497, \n",
      "gamma: 0.06412015110254288, sigma0: 0.2672343850135803, sigma1: 0.0007526885601691902, sigma2: 0.00040296310908161104, sigmaX: 0.15503540635108948\n",
      "forward done\n",
      "tensor([0.0117, 0.0826, 0.1887, 0.6659, 0.3922], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.2847]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-476.8057]], device='cuda:0')\n",
      "sigma0 grad tensor([-469.0751], device='cuda:0')\n",
      "sigma1 grad tensor([[-412.2013]], device='cuda:0')\n",
      "gamma grad tensor([[4112.6045]], device='cuda:0')\n",
      "alpha grad tensor([[-7742.3257]], device='cuda:0')\n",
      "beta2 grad tensor([[8028.4141]], device='cuda:0')\n",
      "beta0 grad tensor([3524.3027], device='cuda:0')\n",
      "beta1 grad tensor([[5006.4805]], device='cuda:0')\n",
      "Epoch 372 | Loss: 9.5171\n",
      "alpha: 0.07737453281879425, beta0: 0.11303899437189102, beta1: -0.0012400242267176509, beta2: 0.003070266917347908, \n",
      "gamma: 0.06402216851711273, sigma0: 0.2672479450702667, sigma1: 0.0007639590767212212, sigma2: 0.000415000191424042, sigmaX: 0.15503551065921783\n",
      "forward done\n",
      "tensor([0.0147, 0.0497, 0.2452, 0.6679, 0.3963], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.7200]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-21.4008]], device='cuda:0')\n",
      "sigma0 grad tensor([-15.6039], device='cuda:0')\n",
      "sigma1 grad tensor([[-16.1939]], device='cuda:0')\n",
      "gamma grad tensor([[-857.4117]], device='cuda:0')\n",
      "alpha grad tensor([[1364.0507]], device='cuda:0')\n",
      "beta2 grad tensor([[-1131.6334]], device='cuda:0')\n",
      "beta0 grad tensor([-471.7303], device='cuda:0')\n",
      "beta1 grad tensor([[-691.5048]], device='cuda:0')\n",
      "Epoch 373 | Loss: 6.2947\n",
      "alpha: 0.07751395553350449, beta0: 0.1129717081785202, beta1: -0.0013322707964107394, beta2: 0.002927768277004361, \n",
      "gamma: 0.06395235657691956, sigma0: 0.2672589421272278, sigma1: 0.0007731374353170395, sigma2: 0.0004248438635841012, sigmaX: 0.15503562986850739\n",
      "forward done\n",
      "tensor([0.0150, 0.1618, 0.4875, 0.6252, 0.3459], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.2004]]], device='cuda:0')\n",
      "sigma2 grad tensor([[804.4171]], device='cuda:0')\n",
      "sigma0 grad tensor([628.9897], device='cuda:0')\n",
      "sigma1 grad tensor([[639.2029]], device='cuda:0')\n",
      "gamma grad tensor([[-5411.9395]], device='cuda:0')\n",
      "alpha grad tensor([[10192.1943]], device='cuda:0')\n",
      "beta2 grad tensor([[-12058.4287]], device='cuda:0')\n",
      "beta0 grad tensor([-4651.8374], device='cuda:0')\n",
      "beta1 grad tensor([[-7082.3550]], device='cuda:0')\n",
      "Epoch 374 | Loss: 17.6578\n",
      "alpha: 0.07752357423305511, beta0: 0.11296439170837402, beta1: -0.0013352445093914866, beta2: 0.002934353658929467, \n",
      "gamma: 0.06395062804222107, sigma0: 0.26726144552230835, sigma1: 0.0007740880828350782, sigma2: 0.0004246746248099953, sigmaX: 0.15503571927547455\n",
      "forward done\n",
      "tensor([0.0137, 0.0426, 0.3895, 0.6159, 0.3081], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.0114]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-8.2894]], device='cuda:0')\n",
      "sigma0 grad tensor([22.4988], device='cuda:0')\n",
      "sigma1 grad tensor([[5.4148]], device='cuda:0')\n",
      "gamma grad tensor([[-1301.5072]], device='cuda:0')\n",
      "alpha grad tensor([[2193.4104]], device='cuda:0')\n",
      "beta2 grad tensor([[-2018.1661]], device='cuda:0')\n",
      "beta0 grad tensor([-837.2242], device='cuda:0')\n",
      "beta1 grad tensor([[-1221.1584]], device='cuda:0')\n",
      "Epoch 375 | Loss: 5.5826\n",
      "alpha: 0.0775093361735344, beta0: 0.11296691000461578, beta1: -0.00132541183847934, beta2: 0.002959803445264697, \n",
      "gamma: 0.06396225839853287, sigma0: 0.2672632336616516, sigma1: 0.0007747944328002632, sigma2: 0.00042462212149985135, sigmaX: 0.1550358086824417\n",
      "forward done\n",
      "tensor([0.0126, 0.1975, 0.2132, 0.6459, 0.3665], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-4.2689]]], device='cuda:0')\n",
      "sigma2 grad tensor([[572.8315]], device='cuda:0')\n",
      "sigma0 grad tensor([637.0620], device='cuda:0')\n",
      "sigma1 grad tensor([[547.8340]], device='cuda:0')\n",
      "gamma grad tensor([[-6014.5571]], device='cuda:0')\n",
      "alpha grad tensor([[11114.4912]], device='cuda:0')\n",
      "beta2 grad tensor([[-11913.2354]], device='cuda:0')\n",
      "beta0 grad tensor([-4999.6860], device='cuda:0')\n",
      "beta1 grad tensor([[-7313.2100]], device='cuda:0')\n",
      "Epoch 376 | Loss: 20.9860\n",
      "alpha: 0.07738679647445679, beta0: 0.11301892250776291, beta1: -0.0012444136664271355, beta2: 0.003099295776337385, \n",
      "gamma: 0.0640317052602768, sigma0: 0.26725828647613525, sigma1: 0.0007698811823502183, sigma2: 0.0004188518214505166, sigmaX: 0.15503592789173126\n",
      "forward done\n",
      "tensor([0.0152, 0.0457, 0.1493, 0.6695, 0.3806], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.8082]]], device='cuda:0')\n",
      "sigma2 grad tensor([[121.0880]], device='cuda:0')\n",
      "sigma0 grad tensor([154.9227], device='cuda:0')\n",
      "sigma1 grad tensor([[127.5581]], device='cuda:0')\n",
      "gamma grad tensor([[-2393.9514]], device='cuda:0')\n",
      "alpha grad tensor([[4274.6265]], device='cuda:0')\n",
      "beta2 grad tensor([[-4166.9097]], device='cuda:0')\n",
      "beta0 grad tensor([-1795.9044], device='cuda:0')\n",
      "beta1 grad tensor([[-2591.0032]], device='cuda:0')\n",
      "Epoch 377 | Loss: 5.7830\n",
      "alpha: 0.07724601775407791, beta0: 0.11307848989963531, beta1: -0.0011537050595507026, beta2: 0.0032525586429983377, \n",
      "gamma: 0.06411120295524597, sigma0: 0.26725277304649353, sigma1: 0.0007646749727427959, sigma2: 0.0004130246816202998, sigmaX: 0.1550360471010208\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0101, 0.1284, 0.1450, 0.6984, 0.4190], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.6166]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-392.2462]], device='cuda:0')\n",
      "sigma0 grad tensor([-490.3002], device='cuda:0')\n",
      "sigma1 grad tensor([[-403.6094]], device='cuda:0')\n",
      "gamma grad tensor([[3869.9478]], device='cuda:0')\n",
      "alpha grad tensor([[-7433.1016]], device='cuda:0')\n",
      "beta2 grad tensor([[7121.3442]], device='cuda:0')\n",
      "beta0 grad tensor([3450.6963], device='cuda:0')\n",
      "beta1 grad tensor([[4692.1899]], device='cuda:0')\n",
      "Epoch 378 | Loss: 14.1098\n",
      "alpha: 0.07720772922039032, beta0: 0.11309164017438889, beta1: -0.001128060044720769, beta2: 0.003303955541923642, \n",
      "gamma: 0.06413610279560089, sigma0: 0.2672532796859741, sigma1: 0.0007645461009815335, sigma2: 0.0004122854443266988, sigmaX: 0.15503615140914917\n",
      "forward done\n",
      "tensor([0.0102, 0.0630, 0.2703, 0.6811, 0.3778], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.6492]]], device='cuda:0')\n",
      "sigma2 grad tensor([[449.4958]], device='cuda:0')\n",
      "sigma0 grad tensor([543.2660], device='cuda:0')\n",
      "sigma1 grad tensor([[451.8793]], device='cuda:0')\n",
      "gamma grad tensor([[-4550.5898]], device='cuda:0')\n",
      "alpha grad tensor([[8682.8467]], device='cuda:0')\n",
      "beta2 grad tensor([[-8513.4697]], device='cuda:0')\n",
      "beta0 grad tensor([-3985.9333], device='cuda:0')\n",
      "beta1 grad tensor([[-5536.7930]], device='cuda:0')\n",
      "Epoch 379 | Loss: 7.6418\n",
      "alpha: 0.07709027081727982, beta0: 0.11314202100038528, beta1: -0.0010521761141717434, beta2: 0.0034302077256143093, \n",
      "gamma: 0.06420152634382248, sigma0: 0.2672482430934906, sigma1: 0.0007599242380820215, sigma2: 0.00040719908429309726, sigmaX: 0.15503625571727753\n",
      "forward done\n",
      "tensor([0.0084, 0.0524, 0.3732, 0.6781, 0.3954], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.2808]]], device='cuda:0')\n",
      "sigma2 grad tensor([[305.8184]], device='cuda:0')\n",
      "sigma0 grad tensor([279.3015], device='cuda:0')\n",
      "sigma1 grad tensor([[256.2997]], device='cuda:0')\n",
      "gamma grad tensor([[-2563.1738]], device='cuda:0')\n",
      "alpha grad tensor([[4841.7085]], device='cuda:0')\n",
      "beta2 grad tensor([[-5017.8643]], device='cuda:0')\n",
      "beta0 grad tensor([-2173.1211], device='cuda:0')\n",
      "beta1 grad tensor([[-3113.7727]], device='cuda:0')\n",
      "Epoch 380 | Loss: 6.6967\n",
      "alpha: 0.076947882771492, beta0: 0.11320405453443527, beta1: -0.0009603312355466187, beta2: 0.0035813881549984217, \n",
      "gamma: 0.06427949666976929, sigma0: 0.2672414183616638, sigma1: 0.0007536637713201344, sigma2: 0.0004000718181487173, sigmaX: 0.15503636002540588\n",
      "forward done\n",
      "tensor([0.0140, 0.0488, 0.1370, 0.6449, 0.3530], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.7497]]], device='cuda:0')\n",
      "sigma2 grad tensor([[215.2175]], device='cuda:0')\n",
      "sigma0 grad tensor([198.0812], device='cuda:0')\n",
      "sigma1 grad tensor([[187.7046]], device='cuda:0')\n",
      "gamma grad tensor([[-2165.9583]], device='cuda:0')\n",
      "alpha grad tensor([[4049.1038]], device='cuda:0')\n",
      "beta2 grad tensor([[-4269.2236]], device='cuda:0')\n",
      "beta0 grad tensor([-1765.2500], device='cuda:0')\n",
      "beta1 grad tensor([[-2604.8047]], device='cuda:0')\n",
      "Epoch 381 | Loss: 6.0244\n",
      "alpha: 0.07679348438978195, beta0: 0.1132713332772255, beta1: -0.0008608073112554848, beta2: 0.0037450247909873724, \n",
      "gamma: 0.06436353176832199, sigma0: 0.2672339677810669, sigma1: 0.0007467783289030194, sigma2: 0.00039221782935783267, sigmaX: 0.15503646433353424\n",
      "forward done\n",
      "tensor([0.0111, 0.0563, 0.1899, 0.6483, 0.3703], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.3357]]], device='cuda:0')\n",
      "sigma2 grad tensor([[79.5284]], device='cuda:0')\n",
      "sigma0 grad tensor([113.0962], device='cuda:0')\n",
      "sigma1 grad tensor([[89.2226]], device='cuda:0')\n",
      "gamma grad tensor([[-1836.0160]], device='cuda:0')\n",
      "alpha grad tensor([[3264.8015]], device='cuda:0')\n",
      "beta2 grad tensor([[-3005.6855]], device='cuda:0')\n",
      "beta0 grad tensor([-1351.6143], device='cuda:0')\n",
      "beta1 grad tensor([[-1905.3070]], device='cuda:0')\n",
      "Epoch 382 | Loss: 6.8498\n",
      "alpha: 0.07663732022047043, beta0: 0.11333867162466049, beta1: -0.0007621350814588368, beta2: 0.0039059908594936132, \n",
      "gamma: 0.06444912403821945, sigma0: 0.2672268748283386, sigma1: 0.0007403777563013136, sigma2: 0.0003851393412332982, sigmaX: 0.1550365686416626\n",
      "forward done\n",
      "tensor([0.0103, 0.0928, 0.1455, 0.6952, 0.4064], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.3904]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-476.3156]], device='cuda:0')\n",
      "sigma0 grad tensor([-493.3530], device='cuda:0')\n",
      "sigma1 grad tensor([[-442.0655]], device='cuda:0')\n",
      "gamma grad tensor([[3420.6499]], device='cuda:0')\n",
      "alpha grad tensor([[-6724.3521]], device='cuda:0')\n",
      "beta2 grad tensor([[6754.4175]], device='cuda:0')\n",
      "beta0 grad tensor([3161.1064], device='cuda:0')\n",
      "beta1 grad tensor([[4387.8394]], device='cuda:0')\n",
      "Epoch 383 | Loss: 10.5378\n",
      "alpha: 0.07657963037490845, beta0: 0.1133609339594841, beta1: -0.0007270757341757417, beta2: 0.00396721949800849, \n",
      "gamma: 0.0644833892583847, sigma0: 0.26722612977027893, sigma1: 0.000739677925594151, sigma2: 0.0003842397127300501, sigmaX: 0.15503665804862976\n",
      "forward done\n",
      "tensor([0.0111, 0.1648, 0.0586, 0.7223, 0.4397], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[0.1893]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-318.9492]], device='cuda:0')\n",
      "sigma0 grad tensor([-451.5233], device='cuda:0')\n",
      "sigma1 grad tensor([[-341.8515]], device='cuda:0')\n",
      "gamma grad tensor([[3464.6860]], device='cuda:0')\n",
      "alpha grad tensor([[-6700.8882]], device='cuda:0')\n",
      "beta2 grad tensor([[5941.2104]], device='cuda:0')\n",
      "beta0 grad tensor([3112.0552], device='cuda:0')\n",
      "beta1 grad tensor([[4076.5925]], device='cuda:0')\n",
      "Epoch 384 | Loss: 17.7161\n",
      "alpha: 0.07660048454999924, beta0: 0.1133476197719574, beta1: -0.0007397941662929952, beta2: 0.0039567905478179455, \n",
      "gamma: 0.06447615474462509, sigma0: 0.2672300636768341, sigma1: 0.0007425366202369332, sigma2: 0.00038670949288643897, sigmaX: 0.15503673255443573\n",
      "forward done\n",
      "tensor([0.0199, 0.2534, 0.1729, 0.6299, 0.3836], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.2493]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-249.0571]], device='cuda:0')\n",
      "sigma0 grad tensor([-412.3529], device='cuda:0')\n",
      "sigma1 grad tensor([[-294.3971]], device='cuda:0')\n",
      "gamma grad tensor([[3006.1079]], device='cuda:0')\n",
      "alpha grad tensor([[-5845.1084]], device='cuda:0')\n",
      "beta2 grad tensor([[5264.0391]], device='cuda:0')\n",
      "beta0 grad tensor([2728.9473], device='cuda:0')\n",
      "beta1 grad tensor([[3576.6865]], device='cuda:0')\n",
      "Epoch 385 | Loss: 26.5460\n",
      "alpha: 0.07667562365531921, beta0: 0.11330968141555786, beta1: -0.0007857357850298285, beta2: 0.003895806847140193, \n",
      "gamma: 0.0644403025507927, sigma0: 0.2672373354434967, sigma1: 0.0007477675098925829, sigma2: 0.00039117588312365115, sigmaX: 0.1550368070602417\n",
      "forward done\n",
      "tensor([0.0171, 0.1561, 0.0877, 0.6496, 0.3749], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.8974]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-356.6506]], device='cuda:0')\n",
      "sigma0 grad tensor([-448.6690], device='cuda:0')\n",
      "sigma1 grad tensor([[-363.5511]], device='cuda:0')\n",
      "gamma grad tensor([[3689.7065]], device='cuda:0')\n",
      "alpha grad tensor([[-7014.8228]], device='cuda:0')\n",
      "beta2 grad tensor([[6442.3169]], device='cuda:0')\n",
      "beta0 grad tensor([3214.4407], device='cuda:0')\n",
      "beta1 grad tensor([[4309.9785]], device='cuda:0')\n",
      "Epoch 386 | Loss: 16.7361\n",
      "alpha: 0.07680588215589523, beta0: 0.11324718594551086, beta1: -0.0008655888377688825, beta2: 0.0037825966719537973, \n",
      "gamma: 0.06437472999095917, sigma0: 0.26724764704704285, sigma1: 0.0007555877673439682, sigma2: 0.00039831551839597523, sigmaX: 0.15503686666488647\n",
      "forward done\n",
      "tensor([0.0158, 0.1135, 0.1747, 0.6422, 0.3551], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-4.8295]]], device='cuda:0')\n",
      "sigma2 grad tensor([[556.5665]], device='cuda:0')\n",
      "sigma0 grad tensor([557.7349], device='cuda:0')\n",
      "sigma1 grad tensor([[496.2822]], device='cuda:0')\n",
      "gamma grad tensor([[-4653.4253]], device='cuda:0')\n",
      "alpha grad tensor([[8831.5684]], device='cuda:0')\n",
      "beta2 grad tensor([[-9045.1475]], device='cuda:0')\n",
      "beta0 grad tensor([-4034.4365], device='cuda:0')\n",
      "beta1 grad tensor([[-5717.7393]], device='cuda:0')\n",
      "Epoch 387 | Loss: 12.5371\n",
      "alpha: 0.07682177424430847, beta0: 0.11323753744363785, beta1: -0.0008722938946448267, beta2: 0.0037824800238013268, \n",
      "gamma: 0.06436880677938461, sigma0: 0.26725029945373535, sigma1: 0.0007568811415694654, sigma2: 0.0003984615614172071, sigmaX: 0.15503697097301483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0165, 0.1173, 0.4314, 0.6538, 0.3813], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.2634]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-380.5642]], device='cuda:0')\n",
      "sigma0 grad tensor([-472.8592], device='cuda:0')\n",
      "sigma1 grad tensor([[-390.2278]], device='cuda:0')\n",
      "gamma grad tensor([[3626.1221]], device='cuda:0')\n",
      "alpha grad tensor([[-7024.7344]], device='cuda:0')\n",
      "beta2 grad tensor([[6700.2471]], device='cuda:0')\n",
      "beta0 grad tensor([3264.9746], device='cuda:0')\n",
      "beta1 grad tensor([[4435.3623]], device='cuda:0')\n",
      "Epoch 388 | Loss: 13.2123\n",
      "alpha: 0.07690473645925522, beta0: 0.11319716274738312, beta1: -0.0009220115607604384, beta2: 0.0037153842858970165, \n",
      "gamma: 0.06432780623435974, sigma0: 0.2672571539878845, sigma1: 0.000761818140745163, sigma2: 0.0004023840301670134, sigmaX: 0.155037060379982\n",
      "forward done\n",
      "tensor([0.0069, 0.0735, 0.2488, 0.6182, 0.3699], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.0439]]], device='cuda:0')\n",
      "sigma2 grad tensor([[202.7401]], device='cuda:0')\n",
      "sigma0 grad tensor([250.8328], device='cuda:0')\n",
      "sigma1 grad tensor([[195.6139]], device='cuda:0')\n",
      "gamma grad tensor([[-2784.5032]], device='cuda:0')\n",
      "alpha grad tensor([[5135.2725]], device='cuda:0')\n",
      "beta2 grad tensor([[-4830.1216]], device='cuda:0')\n",
      "beta0 grad tensor([-2248.0271], device='cuda:0')\n",
      "beta1 grad tensor([[-3112.2410]], device='cuda:0')\n",
      "Epoch 389 | Loss: 8.5913\n",
      "alpha: 0.07691974937915802, beta0: 0.11318734288215637, beta1: -0.0009306633146479726, beta2: 0.0037100089248269796, \n",
      "gamma: 0.06432285159826279, sigma0: 0.2672601342201233, sigma1: 0.0007638115785084665, sigma2: 0.0004034946032334119, sigmaX: 0.15503714978694916\n",
      "forward done\n",
      "tensor([0.0252, 0.0584, 0.2201, 0.6640, 0.3280], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.9868]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-337.6111]], device='cuda:0')\n",
      "sigma0 grad tensor([-302.4394], device='cuda:0')\n",
      "sigma1 grad tensor([[-283.5969]], device='cuda:0')\n",
      "gamma grad tensor([[1463.0641]], device='cuda:0')\n",
      "alpha grad tensor([[-3136.7158]], device='cuda:0')\n",
      "beta2 grad tensor([[3799.9790]], device='cuda:0')\n",
      "beta0 grad tensor([1590.5425], device='cuda:0')\n",
      "beta1 grad tensor([[2322.0308]], device='cuda:0')\n",
      "Epoch 390 | Loss: 7.0771\n",
      "alpha: 0.07696312665939331, beta0: 0.11316358298063278, beta1: -0.0009608049876987934, beta2: 0.003667708719149232, \n",
      "gamma: 0.06430425494909286, sigma0: 0.26726552844047546, sigma1: 0.0007682422874495387, sigma2: 0.0004077591875102371, sigmaX: 0.15503723919391632\n",
      "forward done\n",
      "tensor([0.0085, 0.1296, 0.1109, 0.6690, 0.3934], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.1639]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-252.6837]], device='cuda:0')\n",
      "sigma0 grad tensor([-478.8960], device='cuda:0')\n",
      "sigma1 grad tensor([[-332.6580]], device='cuda:0')\n",
      "gamma grad tensor([[3827.0808]], device='cuda:0')\n",
      "alpha grad tensor([[-7345.3247]], device='cuda:0')\n",
      "beta2 grad tensor([[6476.0591]], device='cuda:0')\n",
      "beta0 grad tensor([3399.4214], device='cuda:0')\n",
      "beta1 grad tensor([[4445.8525]], device='cuda:0')\n",
      "Epoch 391 | Loss: 14.1419\n",
      "alpha: 0.07707128673791885, beta0: 0.11311057955026627, beta1: -0.0010293768718838692, beta2: 0.0035691079683601856, \n",
      "gamma: 0.06425110995769501, sigma0: 0.2672746479511261, sigma1: 0.0007751134689897299, sigma2: 0.0004136976785957813, sigmaX: 0.1550373136997223\n",
      "forward done\n",
      "tensor([0.0123, 0.0860, 0.1831, 0.6581, 0.3695], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.8316]]], device='cuda:0')\n",
      "sigma2 grad tensor([[547.2281]], device='cuda:0')\n",
      "sigma0 grad tensor([530.3290], device='cuda:0')\n",
      "sigma1 grad tensor([[489.9270]], device='cuda:0')\n",
      "gamma grad tensor([[-4529.8750]], device='cuda:0')\n",
      "alpha grad tensor([[8596.8867]], device='cuda:0')\n",
      "beta2 grad tensor([[-8762.8457]], device='cuda:0')\n",
      "beta0 grad tensor([-3927.1399], device='cuda:0')\n",
      "beta1 grad tensor([[-5555.1895]], device='cuda:0')\n",
      "Epoch 392 | Loss: 9.8264\n",
      "alpha: 0.07707184553146362, beta0: 0.11310745030641556, beta1: -0.0010286824544891715, beta2: 0.003577855881303549, \n",
      "gamma: 0.06425388902425766, sigma0: 0.2672766447067261, sigma1: 0.0007757111452519894, sigma2: 0.0004129761946387589, sigmaX: 0.15503738820552826\n",
      "forward done\n",
      "tensor([0.0092, 0.0927, 0.1631, 0.6379, 0.3775], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.0195]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-360.6951]], device='cuda:0')\n",
      "sigma0 grad tensor([-451.6638], device='cuda:0')\n",
      "sigma1 grad tensor([[-364.3615]], device='cuda:0')\n",
      "gamma grad tensor([[3402.8574]], device='cuda:0')\n",
      "alpha grad tensor([[-6640.9546]], device='cuda:0')\n",
      "beta2 grad tensor([[6359.2427]], device='cuda:0')\n",
      "beta0 grad tensor([3108.6685], device='cuda:0')\n",
      "beta1 grad tensor([[4193.7085]], device='cuda:0')\n",
      "Epoch 393 | Loss: 10.4618\n",
      "alpha: 0.07713869959115982, beta0: 0.11307386308908463, beta1: -0.0010700640268623829, beta2: 0.0035212617367506027, \n",
      "gamma: 0.06422208249568939, sigma0: 0.26728275418281555, sigma1: 0.0007798328879289329, sigma2: 0.0004160059615969658, sigmaX: 0.15503746271133423\n",
      "forward done\n",
      "tensor([0.0132, 0.0357, 0.2280, 0.6235, 0.3726], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.5798]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-388.3623]], device='cuda:0')\n",
      "sigma0 grad tensor([-340.7157], device='cuda:0')\n",
      "sigma1 grad tensor([[-321.7874]], device='cuda:0')\n",
      "gamma grad tensor([[1952.4019]], device='cuda:0')\n",
      "alpha grad tensor([[-3991.5713]], device='cuda:0')\n",
      "beta2 grad tensor([[4620.6426]], device='cuda:0')\n",
      "beta0 grad tensor([1954.0743], device='cuda:0')\n",
      "beta1 grad tensor([[2838.5293]], device='cuda:0')\n",
      "Epoch 394 | Loss: 4.8098\n",
      "alpha: 0.07723210006952286, beta0: 0.11302745342254639, beta1: -0.0011315545998513699, beta2: 0.003429780015721917, \n",
      "gamma: 0.06417711824178696, sigma0: 0.26729103922843933, sigma1: 0.0007863481296226382, sigma2: 0.00042231340194121003, sigmaX: 0.1550375372171402\n",
      "forward done\n",
      "tensor([0.0060, 0.0742, 0.3280, 0.5875, 0.3527], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.7070]]], device='cuda:0')\n",
      "sigma2 grad tensor([[81.3050]], device='cuda:0')\n",
      "sigma0 grad tensor([128.0783], device='cuda:0')\n",
      "sigma1 grad tensor([[94.2935]], device='cuda:0')\n",
      "gamma grad tensor([[-2113.0518]], device='cuda:0')\n",
      "alpha grad tensor([[3749.0249]], device='cuda:0')\n",
      "beta2 grad tensor([[-3310.8154]], device='cuda:0')\n",
      "beta0 grad tensor([-1559.3306], device='cuda:0')\n",
      "beta1 grad tensor([[-2149.1304]], device='cuda:0')\n",
      "Epoch 395 | Loss: 8.6985\n",
      "alpha: 0.07726933062076569, beta0: 0.11300591379404068, beta1: -0.0011592557420954108, beta2: 0.0033897028770297766, \n",
      "gamma: 0.06416227668523788, sigma0: 0.2672964036464691, sigma1: 0.0007906174287199974, sigma2: 0.00042654629214666784, sigmaX: 0.15503761172294617\n",
      "forward done\n",
      "tensor([0.0146, 0.0935, 0.3437, 0.5962, 0.3380], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.6829]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-522.5227]], device='cuda:0')\n",
      "sigma0 grad tensor([-484.3134], device='cuda:0')\n",
      "sigma1 grad tensor([[-440.2124]], device='cuda:0')\n",
      "gamma grad tensor([[3904.9841]], device='cuda:0')\n",
      "alpha grad tensor([[-7483.3608]], device='cuda:0')\n",
      "beta2 grad tensor([[8031.8950]], device='cuda:0')\n",
      "beta0 grad tensor([3452.9729], device='cuda:0')\n",
      "beta1 grad tensor([[4942.3052]], device='cuda:0')\n",
      "Epoch 396 | Loss: 10.6439\n",
      "alpha: 0.0773739442229271, beta0: 0.11295415461063385, beta1: -0.0012308397563174367, beta2: 0.0032773222774267197, \n",
      "gamma: 0.06411135196685791, sigma0: 0.26730552315711975, sigma1: 0.0007984349504113197, sigma2: 0.0004351578245405108, sigmaX: 0.15503770112991333\n",
      "forward done\n",
      "tensor([0.0136, 0.0311, 0.1096, 0.6774, 0.3667], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.8112]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-105.6706]], device='cuda:0')\n",
      "sigma0 grad tensor([-94.8328], device='cuda:0')\n",
      "sigma1 grad tensor([[-88.6281]], device='cuda:0')\n",
      "gamma grad tensor([[-336.0160]], device='cuda:0')\n",
      "alpha grad tensor([[319.9592]], device='cuda:0')\n",
      "beta2 grad tensor([[56.1224]], device='cuda:0')\n",
      "beta0 grad tensor([26.6366], device='cuda:0')\n",
      "beta1 grad tensor([[35.5007]], device='cuda:0')\n",
      "Epoch 397 | Loss: 4.2729\n",
      "alpha: 0.07745444029569626, beta0: 0.11291248351335526, beta1: -0.0012884619645774364, beta2: 0.003186856396496296, \n",
      "gamma: 0.06407397240400314, sigma0: 0.26731377840042114, sigma1: 0.0008055752841755748, sigma2: 0.0004431037523318082, sigmaX: 0.1550377905368805\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0110, 0.1351, 0.3008, 0.6148, 0.3415], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-3.5730]]], device='cuda:0')\n",
      "sigma2 grad tensor([[636.4149]], device='cuda:0')\n",
      "sigma0 grad tensor([590.6594], device='cuda:0')\n",
      "sigma1 grad tensor([[555.7773]], device='cuda:0')\n",
      "gamma grad tensor([[-5041.5752]], device='cuda:0')\n",
      "alpha grad tensor([[9551.9248]], device='cuda:0')\n",
      "beta2 grad tensor([[-10581.8945]], device='cuda:0')\n",
      "beta0 grad tensor([-4370.2969], device='cuda:0')\n",
      "beta1 grad tensor([[-6428.5049]], device='cuda:0')\n",
      "Epoch 398 | Loss: 14.7756\n",
      "alpha: 0.07742331922054291, beta0: 0.11292284727096558, beta1: -0.001270274631679058, beta2: 0.003220302751287818, \n",
      "gamma: 0.06409448385238647, sigma0: 0.26731446385383606, sigma1: 0.0008057297673076391, sigma2: 0.0004430963599588722, sigmaX: 0.15503789484500885\n",
      "forward done\n",
      "tensor([0.0156, 0.1373, 0.2134, 0.5634, 0.2783], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.8967]]], device='cuda:0')\n",
      "sigma2 grad tensor([[740.9954]], device='cuda:0')\n",
      "sigma0 grad tensor([614.4528], device='cuda:0')\n",
      "sigma1 grad tensor([[585.9465]], device='cuda:0')\n",
      "gamma grad tensor([[-5267.5581]], device='cuda:0')\n",
      "alpha grad tensor([[9888.6533]], device='cuda:0')\n",
      "beta2 grad tensor([[-11140.5635]], device='cuda:0')\n",
      "beta0 grad tensor([-4499.3628], device='cuda:0')\n",
      "beta1 grad tensor([[-6674.4746]], device='cuda:0')\n",
      "Epoch 399 | Loss: 14.8003\n",
      "alpha: 0.07729953527450562, beta0: 0.11297613382339478, beta1: -0.001188980066217482, beta2: 0.003358465386554599, \n",
      "gamma: 0.06416356563568115, sigma0: 0.2673088610172272, sigma1: 0.0007999938679859042, sigma2: 0.00043568050023168325, sigmaX: 0.155037984251976\n",
      "forward done\n",
      "tensor([0.0063, 0.0518, 0.2070, 0.6692, 0.3940], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.9466]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-46.5992]], device='cuda:0')\n",
      "sigma0 grad tensor([7.7504], device='cuda:0')\n",
      "sigma1 grad tensor([[-16.6967]], device='cuda:0')\n",
      "gamma grad tensor([[-1079.6542]], device='cuda:0')\n",
      "alpha grad tensor([[1795.0546]], device='cuda:0')\n",
      "beta2 grad tensor([[-1340.8440]], device='cuda:0')\n",
      "beta0 grad tensor([-669.8420], device='cuda:0')\n",
      "beta1 grad tensor([[-895.7935]], device='cuda:0')\n",
      "Epoch 400 | Loss: 6.4528\n",
      "alpha: 0.07718255370855331, beta0: 0.11302545666694641, beta1: -0.0011149864876642823, beta2: 0.0034824039321392775, \n",
      "gamma: 0.06422962993383408, sigma0: 0.26730430126190186, sigma1: 0.0007955721230246127, sigma2: 0.0004302137822378427, sigmaX: 0.15503807365894318\n",
      "forward done\n",
      "tensor([0.0080, 0.0829, 0.0908, 0.6430, 0.3711], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.2572]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-420.8995]], device='cuda:0')\n",
      "sigma0 grad tensor([-508.3133], device='cuda:0')\n",
      "sigma1 grad tensor([[-409.2820]], device='cuda:0')\n",
      "gamma grad tensor([[3887.8406]], device='cuda:0')\n",
      "alpha grad tensor([[-7556.9971]], device='cuda:0')\n",
      "beta2 grad tensor([[7180.9258]], device='cuda:0')\n",
      "beta0 grad tensor([3525.6792], device='cuda:0')\n",
      "beta1 grad tensor([[4740.0078]], device='cuda:0')\n",
      "Epoch 401 | Loss: 9.4006\n",
      "alpha: 0.07716453820466995, beta0: 0.11302965879440308, beta1: -0.0011031916365027428, beta2: 0.003509745467454195, \n",
      "gamma: 0.06424359977245331, sigma0: 0.26730573177337646, sigma1: 0.000796127540525049, sigma2: 0.00043004940380342305, sigmaX: 0.15503817796707153\n",
      "forward done\n",
      "tensor([0.0125, 0.0834, 0.1291, 0.6861, 0.3958], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.8069]]], device='cuda:0')\n",
      "sigma2 grad tensor([[365.0729]], device='cuda:0')\n",
      "sigma0 grad tensor([481.6401], device='cuda:0')\n",
      "sigma1 grad tensor([[388.4423]], device='cuda:0')\n",
      "gamma grad tensor([[-4693.7637]], device='cuda:0')\n",
      "alpha grad tensor([[8699.7402]], device='cuda:0')\n",
      "beta2 grad tensor([[-8696.0186]], device='cuda:0')\n",
      "beta0 grad tensor([-3887.3142], device='cuda:0')\n",
      "beta1 grad tensor([[-5519.1602]], device='cuda:0')\n",
      "Epoch 402 | Loss: 9.5598\n",
      "alpha: 0.07706312835216522, beta0: 0.11307189613580704, beta1: -0.0010385641362518072, beta2: 0.0036185788922011852, \n",
      "gamma: 0.06430171430110931, sigma0: 0.2673020660877228, sigma1: 0.000792687467765063, sigma2: 0.00042626718641258776, sigmaX: 0.1550382822751999\n",
      "forward done\n",
      "tensor([0.0052, 0.0646, 0.3630, 0.6118, 0.3505], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.6419]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-283.1567]], device='cuda:0')\n",
      "sigma0 grad tensor([-298.9098], device='cuda:0')\n",
      "sigma1 grad tensor([[-259.6442]], device='cuda:0')\n",
      "gamma grad tensor([[1846.9297]], device='cuda:0')\n",
      "alpha grad tensor([[-3726.9785]], device='cuda:0')\n",
      "beta2 grad tensor([[3885.5117]], device='cuda:0')\n",
      "beta0 grad tensor([1809.1466], device='cuda:0')\n",
      "beta1 grad tensor([[2508.2085]], device='cuda:0')\n",
      "Epoch 403 | Loss: 7.7916\n",
      "alpha: 0.07701927423477173, beta0: 0.11308759450912476, beta1: -0.0010119442595168948, beta2: 0.0036667906679213047, \n",
      "gamma: 0.06432973593473434, sigma0: 0.26730212569236755, sigma1: 0.0007925318204797804, sigma2: 0.00042607297655195, sigmaX: 0.15503837168216705\n",
      "forward done\n",
      "tensor([0.0140, 0.0352, 0.1075, 0.6825, 0.3971], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.9049]]], device='cuda:0')\n",
      "sigma2 grad tensor([[174.4338]], device='cuda:0')\n",
      "sigma0 grad tensor([185.2975], device='cuda:0')\n",
      "sigma1 grad tensor([[162.9288]], device='cuda:0')\n",
      "gamma grad tensor([[-2393.8071]], device='cuda:0')\n",
      "alpha grad tensor([[4316.1606]], device='cuda:0')\n",
      "beta2 grad tensor([[-4187.7739]], device='cuda:0')\n",
      "beta0 grad tensor([-1844.1656], device='cuda:0')\n",
      "beta1 grad tensor([[-2630.3889]], device='cuda:0')\n",
      "Epoch 404 | Loss: 4.7228\n",
      "alpha: 0.07694102823734283, beta0: 0.11311859637498856, beta1: -0.0009643444791436195, beta2: 0.0037472378462553024, \n",
      "gamma: 0.0643760934472084, sigma0: 0.2673003077507019, sigma1: 0.0007907780236564577, sigma2: 0.0004241732822265476, sigmaX: 0.15503846108913422\n",
      "forward done\n",
      "tensor([0.0179, 0.2076, 0.1194, 0.7184, 0.4235], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.5352]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-338.0093]], device='cuda:0')\n",
      "sigma0 grad tensor([-428.2469], device='cuda:0')\n",
      "sigma1 grad tensor([[-344.9402]], device='cuda:0')\n",
      "gamma grad tensor([[3344.9548]], device='cuda:0')\n",
      "alpha grad tensor([[-6484.4009]], device='cuda:0')\n",
      "beta2 grad tensor([[5957.3901]], device='cuda:0')\n",
      "beta0 grad tensor([3015.1116], device='cuda:0')\n",
      "beta1 grad tensor([[4018.5217]], device='cuda:0')\n",
      "Epoch 405 | Loss: 22.0424\n",
      "alpha: 0.0769432783126831, beta0: 0.11311324685811996, beta1: -0.0009664498502388597, beta2: 0.003752021584659815, \n",
      "gamma: 0.0643797293305397, sigma0: 0.26730313897132874, sigma1: 0.0007928243721835315, sigma2: 0.000426033599069342, sigmaX: 0.15503853559494019\n",
      "forward done\n",
      "tensor([0.0317, 0.3309, 0.3348, 0.6717, 0.3857], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.3927]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-206.6163]], device='cuda:0')\n",
      "sigma0 grad tensor([-377.1858], device='cuda:0')\n",
      "sigma1 grad tensor([[-249.1273]], device='cuda:0')\n",
      "gamma grad tensor([[2734.2876]], device='cuda:0')\n",
      "alpha grad tensor([[-5418.4473]], device='cuda:0')\n",
      "beta2 grad tensor([[4382.4932]], device='cuda:0')\n",
      "beta0 grad tensor([2561.5059], device='cuda:0')\n",
      "beta1 grad tensor([[3158.7939]], device='cuda:0')\n",
      "Epoch 406 | Loss: 34.5145\n",
      "alpha: 0.07699926197528839, beta0: 0.11308334767818451, beta1: -0.0009997220477089286, beta2: 0.0037120236083865166, \n",
      "gamma: 0.06435529887676239, sigma0: 0.26730918884277344, sigma1: 0.0007969527505338192, sigma2: 0.00042958802077919245, sigmaX: 0.15503861010074615\n",
      "forward done\n",
      "tensor([0.0083, 0.1606, 0.1486, 0.6540, 0.3854], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.3680]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-335.3037]], device='cuda:0')\n",
      "sigma0 grad tensor([-464.3259], device='cuda:0')\n",
      "sigma1 grad tensor([[-359.1545]], device='cuda:0')\n",
      "gamma grad tensor([[3506.7126]], device='cuda:0')\n",
      "alpha grad tensor([[-6820.2607]], device='cuda:0')\n",
      "beta2 grad tensor([[6090.0737]], device='cuda:0')\n",
      "beta0 grad tensor([3191.3210], device='cuda:0')\n",
      "beta1 grad tensor([[4176.1724]], device='cuda:0')\n",
      "Epoch 407 | Loss: 17.2584\n",
      "alpha: 0.07711225003004074, beta0: 0.11302752047777176, beta1: -0.0010681016137823462, beta2: 0.0036191244143992662, \n",
      "gamma: 0.06430068612098694, sigma0: 0.2673186659812927, sigma1: 0.0008038469823077321, sigma2: 0.000435784604633227, sigmaX: 0.15503869950771332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0101, 0.0977, 0.3109, 0.6422, 0.3692], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.9445]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-447.8166]], device='cuda:0')\n",
      "sigma0 grad tensor([-487.4854], device='cuda:0')\n",
      "sigma1 grad tensor([[-416.0334]], device='cuda:0')\n",
      "gamma grad tensor([[3836.9546]], device='cuda:0')\n",
      "alpha grad tensor([[-7389.3726]], device='cuda:0')\n",
      "beta2 grad tensor([[7333.8633]], device='cuda:0')\n",
      "beta0 grad tensor([3420.3689], device='cuda:0')\n",
      "beta1 grad tensor([[4733.6108]], device='cuda:0')\n",
      "Epoch 408 | Loss: 11.1035\n",
      "alpha: 0.07727653533220291, beta0: 0.11294865608215332, beta1: -0.001170141389593482, beta2: 0.0034714664798229933, \n",
      "gamma: 0.06421862542629242, sigma0: 0.2673311233520508, sigma1: 0.000813522725366056, sigma2: 0.0004452200373634696, sigmaX: 0.15503878891468048\n",
      "forward done\n",
      "tensor([0.0132, 0.1292, 0.1877, 0.6021, 0.3605], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-4.2675]]], device='cuda:0')\n",
      "sigma2 grad tensor([[632.6683]], device='cuda:0')\n",
      "sigma0 grad tensor([560.2681], device='cuda:0')\n",
      "sigma1 grad tensor([[536.3125]], device='cuda:0')\n",
      "gamma grad tensor([[-5357.3638]], device='cuda:0')\n",
      "alpha grad tensor([[9914.5088]], device='cuda:0')\n",
      "beta2 grad tensor([[-10387.2236]], device='cuda:0')\n",
      "beta0 grad tensor([-4450.7339], device='cuda:0')\n",
      "beta1 grad tensor([[-6438.6226]], device='cuda:0')\n",
      "Epoch 409 | Loss: 14.0801\n",
      "alpha: 0.07730881869792938, beta0: 0.112930066883564, beta1: -0.0011873869225382805, beta2: 0.0034572123549878597, \n",
      "gamma: 0.0642065480351448, sigma0: 0.2673354744911194, sigma1: 0.0008159001590684056, sigma2: 0.00044644169975072145, sigmaX: 0.15503890812397003\n",
      "forward done\n",
      "tensor([0.0109, 0.1419, 0.1579, 0.6645, 0.3727], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-4.0473]]], device='cuda:0')\n",
      "sigma2 grad tensor([[626.8860]], device='cuda:0')\n",
      "sigma0 grad tensor([577.0170], device='cuda:0')\n",
      "sigma1 grad tensor([[535.6019]], device='cuda:0')\n",
      "gamma grad tensor([[-5272.9077]], device='cuda:0')\n",
      "alpha grad tensor([[9860.9932]], device='cuda:0')\n",
      "beta2 grad tensor([[-10287.6475]], device='cuda:0')\n",
      "beta0 grad tensor([-4459.3301], device='cuda:0')\n",
      "beta1 grad tensor([[-6399.9648]], device='cuda:0')\n",
      "Epoch 410 | Loss: 15.3917\n",
      "alpha: 0.07723603397607803, beta0: 0.11295978724956512, beta1: -0.0011371837463229895, beta2: 0.00354868546128273, \n",
      "gamma: 0.06424961984157562, sigma0: 0.26733317971229553, sigma1: 0.0008124461164698005, sigma2: 0.00044115015771239996, sigmaX: 0.15503904223442078\n",
      "forward done\n",
      "tensor([0.0111, 0.0489, 0.3630, 0.6284, 0.3646], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.1195]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-101.8073]], device='cuda:0')\n",
      "sigma0 grad tensor([-82.5750], device='cuda:0')\n",
      "sigma1 grad tensor([[-82.2263]], device='cuda:0')\n",
      "gamma grad tensor([[-334.9017]], device='cuda:0')\n",
      "alpha grad tensor([[338.0168]], device='cuda:0')\n",
      "beta2 grad tensor([[27.5993]], device='cuda:0')\n",
      "beta0 grad tensor([3.2346], device='cuda:0')\n",
      "beta1 grad tensor([[13.1935]], device='cuda:0')\n",
      "Epoch 411 | Loss: 6.2569\n",
      "alpha: 0.07717442512512207, beta0: 0.11298353224992752, beta1: -0.0010971531737595797, beta2: 0.003621587995439768, \n",
      "gamma: 0.06428742408752441, sigma0: 0.26733219623565674, sigma1: 0.00081050512380898, sigma2: 0.0004379349993541837, sigmaX: 0.15503916144371033\n",
      "forward done\n",
      "tensor([0.0148, 0.0617, 0.1810, 0.6522, 0.3655], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.6397]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-522.5118]], device='cuda:0')\n",
      "sigma0 grad tensor([-503.5746], device='cuda:0')\n",
      "sigma1 grad tensor([[-453.7164]], device='cuda:0')\n",
      "gamma grad tensor([[3844.7312]], device='cuda:0')\n",
      "alpha grad tensor([[-7416.0054]], device='cuda:0')\n",
      "beta2 grad tensor([[7857.6309]], device='cuda:0')\n",
      "beta0 grad tensor([3441.8982], device='cuda:0')\n",
      "beta1 grad tensor([[4908.3276]], device='cuda:0')\n",
      "Epoch 412 | Loss: 7.3841\n",
      "alpha: 0.0771993026137352, beta0: 0.11296810954809189, beta1: -0.0011142119765281677, beta2: 0.003601333824917674, \n",
      "gamma: 0.0642792209982872, sigma0: 0.2673364281654358, sigma1: 0.0008134894887916744, sigma2: 0.0004405879881232977, sigmaX: 0.15503926575183868\n",
      "forward done\n",
      "tensor([0.0117, 0.0164, 0.5307, 0.6108, 0.3166], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[0.2012]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-276.1210]], device='cuda:0')\n",
      "sigma0 grad tensor([-236.4596], device='cuda:0')\n",
      "sigma1 grad tensor([[-224.8116]], device='cuda:0')\n",
      "gamma grad tensor([[1386.9354]], device='cuda:0')\n",
      "alpha grad tensor([[-2765.7783]], device='cuda:0')\n",
      "beta2 grad tensor([[3166.4131]], device='cuda:0')\n",
      "beta0 grad tensor([1354.3505], device='cuda:0')\n",
      "beta1 grad tensor([[1951.0034]], device='cuda:0')\n",
      "Epoch 413 | Loss: 3.1092\n",
      "alpha: 0.07724685966968536, beta0: 0.11294222623109818, beta1: -0.0011473690392449498, beta2: 0.0035534664057195187, \n",
      "gamma: 0.06425879150629044, sigma0: 0.2673421800136566, sigma1: 0.000818125088699162, sigma2: 0.00044547158177010715, sigmaX: 0.15503935515880585\n",
      "forward done\n",
      "tensor([0.0209, 0.1290, 0.2073, 0.6629, 0.3858], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.4697]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-405.5658]], device='cuda:0')\n",
      "sigma0 grad tensor([-471.1273], device='cuda:0')\n",
      "sigma1 grad tensor([[-384.7596]], device='cuda:0')\n",
      "gamma grad tensor([[3784.0381]], device='cuda:0')\n",
      "alpha grad tensor([[-7274.9434]], device='cuda:0')\n",
      "beta2 grad tensor([[7151.6514]], device='cuda:0')\n",
      "beta0 grad tensor([3363.2141], device='cuda:0')\n",
      "beta1 grad tensor([[4617.3457]], device='cuda:0')\n",
      "Epoch 414 | Loss: 14.1729\n",
      "alpha: 0.07735765725374222, beta0: 0.11288788914680481, beta1: -0.001220068195834756, beta2: 0.003443655790761113, \n",
      "gamma: 0.06420460343360901, sigma0: 0.26735150814056396, sigma1: 0.000825681199785322, sigma2: 0.0004534341278485954, sigmaX: 0.155039444565773\n",
      "forward done\n",
      "tensor([0.0120, 0.0415, 0.2361, 0.6268, 0.3705], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.5967]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-249.9798]], device='cuda:0')\n",
      "sigma0 grad tensor([-256.4540], device='cuda:0')\n",
      "sigma1 grad tensor([[-224.5893]], device='cuda:0')\n",
      "gamma grad tensor([[1198.5006]], device='cuda:0')\n",
      "alpha grad tensor([[-2586.9622]], device='cuda:0')\n",
      "beta2 grad tensor([[2950.4211]], device='cuda:0')\n",
      "beta0 grad tensor([1331.1714], device='cuda:0')\n",
      "beta1 grad tensor([[1877.2598]], device='cuda:0')\n",
      "Epoch 415 | Loss: 5.3946\n",
      "alpha: 0.07747216522693634, beta0: 0.11283110827207565, beta1: -0.0012970000971108675, beta2: 0.003326303092762828, \n",
      "gamma: 0.06414926797151566, sigma0: 0.26736152172088623, sigma1: 0.0008339719497598708, sigma2: 0.00046230395673774183, sigmaX: 0.15503954887390137\n",
      "forward done\n",
      "tensor([0.0120, 0.0488, 0.2834, 0.6624, 0.4182], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.6952]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-41.0156]], device='cuda:0')\n",
      "sigma0 grad tensor([2.4912], device='cuda:0')\n",
      "sigma1 grad tensor([[-16.3613]], device='cuda:0')\n",
      "gamma grad tensor([[-1126.0964]], device='cuda:0')\n",
      "alpha grad tensor([[1835.1246]], device='cuda:0')\n",
      "beta2 grad tensor([[-1510.3535]], device='cuda:0')\n",
      "beta0 grad tensor([-671.9832], device='cuda:0')\n",
      "beta1 grad tensor([[-951.1508]], device='cuda:0')\n",
      "Epoch 416 | Loss: 6.2566\n",
      "alpha: 0.0775454193353653, beta0: 0.11279240250587463, beta1: -0.0013490341370925307, beta2: 0.0032475246116518974, \n",
      "gamma: 0.06411626189947128, sigma0: 0.26736950874328613, sigma1: 0.0008407681598328054, sigma2: 0.00046980998013168573, sigmaX: 0.15503965318202972\n",
      "forward done\n",
      "tensor([0.0108, 0.0927, 0.1518, 0.6833, 0.3846], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-3.6886]]], device='cuda:0')\n",
      "sigma2 grad tensor([[513.0606]], device='cuda:0')\n",
      "sigma0 grad tensor([551.4178], device='cuda:0')\n",
      "sigma1 grad tensor([[485.9008]], device='cuda:0')\n",
      "gamma grad tensor([[-5472.9663]], device='cuda:0')\n",
      "alpha grad tensor([[10107.5771]], device='cuda:0')\n",
      "beta2 grad tensor([[-10377.0469]], device='cuda:0')\n",
      "beta0 grad tensor([-4536.8213], device='cuda:0')\n",
      "beta1 grad tensor([[-6502.2109]], device='cuda:0')\n",
      "Epoch 417 | Loss: 10.5027\n",
      "alpha: 0.07750294357538223, beta0: 0.11280680447816849, beta1: -0.001325639197602868, beta2: 0.003288272302597761, \n",
      "gamma: 0.06414458900690079, sigma0: 0.2673703730106354, sigma1: 0.0008413461619056761, sigma2: 0.0004706842009909451, sigmaX: 0.15503977239131927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0067, 0.0703, 0.1334, 0.6748, 0.4057], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.7359]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-435.4101]], device='cuda:0')\n",
      "sigma0 grad tensor([-518.0595], device='cuda:0')\n",
      "sigma1 grad tensor([[-431.1429]], device='cuda:0')\n",
      "gamma grad tensor([[4341.5640]], device='cuda:0')\n",
      "alpha grad tensor([[-8271.7207]], device='cuda:0')\n",
      "beta2 grad tensor([[8143.6162]], device='cuda:0')\n",
      "beta0 grad tensor([3798.7542], device='cuda:0')\n",
      "beta1 grad tensor([[5267.9248]], device='cuda:0')\n",
      "Epoch 418 | Loss: 8.2465\n",
      "alpha: 0.07755168527364731, beta0: 0.11278034001588821, beta1: -0.0013596025528386235, beta2: 0.0032394342124462128, \n",
      "gamma: 0.06412383168935776, sigma0: 0.26737624406814575, sigma1: 0.0008461199468001723, sigma2: 0.0004757376736961305, sigmaX: 0.15503987669944763\n",
      "forward done\n",
      "tensor([0.0071, 0.0357, 0.2749, 0.6078, 0.4002], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.8312]]], device='cuda:0')\n",
      "sigma2 grad tensor([[44.5495]], device='cuda:0')\n",
      "sigma0 grad tensor([59.0804], device='cuda:0')\n",
      "sigma1 grad tensor([[48.4243]], device='cuda:0')\n",
      "gamma grad tensor([[-1687.9717]], device='cuda:0')\n",
      "alpha grad tensor([[2918.5251]], device='cuda:0')\n",
      "beta2 grad tensor([[-2770.5771]], device='cuda:0')\n",
      "beta0 grad tensor([-1156.6694], device='cuda:0')\n",
      "beta1 grad tensor([[-1692.0842]], device='cuda:0')\n",
      "Epoch 419 | Loss: 4.8607\n",
      "alpha: 0.07756149023771286, beta0: 0.11277073621749878, beta1: -0.001369852339848876, beta2: 0.0032280695158988237, \n",
      "gamma: 0.06412410736083984, sigma0: 0.26738035678863525, sigma1: 0.0008494547219015658, sigma2: 0.0004793349653482437, sigmaX: 0.155039981007576\n",
      "forward done\n",
      "tensor([0.0200, 0.1513, 0.1912, 0.5966, 0.3477], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.2122]]], device='cuda:0')\n",
      "sigma2 grad tensor([[659.6731]], device='cuda:0')\n",
      "sigma0 grad tensor([542.3055], device='cuda:0')\n",
      "sigma1 grad tensor([[531.9830]], device='cuda:0')\n",
      "gamma grad tensor([[-5258.7495]], device='cuda:0')\n",
      "alpha grad tensor([[9762.6084]], device='cuda:0')\n",
      "beta2 grad tensor([[-11359.8135]], device='cuda:0')\n",
      "beta0 grad tensor([-4387.1904], device='cuda:0')\n",
      "beta1 grad tensor([[-6667.2456]], device='cuda:0')\n",
      "Epoch 420 | Loss: 16.2823\n",
      "alpha: 0.07747171074151993, beta0: 0.11280692368745804, beta1: -0.0013113797176629305, beta2: 0.0033325760159641504, \n",
      "gamma: 0.06417691707611084, sigma0: 0.26737821102142334, sigma1: 0.0008468027226626873, sigma2: 0.0004756160487886518, sigmaX: 0.15504008531570435\n",
      "forward done\n",
      "tensor([0.0152, 0.1906, 0.1243, 0.6798, 0.3922], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.8580]]], device='cuda:0')\n",
      "sigma2 grad tensor([[670.7120]], device='cuda:0')\n",
      "sigma0 grad tensor([635.9604], device='cuda:0')\n",
      "sigma1 grad tensor([[584.8908]], device='cuda:0')\n",
      "gamma grad tensor([[-5468.6729]], device='cuda:0')\n",
      "alpha grad tensor([[10308.4561]], device='cuda:0')\n",
      "beta2 grad tensor([[-11172.7256]], device='cuda:0')\n",
      "beta0 grad tensor([-4709.5181], device='cuda:0')\n",
      "beta1 grad tensor([[-6878.7432]], device='cuda:0')\n",
      "Epoch 421 | Loss: 20.2735\n",
      "alpha: 0.07729680091142654, beta0: 0.11288297176361084, beta1: -0.0011958142276853323, beta2: 0.0035279083531349897, \n",
      "gamma: 0.06427384912967682, sigma0: 0.2673701345920563, sigma1: 0.0008388322312384844, sigma2: 0.0004659338155761361, sigmaX: 0.1550401747226715\n",
      "forward done\n",
      "tensor([0.0151, 0.0555, 0.4040, 0.6614, 0.5267], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.4045]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-387.6737]], device='cuda:0')\n",
      "sigma0 grad tensor([-384.1872], device='cuda:0')\n",
      "sigma1 grad tensor([[-344.8200]], device='cuda:0')\n",
      "gamma grad tensor([[2695.5234]], device='cuda:0')\n",
      "alpha grad tensor([[-5292.8462]], device='cuda:0')\n",
      "beta2 grad tensor([[5740.5767]], device='cuda:0')\n",
      "beta0 grad tensor([2503.8379], device='cuda:0')\n",
      "beta1 grad tensor([[3578.1787]], device='cuda:0')\n",
      "Epoch 422 | Loss: 7.1597\n",
      "alpha: 0.07720980048179626, beta0: 0.11291877180337906, beta1: -0.001139143598265946, beta2: 0.0036267684772610664, \n",
      "gamma: 0.06432443857192993, sigma0: 0.26736751198768616, sigma1: 0.0008359040366485715, sigma2: 0.00046206475235521793, sigmaX: 0.15504024922847748\n",
      "forward done\n",
      "tensor([0.0171, 0.1218, 0.2301, 0.6920, 0.3763], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.6526]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-500.4280]], device='cuda:0')\n",
      "sigma0 grad tensor([-474.4225], device='cuda:0')\n",
      "sigma1 grad tensor([[-423.6508]], device='cuda:0')\n",
      "gamma grad tensor([[3644.7021]], device='cuda:0')\n",
      "alpha grad tensor([[-7081.5986]], device='cuda:0')\n",
      "beta2 grad tensor([[7115.6919]], device='cuda:0')\n",
      "beta0 grad tensor([3295.7754], device='cuda:0')\n",
      "beta1 grad tensor([[4557.8276]], device='cuda:0')\n",
      "Epoch 423 | Loss: 13.4978\n",
      "alpha: 0.07721101492643356, beta0: 0.11291445046663284, beta1: -0.0011393853928893805, beta2: 0.003634699620306492, \n",
      "gamma: 0.06432846188545227, sigma0: 0.26737016439437866, sigma1: 0.0008377979975193739, sigma2: 0.0004639737890101969, sigmaX: 0.15504032373428345\n",
      "forward done\n",
      "tensor([0.0074, 0.0500, 0.3742, 0.6097, 0.3933], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.2000]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-229.4502]], device='cuda:0')\n",
      "sigma0 grad tensor([-253.3467], device='cuda:0')\n",
      "sigma1 grad tensor([[-218.6812]], device='cuda:0')\n",
      "gamma grad tensor([[1116.3196]], device='cuda:0')\n",
      "alpha grad tensor([[-2460.3384]], device='cuda:0')\n",
      "beta2 grad tensor([[2663.5737]], device='cuda:0')\n",
      "beta0 grad tensor([1279.7483], device='cuda:0')\n",
      "beta1 grad tensor([[1753.3885]], device='cuda:0')\n",
      "Epoch 424 | Loss: 6.3806\n",
      "alpha: 0.0772365927696228, beta0: 0.11289820075035095, beta1: -0.0011571126524358988, beta2: 0.0036144088953733444, \n",
      "gamma: 0.06432051956653595, sigma0: 0.26737481355667114, sigma1: 0.0008414999465458095, sigma2: 0.00046779552940279245, sigmaX: 0.15504039824008942\n",
      "forward done\n",
      "tensor([0.0210, 0.0410, 0.1980, 0.6642, 0.4200], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.2806]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-191.0750]], device='cuda:0')\n",
      "sigma0 grad tensor([-167.2635], device='cuda:0')\n",
      "sigma1 grad tensor([[-158.0547]], device='cuda:0')\n",
      "gamma grad tensor([[465.1344]], device='cuda:0')\n",
      "alpha grad tensor([[-1156.5316]], device='cuda:0')\n",
      "beta2 grad tensor([[1565.7764]], device='cuda:0')\n",
      "beta0 grad tensor([673.3798], device='cuda:0')\n",
      "beta1 grad tensor([[971.7990]], device='cuda:0')\n",
      "Epoch 425 | Loss: 5.4036\n",
      "alpha: 0.07726862281560898, beta0: 0.1128784641623497, beta1: -0.0011810124851763248, beta2: 0.003582518547773361, \n",
      "gamma: 0.0643095150589943, sigma0: 0.2673802077770233, sigma1: 0.0008460420649498701, sigma2: 0.0004727636696770787, sigmaX: 0.15504047274589539\n",
      "forward done\n",
      "tensor([0.0188, 0.2019, 0.2057, 0.7162, 0.4212], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.2256]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-246.0693]], device='cuda:0')\n",
      "sigma0 grad tensor([-437.5837], device='cuda:0')\n",
      "sigma1 grad tensor([[-307.5146]], device='cuda:0')\n",
      "gamma grad tensor([[3711.2798]], device='cuda:0')\n",
      "alpha grad tensor([[-7081.4707]], device='cuda:0')\n",
      "beta2 grad tensor([[6181.6064]], device='cuda:0')\n",
      "beta0 grad tensor([3260.6465], device='cuda:0')\n",
      "beta1 grad tensor([[4239.4312]], device='cuda:0')\n",
      "Epoch 426 | Loss: 21.5522\n",
      "alpha: 0.07736505568027496, beta0: 0.11283006519079208, beta1: -0.0012425266904756427, beta2: 0.0034951900597661734, \n",
      "gamma: 0.06426359713077545, sigma0: 0.2673889100551605, sigma1: 0.0008527509053237736, sigma2: 0.000479198875837028, sigmaX: 0.15504054725170135\n",
      "forward done\n",
      "tensor([0.0092, 0.0434, 0.1189, 0.6958, 0.3988], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.5234]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-86.2962]], device='cuda:0')\n",
      "sigma0 grad tensor([-63.8943], device='cuda:0')\n",
      "sigma1 grad tensor([[-66.7421]], device='cuda:0')\n",
      "gamma grad tensor([[-546.2758]], device='cuda:0')\n",
      "alpha grad tensor([[736.8570]], device='cuda:0')\n",
      "beta2 grad tensor([[-368.8271]], device='cuda:0')\n",
      "beta0 grad tensor([-170.5832], device='cuda:0')\n",
      "beta1 grad tensor([[-238.0432]], device='cuda:0')\n",
      "Epoch 427 | Loss: 5.5669\n",
      "alpha: 0.07743483781814575, beta0: 0.11279305815696716, beta1: -0.001289357547648251, beta2: 0.0034290156327188015, \n",
      "gamma: 0.06423232704401016, sigma0: 0.2673965096473694, sigma1: 0.0008587854099459946, sigma2: 0.00048521001008339226, sigmaX: 0.15504062175750732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0137, 0.0943, 0.2351, 0.6022, 0.3962], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.6372]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-445.0059]], device='cuda:0')\n",
      "sigma0 grad tensor([-493.6982], device='cuda:0')\n",
      "sigma1 grad tensor([[-413.5880]], device='cuda:0')\n",
      "gamma grad tensor([[4130.1167]], device='cuda:0')\n",
      "alpha grad tensor([[-7875.2324]], device='cuda:0')\n",
      "beta2 grad tensor([[7850.4775]], device='cuda:0')\n",
      "beta0 grad tensor([3620.0210], device='cuda:0')\n",
      "beta1 grad tensor([[5027.0903]], device='cuda:0')\n",
      "Epoch 428 | Loss: 10.6768\n",
      "alpha: 0.07756941765546799, beta0: 0.11272724717855453, beta1: -0.0013770931400358677, beta2: 0.003297571325674653, \n",
      "gamma: 0.06416600942611694, sigma0: 0.26740753650665283, sigma1: 0.0008677488658577204, sigma2: 0.0004944689571857452, sigmaX: 0.1550406813621521\n",
      "forward done\n",
      "tensor([0.0110, 0.1029, 0.2710, 0.6179, 0.3655], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-3.8895]]], device='cuda:0')\n",
      "sigma2 grad tensor([[595.8818]], device='cuda:0')\n",
      "sigma0 grad tensor([569.6482], device='cuda:0')\n",
      "sigma1 grad tensor([[518.3475]], device='cuda:0')\n",
      "gamma grad tensor([[-5019.9897]], device='cuda:0')\n",
      "alpha grad tensor([[9468.1084]], device='cuda:0')\n",
      "beta2 grad tensor([[-10222.1240]], device='cuda:0')\n",
      "beta0 grad tensor([-4315.8892], device='cuda:0')\n",
      "beta1 grad tensor([[-6282.0488]], device='cuda:0')\n",
      "Epoch 429 | Loss: 11.5524\n",
      "alpha: 0.07758239656686783, beta0: 0.11271776258945465, beta1: -0.0013844611821696162, beta2: 0.003294637193903327, \n",
      "gamma: 0.06416315585374832, sigma0: 0.26741063594818115, sigma1: 0.000869736191816628, sigma2: 0.0004959172802045941, sigmaX: 0.15504077076911926\n",
      "forward done\n",
      "tensor([0.0148, 0.1083, 0.1506, 0.6842, 0.3912], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.9542]]], device='cuda:0')\n",
      "sigma2 grad tensor([[555.7856]], device='cuda:0')\n",
      "sigma0 grad tensor([561.1306], device='cuda:0')\n",
      "sigma1 grad tensor([[512.2728]], device='cuda:0')\n",
      "gamma grad tensor([[-5422.4834]], device='cuda:0')\n",
      "alpha grad tensor([[10070.1133]], device='cuda:0')\n",
      "beta2 grad tensor([[-10604.6504]], device='cuda:0')\n",
      "beta0 grad tensor([-4531.9297], device='cuda:0')\n",
      "beta1 grad tensor([[-6591.6768]], device='cuda:0')\n",
      "Epoch 430 | Loss: 12.0739\n",
      "alpha: 0.07749208062887192, beta0: 0.11275549232959747, beta1: -0.0013244388392195106, beta2: 0.003398336237296462, \n",
      "gamma: 0.06421509385108948, sigma0: 0.26740750670433044, sigma1: 0.000866203336045146, sigma2: 0.000491518119815737, sigmaX: 0.15504086017608643\n",
      "forward done\n",
      "tensor([0.0230, 0.2928, 0.2226, 0.5956, 0.3592], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.1730]]], device='cuda:0')\n",
      "sigma2 grad tensor([[872.0812]], device='cuda:0')\n",
      "sigma0 grad tensor([662.1361], device='cuda:0')\n",
      "sigma1 grad tensor([[681.5780]], device='cuda:0')\n",
      "gamma grad tensor([[-5589.1919]], device='cuda:0')\n",
      "alpha grad tensor([[10576.2354]], device='cuda:0')\n",
      "beta2 grad tensor([[-12900.2725]], device='cuda:0')\n",
      "beta0 grad tensor([-4829.9370], device='cuda:0')\n",
      "beta1 grad tensor([[-7481.8638]], device='cuda:0')\n",
      "Epoch 431 | Loss: 30.4809\n",
      "alpha: 0.07731406390666962, beta0: 0.11283397674560547, beta1: -0.0012016022810712457, beta2: 0.0036102982703596354, \n",
      "gamma: 0.06431253999471664, sigma0: 0.2673983871936798, sigma1: 0.0008565612370148301, sigma2: 0.00047927795094437897, sigmaX: 0.1550409495830536\n",
      "forward done\n",
      "tensor([0.0091, 0.0586, 0.3393, 0.6238, 0.4133], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.1050]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-232.9729]], device='cuda:0')\n",
      "sigma0 grad tensor([-267.7166], device='cuda:0')\n",
      "sigma1 grad tensor([[-225.5534]], device='cuda:0')\n",
      "gamma grad tensor([[1349.5721]], device='cuda:0')\n",
      "alpha grad tensor([[-2874.4561]], device='cuda:0')\n",
      "beta2 grad tensor([[3062.7979]], device='cuda:0')\n",
      "beta0 grad tensor([1455.0913], device='cuda:0')\n",
      "beta1 grad tensor([[1995.9814]], device='cuda:0')\n",
      "Epoch 432 | Loss: 7.2446\n",
      "alpha: 0.07720039784908295, beta0: 0.11288221180438995, beta1: -0.001123292837291956, beta2: 0.003749239956960082, \n",
      "gamma: 0.06437700241804123, sigma0: 0.2673937678337097, sigma1: 0.0008511031046509743, sigma2: 0.0004718155541922897, sigmaX: 0.15504102408885956\n",
      "forward done\n",
      "tensor([0.0182, 0.1206, 0.2375, 0.6831, 0.3955], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.3811]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-445.8202]], device='cuda:0')\n",
      "sigma0 grad tensor([-472.9831], device='cuda:0')\n",
      "sigma1 grad tensor([[-410.5439]], device='cuda:0')\n",
      "gamma grad tensor([[3831.7178]], device='cuda:0')\n",
      "alpha grad tensor([[-7339.3809]], device='cuda:0')\n",
      "beta2 grad tensor([[7114.6543]], device='cuda:0')\n",
      "beta0 grad tensor([3380.6797], device='cuda:0')\n",
      "beta1 grad tensor([[4636.6299]], device='cuda:0')\n",
      "Epoch 433 | Loss: 13.3942\n",
      "alpha: 0.07718285918235779, beta0: 0.11288699507713318, beta1: -0.00110701157245785, beta2: 0.003789246780797839, \n",
      "gamma: 0.06439025700092316, sigma0: 0.2673948109149933, sigma1: 0.0008508420432917774, sigma2: 0.00047030384303070605, sigmaX: 0.15504109859466553\n",
      "forward done\n",
      "tensor([0.0177, 0.1718, 0.0834, 0.7166, 0.4251], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.4038]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-378.3795]], device='cuda:0')\n",
      "sigma0 grad tensor([-438.9713], device='cuda:0')\n",
      "sigma1 grad tensor([[-360.5915]], device='cuda:0')\n",
      "gamma grad tensor([[3616.9709]], device='cuda:0')\n",
      "alpha grad tensor([[-6964.5244]], device='cuda:0')\n",
      "beta2 grad tensor([[6400.5664]], device='cuda:0')\n",
      "beta0 grad tensor([3221.3354], device='cuda:0')\n",
      "beta1 grad tensor([[4288.7729]], device='cuda:0')\n",
      "Epoch 434 | Loss: 18.4202\n",
      "alpha: 0.07723847031593323, beta0: 0.1128586083650589, beta1: -0.0011368743143975735, beta2: 0.0037572465371340513, \n",
      "gamma: 0.06436468660831451, sigma0: 0.26740002632141113, sigma1: 0.0008542391005903482, sigma2: 0.00047287828056141734, sigmaX: 0.1550411581993103\n",
      "forward done\n",
      "tensor([0.0073, 0.0612, 0.2041, 0.6718, 0.3740], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.4866]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-202.7765]], device='cuda:0')\n",
      "sigma0 grad tensor([-237.7140], device='cuda:0')\n",
      "sigma1 grad tensor([[-194.6251]], device='cuda:0')\n",
      "gamma grad tensor([[1315.3704]], device='cuda:0')\n",
      "alpha grad tensor([[-2715.1401]], device='cuda:0')\n",
      "beta2 grad tensor([[2761.4595]], device='cuda:0')\n",
      "beta0 grad tensor([1354.9734], device='cuda:0')\n",
      "beta1 grad tensor([[1827.9565]], device='cuda:0')\n",
      "Epoch 435 | Loss: 7.3797\n",
      "alpha: 0.07731011509895325, beta0: 0.11282234638929367, beta1: -0.001179044134914875, beta2: 0.0037040316965430975, \n",
      "gamma: 0.06433107703924179, sigma0: 0.2674065828323364, sigma1: 0.0008589029894210398, sigma2: 0.00047696559340693057, sigmaX: 0.15504123270511627\n",
      "forward done\n",
      "tensor([0.0102, 0.0705, 0.1282, 0.6855, 0.3862], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.9207]]], device='cuda:0')\n",
      "sigma2 grad tensor([[48.6487]], device='cuda:0')\n",
      "sigma0 grad tensor([114.9876], device='cuda:0')\n",
      "sigma1 grad tensor([[75.9372]], device='cuda:0')\n",
      "gamma grad tensor([[-2132.5933]], device='cuda:0')\n",
      "alpha grad tensor([[3764.9363]], device='cuda:0')\n",
      "beta2 grad tensor([[-3316.5457]], device='cuda:0')\n",
      "beta0 grad tensor([-1552.0555], device='cuda:0')\n",
      "beta1 grad tensor([[-2149.7156]], device='cuda:0')\n",
      "Epoch 436 | Loss: 8.2646\n",
      "alpha: 0.07732977718114853, beta0: 0.11280886083841324, beta1: -0.0011912827612832189, beta2: 0.003694625338539481, \n",
      "gamma: 0.06432551890611649, sigma0: 0.26741066575050354, sigma1: 0.000861874723341316, sigma2: 0.0004797489382326603, sigmaX: 0.15504130721092224\n",
      "forward done\n",
      "tensor([0.0115, 0.0475, 0.1972, 0.6551, 0.3759], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.7916]]], device='cuda:0')\n",
      "sigma2 grad tensor([[18.1502]], device='cuda:0')\n",
      "sigma0 grad tensor([63.3639], device='cuda:0')\n",
      "sigma1 grad tensor([[38.2192]], device='cuda:0')\n",
      "gamma grad tensor([[-1652.6299]], device='cuda:0')\n",
      "alpha grad tensor([[2851.0889]], device='cuda:0')\n",
      "beta2 grad tensor([[-2466.8777]], device='cuda:0')\n",
      "beta0 grad tensor([-1134.8960], device='cuda:0')\n",
      "beta1 grad tensor([[-1584.1019]], device='cuda:0')\n",
      "Epoch 437 | Loss: 5.9900\n",
      "alpha: 0.0773169994354248, beta0: 0.11280941963195801, beta1: -0.001185232657007873, beta2: 0.003711769124493003, \n",
      "gamma: 0.0643375962972641, sigma0: 0.26741331815719604, sigma1: 0.0008638699073344469, sigma2: 0.0004817941226065159, sigmaX: 0.1550413817167282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0155, 0.0545, 0.1460, 0.6492, 0.3842], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.0202]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-369.5947]], device='cuda:0')\n",
      "sigma0 grad tensor([-317.2455], device='cuda:0')\n",
      "sigma1 grad tensor([[-301.9170]], device='cuda:0')\n",
      "gamma grad tensor([[2070.1667]], device='cuda:0')\n",
      "alpha grad tensor([[-4147.1699]], device='cuda:0')\n",
      "beta2 grad tensor([[4526.6650]], device='cuda:0')\n",
      "beta0 grad tensor([1992.3564], device='cuda:0')\n",
      "beta1 grad tensor([[2834.9707]], device='cuda:0')\n",
      "Epoch 438 | Loss: 6.6449\n",
      "alpha: 0.0773482471704483, beta0: 0.11278994381427765, beta1: -0.0012087422655895352, beta2: 0.0036802173126488924, \n",
      "gamma: 0.06432655453681946, sigma0: 0.26741859316825867, sigma1: 0.0008684852509759367, sigma2: 0.0004871262062806636, sigmaX: 0.15504145622253418\n",
      "forward done\n",
      "tensor([0.0178, 0.1902, 0.2764, 0.6719, 0.3800], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.8800]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-365.4839]], device='cuda:0')\n",
      "sigma0 grad tensor([-443.4767], device='cuda:0')\n",
      "sigma1 grad tensor([[-366.7499]], device='cuda:0')\n",
      "gamma grad tensor([[3496.6311]], device='cuda:0')\n",
      "alpha grad tensor([[-6731.7744]], device='cuda:0')\n",
      "beta2 grad tensor([[6550.4629]], device='cuda:0')\n",
      "beta0 grad tensor([3116.2019], device='cuda:0')\n",
      "beta1 grad tensor([[4271.2178]], device='cuda:0')\n",
      "Epoch 439 | Loss: 20.3688\n",
      "alpha: 0.07744055986404419, beta0: 0.11274319887161255, beta1: -0.0012702621752396226, beta2: 0.003589471336454153, \n",
      "gamma: 0.06428276002407074, sigma0: 0.2674272656440735, sigma1: 0.0008758450276218355, sigma2: 0.0004950467264279723, sigmaX: 0.15504154562950134\n",
      "forward done\n",
      "tensor([0.0259, 0.3506, 0.3209, 0.5527, 0.2743], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.2822]]], device='cuda:0')\n",
      "sigma2 grad tensor([[823.0273]], device='cuda:0')\n",
      "sigma0 grad tensor([697.8117], device='cuda:0')\n",
      "sigma1 grad tensor([[686.3920]], device='cuda:0')\n",
      "gamma grad tensor([[-5840.5254]], device='cuda:0')\n",
      "alpha grad tensor([[11025.5332]], device='cuda:0')\n",
      "beta2 grad tensor([[-12731.2266]], device='cuda:0')\n",
      "beta0 grad tensor([-5037.5620], device='cuda:0')\n",
      "beta1 grad tensor([[-7592.9312]], device='cuda:0')\n",
      "Epoch 440 | Loss: 36.2301\n",
      "alpha: 0.07740415632724762, beta0: 0.11275617778301239, beta1: -0.0012435488170012832, beta2: 0.003644186770543456, \n",
      "gamma: 0.06430612504482269, sigma0: 0.2674272060394287, sigma1: 0.0008748689433559775, sigma2: 0.0004931528819724917, sigmaX: 0.1550416201353073\n",
      "forward done\n",
      "tensor([0.0091, 0.0242, 0.1909, 0.6382, 0.3554], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.4077]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-114.8902]], device='cuda:0')\n",
      "sigma0 grad tensor([-73.7304], device='cuda:0')\n",
      "sigma1 grad tensor([[-83.0554]], device='cuda:0')\n",
      "gamma grad tensor([[-466.8761]], device='cuda:0')\n",
      "alpha grad tensor([[590.4942]], device='cuda:0')\n",
      "beta2 grad tensor([[-185.6686]], device='cuda:0')\n",
      "beta0 grad tensor([-103.1349], device='cuda:0')\n",
      "beta1 grad tensor([[-131.0868]], device='cuda:0')\n",
      "Epoch 441 | Loss: 3.6092\n",
      "alpha: 0.07736913114786148, beta0: 0.11276759207248688, beta1: -0.001220867270603776, beta2: 0.003689815755933523, \n",
      "gamma: 0.06432949006557465, sigma0: 0.26742789149284363, sigma1: 0.0008749185944907367, sigma2: 0.0004927866975776851, sigmaX: 0.15504169464111328\n",
      "forward done\n",
      "tensor([0.0099, 0.0527, 0.1164, 0.6845, 0.3762], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.5851]]], device='cuda:0')\n",
      "sigma2 grad tensor([[241.8720]], device='cuda:0')\n",
      "sigma0 grad tensor([310.9615], device='cuda:0')\n",
      "sigma1 grad tensor([[255.9805]], device='cuda:0')\n",
      "gamma grad tensor([[-3173.0320]], device='cuda:0')\n",
      "alpha grad tensor([[5880.6904]], device='cuda:0')\n",
      "beta2 grad tensor([[-5760.3413]], device='cuda:0')\n",
      "beta0 grad tensor([-2609.4675], device='cuda:0')\n",
      "beta1 grad tensor([[-3677.0405]], device='cuda:0')\n",
      "Epoch 442 | Loss: 6.4614\n",
      "alpha: 0.07728230208158493, beta0: 0.11280281841754913, beta1: -0.0011659516021609306, beta2: 0.0037839224096387625, \n",
      "gamma: 0.06437990814447403, sigma0: 0.2674253284931183, sigma1: 0.0008723985520191491, sigma2: 0.0004900750354863703, sigmaX: 0.15504176914691925\n",
      "forward done\n",
      "tensor([0.0149, 0.0530, 0.2939, 0.6535, 0.3706], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.3613]]], device='cuda:0')\n",
      "sigma2 grad tensor([[39.5853]], device='cuda:0')\n",
      "sigma0 grad tensor([60.4099], device='cuda:0')\n",
      "sigma1 grad tensor([[43.0462]], device='cuda:0')\n",
      "gamma grad tensor([[-1706.5465]], device='cuda:0')\n",
      "alpha grad tensor([[2927.0378]], device='cuda:0')\n",
      "beta2 grad tensor([[-2632.3918]], device='cuda:0')\n",
      "beta0 grad tensor([-1156.8915], device='cuda:0')\n",
      "beta1 grad tensor([[-1647.8845]], device='cuda:0')\n",
      "Epoch 443 | Loss: 6.6289\n",
      "alpha: 0.0771835669875145, beta0: 0.11284256726503372, beta1: -0.0011055401992052794, beta2: 0.0038855315651744604, \n",
      "gamma: 0.06443730741739273, sigma0: 0.2674226760864258, sigma1: 0.0008699520258232951, sigma2: 0.0004875098529737443, sigmaX: 0.1550418585538864\n",
      "forward done\n",
      "tensor([0.0181, 0.0560, 0.1879, 0.5936, 0.3579], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.4386]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-511.2166]], device='cuda:0')\n",
      "sigma0 grad tensor([-501.1630], device='cuda:0')\n",
      "sigma1 grad tensor([[-442.7544]], device='cuda:0')\n",
      "gamma grad tensor([[3663.8789]], device='cuda:0')\n",
      "alpha grad tensor([[-7118.7563]], device='cuda:0')\n",
      "beta2 grad tensor([[7690.8901]], device='cuda:0')\n",
      "beta0 grad tensor([3320.8564], device='cuda:0')\n",
      "beta1 grad tensor([[4760.3784]], device='cuda:0')\n",
      "Epoch 444 | Loss: 6.7604\n",
      "alpha: 0.07717576622962952, beta0: 0.1128411591053009, beta1: -0.0011048148153349757, beta2: 0.0038899099454283714, \n",
      "gamma: 0.0644465908408165, sigma0: 0.2674255669116974, sigma1: 0.0008724223589524627, sigma2: 0.0004905698588117957, sigmaX: 0.15504194796085358\n",
      "forward done\n",
      "tensor([0.0098, 0.0606, 0.1103, 0.6613, 0.3946], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.0604]]], device='cuda:0')\n",
      "sigma2 grad tensor([[209.2483]], device='cuda:0')\n",
      "sigma0 grad tensor([240.4398], device='cuda:0')\n",
      "sigma1 grad tensor([[203.5914]], device='cuda:0')\n",
      "gamma grad tensor([[-2904.5615]], device='cuda:0')\n",
      "alpha grad tensor([[5290.9277]], device='cuda:0')\n",
      "beta2 grad tensor([[-4868.8711]], device='cuda:0')\n",
      "beta0 grad tensor([-2288.6704], device='cuda:0')\n",
      "beta1 grad tensor([[-3169.3669]], device='cuda:0')\n",
      "Epoch 445 | Loss: 7.2367\n",
      "alpha: 0.07711661607027054, beta0: 0.11286292225122452, beta1: -0.0010725408792495728, beta2: 0.003942101262509823, \n",
      "gamma: 0.06448306143283844, sigma0: 0.2674254775047302, sigma1: 0.0008723626961000264, sigma2: 0.0004909253912046552, sigmaX: 0.15504203736782074\n",
      "forward done\n",
      "tensor([0.0098, 0.0856, 0.1293, 0.6855, 0.3918], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.3117]]], device='cuda:0')\n",
      "sigma2 grad tensor([[465.9785]], device='cuda:0')\n",
      "sigma0 grad tensor([508.1246], device='cuda:0')\n",
      "sigma1 grad tensor([[440.8152]], device='cuda:0')\n",
      "gamma grad tensor([[-4593.2876]], device='cuda:0')\n",
      "alpha grad tensor([[8654.8262]], device='cuda:0')\n",
      "beta2 grad tensor([[-8470.6875]], device='cuda:0')\n",
      "beta0 grad tensor([-3925.2917], device='cuda:0')\n",
      "beta1 grad tensor([[-5459.4946]], device='cuda:0')\n",
      "Epoch 446 | Loss: 9.7771\n",
      "alpha: 0.07698275148868561, beta0: 0.11291958391666412, beta1: -0.0009921267628669739, beta2: 0.004068561363965273, \n",
      "gamma: 0.06455817073583603, sigma0: 0.26742032170295715, sigma1: 0.0008679068414494395, sigma2: 0.00048655003774911165, sigmaX: 0.1550421267747879\n",
      "forward done\n",
      "tensor([0.0130, 0.1164, 0.1582, 0.6875, 0.3882], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.2922]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-399.3090]], device='cuda:0')\n",
      "sigma0 grad tensor([-456.7700], device='cuda:0')\n",
      "sigma1 grad tensor([[-387.6668]], device='cuda:0')\n",
      "gamma grad tensor([[3663.4478]], device='cuda:0')\n",
      "alpha grad tensor([[-7003.6763]], device='cuda:0')\n",
      "beta2 grad tensor([[6918.7915]], device='cuda:0')\n",
      "beta0 grad tensor([3227.5598], device='cuda:0')\n",
      "beta1 grad tensor([[4463.6855]], device='cuda:0')\n",
      "Epoch 447 | Loss: 12.8854\n",
      "alpha: 0.07694569230079651, beta0: 0.11293263733386993, beta1: -0.000972432317212224, beta2: 0.0041005415841937065, \n",
      "gamma: 0.06458162516355515, sigma0: 0.26742076873779297, sigma1: 0.0008682188345119357, sigma2: 0.00048704282380640507, sigmaX: 0.15504221618175507\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0128, 0.0889, 0.1029, 0.6544, 0.3730], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.9481]]], device='cuda:0')\n",
      "sigma2 grad tensor([[562.7047]], device='cuda:0')\n",
      "sigma0 grad tensor([497.2747], device='cuda:0')\n",
      "sigma1 grad tensor([[479.7326]], device='cuda:0')\n",
      "gamma grad tensor([[-4287.1138]], device='cuda:0')\n",
      "alpha grad tensor([[8122.3208]], device='cuda:0')\n",
      "beta2 grad tensor([[-8553.0312]], device='cuda:0')\n",
      "beta0 grad tensor([-3696.9524], device='cuda:0')\n",
      "beta1 grad tensor([[-5345.9458]], device='cuda:0')\n",
      "Epoch 448 | Loss: 10.0375\n",
      "alpha: 0.07683482021093369, beta0: 0.11298005282878876, beta1: -0.0009032172965817153, beta2: 0.00421165581792593, \n",
      "gamma: 0.0646432563662529, sigma0: 0.2674161493778229, sigma1: 0.0008636710699647665, sigma2: 0.00048181001329794526, sigmaX: 0.15504230558872223\n",
      "forward done\n",
      "tensor([0.0074, 0.0390, 0.2232, 0.6006, 0.4338], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.3588]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-454.4137]], device='cuda:0')\n",
      "sigma0 grad tensor([-466.6389], device='cuda:0')\n",
      "sigma1 grad tensor([[-406.0624]], device='cuda:0')\n",
      "gamma grad tensor([[3657.4719]], device='cuda:0')\n",
      "alpha grad tensor([[-7027.8374]], device='cuda:0')\n",
      "beta2 grad tensor([[7063.8882]], device='cuda:0')\n",
      "beta0 grad tensor([3251.5444], device='cuda:0')\n",
      "beta1 grad tensor([[4521.5869]], device='cuda:0')\n",
      "Epoch 449 | Loss: 5.1601\n",
      "alpha: 0.07681640237569809, beta0: 0.11298546940088272, beta1: -0.0008930611656978726, beta2: 0.0042299083434045315, \n",
      "gamma: 0.06465598940849304, sigma0: 0.26741713285446167, sigma1: 0.0008640934829600155, sigma2: 0.0004821679031010717, sigmaX: 0.1550423949956894\n",
      "forward done\n",
      "tensor([0.0128, 0.0646, 0.1252, 0.6731, 0.4034], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.2715]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-463.6495]], device='cuda:0')\n",
      "sigma0 grad tensor([-486.5562], device='cuda:0')\n",
      "sigma1 grad tensor([[-427.5305]], device='cuda:0')\n",
      "gamma grad tensor([[3647.2769]], device='cuda:0')\n",
      "alpha grad tensor([[-7074.1533]], device='cuda:0')\n",
      "beta2 grad tensor([[6948.1787]], device='cuda:0')\n",
      "beta0 grad tensor([3293.3481], device='cuda:0')\n",
      "beta1 grad tensor([[4538.3701]], device='cuda:0')\n",
      "Epoch 450 | Loss: 7.6761\n",
      "alpha: 0.07687240839004517, beta0: 0.11295686662197113, beta1: -0.000930319947656244, beta2: 0.0041750287637114525, \n",
      "gamma: 0.0646297037601471, sigma0: 0.26742276549339294, sigma1: 0.0008687067311257124, sigma2: 0.0004870906996075064, sigmaX: 0.15504248440265656\n",
      "forward done\n",
      "tensor([0.0123, 0.0942, 0.1446, 0.6005, 0.3800], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.3505]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-425.9418]], device='cuda:0')\n",
      "sigma0 grad tensor([-474.5557], device='cuda:0')\n",
      "sigma1 grad tensor([[-403.5049]], device='cuda:0')\n",
      "gamma grad tensor([[3518.2141]], device='cuda:0')\n",
      "alpha grad tensor([[-6863.9243]], device='cuda:0')\n",
      "beta2 grad tensor([[6667.5107]], device='cuda:0')\n",
      "beta0 grad tensor([3205.3142], device='cuda:0')\n",
      "beta1 grad tensor([[4371.5132]], device='cuda:0')\n",
      "Epoch 451 | Loss: 10.5553\n",
      "alpha: 0.07698585093021393, beta0: 0.11290193349123001, beta1: -0.0010038421023637056, beta2: 0.004064450040459633, \n",
      "gamma: 0.0645734891295433, sigma0: 0.2674320340156555, sigma1: 0.0008764324011281133, sigma2: 0.0004952883464284241, sigmaX: 0.15504255890846252\n",
      "forward done\n",
      "tensor([0.0125, 0.0898, 0.1597, 0.7093, 0.4640], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.0047]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-403.6369]], device='cuda:0')\n",
      "sigma0 grad tensor([-476.4686], device='cuda:0')\n",
      "sigma1 grad tensor([[-393.0171]], device='cuda:0')\n",
      "gamma grad tensor([[3647.1052]], device='cuda:0')\n",
      "alpha grad tensor([[-7055.1997]], device='cuda:0')\n",
      "beta2 grad tensor([[6843.3276]], device='cuda:0')\n",
      "beta0 grad tensor([3284.8972], device='cuda:0')\n",
      "beta1 grad tensor([[4467.5083]], device='cuda:0')\n",
      "Epoch 452 | Loss: 10.3212\n",
      "alpha: 0.07714715600013733, beta0: 0.11282514035701752, beta1: -0.0011073348578065634, beta2: 0.003907553851604462, \n",
      "gamma: 0.06449204683303833, sigma0: 0.2674441933631897, sigma1: 0.0008865430718287826, sigma2: 0.0005058828392066061, sigmaX: 0.1550426185131073\n",
      "forward done\n",
      "tensor([0.0086, 0.1151, 0.0768, 0.7162, 0.4224], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.8542]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-340.9438]], device='cuda:0')\n",
      "sigma0 grad tensor([-481.3792], device='cuda:0')\n",
      "sigma1 grad tensor([[-373.8725]], device='cuda:0')\n",
      "gamma grad tensor([[3543.2927]], device='cuda:0')\n",
      "alpha grad tensor([[-6954.5840]], device='cuda:0')\n",
      "beta2 grad tensor([[6418.6250]], device='cuda:0')\n",
      "beta0 grad tensor([3270.4260], device='cuda:0')\n",
      "beta1 grad tensor([[4343.4697]], device='cuda:0')\n",
      "Epoch 453 | Loss: 12.7349\n",
      "alpha: 0.07734575122594833, beta0: 0.11273100227117538, beta1: -0.0012335637584328651, beta2: 0.0037178504280745983, \n",
      "gamma: 0.06439146399497986, sigma0: 0.2674587368965149, sigma1: 0.0008983703446574509, sigma2: 0.0005177678540349007, sigmaX: 0.15504267811775208\n",
      "forward done\n",
      "tensor([0.0128, 0.0512, 0.1816, 0.6559, 0.3722], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.7451]]], device='cuda:0')\n",
      "sigma2 grad tensor([[24.0354]], device='cuda:0')\n",
      "sigma0 grad tensor([62.0914], device='cuda:0')\n",
      "sigma1 grad tensor([[38.4159]], device='cuda:0')\n",
      "gamma grad tensor([[-1666.6848]], device='cuda:0')\n",
      "alpha grad tensor([[2843.5410]], device='cuda:0')\n",
      "beta2 grad tensor([[-2546.5969]], device='cuda:0')\n",
      "beta0 grad tensor([-1127.7172], device='cuda:0')\n",
      "beta1 grad tensor([[-1601.5723]], device='cuda:0')\n",
      "Epoch 454 | Loss: 6.3442\n",
      "alpha: 0.07747618854045868, beta0: 0.11266696453094482, beta1: -0.001318531227298081, beta2: 0.0035915537737309933, \n",
      "gamma: 0.0643276646733284, sigma0: 0.26746976375579834, sigma1: 0.0009074480039998889, sigma2: 0.0005270355031825602, sigmaX: 0.15504273772239685\n",
      "forward done\n",
      "tensor([0.0150, 0.0399, 0.2431, 0.6521, 0.3806], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.5790]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-39.6451]], device='cuda:0')\n",
      "sigma0 grad tensor([-5.0241], device='cuda:0')\n",
      "sigma1 grad tensor([[-18.1877]], device='cuda:0')\n",
      "gamma grad tensor([[-1040.7039]], device='cuda:0')\n",
      "alpha grad tensor([[1686.7440]], device='cuda:0')\n",
      "beta2 grad tensor([[-1399.1686]], device='cuda:0')\n",
      "beta0 grad tensor([-606.4187], device='cuda:0')\n",
      "beta1 grad tensor([[-872.5035]], device='cuda:0')\n",
      "Epoch 455 | Loss: 5.2852\n",
      "alpha: 0.07756367325782776, beta0: 0.11262179911136627, beta1: -0.0013777801068499684, beta2: 0.003504508174955845, \n",
      "gamma: 0.06428702920675278, sigma0: 0.2674786448478699, sigma1: 0.0009148920071311295, sigma2: 0.0005348460981622338, sigmaX: 0.15504281222820282\n",
      "forward done\n",
      "tensor([0.0093, 0.0685, 0.3903, 0.6174, 0.3583], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.1263]]], device='cuda:0')\n",
      "sigma2 grad tensor([[477.9219]], device='cuda:0')\n",
      "sigma0 grad tensor([516.9608], device='cuda:0')\n",
      "sigma1 grad tensor([[440.9418]], device='cuda:0')\n",
      "gamma grad tensor([[-4899.9609]], device='cuda:0')\n",
      "alpha grad tensor([[9162.5791]], device='cuda:0')\n",
      "beta2 grad tensor([[-9342.9775]], device='cuda:0')\n",
      "beta0 grad tensor([-4134.5439], device='cuda:0')\n",
      "beta1 grad tensor([[-5866.4717]], device='cuda:0')\n",
      "Epoch 456 | Loss: 8.2259\n",
      "alpha: 0.07754203677177429, beta0: 0.11262701451778412, beta1: -0.0013665144797414541, beta2: 0.0035283013712614775, \n",
      "gamma: 0.06430352479219437, sigma0: 0.2674805819988251, sigma1: 0.0009164377697743475, sigma2: 0.0005363153759390116, sigmaX: 0.15504290163516998\n",
      "forward done\n",
      "tensor([0.0133, 0.0732, 0.2280, 0.6973, 0.3942], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.4591]]], device='cuda:0')\n",
      "sigma2 grad tensor([[513.7491]], device='cuda:0')\n",
      "sigma0 grad tensor([525.1743], device='cuda:0')\n",
      "sigma1 grad tensor([[474.2875]], device='cuda:0')\n",
      "gamma grad tensor([[-4644.0015]], device='cuda:0')\n",
      "alpha grad tensor([[8787.2715]], device='cuda:0')\n",
      "beta2 grad tensor([[-9156.0127]], device='cuda:0')\n",
      "beta0 grad tensor([-4003.2617], device='cuda:0')\n",
      "beta1 grad tensor([[-5745.4468]], device='cuda:0')\n",
      "Epoch 457 | Loss: 8.6563\n",
      "alpha: 0.07743684947490692, beta0: 0.11267121881246567, beta1: -0.0013000475009903312, beta2: 0.003638896159827709, \n",
      "gamma: 0.06436315923929214, sigma0: 0.2674768567085266, sigma1: 0.000912931514903903, sigma2: 0.0005323532968759537, sigmaX: 0.15504299104213715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0110, 0.0876, 0.0941, 0.6555, 0.3915], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.3835]]], device='cuda:0')\n",
      "sigma2 grad tensor([[314.6138]], device='cuda:0')\n",
      "sigma0 grad tensor([376.0534], device='cuda:0')\n",
      "sigma1 grad tensor([[317.2057]], device='cuda:0')\n",
      "gamma grad tensor([[-3535.3506]], device='cuda:0')\n",
      "alpha grad tensor([[6695.1328]], device='cuda:0')\n",
      "beta2 grad tensor([[-6544.9482]], device='cuda:0')\n",
      "beta0 grad tensor([-3025.8555], device='cuda:0')\n",
      "beta1 grad tensor([[-4218.0552]], device='cuda:0')\n",
      "Epoch 458 | Loss: 9.9081\n",
      "alpha: 0.0772857517004013, beta0: 0.11273684352636337, beta1: -0.0012046934571117163, beta2: 0.003792821429669857, \n",
      "gamma: 0.06444621831178665, sigma0: 0.267470121383667, sigma1: 0.0009069544612430036, sigma2: 0.0005260374746285379, sigmaX: 0.1550430804491043\n",
      "forward done\n",
      "tensor([0.0111, 0.0409, 0.4091, 0.6136, 0.3624], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.3041]]], device='cuda:0')\n",
      "sigma2 grad tensor([[197.6458]], device='cuda:0')\n",
      "sigma0 grad tensor([173.2857], device='cuda:0')\n",
      "sigma1 grad tensor([[161.2992]], device='cuda:0')\n",
      "gamma grad tensor([[-2009.8295]], device='cuda:0')\n",
      "alpha grad tensor([[3771.7329]], device='cuda:0')\n",
      "beta2 grad tensor([[-3668.7439]], device='cuda:0')\n",
      "beta0 grad tensor([-1639.1909], device='cuda:0')\n",
      "beta1 grad tensor([[-2304.6897]], device='cuda:0')\n",
      "Epoch 459 | Loss: 5.4870\n",
      "alpha: 0.07712715864181519, beta0: 0.11280573159456253, beta1: -0.0011053632479161024, beta2: 0.0039526489563286304, \n",
      "gamma: 0.06453276425600052, sigma0: 0.26746299862861633, sigma1: 0.000900559825822711, sigma2: 0.0005190083757042885, sigmaX: 0.15504316985607147\n",
      "forward done\n",
      "tensor([0.0114, 0.0470, 0.1128, 0.6492, 0.3719], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.9475]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-384.1998]], device='cuda:0')\n",
      "sigma0 grad tensor([-446.7889], device='cuda:0')\n",
      "sigma1 grad tensor([[-371.5506]], device='cuda:0')\n",
      "gamma grad tensor([[3144.6902]], device='cuda:0')\n",
      "alpha grad tensor([[-6205.9009]], device='cuda:0')\n",
      "beta2 grad tensor([[6211.5737]], device='cuda:0')\n",
      "beta0 grad tensor([2933.2598], device='cuda:0')\n",
      "beta1 grad tensor([[4026.4768]], device='cuda:0')\n",
      "Epoch 460 | Loss: 5.8465\n",
      "alpha: 0.07706233859062195, beta0: 0.11283151060342789, beta1: -0.001066163880750537, beta2: 0.004018395207822323, \n",
      "gamma: 0.06457055360078812, sigma0: 0.26746177673339844, sigma1: 0.0008991596405394375, sigma2: 0.0005172271048650146, sigmaX: 0.15504325926303864\n",
      "forward done\n",
      "tensor([0.0084, 0.1114, 0.1664, 0.6234, 0.3736], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.2533]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-383.4513]], device='cuda:0')\n",
      "sigma0 grad tensor([-461.8552], device='cuda:0')\n",
      "sigma1 grad tensor([[-376.1880]], device='cuda:0')\n",
      "gamma grad tensor([[3963.2322]], device='cuda:0')\n",
      "alpha grad tensor([[-7525.9492]], device='cuda:0')\n",
      "beta2 grad tensor([[6959.3818]], device='cuda:0')\n",
      "beta0 grad tensor([3443.8020], device='cuda:0')\n",
      "beta1 grad tensor([[4626.2881]], device='cuda:0')\n",
      "Epoch 461 | Loss: 12.3145\n",
      "alpha: 0.07708574086427689, beta0: 0.11281769722700119, beta1: -0.0010810672538354993, beta2: 0.00400139857083559, \n",
      "gamma: 0.0645611509680748, sigma0: 0.26746541261672974, sigma1: 0.0009018013370223343, sigma2: 0.0005196366109885275, sigmaX: 0.1550433486700058\n",
      "forward done\n",
      "tensor([0.0214, 0.0523, 0.2987, 0.6760, 0.4047], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.4662]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-81.4614]], device='cuda:0')\n",
      "sigma0 grad tensor([-58.3187], device='cuda:0')\n",
      "sigma1 grad tensor([[-60.1154]], device='cuda:0')\n",
      "gamma grad tensor([[-478.4252]], device='cuda:0')\n",
      "alpha grad tensor([[645.1714]], device='cuda:0')\n",
      "beta2 grad tensor([[-313.7520]], device='cuda:0')\n",
      "beta0 grad tensor([-146.4077], device='cuda:0')\n",
      "beta1 grad tensor([[-201.1177]], device='cuda:0')\n",
      "Epoch 462 | Loss: 6.6324\n",
      "alpha: 0.07709801197052002, beta0: 0.11280810832977295, beta1: -0.0010909787379205227, beta2: 0.003990938887000084, \n",
      "gamma: 0.06455841660499573, sigma0: 0.2674688994884491, sigma1: 0.0009045158512890339, sigma2: 0.0005223788321018219, sigmaX: 0.15504343807697296\n",
      "forward done\n",
      "tensor([0.0042, 0.0520, 0.1522, 0.6892, 0.3860], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.5336]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-217.5119]], device='cuda:0')\n",
      "sigma0 grad tensor([-265.8691], device='cuda:0')\n",
      "sigma1 grad tensor([[-215.7525]], device='cuda:0')\n",
      "gamma grad tensor([[1422.7710]], device='cuda:0')\n",
      "alpha grad tensor([[-2945.6897]], device='cuda:0')\n",
      "beta2 grad tensor([[3027.7017]], device='cuda:0')\n",
      "beta0 grad tensor([1471.2102], device='cuda:0')\n",
      "beta1 grad tensor([[1994.0344]], device='cuda:0')\n",
      "Epoch 463 | Loss: 6.4325\n",
      "alpha: 0.0771372839808464, beta0: 0.11278572678565979, beta1: -0.0011188483331352472, beta2: 0.003952294122427702, \n",
      "gamma: 0.0645420029759407, sigma0: 0.26747435331344604, sigma1: 0.0009088449878618121, sigma2: 0.000526747724507004, sigmaX: 0.15504352748394012\n",
      "forward done\n",
      "tensor([0.0120, 0.0728, 0.3900, 0.6197, 0.3365], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.7741]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-355.9791]], device='cuda:0')\n",
      "sigma0 grad tensor([-385.9739], device='cuda:0')\n",
      "sigma1 grad tensor([[-325.2475]], device='cuda:0')\n",
      "gamma grad tensor([[2957.0010]], device='cuda:0')\n",
      "alpha grad tensor([[-5700.2441]], device='cuda:0')\n",
      "beta2 grad tensor([[5707.8398]], device='cuda:0')\n",
      "beta0 grad tensor([2652.2910], device='cuda:0')\n",
      "beta1 grad tensor([[3665.6785]], device='cuda:0')\n",
      "Epoch 464 | Loss: 8.6419\n",
      "alpha: 0.0772257074713707, beta0: 0.11274129897356033, beta1: -0.0011778008192777634, beta2: 0.003864299738779664, \n",
      "gamma: 0.06449930369853973, sigma0: 0.26748257875442505, sigma1: 0.0009155607549473643, sigma2: 0.0005338026094250381, sigmaX: 0.1550436168909073\n",
      "forward done\n",
      "tensor([0.0111, 0.0735, 0.1809, 0.6567, 0.3985], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.3543]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-343.7755]], device='cuda:0')\n",
      "sigma0 grad tensor([-441.5748], device='cuda:0')\n",
      "sigma1 grad tensor([[-360.0415]], device='cuda:0')\n",
      "gamma grad tensor([[3270.6953]], device='cuda:0')\n",
      "alpha grad tensor([[-6387.4253]], device='cuda:0')\n",
      "beta2 grad tensor([[5927.9028]], device='cuda:0')\n",
      "beta0 grad tensor([3003.4109], device='cuda:0')\n",
      "beta1 grad tensor([[3996.6934]], device='cuda:0')\n",
      "Epoch 465 | Loss: 8.5989\n",
      "alpha: 0.07736031711101532, beta0: 0.11267571896314621, beta1: -0.001264929655008018, beta2: 0.0037346251774579287, \n",
      "gamma: 0.06443243473768234, sigma0: 0.2674935758113861, sigma1: 0.0009245338151231408, sigma2: 0.0005428842850960791, sigmaX: 0.15504369139671326\n",
      "forward done\n",
      "tensor([0.0076, 0.0495, 0.1976, 0.6829, 0.3922], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.3743]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-425.4692]], device='cuda:0')\n",
      "sigma0 grad tensor([-509.7698], device='cuda:0')\n",
      "sigma1 grad tensor([[-425.1971]], device='cuda:0')\n",
      "gamma grad tensor([[3895.7922]], device='cuda:0')\n",
      "alpha grad tensor([[-7573.7930]], device='cuda:0')\n",
      "beta2 grad tensor([[7564.6499]], device='cuda:0')\n",
      "beta0 grad tensor([3536.3572], device='cuda:0')\n",
      "beta1 grad tensor([[4891.8960]], device='cuda:0')\n",
      "Epoch 466 | Loss: 6.2338\n",
      "alpha: 0.07754374295473099, beta0: 0.11258789151906967, beta1: -0.0013835517456755042, beta2: 0.0035552391782402992, \n",
      "gamma: 0.06433998048305511, sigma0: 0.2675074636936188, sigma1: 0.0009359642281197011, sigma2: 0.0005544043378904462, sigmaX: 0.15504376590251923\n",
      "forward done\n",
      "tensor([0.0121, 0.0868, 0.1746, 0.6745, 0.3959], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.0421]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-431.7724]], device='cuda:0')\n",
      "sigma0 grad tensor([-504.3305], device='cuda:0')\n",
      "sigma1 grad tensor([[-420.8892]], device='cuda:0')\n",
      "gamma grad tensor([[3729.9700]], device='cuda:0')\n",
      "alpha grad tensor([[-7331.9336]], device='cuda:0')\n",
      "beta2 grad tensor([[7206.0527]], device='cuda:0')\n",
      "beta0 grad tensor([3452.2666], device='cuda:0')\n",
      "beta1 grad tensor([[4715.7383]], device='cuda:0')\n",
      "Epoch 467 | Loss: 9.9369\n",
      "alpha: 0.07776380330324173, beta0: 0.11248310655355453, beta1: -0.0015256067272275686, beta2: 0.003339669667184353, \n",
      "gamma: 0.06422872096300125, sigma0: 0.2675236165523529, sigma1: 0.000949317472986877, sigma2: 0.0005679380847141147, sigmaX: 0.1550438404083252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0190, 0.2197, 0.2318, 0.6315, 0.3801], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.3783]]], device='cuda:0')\n",
      "sigma2 grad tensor([[702.8431]], device='cuda:0')\n",
      "sigma0 grad tensor([643.0943], device='cuda:0')\n",
      "sigma1 grad tensor([[603.6385]], device='cuda:0')\n",
      "gamma grad tensor([[-5612.5342]], device='cuda:0')\n",
      "alpha grad tensor([[10643.3223]], device='cuda:0')\n",
      "beta2 grad tensor([[-11623.4854]], device='cuda:0')\n",
      "beta0 grad tensor([-4877.8037], device='cuda:0')\n",
      "beta1 grad tensor([[-7123.9287]], device='cuda:0')\n",
      "Epoch 468 | Loss: 23.2289\n",
      "alpha: 0.07783342152833939, beta0: 0.1124480590224266, beta1: -0.001568011473864317, beta2: 0.0032834489829838276, \n",
      "gamma: 0.06419583410024643, sigma0: 0.2675301134586334, sigma1: 0.0009539636666886508, sigma2: 0.0005717366584576666, sigmaX: 0.15504390001296997\n",
      "forward done\n",
      "tensor([0.0174, 0.1875, 0.2460, 0.5815, 0.3621], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.7295]]], device='cuda:0')\n",
      "sigma2 grad tensor([[602.8728]], device='cuda:0')\n",
      "sigma0 grad tensor([632.3309], device='cuda:0')\n",
      "sigma1 grad tensor([[550.6931]], device='cuda:0')\n",
      "gamma grad tensor([[-5476.3052]], device='cuda:0')\n",
      "alpha grad tensor([[10367.1611]], device='cuda:0')\n",
      "beta2 grad tensor([[-11382.9053]], device='cuda:0')\n",
      "beta0 grad tensor([-4756.8555], device='cuda:0')\n",
      "beta1 grad tensor([[-6959.0078]], device='cuda:0')\n",
      "Epoch 469 | Loss: 19.9596\n",
      "alpha: 0.0777854397892952, beta0: 0.11246758699417114, beta1: -0.001532345195300877, beta2: 0.0033523014280945063, \n",
      "gamma: 0.06422428786754608, sigma0: 0.2675289809703827, sigma1: 0.0009521736647002399, sigma2: 0.0005687467637471855, sigmaX: 0.15504395961761475\n",
      "forward done\n",
      "tensor([0.0175, 0.1088, 0.3603, 0.6580, 0.3869], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.9614]]], device='cuda:0')\n",
      "sigma2 grad tensor([[541.0382]], device='cuda:0')\n",
      "sigma0 grad tensor([541.0370], device='cuda:0')\n",
      "sigma1 grad tensor([[487.9054]], device='cuda:0')\n",
      "gamma grad tensor([[-4986.5278]], device='cuda:0')\n",
      "alpha grad tensor([[9392.5801]], device='cuda:0')\n",
      "beta2 grad tensor([[-10057.9648]], device='cuda:0')\n",
      "beta0 grad tensor([-4267.1196], device='cuda:0')\n",
      "beta1 grad tensor([[-6175.1499]], device='cuda:0')\n",
      "Epoch 470 | Loss: 12.3006\n",
      "alpha: 0.07765313237905502, beta0: 0.11252588033676147, beta1: -0.0014420606894418597, beta2: 0.0035079631488770247, \n",
      "gamma: 0.0642969161272049, sigma0: 0.2675226628780365, sigma1: 0.000945862615481019, sigma2: 0.0005609444924630225, sigmaX: 0.15504401922225952\n",
      "forward done\n",
      "tensor([0.0080, 0.1088, 0.4410, 0.6224, 0.3567], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-4.3511]]], device='cuda:0')\n",
      "sigma2 grad tensor([[488.4886]], device='cuda:0')\n",
      "sigma0 grad tensor([561.5190], device='cuda:0')\n",
      "sigma1 grad tensor([[464.8761]], device='cuda:0')\n",
      "gamma grad tensor([[-4992.5615]], device='cuda:0')\n",
      "alpha grad tensor([[9420.1104]], device='cuda:0')\n",
      "beta2 grad tensor([[-9959.7314]], device='cuda:0')\n",
      "beta0 grad tensor([-4293.1592], device='cuda:0')\n",
      "beta1 grad tensor([[-6147.3784]], device='cuda:0')\n",
      "Epoch 471 | Loss: 12.3073\n",
      "alpha: 0.07745308429002762, beta0: 0.11261545121669769, beta1: -0.0013083593221381307, beta2: 0.0037320898845791817, \n",
      "gamma: 0.0644049420952797, sigma0: 0.2675119936466217, sigma1: 0.0009361650445498526, sigma2: 0.0005498178070411086, sigmaX: 0.15504410862922668\n",
      "forward done\n",
      "tensor([0.0133, 0.0705, 0.4416, 0.6033, 0.3699], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.6506]]], device='cuda:0')\n",
      "sigma2 grad tensor([[103.8507]], device='cuda:0')\n",
      "sigma0 grad tensor([146.8839], device='cuda:0')\n",
      "sigma1 grad tensor([[109.2603]], device='cuda:0')\n",
      "gamma grad tensor([[-2462.8613]], device='cuda:0')\n",
      "alpha grad tensor([[4402.9775]], device='cuda:0')\n",
      "beta2 grad tensor([[-4238.8877]], device='cuda:0')\n",
      "beta0 grad tensor([-1842.4772], device='cuda:0')\n",
      "beta1 grad tensor([[-2640.5938]], device='cuda:0')\n",
      "Epoch 472 | Loss: 8.4827\n",
      "alpha: 0.07724901288747787, beta0: 0.1127055287361145, beta1: -0.0011749922996386886, beta2: 0.003953780047595501, \n",
      "gamma: 0.06451599299907684, sigma0: 0.26750198006629944, sigma1: 0.0009273143950849771, sigma2: 0.0005398779176175594, sigmaX: 0.15504419803619385\n",
      "forward done\n",
      "tensor([0.0271, 0.2096, 0.2178, 0.6614, 0.3783], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.0939]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-388.3843]], device='cuda:0')\n",
      "sigma0 grad tensor([-425.0427], device='cuda:0')\n",
      "sigma1 grad tensor([[-353.0596]], device='cuda:0')\n",
      "gamma grad tensor([[3172.4136]], device='cuda:0')\n",
      "alpha grad tensor([[-6196.5298]], device='cuda:0')\n",
      "beta2 grad tensor([[6020.2402]], device='cuda:0')\n",
      "beta0 grad tensor([2898.5881], device='cuda:0')\n",
      "beta1 grad tensor([[3925.1929]], device='cuda:0')\n",
      "Epoch 473 | Loss: 22.2404\n",
      "alpha: 0.0771477222442627, beta0: 0.11274860799312592, beta1: -0.0011075505753979087, beta2: 0.00407092971727252, \n",
      "gamma: 0.06457310914993286, sigma0: 0.2674982249736786, sigma1: 0.0009237644262611866, sigma2: 0.0005358098424039781, sigmaX: 0.15504427254199982\n",
      "forward done\n",
      "tensor([0.0067, 0.0498, 0.1669, 0.6958, 0.4141], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.9007]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-31.1808]], device='cuda:0')\n",
      "sigma0 grad tensor([22.5717], device='cuda:0')\n",
      "sigma1 grad tensor([[-0.3096]], device='cuda:0')\n",
      "gamma grad tensor([[-1157.1582]], device='cuda:0')\n",
      "alpha grad tensor([[1972.9327]], device='cuda:0')\n",
      "beta2 grad tensor([[-1563.6404]], device='cuda:0')\n",
      "beta0 grad tensor([-756.3123], device='cuda:0')\n",
      "beta1 grad tensor([[-1029.7994]], device='cuda:0')\n",
      "Epoch 474 | Loss: 6.2675\n",
      "alpha: 0.0770469605922699, beta0: 0.11279062926769257, beta1: -0.001043299213051796, beta2: 0.004180286079645157, \n",
      "gamma: 0.06463037431240082, sigma0: 0.2674950063228607, sigma1: 0.0009209275594912469, sigma2: 0.0005328672123141587, sigmaX: 0.1550443470478058\n",
      "forward done\n",
      "tensor([0.0093, 0.0830, 0.1398, 0.7012, 0.3951], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.5654]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-390.6025]], device='cuda:0')\n",
      "sigma0 grad tensor([-478.2329], device='cuda:0')\n",
      "sigma1 grad tensor([[-385.9203]], device='cuda:0')\n",
      "gamma grad tensor([[3819.9766]], device='cuda:0')\n",
      "alpha grad tensor([[-7319.2056]], device='cuda:0')\n",
      "beta2 grad tensor([[7122.2925]], device='cuda:0')\n",
      "beta0 grad tensor([3369.8635], device='cuda:0')\n",
      "beta1 grad tensor([[4637.4639]], device='cuda:0')\n",
      "Epoch 475 | Loss: 9.5438\n",
      "alpha: 0.07703954726457596, beta0: 0.112790547311306, beta1: -0.0010382727487012744, beta2: 0.004196547903120518, \n",
      "gamma: 0.06463798880577087, sigma0: 0.2674972116947174, sigma1: 0.0009225172689184546, sigma2: 0.0005344191449694335, sigmaX: 0.15504442155361176\n",
      "forward done\n",
      "tensor([0.0089, 0.0466, 0.3819, 0.6351, 0.3712], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.5612]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-40.6920]], device='cuda:0')\n",
      "sigma0 grad tensor([-17.4261], device='cuda:0')\n",
      "sigma1 grad tensor([[-27.8694]], device='cuda:0')\n",
      "gamma grad tensor([[-746.1425]], device='cuda:0')\n",
      "alpha grad tensor([[1177.1255]], device='cuda:0')\n",
      "beta2 grad tensor([[-815.3813]], device='cuda:0')\n",
      "beta0 grad tensor([-399.5513], device='cuda:0')\n",
      "beta1 grad tensor([[-538.0948]], device='cuda:0')\n",
      "Epoch 476 | Loss: 6.0546\n",
      "alpha: 0.07702184468507767, beta0: 0.11279448121786118, beta1: -0.0010288705816492438, beta2: 0.00421771127730608, \n",
      "gamma: 0.06465154141187668, sigma0: 0.2674991488456726, sigma1: 0.0009240677463822067, sigma2: 0.0005360675859265029, sigmaX: 0.15504451096057892\n",
      "forward done\n",
      "tensor([0.0213, 0.1720, 0.1009, 0.6952, 0.4003], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.0776]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-368.9622]], device='cuda:0')\n",
      "sigma0 grad tensor([-440.2922], device='cuda:0')\n",
      "sigma1 grad tensor([[-369.4406]], device='cuda:0')\n",
      "gamma grad tensor([[3083.6458]], device='cuda:0')\n",
      "alpha grad tensor([[-6100.2378]], device='cuda:0')\n",
      "beta2 grad tensor([[5971.3477]], device='cuda:0')\n",
      "beta0 grad tensor([2877.8701], device='cuda:0')\n",
      "beta1 grad tensor([[3933.5085]], device='cuda:0')\n",
      "Epoch 477 | Loss: 18.4164\n",
      "alpha: 0.07706868648529053, beta0: 0.11276885122060776, beta1: -0.0010606839787214994, beta2: 0.004174928646534681, \n",
      "gamma: 0.06463154405355453, sigma0: 0.26750510931015015, sigma1: 0.0009290025336667895, sigma2: 0.0005410759476944804, sigmaX: 0.1550445854663849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0121, 0.0345, 0.3169, 0.6539, 0.3664], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.8588]]], device='cuda:0')\n",
      "sigma2 grad tensor([[404.7360]], device='cuda:0')\n",
      "sigma0 grad tensor([352.1850], device='cuda:0')\n",
      "sigma1 grad tensor([[343.5055]], device='cuda:0')\n",
      "gamma grad tensor([[-3143.6987]], device='cuda:0')\n",
      "alpha grad tensor([[5957.0239]], device='cuda:0')\n",
      "beta2 grad tensor([[-6108.7300]], device='cuda:0')\n",
      "beta0 grad tensor([-2694.6841], device='cuda:0')\n",
      "beta1 grad tensor([[-3844.0535]], device='cuda:0')\n",
      "Epoch 478 | Loss: 4.7979\n",
      "alpha: 0.07704658806324005, beta0: 0.1127752885222435, beta1: -0.0010476941242814064, beta2: 0.004201789852231741, \n",
      "gamma: 0.06464698165655136, sigma0: 0.26750636100769043, sigma1: 0.0009295152849517763, sigma2: 0.0005410353187471628, sigmaX: 0.15504465997219086\n",
      "forward done\n",
      "tensor([0.0176, 0.2015, 0.1522, 0.6944, 0.3821], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.8303]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-320.8317]], device='cuda:0')\n",
      "sigma0 grad tensor([-417.2687], device='cuda:0')\n",
      "sigma1 grad tensor([[-335.7427]], device='cuda:0')\n",
      "gamma grad tensor([[3399.1833]], device='cuda:0')\n",
      "alpha grad tensor([[-6515.7495]], device='cuda:0')\n",
      "beta2 grad tensor([[5902.0400]], device='cuda:0')\n",
      "beta0 grad tensor([3007.1316], device='cuda:0')\n",
      "beta1 grad tensor([[3995.1941]], device='cuda:0')\n",
      "Epoch 479 | Loss: 21.3945\n",
      "alpha: 0.07709406316280365, beta0: 0.11275036633014679, beta1: -0.0010772541863843799, beta2: 0.004164258483797312, \n",
      "gamma: 0.0646253451704979, sigma0: 0.2675115168094635, sigma1: 0.0009332829504273832, sigma2: 0.0005442111287266016, sigmaX: 0.15504473447799683\n",
      "forward done\n",
      "tensor([0.0069, 0.1153, 0.1393, 0.6588, 0.3822], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.5845]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-334.3679]], device='cuda:0')\n",
      "sigma0 grad tensor([-461.6643], device='cuda:0')\n",
      "sigma1 grad tensor([[-362.8642]], device='cuda:0')\n",
      "gamma grad tensor([[3692.6428]], device='cuda:0')\n",
      "alpha grad tensor([[-7136.2534]], device='cuda:0')\n",
      "beta2 grad tensor([[6557.9365]], device='cuda:0')\n",
      "beta0 grad tensor([3309.4316], device='cuda:0')\n",
      "beta1 grad tensor([[4416.2056]], device='cuda:0')\n",
      "Epoch 480 | Loss: 12.7177\n",
      "alpha: 0.0772034078836441, beta0: 0.11269734054803848, beta1: -0.001145064365118742, beta2: 0.004068654030561447, \n",
      "gamma: 0.06457110494375229, sigma0: 0.2675202786922455, sigma1: 0.0009399257251061499, sigma2: 0.0005500954575836658, sigmaX: 0.1550448089838028\n",
      "forward done\n",
      "tensor([0.0175, 0.2034, 0.0566, 0.6537, 0.4003], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.2062]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-365.2315]], device='cuda:0')\n",
      "sigma0 grad tensor([-436.7780], device='cuda:0')\n",
      "sigma1 grad tensor([[-355.4022]], device='cuda:0')\n",
      "gamma grad tensor([[2918.3137]], device='cuda:0')\n",
      "alpha grad tensor([[-5840.9580]], device='cuda:0')\n",
      "beta2 grad tensor([[5695.4585]], device='cuda:0')\n",
      "beta0 grad tensor([2785.2324], device='cuda:0')\n",
      "beta1 grad tensor([[3780.6548]], device='cuda:0')\n",
      "Epoch 481 | Loss: 21.4636\n",
      "alpha: 0.07734929025173187, beta0: 0.1126270666718483, beta1: -0.001237118965946138, beta2: 0.003935215994715691, \n",
      "gamma: 0.06449852883815765, sigma0: 0.2675316333770752, sigma1: 0.0009487939532846212, sigma2: 0.000558455241844058, sigmaX: 0.15504486858844757\n",
      "forward done\n",
      "tensor([0.0101, 0.1512, 0.3241, 0.6302, 0.3721], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.7888]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-362.4704]], device='cuda:0')\n",
      "sigma0 grad tensor([-456.0599], device='cuda:0')\n",
      "sigma1 grad tensor([[-362.9182]], device='cuda:0')\n",
      "gamma grad tensor([[3418.8821]], device='cuda:0')\n",
      "alpha grad tensor([[-6749.1323]], device='cuda:0')\n",
      "beta2 grad tensor([[6337.1343]], device='cuda:0')\n",
      "beta0 grad tensor([3165.8218], device='cuda:0')\n",
      "beta1 grad tensor([[4238.6108]], device='cuda:0')\n",
      "Epoch 482 | Loss: 16.4593\n",
      "alpha: 0.07753349095582962, beta0: 0.11253918707370758, beta1: -0.0013531488366425037, beta2: 0.003765094093978405, \n",
      "gamma: 0.06440628319978714, sigma0: 0.26754528284072876, sigma1: 0.0009595177252776921, sigma2: 0.0005687677767127752, sigmaX: 0.15504494309425354\n",
      "forward done\n",
      "tensor([0.0105, 0.0480, 0.1626, 0.6247, 0.3479], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.0144]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-36.5043]], device='cuda:0')\n",
      "sigma0 grad tensor([-19.9717], device='cuda:0')\n",
      "sigma1 grad tensor([[-25.4780]], device='cuda:0')\n",
      "gamma grad tensor([[-863.8904]], device='cuda:0')\n",
      "alpha grad tensor([[1360.4688]], device='cuda:0')\n",
      "beta2 grad tensor([[-1059.9613]], device='cuda:0')\n",
      "beta0 grad tensor([-464.1504], device='cuda:0')\n",
      "beta1 grad tensor([[-664.0970]], device='cuda:0')\n",
      "Epoch 483 | Loss: 5.9444\n",
      "alpha: 0.0776672437787056, beta0: 0.11247352510690689, beta1: -0.0014393316814675927, beta2: 0.0036395960487425327, \n",
      "gamma: 0.06434112042188644, sigma0: 0.26755639910697937, sigma1: 0.0009683514945209026, sigma2: 0.0005773828597739339, sigmaX: 0.1550450176000595\n",
      "forward done\n",
      "tensor([0.0133, 0.0393, 0.1984, 0.6375, 0.3507], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.5976]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-57.8414]], device='cuda:0')\n",
      "sigma0 grad tensor([-24.8497], device='cuda:0')\n",
      "sigma1 grad tensor([[-37.9544]], device='cuda:0')\n",
      "gamma grad tensor([[-832.4962]], device='cuda:0')\n",
      "alpha grad tensor([[1301.7944]], device='cuda:0')\n",
      "beta2 grad tensor([[-1024.0438]], device='cuda:0')\n",
      "beta0 grad tensor([-437.1924], device='cuda:0')\n",
      "beta1 grad tensor([[-625.6365]], device='cuda:0')\n",
      "Epoch 484 | Loss: 5.1290\n",
      "alpha: 0.07776123285293579, beta0: 0.11242536455392838, beta1: -0.0015020216815173626, beta2: 0.003549438202753663, \n",
      "gamma: 0.06429731845855713, sigma0: 0.2675655484199524, sigma1: 0.0009757980587892234, sigma2: 0.0005848533473908901, sigmaX: 0.15504509210586548\n",
      "forward done\n",
      "tensor([0.0138, 0.1031, 0.2086, 0.7074, 0.4119], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.2196]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-375.4649]], device='cuda:0')\n",
      "sigma0 grad tensor([-496.8893], device='cuda:0')\n",
      "sigma1 grad tensor([[-386.1317]], device='cuda:0')\n",
      "gamma grad tensor([[4002.1848]], device='cuda:0')\n",
      "alpha grad tensor([[-7739.7344]], device='cuda:0')\n",
      "beta2 grad tensor([[7520.0850]], device='cuda:0')\n",
      "beta0 grad tensor([3584.3447], device='cuda:0')\n",
      "beta1 grad tensor([[4912.6987]], device='cuda:0')\n",
      "Epoch 485 | Loss: 11.6508\n",
      "alpha: 0.07791382074356079, beta0: 0.11235099285840988, beta1: -0.0016013006679713726, beta2: 0.0034021111205220222, \n",
      "gamma: 0.06422225385904312, sigma0: 0.2675778269767761, sigma1: 0.000985616585239768, sigma2: 0.0005945843877270818, sigmaX: 0.15504518151283264\n",
      "forward done\n",
      "tensor([0.0109, 0.0263, 0.1728, 0.6268, 0.3720], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.0049]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-76.8089]], device='cuda:0')\n",
      "sigma0 grad tensor([-50.0945], device='cuda:0')\n",
      "sigma1 grad tensor([[-56.9656]], device='cuda:0')\n",
      "gamma grad tensor([[-536.6510]], device='cuda:0')\n",
      "alpha grad tensor([[725.1292]], device='cuda:0')\n",
      "beta2 grad tensor([[-397.4921]], device='cuda:0')\n",
      "beta0 grad tensor([-185.0164], device='cuda:0')\n",
      "beta1 grad tensor([[-255.2698]], device='cuda:0')\n",
      "Epoch 486 | Loss: 3.8102\n",
      "alpha: 0.07802864164113998, beta0: 0.11229334771633148, beta1: -0.0016781711019575596, beta2: 0.0032882243394851685, \n",
      "gamma: 0.0641675665974617, sigma0: 0.26758816838264465, sigma1: 0.000994041096419096, sigma2: 0.0006031373050063848, sigmaX: 0.1550452709197998\n",
      "forward done\n",
      "tensor([0.0101, 0.0638, 0.4160, 0.6051, 0.3827], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.8047]]], device='cuda:0')\n",
      "sigma2 grad tensor([[223.6157]], device='cuda:0')\n",
      "sigma0 grad tensor([301.4829], device='cuda:0')\n",
      "sigma1 grad tensor([[238.1248]], device='cuda:0')\n",
      "gamma grad tensor([[-3287.0247]], device='cuda:0')\n",
      "alpha grad tensor([[6113.4790]], device='cuda:0')\n",
      "beta2 grad tensor([[-6163.9922]], device='cuda:0')\n",
      "beta0 grad tensor([-2709.5811], device='cuda:0')\n",
      "beta1 grad tensor([[-3868.8425]], device='cuda:0')\n",
      "Epoch 487 | Loss: 7.7986\n",
      "alpha: 0.0780593603849411, beta0: 0.11227432638406754, beta1: -0.0017009790753945708, beta2: 0.0032587547320872545, \n",
      "gamma: 0.06415668874979019, sigma0: 0.2675934135913849, sigma1: 0.0009983994532376528, sigma2: 0.0006077434518374503, sigmaX: 0.15504536032676697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0170, 0.0336, 0.2380, 0.6403, 0.3602], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.3909]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-210.9182]], device='cuda:0')\n",
      "sigma0 grad tensor([-180.6431], device='cuda:0')\n",
      "sigma1 grad tensor([[-171.2052]], device='cuda:0')\n",
      "gamma grad tensor([[391.2401]], device='cuda:0')\n",
      "alpha grad tensor([[-1101.7504]], device='cuda:0')\n",
      "beta2 grad tensor([[1601.1180]], device='cuda:0')\n",
      "beta0 grad tensor([678.0513], device='cuda:0')\n",
      "beta1 grad tensor([[980.3531]], device='cuda:0')\n",
      "Epoch 488 | Loss: 4.6118\n",
      "alpha: 0.0780949518084526, beta0: 0.11225233227014542, beta1: -0.0017290289979428053, beta2: 0.003219167934730649, \n",
      "gamma: 0.0641440749168396, sigma0: 0.2675994336605072, sigma1: 0.0010035982122644782, sigma2: 0.0006135375588200986, sigmaX: 0.15504544973373413\n",
      "forward done\n",
      "tensor([0.0128, 0.1664, 0.2210, 0.5782, 0.3081], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.0744]]], device='cuda:0')\n",
      "sigma2 grad tensor([[660.4429]], device='cuda:0')\n",
      "sigma0 grad tensor([605.9611], device='cuda:0')\n",
      "sigma1 grad tensor([[562.4666]], device='cuda:0')\n",
      "gamma grad tensor([[-6293.3579]], device='cuda:0')\n",
      "alpha grad tensor([[11526.3672]], device='cuda:0')\n",
      "beta2 grad tensor([[-12806.0615]], device='cuda:0')\n",
      "beta0 grad tensor([-5132.1206], device='cuda:0')\n",
      "beta1 grad tensor([[-7657.7095]], device='cuda:0')\n",
      "Epoch 489 | Loss: 17.7625\n",
      "alpha: 0.07800815999507904, beta0: 0.1122860535979271, beta1: -0.0016748917987570167, beta2: 0.00331555912271142, \n",
      "gamma: 0.06419691443443298, sigma0: 0.2675981819629669, sigma1: 0.001002132543362677, sigma2: 0.000611568393651396, sigmaX: 0.1550455391407013\n",
      "forward done\n",
      "tensor([0.0127, 0.2504, 0.3382, 0.6052, 0.4351], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[0.7219]]], device='cuda:0')\n",
      "sigma2 grad tensor([[590.7955]], device='cuda:0')\n",
      "sigma0 grad tensor([645.2167], device='cuda:0')\n",
      "sigma1 grad tensor([[549.8395]], device='cuda:0')\n",
      "gamma grad tensor([[-6613.9980]], device='cuda:0')\n",
      "alpha grad tensor([[12161.4961]], device='cuda:0')\n",
      "beta2 grad tensor([[-12943.9502]], device='cuda:0')\n",
      "beta0 grad tensor([-5440.8691], device='cuda:0')\n",
      "beta1 grad tensor([[-7923.7173]], device='cuda:0')\n",
      "Epoch 490 | Loss: 26.4352\n",
      "alpha: 0.07781711220741272, beta0: 0.11236744374036789, beta1: -0.0015523448819294572, beta2: 0.0035221115685999393, \n",
      "gamma: 0.06430532783269882, sigma0: 0.26759073138237, sigma1: 0.0009954615961760283, sigma2: 0.0006040851003490388, sigmaX: 0.15504559874534607\n",
      "forward done\n",
      "tensor([0.0066, 0.1052, 0.3423, 0.6192, 0.3618], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.9321]]], device='cuda:0')\n",
      "sigma2 grad tensor([[475.5783]], device='cuda:0')\n",
      "sigma0 grad tensor([538.6264], device='cuda:0')\n",
      "sigma1 grad tensor([[450.0659]], device='cuda:0')\n",
      "gamma grad tensor([[-4804.3696]], device='cuda:0')\n",
      "alpha grad tensor([[9073.9102]], device='cuda:0')\n",
      "beta2 grad tensor([[-9675.0146]], device='cuda:0')\n",
      "beta0 grad tensor([-4141.8521], device='cuda:0')\n",
      "beta1 grad tensor([[-5963.3369]], device='cuda:0')\n",
      "Epoch 491 | Loss: 11.8476\n",
      "alpha: 0.07757353782653809, beta0: 0.1124739721417427, beta1: -0.0013946739491075277, beta2: 0.003784103551879525, \n",
      "gamma: 0.06444010138511658, sigma0: 0.2675793766975403, sigma1: 0.0009856241522356868, sigma2: 0.0005933427019044757, sigmaX: 0.15504565834999084\n",
      "forward done\n",
      "tensor([0.0099, 0.0495, 0.3540, 0.6128, 0.3935], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.0165]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-65.9314]], device='cuda:0')\n",
      "sigma0 grad tensor([-17.0860], device='cuda:0')\n",
      "sigma1 grad tensor([[-35.6639]], device='cuda:0')\n",
      "gamma grad tensor([[-850.1914]], device='cuda:0')\n",
      "alpha grad tensor([[1367.6892]], device='cuda:0')\n",
      "beta2 grad tensor([[-963.7562]], device='cuda:0')\n",
      "beta0 grad tensor([-477.6309], device='cuda:0')\n",
      "beta1 grad tensor([[-642.0068]], device='cuda:0')\n",
      "Epoch 492 | Loss: 6.3217\n",
      "alpha: 0.07736500352621078, beta0: 0.11256396770477295, beta1: -0.001262117177248001, beta2: 0.004003334790468216, \n",
      "gamma: 0.06455641984939575, sigma0: 0.26757046580314636, sigma1: 0.0009781108237802982, sigma2: 0.0005854081246070564, sigmaX: 0.15504571795463562\n",
      "forward done\n",
      "tensor([0.0076, 0.0512, 0.2435, 0.6278, 0.3513], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.9093]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-279.6889]], device='cuda:0')\n",
      "sigma0 grad tensor([-313.9291], device='cuda:0')\n",
      "sigma1 grad tensor([[-263.9626]], device='cuda:0')\n",
      "gamma grad tensor([[2042.4235]], device='cuda:0')\n",
      "alpha grad tensor([[-4105.6929]], device='cuda:0')\n",
      "beta2 grad tensor([[4277.3955]], device='cuda:0')\n",
      "beta0 grad tensor([1981.8052], device='cuda:0')\n",
      "beta1 grad tensor([[2750.0410]], device='cuda:0')\n",
      "Epoch 493 | Loss: 6.3529\n",
      "alpha: 0.07723923027515411, beta0: 0.1126161515712738, beta1: -0.0011835721088573337, beta2: 0.004135945811867714, \n",
      "gamma: 0.06462905555963516, sigma0: 0.2675664722919464, sigma1: 0.0009747398435138166, sigma2: 0.000581857340876013, sigmaX: 0.1550457775592804\n",
      "forward done\n",
      "tensor([0.0141, 0.1785, 0.2654, 0.6015, 0.3463], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[0.2340]]], device='cuda:0')\n",
      "sigma2 grad tensor([[661.5149]], device='cuda:0')\n",
      "sigma0 grad tensor([583.3807], device='cuda:0')\n",
      "sigma1 grad tensor([[548.5237]], device='cuda:0')\n",
      "gamma grad tensor([[-4857.1157]], device='cuda:0')\n",
      "alpha grad tensor([[9202.6318]], device='cuda:0')\n",
      "beta2 grad tensor([[-10126.7998]], device='cuda:0')\n",
      "beta0 grad tensor([-4208.7979], device='cuda:0')\n",
      "beta1 grad tensor([[-6176.4780]], device='cuda:0')\n",
      "Epoch 494 | Loss: 19.0785\n",
      "alpha: 0.07704658806324005, beta0: 0.11269998550415039, beta1: -0.0010589712765067816, beta2: 0.004343302454799414, \n",
      "gamma: 0.06473573297262192, sigma0: 0.26755744218826294, sigma1: 0.0009665578254498541, sigma2: 0.0005724015645682812, sigmaX: 0.15504582226276398\n",
      "forward done\n",
      "tensor([0.0090, 0.0388, 0.2419, 0.6447, 0.3681], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.8317]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-111.2649]], device='cuda:0')\n",
      "sigma0 grad tensor([-86.8198], device='cuda:0')\n",
      "sigma1 grad tensor([[-87.1188]], device='cuda:0')\n",
      "gamma grad tensor([[-296.3073]], device='cuda:0')\n",
      "alpha grad tensor([[287.7516]], device='cuda:0')\n",
      "beta2 grad tensor([[72.4410]], device='cuda:0')\n",
      "beta0 grad tensor([25.5030], device='cuda:0')\n",
      "beta1 grad tensor([[41.7004]], device='cuda:0')\n",
      "Epoch 495 | Loss: 5.1468\n",
      "alpha: 0.07688959687948227, beta0: 0.112766794860363, beta1: -0.0009597076568752527, beta2: 0.00450846366584301, \n",
      "gamma: 0.06482403725385666, sigma0: 0.26755109429359436, sigma1: 0.0009608833934180439, sigma2: 0.0005659495946019888, sigmaX: 0.15504588186740875\n",
      "forward done\n",
      "tensor([0.0123, 0.1127, 0.2431, 0.6549, 0.3824], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-2.4075]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-397.6570]], device='cuda:0')\n",
      "sigma0 grad tensor([-447.0764], device='cuda:0')\n",
      "sigma1 grad tensor([[-384.0531]], device='cuda:0')\n",
      "gamma grad tensor([[3651.8247]], device='cuda:0')\n",
      "alpha grad tensor([[-6970.9321]], device='cuda:0')\n",
      "beta2 grad tensor([[6721.6738]], device='cuda:0')\n",
      "beta0 grad tensor([3198.1665], device='cuda:0')\n",
      "beta1 grad tensor([[4391.0562]], device='cuda:0')\n",
      "Epoch 496 | Loss: 12.5636\n",
      "alpha: 0.07683371007442474, beta0: 0.11278825998306274, beta1: -0.0009242073283530772, beta2: 0.004573375917971134, \n",
      "gamma: 0.06485816091299057, sigma0: 0.2675504982471466, sigma1: 0.000960184377618134, sigma2: 0.0005647646030411124, sigmaX: 0.15504595637321472\n",
      "forward done\n",
      "tensor([0.0167, 0.1032, 0.2779, 0.6675, 0.3733], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-1.7962]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-467.1730]], device='cuda:0')\n",
      "sigma0 grad tensor([-466.5500], device='cuda:0')\n",
      "sigma1 grad tensor([[-405.4315]], device='cuda:0')\n",
      "gamma grad tensor([[3284.9890]], device='cuda:0')\n",
      "alpha grad tensor([[-6452.6694]], device='cuda:0')\n",
      "beta2 grad tensor([[6426.1533]], device='cuda:0')\n",
      "beta0 grad tensor([3025.5798], device='cuda:0')\n",
      "beta1 grad tensor([[4152.4663]], device='cuda:0')\n",
      "Epoch 497 | Loss: 11.6555\n",
      "alpha: 0.07685352861881256, beta0: 0.11277517676353455, beta1: -0.0009373317006975412, beta2: 0.004561044275760651, \n",
      "gamma: 0.06485261023044586, sigma0: 0.2675546705722809, sigma1: 0.0009636794566176832, sigma2: 0.0005684883217327297, sigmaX: 0.1550460308790207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward done\n",
      "tensor([0.0220, 0.2812, 0.0706, 0.7113, 0.4203], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[2.0760]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-227.0005]], device='cuda:0')\n",
      "sigma0 grad tensor([-386.4917], device='cuda:0')\n",
      "sigma1 grad tensor([[-270.8184]], device='cuda:0')\n",
      "gamma grad tensor([[2822.2390]], device='cuda:0')\n",
      "alpha grad tensor([[-5552.2178]], device='cuda:0')\n",
      "beta2 grad tensor([[4672.7656]], device='cuda:0')\n",
      "beta0 grad tensor([2608.7866], device='cuda:0')\n",
      "beta1 grad tensor([[3305.1284]], device='cuda:0')\n",
      "Epoch 498 | Loss: 29.3417\n",
      "alpha: 0.07692490518093109, beta0: 0.11273862421512604, beta1: -0.000980882439762354, beta2: 0.004504451062530279, \n",
      "gamma: 0.06481994688510895, sigma0: 0.2675618827342987, sigma1: 0.0009691836894489825, sigma2: 0.0005737373139709234, sigmaX: 0.15504607558250427\n",
      "forward done\n",
      "tensor([0.0178, 0.1999, 0.3141, 0.6803, 0.4323], device='cuda:0',\n",
      "       dtype=torch.float64, grad_fn=<CatBackward0>)\n",
      "sigmaX grad tensor([[[-0.7952]]], device='cuda:0')\n",
      "sigma2 grad tensor([[-316.0741]], device='cuda:0')\n",
      "sigma0 grad tensor([-425.1870], device='cuda:0')\n",
      "sigma1 grad tensor([[-336.4153]], device='cuda:0')\n",
      "gamma grad tensor([[2949.6885]], device='cuda:0')\n",
      "alpha grad tensor([[-5857.4580]], device='cuda:0')\n",
      "beta2 grad tensor([[5301.5576]], device='cuda:0')\n",
      "beta0 grad tensor([2776.7830], device='cuda:0')\n",
      "beta1 grad tensor([[3623.3735]], device='cuda:0')\n",
      "Epoch 499 | Loss: 21.4361\n",
      "alpha: 0.07704058289527893, beta0: 0.11268161237239838, beta1: -0.0010519567877054214, beta2: 0.004406161140650511, \n",
      "gamma: 0.06476432085037231, sigma0: 0.26757189631462097, sigma1: 0.0009769512107595801, sigma2: 0.000581097265239805, sigmaX: 0.15504612028598785\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "\n",
    "#datadirName = \"/content/drive/MyDrive/trajectories_miura/\"\n",
    "\n",
    "alpha_init = 0.0741\n",
    "beta0_init = 0.116\n",
    "beta1_init = 0.0\n",
    "beta2_init = 0.0\n",
    "gamma_init = 0.0641\n",
    "sigma0_init = 0.266\n",
    "sigma1_init = 0.0\n",
    "sigma2_init = 0.0\n",
    "sigmaX_init = 0.155\n",
    "\n",
    "initIns = {'alpha': alpha_init,\n",
    "           'beta0': beta0_init,\n",
    "           'beta1': beta1_init,\n",
    "           'beta2': beta2_init,\n",
    "           'gamma': gamma_init,\n",
    "           'sigma0': sigma0_init,\n",
    "           'sigma1': sigma1_init,\n",
    "           'sigma2': sigma2_init,\n",
    "           'sigmaX': sigmaX_init}\n",
    "\n",
    "model = moduleSDE(initIns)\n",
    "\n",
    "#print(list(model.parameters()))\n",
    "\n",
    "printparams(model)\n",
    "\n",
    "lossfunc = customLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-8, momentum=0.8)#, weight_decay=5e-4)\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=1e-5, momentum=0.5)#, weight_decay=5e-4)\n",
    "\n",
    "loss_log = []\n",
    "\n",
    "params_log = []\n",
    "\n",
    "# learnig loop\n",
    "for epoch in range(500):\n",
    "    if 'out' in globals():\n",
    "        del out\n",
    "    if 'loss' in globals():\n",
    "        del loss\n",
    "        \n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    bm = BrownianInterval(t0=ts[0], \n",
    "                          t1=ts[-1], \n",
    "                          size=(batch_size, brownian_size),\n",
    "                          dt=stepSDE,\n",
    "                          device=device)\n",
    "\n",
    "    y0 = torch.rand((batch_size,1), device=device)\n",
    "    y1 = torch.concat((torch.zeros_like(y0), torch.zeros_like(y0),          #x,y = 0,0\n",
    "                     torch.cos(y0*(2*np.pi)), torch.sin(y0*(2*np.pi)),    #|v| = 1\n",
    "                     torch.zeros_like(y0), torch.zeros_like(y0)), 1)      #|V| = 0\n",
    "\n",
    "    rnoise = torch.randn((Nts, batch_size, 2), device=device)\n",
    "\n",
    "    #with torch.autograd.detect_anomaly():\n",
    "    out = model(y1, bm, rnoise)\n",
    "    #print('out', out)\n",
    "    print('forward done')\n",
    "\n",
    "    #out.register_hook(lambda grad: print('trajectory back', grad))#(grad != grad).any().item()))\n",
    "\n",
    "    loss = lossfunc(out)\n",
    "    #print('loss {}'.format(str(loss)))\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print('Epoch %d | Loss: %.4f' % (epoch, loss.item()))\n",
    "    \n",
    "    loss_log.append(loss.item())\n",
    "    params_log.append(extractParams(model))\n",
    "\n",
    "    printparams(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T16:23:27.955166Z",
     "start_time": "2022-10-06T16:23:27.813174Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10.60167521 17.98827909  7.83476701  8.57818044  4.51224523  7.1977604\n",
      "  7.59517666  9.94403461 25.1852509  15.39022832 11.65748973  6.45470952\n",
      " 44.72166476 27.49383018 20.97511964  9.74196542 23.03551399  8.48582426\n",
      " 11.48807697  9.76270781 19.94220506 24.03273917 29.97888963 15.75355318\n",
      " 13.91816036 11.79986473 15.27084793  5.80676458  7.45305633  5.44868063\n",
      " 26.79577938 14.69087058 17.55245563  8.6892284  23.95957737 11.10845894\n",
      " 23.51173319 26.34996535 20.4038348   8.88247302  6.00003987  7.36748339\n",
      " 12.55649429 12.25314042 36.30035321 14.50287003  6.86453761 15.57986867\n",
      " 23.64479172 21.85616604  9.55524047  6.16017852  8.73908397 20.79631302\n",
      "  8.02823776 17.56702727  5.6792248   4.66918895 49.46028164 10.57208547\n",
      " 18.12547754 10.15168231 28.06513448 18.32422746  7.14164839 11.05543291\n",
      " 16.25732271  9.22838256  6.96327189 15.32388443  5.10165244  5.28941676\n",
      " 11.51200031  8.58001375 38.56410642  8.71103815 20.98098678 17.36928304\n",
      "  8.72205677  8.02919494  7.84805359  6.17034904 12.47716884  7.75070736\n",
      "  8.6226943   9.44995051 21.49450089  7.66176847  8.54070608  7.58250568\n",
      "  6.80810137  6.9609715   7.72674455 24.82188299  6.08284785 17.70169608\n",
      "  9.3236771  19.53583113 24.86643808  5.85202771 13.45029074  6.60651973\n",
      " 20.58868421  6.11174131  8.67175266  9.25375849 17.08352175 28.37357076\n",
      " 30.24090545  5.32933787  6.34852481 18.6839106   8.20463005  4.98491382\n",
      "  5.06384837 15.7612566  29.30302247 17.31974871  7.68524605  9.11325059\n",
      " 17.3926888   7.43290211  5.10536564  5.31718431 32.4000364  12.61545823\n",
      " 12.60892988  5.46221034  6.63200259 15.92458155 12.15896192 19.03821305\n",
      " 10.76771262  7.18970068 12.19972919  3.72084376 18.88569487  4.83574074\n",
      " 14.12767793 22.79194392 14.0720999   6.87979966  9.48357904  9.11270867\n",
      " 10.22829425 20.57264338 41.84501194 31.49704298  6.38744012  5.39456316\n",
      "  6.36540834  9.6951187  12.38570673 23.84379546 24.34448148  7.05910465\n",
      "  6.85087448  5.53279923  9.94780205  8.81181073 25.38046259  5.35849827\n",
      " 25.36426739 11.69753932 36.07361685  8.69032496  4.26153365  7.09106803\n",
      " 15.99455529 23.49456764 19.19953396 20.65322391 16.90829041 17.28485587\n",
      " 23.57823427 11.0593281  22.77562177  9.01568057 11.32146458  6.01231359\n",
      " 12.84490573  6.43953466 19.84601893  6.78189054  6.83803514  6.55983228\n",
      " 12.40726148  7.67886082  7.39381847 20.69622738  6.92158432 17.65586374\n",
      " 10.2226363  19.47429276 12.62286439  4.9480105  12.95493302  7.51138734\n",
      "  5.16790604 16.53137728 25.88373598  7.58427484  8.2673326  15.12321108\n",
      "  9.0015384  23.36986712  7.88492321 15.23419136  6.56910351  7.57848025\n",
      "  5.74010586 13.89476316  8.55728998  4.708195    8.05989213  6.72744147\n",
      " 15.6047982   9.61638796 19.81418062 14.90255463  8.34234997  5.59930002\n",
      " 20.38824036  9.82603833 13.06336476  6.66109002  6.68901725  9.61823734\n",
      " 28.19913255  6.92838791  7.47727982 13.42768034 18.78046332  7.19773882\n",
      " 13.95872065  7.02943099 17.73362937 10.17875475  9.8999496  12.36603152\n",
      "  6.01351365  8.4763459   7.41342243 13.57353163  7.49243967  7.15603235\n",
      "  6.22565089  7.81477942 26.58819687  6.39802323  5.21407349  6.6593368\n",
      " 11.15367122 18.15350586 10.83318386 19.69758838  6.43429756 20.2671582\n",
      "  8.46184618  7.19111192  8.32088867  6.28867367  4.55251299  8.39960358\n",
      " 10.21023953 14.85535515  6.56522572  7.2290137   8.26705837  6.61346729\n",
      " 16.89538831  7.92662988  7.69832935  9.78032486 16.04925129 20.81770698\n",
      " 10.30958602  2.51209041 10.11325889 11.03251611 19.67086623 21.72652622\n",
      "  5.37201762  7.13963246  5.37072859 36.5563099   6.58162046  6.70375873\n",
      "  5.11474165  7.72276764  5.33632362  8.06974215 21.11664205 23.74862167\n",
      "  7.73774587 10.33260743  5.52197704 16.53169363 10.92195266  7.165155\n",
      " 12.83000186  4.61888578 24.69190396 31.58953895  6.21985347 15.5497606\n",
      "  6.65747029 11.7585419   6.76636471 11.3643418   9.90566447  8.83064424\n",
      " 15.33275696 24.91981898 12.15581777  5.21706228  6.76850392  5.84295739\n",
      "  7.19793673 15.48327464  4.18933849  5.51528295 14.91725998 16.73304178\n",
      "  5.60701216 11.4478346   7.56999955  6.97678696 13.93813986  6.03111449\n",
      "  4.89999203 17.58710807  7.78614769 15.93251706  8.19176716  6.70770686\n",
      " 26.63716629  6.68860287  8.51250205  6.18254485 13.62374628  9.86246096\n",
      " 11.98617907 27.74004445  9.60669561  9.33315456 17.98071314  6.14376987\n",
      "  8.14322954  5.96531586  5.18395742  6.46725964  4.96538201 12.17416564\n",
      "  5.74326696  6.04396113  9.26553491  6.18462582  7.93016484  9.19863305\n",
      "  8.94302269  7.68266762  6.132109    5.2659361   6.115065    8.95777484\n",
      " 23.06471035 15.55746653  5.11984711  8.47681038 11.56332623  7.09616718\n",
      "  9.51710616  6.29465431 17.65775499  5.58255216 20.9860174   5.78301856\n",
      " 14.1097826   7.6417777   6.69673084  6.02442371  6.84982915 10.53776987\n",
      " 17.71614734 26.54596037 16.73612418 12.53713925 13.21226611  8.59126173\n",
      "  7.07713595 14.14185954  9.82638974 10.46177031  4.80977333  8.69848643\n",
      " 10.64389264  4.27286117 14.77556706 14.8003215   6.45275078  9.40056647\n",
      "  9.55980367  7.79164931  4.72281163 22.04243247 34.51445489 17.25840479\n",
      " 11.1034935  14.08008435 15.3917094   6.25693227  7.38411223  3.10915806\n",
      " 14.17288996  5.3945664   6.25657235 10.50272425  8.24652349  4.86072664\n",
      " 16.28227654 20.27345212  7.15974372 13.49777167  6.38058566  5.40362485\n",
      " 21.55218288  5.56691695 10.67680088 11.55235017 12.07386058 30.48094153\n",
      "  7.2446281  13.39415517 18.42024383  7.37974108  8.26461785  5.9899504\n",
      "  6.64491009 20.36882549 36.23005024  3.60922899  6.46138291  6.62889657\n",
      "  6.76037182  7.23673287  9.77707114 12.88535626 10.03748821  5.16009591\n",
      "  7.67614782 10.55534987 10.32117127 12.73486364  6.34415322  5.28517147\n",
      "  8.22591896  8.65629641  9.90810503  5.48697368  5.84651873 12.3144544\n",
      "  6.63243298  6.43248891  8.64185253  8.59893834  6.23380557  9.9369086\n",
      " 23.22885703 19.9596061  12.30064127 12.30725794  8.48267446 22.24035749\n",
      "  6.26754313  9.54381516  6.05460611 18.4164044   4.79794421 21.39452152\n",
      " 12.71771906 21.46361279 16.45934677  5.94436827  5.1289706  11.65084946\n",
      "  3.81018926  7.79864444  4.61182394 17.76252785 26.43517766 11.8475832\n",
      "  6.32166497  6.35290462 19.07845945  5.14676816 12.56364837 11.65548371\n",
      " 29.34173209 21.43610033]\n"
     ]
    }
   ],
   "source": [
    "print(np.array(loss_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T16:23:29.312718Z",
     "start_time": "2022-10-06T16:23:27.998620Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe20f747670>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(np.array(loss_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T16:23:29.327479Z",
     "start_time": "2022-10-06T16:23:29.316669Z"
    },
    "id": "CXVcQSJczvlj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.8310e-01, -4.2476e-01],\n",
      "         [ 1.5914e-01,  1.9628e-03],\n",
      "         [-4.6995e-02,  1.1458e-01],\n",
      "         ...,\n",
      "         [ 7.6170e-03,  4.1051e-02],\n",
      "         [-2.7421e-01,  2.7821e-01],\n",
      "         [-1.5481e-01,  1.0454e-01]],\n",
      "\n",
      "        [[ 6.6041e-01,  6.9480e-01],\n",
      "         [ 1.2126e-01, -6.8379e-01],\n",
      "         [ 3.1913e-01, -9.9805e-01],\n",
      "         ...,\n",
      "         [-5.9067e-01, -6.2891e-01],\n",
      "         [ 1.0239e+00, -1.4181e-01],\n",
      "         [ 1.4057e+00, -2.4383e-01]],\n",
      "\n",
      "        [[ 1.5732e+00,  8.4011e-01],\n",
      "         [ 3.3699e-01, -1.1698e+00],\n",
      "         [ 2.1163e-01, -1.4536e+00],\n",
      "         ...,\n",
      "         [-1.5293e+00, -1.0544e+00],\n",
      "         [ 1.8858e+00, -4.0741e-01],\n",
      "         [ 2.5703e+00, -1.0408e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-1.0208e+02,  2.4389e+02],\n",
      "         [-4.5408e+01, -5.4400e+00],\n",
      "         [ 2.4738e+02,  4.8769e+01],\n",
      "         ...,\n",
      "         [-1.8133e+02,  2.2193e+02],\n",
      "         [-2.2441e+02, -1.1226e+02],\n",
      "         [ 1.4660e+02, -1.0796e+02]],\n",
      "\n",
      "        [[-1.0172e+02,  2.4430e+02],\n",
      "         [-4.5401e+01, -4.6791e+00],\n",
      "         [ 2.4745e+02,  4.8962e+01],\n",
      "         ...,\n",
      "         [-1.8254e+02,  2.2254e+02],\n",
      "         [-2.2266e+02, -1.1144e+02],\n",
      "         [ 1.4495e+02, -1.0794e+02]],\n",
      "\n",
      "        [[-1.0149e+02,  2.4438e+02],\n",
      "         [-4.5833e+01, -4.1140e+00],\n",
      "         [ 2.4733e+02,  4.8949e+01],\n",
      "         ...,\n",
      "         [-1.8366e+02,  2.2323e+02],\n",
      "         [-2.2083e+02, -1.1098e+02],\n",
      "         [ 1.4319e+02, -1.0797e+02]]], device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-06T16:23:29.356953Z",
     "start_time": "2022-10-06T16:23:29.330406Z"
    },
    "id": "MZNhI5GFFacj"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "bestParams = extractParams(model)\n",
    "\n",
    "np.savez(savedir+'bestParams_' + now.strftime('%Y%m%d_%H%M%S'),\n",
    "        bestParams=bestParams,\n",
    "        optimizer=optimizer,\n",
    "        loss_log=loss_log,\n",
    "        lossfunc=lossfunc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rktzzGJTn161"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOyexgXk7VjzKwoeEmDr4SK",
   "collapsed_sections": [],
   "provenance": [
    {
     "file_id": "1iThXlCWDmK8QDx5A3VzYH6m7GkQczcPP",
     "timestamp": 1646628037404
    },
    {
     "file_id": "1cC1UC5ySJ6V1P8CJlI1rat7GHYmXTtcb",
     "timestamp": 1646395520305
    },
    {
     "file_id": "1Q2O4CtsXiZkN21hP3997Mxzf1ef1RmDJ",
     "timestamp": 1646225534045
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
