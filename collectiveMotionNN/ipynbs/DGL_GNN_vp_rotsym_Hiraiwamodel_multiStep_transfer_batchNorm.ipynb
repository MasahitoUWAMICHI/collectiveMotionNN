{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f855b76a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T08:41:02.454494Z",
     "start_time": "2023-03-02T08:41:02.452466Z"
    }
   },
   "outputs": [],
   "source": [
    "#!pip install dgl-cu113 dglgo -f https://data.dgl.ai/wheels/repo.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7807020c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T08:41:02.462231Z",
     "start_time": "2023-03-02T08:41:02.459679Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['DGLBACKEND'] = 'pytorch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d12568c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T08:41:02.468249Z",
     "start_time": "2023-03-02T08:41:02.464992Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "\n",
    "import networkx as nx\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# デバイス設定\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "61e1f3ee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T08:41:02.472694Z",
     "start_time": "2023-03-02T08:41:02.469852Z"
    }
   },
   "outputs": [],
   "source": [
    "def printNPZ(npz):\n",
    "    for kw in npz.files:\n",
    "        print(kw, npz[kw])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0ba5ba52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T08:41:02.488086Z",
     "start_time": "2023-03-02T08:41:02.474614Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v0 1.0\n",
      "r 1.0\n",
      "D 0.0\n",
      "A 0.0\n",
      "L 20\n",
      "rho 1.0\n",
      "beta 1.0\n",
      "A_CFs [0.9 0.5]\n",
      "A_CIL 0.0\n",
      "cellType_ratio [0.7 0.3]\n",
      "quiv_colors ['k' 'r']\n",
      "kappa 0.5\n",
      "A_Macdonalds [0.5 0.5]\n",
      "batch_size 400\n",
      "state_size 3\n",
      "brownian_size 1\n",
      "periodic True\n",
      "t_max 1000\n",
      "methodSDE heun\n",
      "isIto False\n",
      "stepSDE 0.01\n"
     ]
    }
   ],
   "source": [
    "dirName = '/home/uwamichi/jupyter/HiraiwaModel_chem20230227_160803/'\n",
    "savedirName = dirName + 'ActiveNet_vp_rotsym_multiStep_transfer_batchNorm/'\n",
    "os.makedirs(savedirName, exist_ok=True)\n",
    "\n",
    "params = np.load(dirName+'params.npz')\n",
    "#traj = np.load(dirName+'result.npz')\n",
    "\n",
    "printNPZ(params)\n",
    "#printNPZ(traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c4e73591",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T08:41:02.501140Z",
     "start_time": "2023-03-02T08:41:02.490213Z"
    }
   },
   "outputs": [],
   "source": [
    "if params['periodic']:\n",
    "    L = torch.tensor(params['L'])\n",
    "    def calc_dr(r1, r2):\n",
    "        dr = torch.remainder((r1 - r2), L)\n",
    "        dr[dr > L/2] = dr[dr > L/2] - L\n",
    "        return dr\n",
    "else:\n",
    "    def calc_dr(r1, r2):\n",
    "        return r1 - r2\n",
    "    \n",
    "def makeGraph(x_data, r_thresh):\n",
    "        Ndata = x_data.size(0)\n",
    "        dx = calc_dr(torch.unsqueeze(x_data, 0), torch.unsqueeze(x_data, 1))\n",
    "        dx = torch.sum(dx**2, dim=2)\n",
    "        edges = torch.argwhere(dx < r_thresh/2)\n",
    "        return dgl.graph((edges[:,0], edges[:,1]), num_nodes=Ndata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e3e01d8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T08:41:02.519502Z",
     "start_time": "2023-03-02T08:41:02.504553Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/uwamichi/jupyter/HiraiwaModel_chem20230227_160803/20230228_024901', '/home/uwamichi/jupyter/HiraiwaModel_chem20230227_160803/20230228_064020', '/home/uwamichi/jupyter/HiraiwaModel_chem20230227_160803/20230228_103154', '/home/uwamichi/jupyter/HiraiwaModel_chem20230227_160803/20230228_142155', '/home/uwamichi/jupyter/HiraiwaModel_chem20230227_160803/20230228_181400', '/home/uwamichi/jupyter/HiraiwaModel_chem20230227_160803/20230228_220458', '/home/uwamichi/jupyter/HiraiwaModel_chem20230227_160803/20230301_015428', '/home/uwamichi/jupyter/HiraiwaModel_chem20230227_160803/20230301_054439', '/home/uwamichi/jupyter/HiraiwaModel_chem20230227_160803/20230301_093612', '/home/uwamichi/jupyter/HiraiwaModel_chem20230227_160803/20230301_132715', '/home/uwamichi/jupyter/HiraiwaModel_chem20230227_160803/ActiveNet_vp_rotsym_multiStep_batchNorm', '/home/uwamichi/jupyter/HiraiwaModel_chem20230227_160803/ActiveNet_vp_rotsym_batchNorm', '/home/uwamichi/jupyter/HiraiwaModel_chem20230227_160803/ActiveNet_vp_rotsym_multiStep_transfer_batchNorm']\n",
      "['/home/uwamichi/jupyter/HiraiwaModel_chem20230227_160803/20230228_024901', '/home/uwamichi/jupyter/HiraiwaModel_chem20230227_160803/20230228_064020', '/home/uwamichi/jupyter/HiraiwaModel_chem20230227_160803/20230228_103154', '/home/uwamichi/jupyter/HiraiwaModel_chem20230227_160803/20230228_142155', '/home/uwamichi/jupyter/HiraiwaModel_chem20230227_160803/20230228_181400', '/home/uwamichi/jupyter/HiraiwaModel_chem20230227_160803/20230228_220458', '/home/uwamichi/jupyter/HiraiwaModel_chem20230227_160803/20230301_015428', '/home/uwamichi/jupyter/HiraiwaModel_chem20230227_160803/20230301_054439', '/home/uwamichi/jupyter/HiraiwaModel_chem20230227_160803/20230301_093612', '/home/uwamichi/jupyter/HiraiwaModel_chem20230227_160803/20230301_132715']\n"
     ]
    }
   ],
   "source": [
    "subdir_list = [f.path for f in os.scandir(dirName) if f.is_dir()]\n",
    "\n",
    "print(subdir_list)\n",
    "\n",
    "datadir_list = [f for f in subdir_list if 'result.npz' in [ff.name for ff in os.scandir(f)]]\n",
    "\n",
    "print(datadir_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3260481d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T08:41:02.529692Z",
     "start_time": "2023-03-02T08:41:02.521407Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], ['/home/uwamichi/jupyter/HiraiwaModel_chem20230227_160803/ActiveNet_vp_rotsym_batchNorm/20230301_231603/20230301_231603_Model.pt']]\n",
      "['/home/uwamichi/jupyter/HiraiwaModel_chem20230227_160803/ActiveNet_vp_rotsym_batchNorm/20230301_231603/20230301_231603_Model.pt']\n",
      "20230301_231603/20230301_231603\n"
     ]
    }
   ],
   "source": [
    "modeldirName = dirName + 'ActiveNet_vp_rotsym_batchNorm/'\n",
    "\n",
    "#datename = '20220921_160055'\n",
    "i_model = -1\n",
    "\n",
    "model_files_list = [[os.path.join(c, ff) for ff in f if ff.endswith('_Model.pt')]\n",
    "               for c, s, f in os.walk(modeldirName)]\n",
    "print(model_files_list)\n",
    "\n",
    "model_files = []\n",
    "for i in range(len(model_files_list)):\n",
    "    for j in range(len(model_files_list[i])):\n",
    "        model_files.append(model_files_list[i][j])\n",
    "print(model_files)\n",
    "\n",
    "model_dir = os.path.dirname(model_files[i_model])\n",
    "\n",
    "model_name = model_files[i_model].replace('_Model.pt', '').replace(modeldirName, '')\n",
    "print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "19f22447",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T08:41:02.537487Z",
     "start_time": "2023-03-02T08:41:02.532299Z"
    }
   },
   "outputs": [],
   "source": [
    "class myDataset(Dataset):\n",
    "    def __init__(self, data_x, celltype_List, t_yseq=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.data_x = data_x # List of tensors\n",
    "        #self.data_y = data_y\n",
    "        self.celltype_List = celltype_List\n",
    "        \n",
    "        self.data_len = np.array([xx.size(0) for xx in self.data_x])\n",
    "        self.t_yseq = t_yseq\n",
    "        \n",
    "        self.data_len_cumsum = np.cumsum(self.data_len - (self.t_yseq - 1))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return (self.data_len - (self.t_yseq - 1)).sum()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        id_List = np.argwhere(index<self.data_len_cumsum)[0,0]\n",
    "        \n",
    "        if id_List:\n",
    "            id_tensor = index - self.data_len_cumsum[id_List-1]\n",
    "        else:\n",
    "            id_tensor = index\n",
    "        \n",
    "        return self.data_x[id_List][id_tensor], self.data_x[id_List][id_tensor:(id_tensor+self.t_yseq)], self.celltype_List[id_List]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3e9e2f01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T08:41:02.989541Z",
     "start_time": "2023-03-02T08:41:02.541174Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dr_thresh = 7\n",
    "dt = 1\n",
    "batch_size = 8\n",
    "\n",
    "T_pred = 10\n",
    "\n",
    "N_data = len(datadir_list)\n",
    "\n",
    "#TR_VA_rate = np.array([0.6, 0.2])\n",
    "\n",
    "TR_last = 3\n",
    "VA_last = 4\n",
    "\n",
    "shuffle_inds = np.arange(N_data, dtype=int)\n",
    "np.random.shuffle(shuffle_inds)\n",
    "\n",
    "train_inds = shuffle_inds[:TR_last]\n",
    "valid_inds = shuffle_inds[TR_last:VA_last]\n",
    "test_inds = shuffle_inds[VA_last:]\n",
    "\n",
    "celltype_lst = []\n",
    "\n",
    "train_x = []\n",
    "valid_x = []\n",
    "test_x = []\n",
    "\n",
    "train_y = []\n",
    "valid_y = []\n",
    "test_y = []\n",
    "\n",
    "train_ct = []\n",
    "valid_ct = []\n",
    "test_ct = []\n",
    "\n",
    "for i_dir, subdirName in enumerate(datadir_list):\n",
    "    \n",
    "    traj = np.load(subdirName+'/result.npz')\n",
    "    \n",
    "    xy_t = torch.tensor(traj['xy'])#[:-1,:,:])\n",
    "    #v_t = calc_dr(torch.tensor(traj['xy'][1:,:,:]), torch.tensor(traj['xy'][:-1,:,:])) / dt\n",
    "    p_t = torch.unsqueeze(torch.tensor(traj['theta']), dim=2)#[:-1,:]), dim=2)\n",
    "    #w_t = torch.unsqueeze(torch.tensor((traj['theta'][1:,:]-traj['theta'][:-1,:])%(2*np.pi)/dt), dim=2)\n",
    "    \n",
    "    if i_dir in train_inds:\n",
    "        train_x.append(torch.concat((xy_t, p_t), -1))\n",
    "        #train_y.append(torch.concat((v_t, w_t), -1))\n",
    "        train_ct.append(torch.tensor(traj['celltype_label']).view(-1,1))\n",
    "\n",
    "    if i_dir in valid_inds:\n",
    "        valid_x.append(torch.concat((xy_t, p_t), -1))\n",
    "        #valid_y.append(torch.concat((v_t, w_t), -1))\n",
    "        valid_ct.append(torch.tensor(traj['celltype_label']).view(-1,1))\n",
    "        \n",
    "    if i_dir in test_inds:\n",
    "        test_x.append(torch.concat((xy_t, p_t), -1))\n",
    "        #test_y.append(torch.concat((v_t, w_t), -1))\n",
    "        test_ct.append(torch.tensor(traj['celltype_label']).view(-1,1))\n",
    "    \n",
    "train_dataset = myDataset(train_x, train_ct, t_yseq=T_pred)\n",
    "\n",
    "valid_dataset = myDataset(valid_x, valid_ct, t_yseq=T_pred)\n",
    "\n",
    "test_dataset = myDataset(test_x, test_ct, t_yseq=T_pred)\n",
    "\n",
    "\n",
    "train_data = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, pin_memory=True)\n",
    "valid_data = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, pin_memory=True)\n",
    "test_data = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, pin_memory=True)\n",
    "\n",
    "del train_x, train_ct, train_dataset\n",
    "del valid_x, valid_ct, valid_dataset\n",
    "del test_x, test_ct, test_dataset\n",
    "gc.collect()\n",
    "\n",
    "#print(data)\n",
    "#print(data.num_graphs)\n",
    "#print(data.x)\n",
    "#print(data.y)\n",
    "#print(data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1c0a633b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T08:41:03.002968Z",
     "start_time": "2023-03-02T08:41:02.994870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 4 3]\n"
     ]
    }
   ],
   "source": [
    "print(train_inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4f35452f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T08:41:03.011153Z",
     "start_time": "2023-03-02T08:41:03.007012Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_DataLoader__initialized',\n",
       " '_DataLoader__multiprocessing_context',\n",
       " '_IterableDataset_len_called',\n",
       " '__annotations__',\n",
       " '__class__',\n",
       " '__class_getitem__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__orig_bases__',\n",
       " '__parameters__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__slots__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_auto_collation',\n",
       " '_dataset_kind',\n",
       " '_get_iterator',\n",
       " '_get_shared_seed',\n",
       " '_index_sampler',\n",
       " '_is_protocol',\n",
       " '_iterator',\n",
       " 'batch_sampler',\n",
       " 'batch_size',\n",
       " 'check_worker_number_rationality',\n",
       " 'collate_fn',\n",
       " 'dataset',\n",
       " 'drop_last',\n",
       " 'generator',\n",
       " 'multiprocessing_context',\n",
       " 'num_workers',\n",
       " 'persistent_workers',\n",
       " 'pin_memory',\n",
       " 'pin_memory_device',\n",
       " 'prefetch_factor',\n",
       " 'sampler',\n",
       " 'timeout',\n",
       " 'worker_init_fn']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e5e6c153",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T08:41:03.028502Z",
     "start_time": "2023-03-02T08:41:03.012979Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ca11fa4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T08:41:03.036774Z",
     "start_time": "2023-03-02T08:41:03.033114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 992 1984 2976]\n"
     ]
    }
   ],
   "source": [
    "print(train_data.dataset.data_len_cumsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f94ee7f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T08:41:03.079995Z",
     "start_time": "2023-03-02T08:41:03.039450Z"
    }
   },
   "outputs": [],
   "source": [
    "def plotGraph(data):\n",
    "\n",
    "    # networkxのグラフに変換\n",
    "    nxg = dgl.to_networkx(data)\n",
    "\n",
    "    # 可視化のためのページランク計算\n",
    "    pr = nx.pagerank(nxg)\n",
    "    pr_max = np.array(list(pr.values())).max()\n",
    "\n",
    "    # 可視化する際のノード位置\n",
    "    draw_pos = nx.spring_layout(nxg, seed=0) \n",
    "\n",
    "    # ノードの色設定\n",
    "    cmap = plt.get_cmap('tab10')\n",
    "    labels = data.y.numpy()\n",
    "    colors = [cmap(l) for l in labels]\n",
    "\n",
    "    # 図のサイズ\n",
    "    fig0 = plt.figure(figsize=(10, 10))\n",
    "\n",
    "    # 描画\n",
    "    nx.draw_networkx_nodes(nxg, \n",
    "                          draw_pos,\n",
    "                          node_size=[v / pr_max * 1000 for v in pr.values()])#,\n",
    "                          #node_color=colors, alpha=0.5)\n",
    "    nx.draw_networkx_edges(nxg, draw_pos, arrowstyle='-', alpha=0.2)\n",
    "    nx.draw_networkx_labels(nxg, draw_pos, font_size=10)\n",
    "\n",
    "    #plt.title('KarateClub')\n",
    "    plt.show()\n",
    "\n",
    "    return fig0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "21e97796",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T08:41:03.133294Z",
     "start_time": "2023-03-02T08:41:03.083702Z"
    }
   },
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, Nchannels, dropout=0, batchN=False, flgBias=False):\n",
    "        super(NeuralNet, self).__init__()\n",
    "\n",
    "        if dropout:\n",
    "            self.dropout = nn.Dropout(p=dropout)\n",
    "        else:\n",
    "            self.dropout = 0\n",
    "            \n",
    "        if batchN:\n",
    "            self.bNorm1 = nn.BatchNorm1d(Nchannels)\n",
    "            self.bNorm2 = nn.BatchNorm1d(Nchannels)\n",
    "            self.bNorm3 = nn.BatchNorm1d(Nchannels)\n",
    "            \n",
    "        self.batchN=batchN\n",
    "        \n",
    "        self.layer1 = nn.Linear(in_channels, Nchannels, bias=flgBias)\n",
    "        self.layer2 = nn.Linear(Nchannels, Nchannels, bias=flgBias)\n",
    "        self.layer3 = nn.Linear(Nchannels, Nchannels, bias=flgBias)\n",
    "        self.layer4 = nn.Linear(Nchannels, out_channels, bias=flgBias)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.layer1.reset_parameters()\n",
    "        self.layer2.reset_parameters()\n",
    "        self.layer3.reset_parameters()\n",
    "        self.layer4.reset_parameters()\n",
    "        #nn.init.zeros_(self.layer1.weight)\n",
    "        #nn.init.zeros_(self.layer2.weight)\n",
    "        #nn.init.zeros_(self.layer3.weight)\n",
    "        #nn.init.zeros_(self.layer4.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.activation(self.layer1(x))\n",
    "        if self.batchN:\n",
    "            out = self.bNorm1(out)\n",
    "        if self.dropout:\n",
    "            out = self.dropout(out)\n",
    "        \n",
    "        out = self.activation(self.layer2(out))\n",
    "        if self.batchN:\n",
    "            out = self.bNorm2(out)\n",
    "        if self.dropout:\n",
    "            out = self.dropout(out)\n",
    "        \n",
    "        out = self.activation(self.layer3(out))\n",
    "        if self.batchN:\n",
    "            out = self.bNorm3(out)\n",
    "        if self.dropout:\n",
    "            out = self.dropout(out)\n",
    "        \n",
    "        out = self.layer4(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ActiveNet(nn.Module):\n",
    "    def __init__(self, xy_dim, r, dropout=0, batchN=False, bias=False, Nchannels=128):\n",
    "        super().__init__()\n",
    "\n",
    "        self.interactNN = NeuralNet(xy_dim*2 + 2, xy_dim, Nchannels, dropout, batchN, bias)\n",
    "\n",
    "        self.thetaDotNN = NeuralNet(xy_dim*2 + 2, 1, Nchannels, dropout, batchN, bias)\n",
    "        \n",
    "        self.selfpropel = nn.Parameter(torch.tensor(0.0, requires_grad=True, device=device))\n",
    "\n",
    "        #self.Normalizer = nn.Softmax(dim=1)\n",
    "\n",
    "        self.xy_dim = xy_dim\n",
    "        \n",
    "        self.r = r\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.interactNN.reset_parameters()\n",
    "\n",
    "        self.thetaDotNN.reset_parameters()\n",
    "        \n",
    "        nn.init.uniform_(self.selfpropel)\n",
    "\n",
    "        #self.bias.data.zero_()\n",
    "        \n",
    "    def load_celltypes(self, celltype):\n",
    "        self.celltype = celltype\n",
    "\n",
    "    def calc_message(self, edges):\n",
    "        dx = calc_dr(edges.dst['x'], edges.src['x'])\n",
    "\n",
    "        costheta = torch.cos(edges.dst['theta'])\n",
    "        sintheta = torch.sin(edges.dst['theta'])\n",
    "\n",
    "        dx_para = costheta * dx[..., :1] + sintheta * dx[..., 1:]\n",
    "        dx_perp = costheta * dx[..., 1:] - sintheta * dx[..., :1]\n",
    "\n",
    "        p_para_src = torch.cos(edges.src['theta'] - edges.dst['theta'])\n",
    "        p_perp_src = torch.sin(edges.src['theta'] - edges.dst['theta'])\n",
    "\n",
    "        rot_m_v = self.interactNN(torch.concat((dx_para, dx_perp, \n",
    "                                                p_para_src, p_perp_src,\n",
    "                                                edges.dst['type'], edges.src['type']), -1))\n",
    "\n",
    "        m_v = torch.concat((costheta * rot_m_v[..., :1] - sintheta * rot_m_v[..., 1:],\n",
    "                            costheta * rot_m_v[..., 1:] + sintheta * rot_m_v[..., :1]), -1)\n",
    "\n",
    "        m_theta = self.thetaDotNN(torch.concat((dx_para, dx_perp, \n",
    "                                                p_para_src, p_perp_src, \n",
    "                                                edges.dst['type'], edges.src['type']), -1))\n",
    "        \n",
    "        return {'m': torch.concat((m_v, m_theta), -1)}\n",
    "        \n",
    "    def forward(self, xv):\n",
    "        r_g = makeGraph(xv[..., :self.xy_dim], self.r/2)\n",
    "        r_g.ndata['x'] = xv[..., :self.xy_dim]\n",
    "        r_g.ndata['theta'] = xv[..., self.xy_dim:(self.xy_dim+1)]\n",
    "        r_g.ndata['type'] = self.celltype\n",
    "        r_g.update_all(self.calc_message, fn.sum('m', 'a'))\n",
    "        r_g.ndata['a'][..., :self.xy_dim] = r_g.ndata['a'][..., :self.xy_dim] + self.selfpropel * torch.concat((torch.cos(r_g.ndata['theta']), torch.sin(r_g.ndata['theta'])), -1)\n",
    "        \n",
    "        return r_g.ndata['a']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b52c1e60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T08:41:03.166677Z",
     "start_time": "2023-03-02T08:41:03.144501Z"
    }
   },
   "outputs": [],
   "source": [
    "def myLoss(out, target):\n",
    "    #dv = torch.sum(torch.square(out[..., :xy_dim] - target[..., :xy_dim]), dim=-1)\n",
    "    dv = torch.sum(torch.square(calc_dr(out[..., :xy_dim], target[..., :xy_dim])), dim=-1)\n",
    "    dcos = torch.cos(out[..., xy_dim] - target[..., xy_dim])\n",
    "    \n",
    "    wei_shape = np.ones([dv.dim()], dtype=int)\n",
    "    wei_shape[0] = T_pred\n",
    "    wei = torch.tensor(np.reshape(1/np.arange(1, T_pred+1), wei_shape)).to(dv.device)\n",
    "    wei = wei/wei.mean()\n",
    "    \n",
    "    return torch.mean(dv*wei), torch.mean((1-dcos)*wei)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a8ed0774",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T08:41:03.226481Z",
     "start_time": "2023-03-02T08:41:03.182236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dr_thresh 4\n",
      "batch_size 8\n",
      "train_inds [6 1 4 5 7]\n",
      "valid_inds [2 9]\n",
      "test_inds [0 8 3]\n",
      "val_loss_log [[0.06957185 0.01138402]\n",
      " [0.06715702 0.01138812]\n",
      " [0.05852827 0.01076387]\n",
      " [0.05464074 0.01047792]\n",
      " [0.04124076 0.01028508]\n",
      " [0.04581858 0.01010125]\n",
      " [0.03636987 0.00993934]\n",
      " [0.03513648 0.00985879]\n",
      " [0.03662048 0.00865206]\n",
      " [0.0346748  0.00870927]\n",
      " [0.0328907  0.00827903]\n",
      " [0.03297586 0.00823795]\n",
      " [0.02731015 0.00815105]\n",
      " [0.03475118 0.00824428]\n",
      " [0.03300626 0.00805876]\n",
      " [0.03231701 0.00799449]\n",
      " [0.03065317 0.00789906]\n",
      " [0.03004111 0.00781185]\n",
      " [0.02944164 0.00775791]\n",
      " [0.02152422 0.00777418]\n",
      " [0.02077205 0.00775165]\n",
      " [0.02282816 0.00787244]\n",
      " [0.02027514 0.00775065]\n",
      " [0.02011793 0.007732  ]\n",
      " [0.02029534 0.00774424]\n",
      " [0.01848694 0.00769201]\n",
      " [0.02006832 0.00769452]\n",
      " [0.01811177 0.0076291 ]\n",
      " [0.0193208  0.00749339]\n",
      " [0.01931852 0.00757757]\n",
      " [0.01905341 0.00756452]\n",
      " [0.01934462 0.00758915]\n",
      " [0.01876732 0.00760899]\n",
      " [0.01857739 0.00751577]\n",
      " [0.01504676 0.00637165]\n",
      " [0.01473385 0.00635003]\n",
      " [0.01413056 0.00634328]\n",
      " [0.0146804  0.00633149]\n",
      " [0.01452563 0.00632541]\n",
      " [0.01446514 0.00630054]\n",
      " [0.01358877 0.00630585]\n",
      " [0.01404009 0.00630019]\n",
      " [0.01434777 0.00630019]\n",
      " [0.01338325 0.00630719]\n",
      " [0.01400817 0.00632269]\n",
      " [0.01419251 0.00631402]\n",
      " [0.01385686 0.00631151]\n",
      " [0.01322458 0.0062983 ]\n",
      " [0.01315278 0.00629981]\n",
      " [0.01320085 0.00627887]\n",
      " [0.01321862 0.00627943]\n",
      " [0.01320618 0.00624829]\n",
      " [0.01307684 0.00625205]\n",
      " [0.01311702 0.00623041]\n",
      " [0.01303334 0.00623185]\n",
      " [0.01380045 0.00622496]\n",
      " [0.01299917 0.00621545]\n",
      " [0.01295246 0.00621811]\n",
      " [0.01293376 0.00621693]\n",
      " [0.01287559 0.00620396]\n",
      " [0.01286103 0.00619397]\n",
      " [0.01271649 0.00621551]\n",
      " [0.01347225 0.00620533]\n",
      " [0.01276508 0.00620433]\n",
      " [0.01260366 0.00620725]\n",
      " [0.01270233 0.00622247]\n",
      " [0.01267491 0.00620142]\n",
      " [0.01265183 0.00619402]\n",
      " [0.01263349 0.00619447]\n",
      " [0.01267075 0.00618936]\n",
      " [0.0126228  0.00619034]\n",
      " [0.01148899 0.00574196]\n",
      " [0.01171222 0.00573112]\n",
      " [0.01165032 0.00572414]\n",
      " [0.01158931 0.00571909]\n",
      " [0.01117669 0.00570819]\n",
      " [0.01152413 0.0057083 ]\n",
      " [0.01108835 0.00570055]\n",
      " [0.0110643  0.00570169]\n",
      " [0.01107242 0.00569962]\n",
      " [0.01104561 0.00569113]\n",
      " [0.01143452 0.00569424]\n",
      " [0.01142153 0.0056881 ]\n",
      " [0.01108568 0.00568251]\n",
      " [0.01142243 0.00568251]\n",
      " [0.0114283  0.00567903]\n",
      " [0.01134206 0.00567557]\n",
      " [0.01092238 0.00562536]\n",
      " [0.01090276 0.00562225]\n",
      " [0.0108878  0.00561999]\n",
      " [0.01090024 0.00561721]\n",
      " [0.01088327 0.00561625]\n",
      " [0.01089209 0.00561466]\n",
      " [0.010878   0.00561324]\n",
      " [0.01085239 0.00560952]\n",
      " [0.01086961 0.00560984]\n",
      " [0.01085168 0.00560673]\n",
      " [0.01081225 0.00560675]\n",
      " [0.01084747 0.00560374]\n",
      " [0.01083153 0.00560389]\n",
      " [0.01082114 0.0056015 ]\n",
      " [0.01080061 0.00559962]\n",
      " [0.01081342 0.00559986]\n",
      " [0.01081137 0.00560236]\n",
      " [0.01078877 0.00559779]\n",
      " [0.01080642 0.00559684]\n",
      " [0.01080345 0.00559605]\n",
      " [0.01079144 0.00559542]\n",
      " [0.01078119 0.00559361]\n",
      " [0.01078034 0.00559236]\n",
      " [0.01076949 0.00559131]\n",
      " [0.01075263 0.00559007]\n",
      " [0.01077991 0.00559231]\n",
      " [0.0107687  0.00558699]\n",
      " [0.01072495 0.00558715]\n",
      " [0.01075564 0.00558503]\n",
      " [0.01074324 0.00558416]\n",
      " [0.01076323 0.00558329]\n",
      " [0.01073971 0.00558227]\n",
      " [0.01074861 0.00558194]\n",
      " [0.01074636 0.00558063]\n",
      " [0.01060679 0.00556142]\n",
      " [0.01060372 0.0055604 ]\n",
      " [0.01060063 0.00555971]\n",
      " [0.01059744 0.00555921]\n",
      " [0.01059452 0.00555857]\n",
      " [0.01059189 0.00555828]\n",
      " [0.01058902 0.00555769]\n",
      " [0.01058651 0.00555725]\n",
      " [0.01058329 0.00555666]\n",
      " [0.01058032 0.00555626]\n",
      " [0.01057758 0.00555578]\n",
      " [0.01057486 0.00555538]\n",
      " [0.01057235 0.00555484]\n",
      " [0.01056961 0.00555416]\n",
      " [0.0105669  0.0055542 ]\n",
      " [0.01056445 0.00555363]\n",
      " [0.01056158 0.00555318]\n",
      " [0.01055882 0.00555273]\n",
      " [0.01055615 0.00555232]\n",
      " [0.0105534  0.00555162]\n",
      " [0.01055119 0.00555155]\n",
      " [0.01054877 0.00555122]\n",
      " [0.01054613 0.00555087]\n",
      " [0.01054335 0.00555037]\n",
      " [0.01054091 0.00554996]\n",
      " [0.01053821 0.0055497 ]\n",
      " [0.01053593 0.00554939]\n",
      " [0.01053342 0.00554881]\n",
      " [0.01053107 0.00554836]\n",
      " [0.01052854 0.005548  ]\n",
      " [0.01052661 0.00554758]\n",
      " [0.01052432 0.00554744]\n",
      " [0.01052158 0.00554696]\n",
      " [0.01051928 0.0055465 ]\n",
      " [0.01051755 0.00554639]\n",
      " [0.01051466 0.00554574]\n",
      " [0.01051237 0.00554494]\n",
      " [0.01051036 0.0055446 ]\n",
      " [0.01050821 0.00554486]\n",
      " [0.01050569 0.00554444]\n",
      " [0.01050392 0.00554404]\n",
      " [0.01050168 0.00554364]\n",
      " [0.01049872 0.00554344]\n",
      " [0.01049702 0.0055429 ]\n",
      " [0.01049463 0.00554253]\n",
      " [0.01049243 0.00554219]\n",
      " [0.01049028 0.00554178]\n",
      " [0.01048801 0.00554151]\n",
      " [0.01048605 0.00554116]\n",
      " [0.01048431 0.00554083]\n",
      " [0.01048211 0.0055405 ]\n",
      " [0.01048    0.00553978]\n",
      " [0.01047799 0.00553936]\n",
      " [0.01047614 0.00553909]\n",
      " [0.01047381 0.00553911]\n",
      " [0.01047187 0.00553838]\n",
      " [0.01047051 0.00553849]\n",
      " [0.01046802 0.00553816]\n",
      " [0.01046581 0.00553785]\n",
      " [0.01046413 0.0055375 ]\n",
      " [0.01046251 0.00553686]\n",
      " [0.0104598  0.00553683]\n",
      " [0.01045796 0.00553658]\n",
      " [0.0104561  0.0055363 ]\n",
      " [0.01045375 0.00553603]\n",
      " [0.01045213 0.00553568]\n",
      " [0.01044985 0.00553548]\n",
      " [0.01044847 0.00553506]\n",
      " [0.01044621 0.00553486]\n",
      " [0.0104443  0.00553461]\n",
      " [0.01044475 0.00553425]\n",
      " [0.01044053 0.005534  ]\n",
      " [0.01043981 0.00553333]\n",
      " [0.01043934 0.00553334]\n",
      " [0.01043584 0.00553294]\n",
      " [0.01043576 0.00553272]\n",
      " [0.01043182 0.00553238]\n",
      " [0.01043032 0.00553173]\n",
      " [0.01042795 0.00553179]\n",
      " [0.01042748 0.0055315 ]\n",
      " [0.01042456 0.00553118]\n",
      " [0.01042257 0.005531  ]\n",
      " [0.01042112 0.00553032]\n",
      " [0.01041922 0.00553042]\n",
      " [0.01041728 0.00553019]\n",
      " [0.01041558 0.00552986]\n",
      " [0.01041422 0.0055298 ]\n",
      " [0.01041283 0.0055293 ]\n",
      " [0.01041078 0.005529  ]\n",
      " [0.01040896 0.00552897]\n",
      " [0.01040731 0.00552888]\n",
      " [0.0104053  0.0055286 ]\n",
      " [0.01040368 0.00552816]\n",
      " [0.01040252 0.00552778]\n",
      " [0.01040306 0.00552755]\n",
      " [0.01040108 0.00552727]\n",
      " [0.01039909 0.00552725]\n",
      " [0.01039778 0.00552657]\n",
      " [0.01039663 0.00552651]\n",
      " [0.01039405 0.00552604]\n",
      " [0.010393   0.00552573]\n",
      " [0.01039135 0.00552586]\n",
      " [0.01038965 0.00552537]\n",
      " [0.01038798 0.00552558]\n",
      " [0.01038573 0.00552548]\n",
      " [0.01038481 0.00552508]\n",
      " [0.01038284 0.0055243 ]\n",
      " [0.01038126 0.00552456]\n",
      " [0.01038016 0.00552394]\n",
      " [0.01037893 0.00552357]\n",
      " [0.01037743 0.00552329]\n",
      " [0.01037542 0.00552303]\n",
      " [0.01037362 0.00552333]\n",
      " [0.01037233 0.00552252]\n",
      " [0.01037059 0.00552232]\n",
      " [0.01036945 0.0055221 ]\n",
      " [0.01036733 0.00552133]\n",
      " [0.01036587 0.00552158]\n",
      " [0.01036457 0.00552169]\n",
      " [0.01036321 0.00552116]\n",
      " [0.01036116 0.00552091]\n",
      " [0.01036118 0.00552069]\n",
      " [0.01035958 0.00552036]\n",
      " [0.01035781 0.00552019]\n",
      " [0.01035664 0.00551988]\n",
      " [0.01035519 0.00551974]\n",
      " [0.01035349 0.00551944]\n",
      " [0.01035176 0.00551931]\n",
      " [0.01035082 0.00551904]\n",
      " [0.01034914 0.00551874]\n",
      " [0.01034762 0.00551859]\n",
      " [0.01034628 0.00551832]\n",
      " [0.01034463 0.00551766]\n",
      " [0.01034331 0.00551743]\n",
      " [0.01034196 0.00551772]\n",
      " [0.01034028 0.00551706]\n",
      " [0.01033909 0.00551733]\n",
      " [0.01033773 0.00551707]\n",
      " [0.01033647 0.0055168 ]\n",
      " [0.01033514 0.00551662]\n",
      " [0.01033282 0.00551644]\n",
      " [0.01033164 0.00551625]\n",
      " [0.01033036 0.00551598]\n",
      " [0.01032915 0.0055158 ]\n",
      " [0.01032775 0.00551555]\n",
      " [0.0103261  0.00551539]\n",
      " [0.01032444 0.0055151 ]\n",
      " [0.01032334 0.00551494]\n",
      " [0.01032224 0.00551478]\n",
      " [0.01032066 0.00551451]\n",
      " [0.01031946 0.0055146 ]\n",
      " [0.01031851 0.00551421]\n",
      " [0.01031635 0.00551397]\n",
      " [0.01031531 0.00551371]\n",
      " [0.01031385 0.00551355]\n",
      " [0.01031298 0.0055133 ]\n",
      " [0.01031162 0.00551256]\n",
      " [0.01031006 0.00551294]\n",
      " [0.0103085  0.00551266]\n",
      " [0.01030792 0.0055126 ]\n",
      " [0.01030652 0.00551163]\n",
      " [0.01030541 0.00551218]\n",
      " [0.01030421 0.00551195]\n",
      " [0.01030238 0.00551161]\n",
      " [0.01030133 0.00551095]\n",
      " [0.01030012 0.00551072]\n",
      " [0.01029912 0.00551103]\n",
      " [0.01029746 0.0055109 ]\n",
      " [0.01029658 0.00551074]\n",
      " [0.01029487 0.00551045]\n",
      " [0.01029374 0.00550981]\n",
      " [0.01029263 0.00551008]\n",
      " [0.01029137 0.00550939]\n",
      " [0.01029033 0.00550973]\n",
      " [0.01028867 0.00550944]\n",
      " [0.01028773 0.00550922]\n",
      " [0.01028678 0.00550914]\n",
      " [0.01028545 0.00550894]\n",
      " [0.01028351 0.00550874]]\n",
      "test_loss [0.01019601 0.00551089]\n"
     ]
    }
   ],
   "source": [
    "filename1 = modeldirName + model_name + '_Model.pt'\n",
    "model = torch.load(filename1, map_location=torch.device(device)) #pickle.load(open(filename1, 'rb'))\n",
    "model.train()\n",
    "\n",
    "filename3 = modeldirName + model_name + '_Separation.npz'\n",
    "learn_params = np.load(filename3, allow_pickle=True)\n",
    "\n",
    "printNPZ(learn_params)\n",
    "\n",
    "dr_thresh = learn_params['dr_thresh'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6033283c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T11:22:59.106897Z",
     "start_time": "2023-03-02T08:41:03.228445Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | train Loss: [3.6737, 0.2377] | valid Loss: [3.4095, 0.2219]\n",
      "Epoch 1 | train Loss: [3.4591, 0.2413] | valid Loss: [3.3853, 0.2215]\n",
      "Epoch 2 | train Loss: [3.5780, 0.2353] | valid Loss: [3.3881, 0.2219]\n",
      "Epoch 3 | train Loss: [3.5287, 0.2365] | valid Loss: [3.3911, 0.2213]\n",
      "Epoch 4 | train Loss: [3.5383, 0.2395] | valid Loss: [3.3930, 0.2217]\n",
      "Epoch 5 | train Loss: [3.5548, 0.2363] | valid Loss: [3.3893, 0.2217]\n",
      "Epoch 6 | train Loss: [3.5902, 0.2358] | valid Loss: [3.3933, 0.2219]\n",
      "Epoch 00008: reducing learning rate of group 0 to 1.5000e-06.\n",
      "Epoch 7 | train Loss: [3.5181, 0.2336] | valid Loss: [3.3881, 0.2215]\n",
      "Epoch 8 | train Loss: [3.6187, 0.2362] | valid Loss: [3.3897, 0.2220]\n",
      "Epoch 9 | train Loss: [3.6344, 0.2367] | valid Loss: [3.3870, 0.2221]\n",
      "Epoch 10 | train Loss: [3.5825, 0.2347] | valid Loss: [3.3933, 0.2219]\n",
      "Epoch 11 | train Loss: [3.5599, 0.2349] | valid Loss: [3.3925, 0.2219]\n",
      "Epoch 12 | train Loss: [3.6539, 0.2398] | valid Loss: [3.3890, 0.2220]\n",
      "Epoch 13 | train Loss: [3.5931, 0.2379] | valid Loss: [3.3846, 0.2218]\n",
      "Epoch 14 | train Loss: [3.5541, 0.2394] | valid Loss: [3.3847, 0.2222]\n",
      "Epoch 15 | train Loss: [3.5063, 0.2364] | valid Loss: [3.3830, 0.2219]\n",
      "Epoch 16 | train Loss: [3.4817, 0.2357] | valid Loss: [3.3731, 0.2217]\n",
      "Epoch 17 | train Loss: [3.5051, 0.2339] | valid Loss: [3.3704, 0.2217]\n",
      "Epoch 18 | train Loss: [3.5350, 0.2379] | valid Loss: [3.3730, 0.2216]\n",
      "Epoch 19 | train Loss: [3.5291, 0.2358] | valid Loss: [3.3745, 0.2222]\n",
      "Epoch 20 | train Loss: [3.5702, 0.2392] | valid Loss: [3.3819, 0.2231]\n",
      "Epoch 21 | train Loss: [3.5769, 0.2390] | valid Loss: [3.3767, 0.2221]\n",
      "Epoch 22 | train Loss: [3.5737, 0.2372] | valid Loss: [3.3725, 0.2219]\n",
      "Epoch 00024: reducing learning rate of group 0 to 7.5000e-07.\n",
      "Epoch 23 | train Loss: [3.5838, 0.2409] | valid Loss: [3.3760, 0.2222]\n",
      "Epoch 24 | train Loss: [3.5222, 0.2349] | valid Loss: [3.3762, 0.2224]\n",
      "Epoch 25 | train Loss: [3.5394, 0.2349] | valid Loss: [3.3782, 0.2223]\n",
      "Epoch 26 | train Loss: [3.5816, 0.2349] | valid Loss: [3.3779, 0.2223]\n",
      "Epoch 27 | train Loss: [3.5149, 0.2342] | valid Loss: [3.3756, 0.2229]\n",
      "Epoch 28 | train Loss: [3.5714, 0.2402] | valid Loss: [3.3745, 0.2223]\n",
      "Epoch 00030: reducing learning rate of group 0 to 3.7500e-07.\n",
      "Epoch 29 | train Loss: [3.5675, 0.2419] | valid Loss: [3.3786, 0.2222]\n",
      "Epoch 30 | train Loss: [3.5232, 0.2385] | valid Loss: [3.3790, 0.2224]\n",
      "Epoch 31 | train Loss: [3.5886, 0.2404] | valid Loss: [3.3813, 0.2226]\n",
      "Epoch 32 | train Loss: [3.5449, 0.2366] | valid Loss: [3.3785, 0.2223]\n",
      "Epoch 33 | train Loss: [3.5554, 0.2384] | valid Loss: [3.3802, 0.2223]\n",
      "Epoch 34 | train Loss: [3.5153, 0.2398] | valid Loss: [3.3753, 0.2222]\n",
      "Epoch 00036: reducing learning rate of group 0 to 1.8750e-07.\n",
      "Epoch 35 | train Loss: [3.5362, 0.2404] | valid Loss: [3.3781, 0.2224]\n",
      "Epoch 36 | train Loss: [3.5496, 0.2369] | valid Loss: [3.3785, 0.2224]\n",
      "Epoch 37 | train Loss: [3.5873, 0.2379] | valid Loss: [3.3763, 0.2222]\n",
      "Epoch 38 | train Loss: [3.5317, 0.2371] | valid Loss: [3.3772, 0.2224]\n",
      "Epoch 39 | train Loss: [3.4898, 0.2367] | valid Loss: [3.3781, 0.2221]\n",
      "Epoch 40 | train Loss: [3.4757, 0.2385] | valid Loss: [3.3775, 0.2223]\n",
      "Epoch 00042: reducing learning rate of group 0 to 9.3750e-08.\n",
      "Epoch 41 | train Loss: [3.5006, 0.2359] | valid Loss: [3.3735, 0.2218]\n",
      "Epoch 42 | train Loss: [3.4612, 0.2358] | valid Loss: [3.3750, 0.2221]\n",
      "Epoch 43 | train Loss: [3.5193, 0.2372] | valid Loss: [3.3736, 0.2222]\n",
      "Epoch 44 | train Loss: [3.5616, 0.2376] | valid Loss: [3.3758, 0.2223]\n",
      "Epoch 45 | train Loss: [3.5008, 0.2379] | valid Loss: [3.3762, 0.2220]\n",
      "Epoch 46 | train Loss: [3.4879, 0.2364] | valid Loss: [3.3733, 0.2220]\n",
      "Epoch 00048: reducing learning rate of group 0 to 4.6875e-08.\n",
      "Epoch 47 | train Loss: [3.4927, 0.2350] | valid Loss: [3.3739, 0.2224]\n",
      "Epoch 48 | train Loss: [3.4956, 0.2358] | valid Loss: [3.3775, 0.2223]\n",
      "Epoch 49 | train Loss: [3.4643, 0.2364] | valid Loss: [3.3787, 0.2222]\n"
     ]
    }
   ],
   "source": [
    "# モデルのインスタンス生成\n",
    "xy_dim = 2\n",
    "\n",
    "#model = ActiveNet(xy_dim, dr_thresh, dropout=0, batchN=True, bias=True, Nchannels=128).to(device)\n",
    "# input data\n",
    "#data = dataset[0]\n",
    "\n",
    "def calc_multiSteps(x0):\n",
    "    outs = []\n",
    "    x_i = x0\n",
    "    for i_step in range(T_pred):\n",
    "        x_i = x_i + model(x_i) * dt\n",
    "        outs.append(x_i.clone())\n",
    "    return torch.stack(outs, dim=0)\n",
    "\n",
    "# optimizer\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-6)#, weight_decay=5e-4)\n",
    "#optimizer = torch.optim.Adadelta(model.parameters())#, rho=0.95)#, lr=1e-1, momentum=0.9)\n",
    "\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "val_loss_log = []\n",
    "\n",
    "val_loss_min = np.Inf\n",
    "\n",
    "# learnig loop\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    for batch_x, batch_y, batch_ct in train_data:\n",
    "        optimizer.zero_grad()\n",
    "        lossv = 0\n",
    "        losstheta = 0\n",
    "        for ib in range(batch_x.size(0)):\n",
    "            model.load_celltypes(batch_ct[ib].to(device))\n",
    "            out = calc_multiSteps(batch_x[ib].to(device))\n",
    "            lv, ltheta = myLoss(out, batch_y[ib].to(device))\n",
    "            lossv = lossv + lv\n",
    "            losstheta = losstheta + ltheta\n",
    "        lossv = lossv / batch_x.size(0)\n",
    "        losstheta = losstheta / batch_x.size(0)\n",
    "        (lossv+losstheta).backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    val_lossv = 0\n",
    "    val_losstheta = 0\n",
    "    val_count = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_x, batch_y, batch_ct in valid_data:\n",
    "            for ib in range(batch_x.size(0)):\n",
    "                model.load_celltypes(batch_ct[ib].to(device))\n",
    "                val_out = calc_multiSteps(batch_x[ib].to(device))\n",
    "                lv, ltheta = myLoss(val_out, batch_y[ib].to(device))\n",
    "                val_lossv = val_lossv + lv\n",
    "                val_losstheta = val_losstheta + ltheta\n",
    "            val_count = val_count + batch_x.size(0)\n",
    "    val_lossv = val_lossv/val_count\n",
    "    val_losstheta = val_losstheta/val_count\n",
    "    val_loss = val_lossv + val_losstheta\n",
    "    scheduler.step(val_loss)\n",
    "    print('Epoch %d | train Loss: [%.4f, %.4f] | valid Loss: [%.4f, %.4f]' % (epoch,\n",
    "                                                                              lossv.item(), \n",
    "                                                                              losstheta.item(),\n",
    "                                                                              val_lossv.item(), \n",
    "                                                                              val_losstheta.item()))\n",
    "    val_loss_log.append([val_lossv.cpu().item(), val_losstheta.cpu().item()])\n",
    "    if val_loss.item() < val_loss_min:\n",
    "        stored_model = model\n",
    "        val_loss_min = val_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "605ebb18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T11:22:59.120801Z",
     "start_time": "2023-03-02T11:22:59.109080Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 400, 3])\n",
      "torch.Size([8, 10, 400, 3])\n",
      "torch.Size([8, 400, 1])\n"
     ]
    }
   ],
   "source": [
    "print(batch_x.shape)\n",
    "print(batch_y.shape)\n",
    "print(batch_ct.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b3cf1e91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T11:22:59.214466Z",
     "start_time": "2023-03-02T11:22:59.125772Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('selfpropel', tensor(1.0137, device='cuda:0')),\n",
       "             ('interactNN.layer1.weight',\n",
       "              tensor([[-6.2236e-01,  4.4161e-01, -3.2166e-01,  2.3285e-01, -3.5735e-02,\n",
       "                        1.4747e-02],\n",
       "                      [ 1.2277e-03, -2.4975e-01, -1.7714e-02,  2.3002e-01,  1.0570e-01,\n",
       "                        1.0600e-01],\n",
       "                      [ 8.0876e-02, -6.8451e-02,  6.2910e-02,  2.8809e-02, -2.7933e-01,\n",
       "                       -3.7462e-01],\n",
       "                      [ 2.7385e-01, -3.7914e-01, -3.7419e-01, -2.9074e-02,  1.2012e-02,\n",
       "                        5.6747e-03],\n",
       "                      [-2.0044e-01,  4.9273e-02, -2.8922e-01,  1.4737e-01,  2.3178e-01,\n",
       "                        1.0604e-01],\n",
       "                      [-4.1265e-01, -2.9591e-01, -1.8542e-01, -1.3536e-01, -2.8173e-02,\n",
       "                        1.6512e-02],\n",
       "                      [-3.4694e-02,  1.0687e-01,  2.0695e-02, -1.5187e-01, -4.3258e-03,\n",
       "                        1.0713e-02],\n",
       "                      [-1.5939e-01, -2.0745e-02,  4.1916e-01, -2.0341e-01,  6.9021e-03,\n",
       "                        9.4478e-03],\n",
       "                      [ 8.0898e-01,  8.7605e-02, -1.3757e-01, -2.1866e-01, -8.4343e-03,\n",
       "                        2.4736e-02],\n",
       "                      [-1.1002e-01, -7.9958e-01,  1.9834e-01, -1.7433e-01, -6.9947e-03,\n",
       "                       -1.4330e-02],\n",
       "                      [ 1.9944e-01,  6.6291e-01,  2.4634e-01, -3.1398e-01, -8.8489e-03,\n",
       "                        1.1076e-02],\n",
       "                      [-5.0969e-01, -4.0781e-01, -4.0638e-01, -2.2625e-01,  3.2425e-03,\n",
       "                        2.4238e-01],\n",
       "                      [ 1.6240e-01, -3.8724e-01, -4.1382e-01,  3.4465e-01,  4.5671e-02,\n",
       "                       -7.1921e-02],\n",
       "                      [ 2.1476e-01,  9.3802e-02, -7.5110e-02,  1.4175e-01,  1.9311e-01,\n",
       "                       -1.8605e-01],\n",
       "                      [ 3.0426e-01,  3.4085e-01, -1.4774e-01,  1.9554e-02,  1.4085e-02,\n",
       "                        7.4270e-02],\n",
       "                      [-4.2567e-01, -8.9798e-01,  4.9615e-02,  4.6736e-02, -3.5332e-02,\n",
       "                        1.6598e-01],\n",
       "                      [ 2.0493e-01, -5.4240e-02,  2.6673e-02,  2.4259e-01, -3.5150e-02,\n",
       "                        4.4487e-03],\n",
       "                      [-4.4774e-01,  1.5149e-01, -1.0239e-01, -1.4429e-02, -2.3822e-01,\n",
       "                       -2.0529e-01],\n",
       "                      [ 3.8248e-01, -2.5363e-01, -2.0680e-01, -1.7298e-01, -3.2054e-01,\n",
       "                       -1.2918e-02],\n",
       "                      [ 1.2084e-01, -4.8997e-01,  3.2902e-01,  3.3539e-01,  7.7359e-03,\n",
       "                        2.6611e-01],\n",
       "                      [-7.1330e-03,  2.0832e-01,  1.4626e-01,  1.5807e-02,  6.1363e-02,\n",
       "                       -2.3551e-01],\n",
       "                      [ 2.4813e-01,  3.5400e-01, -1.8502e-01,  5.0815e-01, -3.1795e-02,\n",
       "                        4.5299e-02],\n",
       "                      [ 8.8471e-02, -1.1788e-01, -3.9168e-02,  7.6829e-02,  1.5544e-02,\n",
       "                       -2.3609e-01],\n",
       "                      [-3.3033e-01, -8.1929e-01, -1.0158e-01,  6.3249e-02, -2.4954e-02,\n",
       "                       -1.3125e-01],\n",
       "                      [ 2.8797e-02, -1.5102e-01,  1.1647e-01,  2.6790e-01,  5.7601e-02,\n",
       "                        5.6154e-02],\n",
       "                      [ 3.7313e-01, -3.9749e-01, -4.8354e-01,  4.2409e-01,  1.1126e-02,\n",
       "                        6.4913e-02],\n",
       "                      [-1.5483e-01,  2.0940e-02, -3.6524e-01, -6.4489e-02,  2.3084e-01,\n",
       "                       -1.4417e-03],\n",
       "                      [ 2.6878e-01, -2.9773e-01, -3.3838e-02, -1.9267e-01,  3.8496e-01,\n",
       "                       -1.8712e-01],\n",
       "                      [-4.9011e-01, -7.0501e-01,  2.4103e-02, -2.7595e-01, -1.0245e-02,\n",
       "                       -4.7376e-04],\n",
       "                      [ 8.7074e-03, -3.5852e-01, -1.8302e-01,  1.4419e-01, -1.5107e-01,\n",
       "                       -3.4732e-02],\n",
       "                      [-9.1692e-02,  2.7611e-01,  1.8719e-02, -1.9045e-01, -7.0391e-02,\n",
       "                        1.1038e-01],\n",
       "                      [-2.3668e-01,  6.2405e-01, -4.5757e-02, -2.6050e-01,  8.9307e-02,\n",
       "                        5.4014e-03],\n",
       "                      [-2.5299e-01,  3.4785e-01, -1.1419e-01, -2.3691e-01, -3.9843e-01,\n",
       "                       -2.1532e-02],\n",
       "                      [ 1.5473e-02,  3.8262e-01,  2.2410e-01,  3.5746e-02, -2.2620e-01,\n",
       "                       -4.0611e-03],\n",
       "                      [ 3.6496e-01,  9.5115e-01, -2.0338e-01,  2.9220e-02,  6.4120e-02,\n",
       "                        1.4546e-02],\n",
       "                      [-3.2888e-01,  1.9928e-01,  2.3284e-01, -2.9987e-02,  3.7165e-04,\n",
       "                       -2.3167e-01],\n",
       "                      [ 6.4280e-01,  1.1743e-01, -1.5188e-01,  1.5294e-01,  3.6238e-02,\n",
       "                        2.9367e-02],\n",
       "                      [ 1.6333e-01,  1.4520e-01,  2.1358e-02, -2.2018e-01, -2.1071e-03,\n",
       "                       -1.6192e-01],\n",
       "                      [-3.2751e-01,  2.0940e-01, -5.0377e-02, -4.3284e-01,  6.1332e-03,\n",
       "                       -8.2735e-03],\n",
       "                      [ 4.1183e-02,  1.0750e-01,  9.6196e-02, -1.8741e-01,  6.7892e-03,\n",
       "                        4.6828e-02],\n",
       "                      [-1.0440e+00, -2.9821e-01, -1.0167e-01,  2.0464e-01, -2.5572e-03,\n",
       "                        1.4393e-02],\n",
       "                      [-2.5179e-01, -3.6854e-01, -2.9899e-01,  3.5019e-01, -4.0979e-01,\n",
       "                       -2.3654e-02],\n",
       "                      [ 3.4860e-01,  4.0666e-01, -3.1033e-02,  6.9415e-02, -8.1862e-02,\n",
       "                       -1.3769e-01],\n",
       "                      [-8.1632e-03, -2.8359e-01,  2.2538e-01,  4.5848e-01, -3.8585e-03,\n",
       "                       -2.8986e-02],\n",
       "                      [-4.0431e-01, -2.3659e-01, -3.5472e-01, -1.3755e-02, -1.9339e-01,\n",
       "                       -1.1513e-01],\n",
       "                      [-4.8410e-01,  6.3546e-01, -3.0114e-01,  2.2004e-02, -8.4094e-02,\n",
       "                        5.9456e-04],\n",
       "                      [-1.2247e-01, -2.0318e-01, -2.5761e-01,  3.7832e-01,  1.5599e-01,\n",
       "                        8.5359e-02],\n",
       "                      [ 3.7600e-02,  4.8315e-01,  1.2731e-01, -4.5996e-01, -2.0261e-03,\n",
       "                        2.2692e-02],\n",
       "                      [-5.2666e-02,  2.8603e-01,  6.9050e-02, -1.7183e-01,  1.2270e-01,\n",
       "                        9.0991e-02],\n",
       "                      [-4.7361e-02,  2.8194e-01,  2.9967e-01, -2.7446e-01, -8.6096e-04,\n",
       "                        4.2817e-03],\n",
       "                      [-1.8226e-01,  3.5852e-02,  2.6478e-02,  4.5577e-01,  2.7556e-03,\n",
       "                        7.7707e-03],\n",
       "                      [-2.7321e-01,  8.1511e-01, -5.0319e-02, -1.2235e-01,  1.3128e-02,\n",
       "                        3.0517e-03],\n",
       "                      [-5.9928e-01, -1.5107e-01, -1.4273e-01,  7.1864e-02,  2.0953e-01,\n",
       "                        4.3196e-03],\n",
       "                      [-1.0180e-01,  5.4184e-01, -4.4968e-02, -1.1157e-01,  3.0331e-01,\n",
       "                        1.9317e-02],\n",
       "                      [ 2.8255e-01,  2.3075e-01, -1.1404e-01, -2.7994e-01, -2.0630e-01,\n",
       "                        9.1699e-02],\n",
       "                      [-5.2863e-01, -1.7334e-01, -3.3424e-01,  1.0224e-02, -1.5807e-02,\n",
       "                       -4.3330e-01],\n",
       "                      [-2.7208e-02, -1.1004e-01,  1.7882e-02,  1.5476e-01, -1.1065e-01,\n",
       "                        2.0072e-01],\n",
       "                      [-7.1904e-02, -1.5728e-01, -1.6370e-01, -6.0051e-02, -8.0818e-02,\n",
       "                        1.4931e-01],\n",
       "                      [-2.9019e-01,  1.8825e-02, -2.8891e-01, -4.6314e-02, -2.2346e-01,\n",
       "                        2.3495e-01],\n",
       "                      [ 9.4500e-01, -5.4700e-01, -5.6294e-02, -2.3839e-01,  3.6547e-03,\n",
       "                        1.9494e-02],\n",
       "                      [ 3.0836e-02,  1.2004e-01,  2.4349e-01,  6.5628e-02,  2.5082e-01,\n",
       "                       -7.4785e-03],\n",
       "                      [ 4.4167e-01,  5.2817e-03, -4.3662e-02,  2.3409e-01, -4.8563e-02,\n",
       "                        4.8988e-03],\n",
       "                      [-1.1820e-01, -9.9368e-02,  1.0900e-01, -1.6791e-02,  6.0012e-02,\n",
       "                       -5.6162e-02],\n",
       "                      [-1.5059e-01,  3.6288e-01, -1.7353e-02, -3.1793e-01, -1.7754e-02,\n",
       "                       -1.6002e-01],\n",
       "                      [-2.3977e-01, -7.2994e-02,  1.3230e-01,  5.4147e-01,  1.7435e-02,\n",
       "                        1.3818e-02],\n",
       "                      [-1.3091e-01, -1.5785e-01,  2.8083e-01,  3.6951e-01, -4.9791e-01,\n",
       "                        4.5428e-03],\n",
       "                      [-5.7896e-01,  1.2320e-01,  3.0270e-01,  5.1118e-02,  1.2581e-02,\n",
       "                        1.3196e-01],\n",
       "                      [ 2.5238e-01, -1.5269e-02,  1.0170e-01, -2.9699e-01,  2.5336e-01,\n",
       "                       -4.9717e-03],\n",
       "                      [ 3.7079e-01,  2.4881e-01,  9.2819e-02, -3.4523e-01,  2.1974e-01,\n",
       "                        9.6598e-02],\n",
       "                      [ 2.5253e-01, -5.4040e-01, -5.0457e-02,  7.0633e-02, -6.0977e-02,\n",
       "                        2.4000e-01],\n",
       "                      [-8.3577e-01,  1.4120e-01,  1.4255e-01, -1.3902e-01,  2.2078e-03,\n",
       "                        4.2907e-02],\n",
       "                      [ 2.1694e-01,  1.9342e-01, -2.3797e-01, -2.1809e-01,  5.1100e-02,\n",
       "                       -3.5495e-02],\n",
       "                      [ 3.1258e-01, -1.0229e-01, -8.5744e-02,  4.8872e-01, -2.1563e-02,\n",
       "                       -1.4433e-01],\n",
       "                      [ 3.3918e-01, -3.5516e-01,  1.9830e-01,  4.0290e-01,  5.8759e-03,\n",
       "                        2.5209e-02],\n",
       "                      [ 1.6126e-01, -3.0453e-02, -3.6515e-01, -2.5139e-01, -1.2094e-02,\n",
       "                       -3.3029e-01],\n",
       "                      [ 1.0534e-01, -1.0077e-01, -8.1447e-02,  6.1583e-02, -3.5491e-01,\n",
       "                        9.2236e-02],\n",
       "                      [-4.7515e-01,  8.3325e-02,  2.4474e-01,  1.2695e-01, -3.5680e-05,\n",
       "                        1.5593e-02],\n",
       "                      [-2.0222e-02, -1.4861e-01,  1.1890e-01,  8.1671e-03, -9.0024e-02,\n",
       "                       -1.0073e-01],\n",
       "                      [-3.5703e-03,  5.1249e-01, -2.5314e-02,  7.2182e-02, -1.0054e-03,\n",
       "                       -3.6363e-01],\n",
       "                      [-2.4448e-01, -2.7732e-01,  1.5208e-01,  7.1720e-02, -2.8734e-02,\n",
       "                       -2.1648e-01],\n",
       "                      [ 6.0880e-01,  6.0349e-01, -1.6162e-01,  3.8301e-01, -6.4244e-03,\n",
       "                       -4.2653e-02],\n",
       "                      [-1.0845e-02,  1.5570e-01, -6.6580e-02, -8.9923e-02, -2.3109e-03,\n",
       "                       -1.1147e-02],\n",
       "                      [-4.2848e-01,  2.6585e-01,  1.9929e-01, -5.3239e-01,  9.4148e-03,\n",
       "                        1.7369e-02],\n",
       "                      [-6.5496e-01,  5.5220e-01,  2.9804e-01,  1.0441e-01,  2.0692e-02,\n",
       "                        1.9787e-02],\n",
       "                      [ 5.4306e-01,  2.0455e-01, -1.5563e-01,  3.9439e-01, -1.4847e-02,\n",
       "                        2.0265e-02],\n",
       "                      [-2.2168e-01, -4.9527e-01, -8.7988e-02,  3.9977e-01, -1.5291e-02,\n",
       "                       -1.1067e-02],\n",
       "                      [ 2.3587e-01,  7.2840e-01,  1.6646e-01, -2.0003e-02, -1.3410e-01,\n",
       "                        1.0298e-02],\n",
       "                      [ 3.6350e-02,  6.4143e-01, -4.2120e-01, -4.6546e-02, -1.6514e-01,\n",
       "                        1.7554e-02],\n",
       "                      [-1.9514e-01,  5.2108e-02,  1.3243e-01,  3.6837e-01, -2.4710e-01,\n",
       "                       -3.4532e-02],\n",
       "                      [-7.7563e-01, -1.0281e-01, -7.5034e-02,  5.6927e-02, -4.6889e-03,\n",
       "                        4.6961e-03],\n",
       "                      [ 1.5690e-01, -5.3397e-01,  2.5497e-01, -1.0815e-01,  1.9481e-02,\n",
       "                        2.8361e-02],\n",
       "                      [-6.2035e-02,  5.8849e-01, -3.8560e-01, -3.8533e-01, -8.5572e-04,\n",
       "                        4.4078e-03],\n",
       "                      [ 5.6340e-02,  5.5529e-02, -1.5887e-01,  1.1671e-01, -2.2903e-01,\n",
       "                       -1.8514e-01],\n",
       "                      [ 2.3663e-01, -5.2231e-01, -2.7400e-01,  1.9577e-02,  6.7323e-02,\n",
       "                        2.6969e-01],\n",
       "                      [ 2.5567e-02,  2.9667e-01,  3.7965e-01, -3.2943e-01, -3.9122e-02,\n",
       "                       -3.6771e-02],\n",
       "                      [ 2.0854e-01, -2.7702e-01, -1.5222e-01,  1.3578e-01, -9.2586e-02,\n",
       "                       -1.4370e-01],\n",
       "                      [ 3.1255e-01, -9.9095e-02,  1.0141e-01, -4.5165e-03, -3.4211e-02,\n",
       "                        5.5012e-03],\n",
       "                      [ 2.8145e-01, -4.9369e-01,  1.0305e-01,  5.7937e-02, -1.5552e-02,\n",
       "                       -2.8306e-01],\n",
       "                      [-2.4448e-01,  4.6825e-01,  7.5348e-02, -6.6634e-02, -3.1244e-01,\n",
       "                        9.1886e-02],\n",
       "                      [-1.2398e-01, -4.3781e-01,  1.1804e-02,  4.0334e-01,  3.3022e-03,\n",
       "                        2.3464e-03],\n",
       "                      [-4.3841e-02, -2.5064e-01, -2.0390e-01,  2.2066e-01, -1.8805e-03,\n",
       "                       -1.0734e-01],\n",
       "                      [-2.7834e-01, -5.9901e-01, -5.2227e-02,  6.0831e-01, -3.7857e-03,\n",
       "                        7.0609e-03],\n",
       "                      [-1.5668e-01, -1.5913e-02,  1.8920e-01,  4.6305e-02, -2.7812e-01,\n",
       "                       -2.7905e-01],\n",
       "                      [-2.4494e-01,  8.7888e-02,  1.0724e-01,  1.8234e-01,  5.1719e-03,\n",
       "                       -2.1281e-01],\n",
       "                      [-1.3414e-01,  2.5599e-01, -6.9659e-03, -3.5609e-01,  9.4094e-02,\n",
       "                       -1.1334e-01],\n",
       "                      [ 2.4234e-02,  3.8309e-03, -1.2510e-01, -1.3319e-01,  9.4544e-02,\n",
       "                        6.0720e-02],\n",
       "                      [-5.0689e-03,  2.1661e-01, -2.9135e-02, -4.7167e-01, -6.9030e-03,\n",
       "                        4.8121e-03],\n",
       "                      [ 3.6514e-03,  1.0834e-01,  3.5052e-01,  1.1899e-01,  5.1088e-03,\n",
       "                        2.1052e-02],\n",
       "                      [ 7.9465e-02, -5.2291e-02,  2.3482e-01,  6.0894e-02, -3.9587e-01,\n",
       "                       -3.9827e-01],\n",
       "                      [-7.4559e-01,  4.5776e-01, -8.1930e-02,  1.6808e-02,  1.9781e-03,\n",
       "                        3.5948e-02],\n",
       "                      [ 2.4340e-02, -4.9249e-01,  7.1955e-02,  3.9983e-01, -5.2089e-02,\n",
       "                       -2.4515e-01],\n",
       "                      [ 4.9038e-02,  5.8084e-01,  4.4427e-02,  1.0620e-01,  2.1283e-01,\n",
       "                        1.2943e-01],\n",
       "                      [-2.5015e-01,  3.0504e-01, -1.0467e-01, -1.1939e-01,  3.2169e-01,\n",
       "                       -2.8926e-01],\n",
       "                      [ 5.6181e-02, -6.3911e-01,  9.2501e-02, -4.0899e-02, -4.5490e-03,\n",
       "                       -2.5842e-01],\n",
       "                      [-3.0739e-01, -1.9261e-01, -2.5866e-01,  1.0623e-01, -1.6410e-02,\n",
       "                       -2.8959e-01],\n",
       "                      [-1.9904e-01,  6.2716e-01, -4.4837e-01, -3.1313e-01, -9.8735e-03,\n",
       "                        1.2533e-01],\n",
       "                      [-5.7271e-02,  1.6732e-02, -3.5534e-02, -1.5894e-01, -5.2399e-03,\n",
       "                        7.9380e-02],\n",
       "                      [-4.5447e-01, -1.2181e-01, -1.2421e-01,  8.5217e-02, -4.9119e-02,\n",
       "                        1.2670e-01],\n",
       "                      [ 9.2569e-02,  1.2033e-01, -1.8439e-02, -2.9572e-01,  1.0792e-01,\n",
       "                        6.3223e-03],\n",
       "                      [ 7.1795e-01,  8.0668e-02,  2.1501e-02, -1.8256e-01,  1.3453e-02,\n",
       "                        1.2429e-03],\n",
       "                      [-3.0704e-01, -3.2904e-02, -3.1856e-01, -1.0498e-01, -6.5446e-04,\n",
       "                       -3.3517e-01],\n",
       "                      [-1.0642e-01,  4.1401e-01, -2.9898e-01,  3.2839e-01,  2.0719e-01,\n",
       "                       -2.7422e-01],\n",
       "                      [ 4.5807e-01,  7.6846e-02,  1.1250e-01, -1.8541e-01, -8.2296e-02,\n",
       "                        1.8656e-02],\n",
       "                      [ 2.5954e-01,  2.1169e-01,  2.0613e-01, -5.1692e-01, -3.9671e-01,\n",
       "                       -8.9570e-03],\n",
       "                      [-3.1232e-01, -4.8481e-01, -2.0026e-01,  5.8017e-02,  1.8028e-01,\n",
       "                        1.3286e-02],\n",
       "                      [ 4.2682e-01, -1.5246e-02,  2.2513e-01, -1.6611e-02, -1.8437e-02,\n",
       "                       -2.3993e-01],\n",
       "                      [ 3.0212e-01,  2.3114e-01,  3.0509e-03, -2.7854e-01,  1.6275e-01,\n",
       "                        7.8249e-02],\n",
       "                      [ 2.0366e-02,  8.0485e-01, -8.7587e-02, -2.6476e-01, -2.2920e-02,\n",
       "                       -3.6171e-02]], device='cuda:0')),\n",
       "             ('interactNN.layer1.bias',\n",
       "              tensor([-0.3538, -0.0926,  0.0237,  0.2438, -0.0988,  0.0655, -0.0171, -0.3454,\n",
       "                       0.0529, -0.3192, -0.0235, -0.3479,  0.3523, -0.0274, -0.0132, -0.3714,\n",
       "                      -0.0292,  0.0140,  0.0652, -0.4713, -0.1659, -0.0659,  0.0828, -0.0490,\n",
       "                      -0.1815,  0.3865,  0.1721, -0.4105, -0.2327, -0.3518, -0.0064, -0.1588,\n",
       "                      -0.1936, -0.2865, -0.0759, -0.1071, -0.0832, -0.0088, -0.0963, -0.3008,\n",
       "                       0.0987,  0.0224, -0.0034, -0.2017,  0.2196,  0.1476, -0.2078, -0.0148,\n",
       "                      -0.1264, -0.2511, -0.2217, -0.1800, -0.3150, -0.3036,  0.0616, -0.0405,\n",
       "                      -0.1301,  0.0957,  0.0629, -0.0934, -0.3805, -0.0873, -0.0378,  0.1254,\n",
       "                      -0.1717, -0.2040, -0.4835, -0.4157, -0.4084, -0.3384, -0.2223,  0.2380,\n",
       "                       0.0694, -0.1107,  0.2354,  0.0708,  0.0223,  0.0031, -0.1496, -0.1531,\n",
       "                      -0.4125,  0.0989, -0.0759, -0.3265,  0.1965, -0.0162, -0.2588,  0.2416,\n",
       "                      -0.2556, -0.0630, -0.3797,  0.2635,  0.1329, -0.2210, -0.3456, -0.3208,\n",
       "                       0.2288, -0.2671, -0.1666,  0.0606,  0.2090,  0.0435, -0.1280, -0.0877,\n",
       "                      -0.2178,  0.1045, -0.0983, -0.3074, -0.3373, -0.0900,  0.0019, -0.3868,\n",
       "                      -0.4015, -0.3099,  0.2540,  0.0527,  0.0048, -0.1758, -0.0840, -0.2852,\n",
       "                      -0.3575, -0.3324, -0.2468, -0.1822, -0.0825, -0.2610, -0.1636, -0.1034],\n",
       "                     device='cuda:0')),\n",
       "             ('interactNN.layer2.weight',\n",
       "              tensor([[ 1.6299e-02, -5.7029e-02,  3.8852e-02,  ...,  8.3076e-02,\n",
       "                       -5.0420e-02,  7.3688e-03],\n",
       "                      [-6.7584e-03,  1.4148e-02, -3.9005e-02,  ..., -8.3846e-04,\n",
       "                       -5.5056e-02, -2.3103e-02],\n",
       "                      [ 1.5389e-01, -8.6247e-02,  2.9087e-02,  ..., -5.4761e-02,\n",
       "                        3.7889e-02,  1.0561e-01],\n",
       "                      ...,\n",
       "                      [-1.3230e-02,  1.1152e-01, -1.7634e-05,  ..., -1.9301e-02,\n",
       "                        4.2809e-02,  4.9786e-02],\n",
       "                      [ 7.4009e-02, -9.3462e-02, -4.9306e-03,  ..., -4.9218e-02,\n",
       "                        1.3863e-02, -5.8401e-02],\n",
       "                      [ 5.4616e-02,  8.0244e-02, -1.3899e-02,  ...,  1.2630e-02,\n",
       "                       -6.8254e-02,  7.1437e-02]], device='cuda:0')),\n",
       "             ('interactNN.layer2.bias',\n",
       "              tensor([-0.0582, -0.0307, -0.2576, -0.0770,  0.1334, -0.4005, -0.1153, -0.1547,\n",
       "                      -0.0456,  0.0741, -0.0736,  0.2099,  0.0330, -0.1118, -0.0397, -0.2206,\n",
       "                      -0.1657, -0.1723, -0.1496, -0.2062, -0.1783, -0.0482, -0.1224, -0.5501,\n",
       "                      -0.0650,  0.0251, -0.0631,  0.0260, -0.1304, -0.3151, -0.0213, -0.0266,\n",
       "                       0.1075, -0.3711, -0.0610,  0.0057, -0.1213, -0.3882, -0.0037, -0.0496,\n",
       "                      -0.0313, -0.3148, -0.3218, -0.4656, -0.2906, -0.0539, -0.3322,  0.0344,\n",
       "                      -0.3868,  0.5004, -0.0836, -0.4043,  0.1059, -0.0204, -0.0058,  0.4486,\n",
       "                      -0.4408, -0.1770,  0.0083,  0.1262,  0.0043,  0.0020,  0.0726, -0.3993,\n",
       "                      -0.0747,  0.0512,  0.0011,  0.1190, -0.0058,  0.1765, -0.2444,  0.1643,\n",
       "                      -0.2767, -0.2200, -0.3090, -0.1011, -0.2907,  0.1206, -0.0449, -0.0945,\n",
       "                      -0.2136, -0.2700,  0.0191, -0.0724,  0.1231, -0.0698, -0.1453,  0.1867,\n",
       "                       0.2149, -0.6027, -0.1137,  0.2279,  0.2737,  0.2719,  0.2018, -0.0744,\n",
       "                      -0.0278, -0.2993, -0.0116, -0.0535, -0.1780, -0.3865, -0.1604,  0.0064,\n",
       "                      -0.2435, -0.0880, -0.4736, -0.4627, -0.0919, -0.4723, -0.1436, -0.0294,\n",
       "                       0.1308, -0.0228, -0.0852, -0.6144,  0.0830, -0.0549, -0.2448, -0.1180,\n",
       "                      -0.2931, -0.2866, -0.4058, -0.1101, -0.4676, -0.0770, -0.0159, -0.2490],\n",
       "                     device='cuda:0')),\n",
       "             ('interactNN.layer3.weight',\n",
       "              tensor([[-0.0236, -0.0672, -0.0115,  ..., -0.0650,  0.0055,  0.0604],\n",
       "                      [-0.0469, -0.0600, -0.0801,  ...,  0.0082, -0.0514,  0.0695],\n",
       "                      [-0.0717, -0.0531,  0.0322,  ..., -0.0375,  0.0345, -0.1415],\n",
       "                      ...,\n",
       "                      [-0.0306, -0.0691,  0.0642,  ...,  0.0279,  0.0092,  0.0552],\n",
       "                      [-0.0352,  0.0733,  0.0290,  ...,  0.0368, -0.0143, -0.0530],\n",
       "                      [-0.0298, -0.0529,  0.1152,  ..., -0.0055,  0.0501, -0.1160]],\n",
       "                     device='cuda:0')),\n",
       "             ('interactNN.layer3.bias',\n",
       "              tensor([ 0.0479,  0.0628, -0.2429,  0.0050,  0.3563, -0.1239,  0.2714,  0.3239,\n",
       "                      -0.0992, -0.2454,  0.3780,  0.0643,  0.3509,  0.1898, -0.1101,  0.1527,\n",
       "                      -0.1459, -0.0655,  0.2200, -0.0612,  0.3188, -0.0248, -0.0865, -0.0342,\n",
       "                      -0.1595, -0.1296,  0.0502, -0.1282,  0.2836, -0.0916,  0.2993,  0.3454,\n",
       "                      -0.0889,  0.3118,  0.3747, -0.1337, -0.0573,  0.0269, -0.3672, -0.2227,\n",
       "                      -0.3707, -0.2561, -0.1066, -0.2784, -0.0996,  0.1068,  0.2145, -0.0759,\n",
       "                      -0.3366, -0.3185, -0.1519, -0.0964, -0.2272,  0.0523,  0.1013,  0.3643,\n",
       "                       0.3749, -0.0927,  0.2995,  0.2683,  0.3054,  0.0256,  0.1397, -0.0277,\n",
       "                       0.0042,  0.2114, -0.0074, -0.0463, -0.0633, -0.0891,  0.1399,  0.3016,\n",
       "                       0.4234,  0.0964,  0.2496, -0.1195, -0.0847, -0.0355, -0.1689, -0.0441,\n",
       "                      -0.2769, -0.0054,  0.3945, -0.0402,  0.0737, -0.0523,  0.4058, -0.2369,\n",
       "                      -0.2148,  0.0757,  0.0201, -0.0892, -0.1948,  0.0511,  0.2673, -0.1198,\n",
       "                       0.1059, -0.0289,  0.1764, -0.0087, -0.1803, -0.1217,  0.1035, -0.3720,\n",
       "                      -0.0828, -0.3095, -0.0908,  0.3822, -0.0284, -0.1132, -0.0463,  0.3123,\n",
       "                       0.3552, -0.3652,  0.2347,  0.0623, -0.1037, -0.0071, -0.4200, -0.2243,\n",
       "                      -0.1398,  0.2552,  0.1045,  0.0271,  0.2788, -0.1576,  0.0138,  0.0882],\n",
       "                     device='cuda:0')),\n",
       "             ('interactNN.layer4.weight',\n",
       "              tensor([[ 0.2541, -0.0221,  0.2318,  0.2049, -0.1628, -0.0006,  0.1460,  0.2682,\n",
       "                       -0.0899,  0.3256,  0.1325,  0.0580,  0.2963, -0.2820, -0.0718,  0.0332,\n",
       "                       -0.0333,  0.0106, -0.3267, -0.0505, -0.4183,  0.1196,  0.0789,  0.0783,\n",
       "                       -0.2785,  0.3762,  0.2156, -0.1445, -0.2900,  0.1151,  0.2281,  0.3857,\n",
       "                       -0.1127,  0.0514,  0.3193,  0.2070, -0.0578,  0.1275,  0.2625, -0.2116,\n",
       "                        0.1831,  0.1798, -0.0964,  0.2910,  0.1727, -0.0785, -0.1412,  0.0035,\n",
       "                       -0.1760,  0.1525, -0.0445,  0.0857, -0.1555, -0.2645,  0.1391,  0.1309,\n",
       "                       -0.1573, -0.1701,  0.2538, -0.3733, -0.2788, -0.1311,  0.2949,  0.0135,\n",
       "                       -0.1307, -0.4104, -0.0935, -0.1369,  0.0581,  0.1361,  0.1451,  0.0126,\n",
       "                        0.0422, -0.5144,  0.3490, -0.0092,  0.0577,  0.0041, -0.1339,  0.0776,\n",
       "                       -0.3036,  0.0197, -0.2998,  0.2350,  0.0823,  0.0675, -0.2608, -0.1358,\n",
       "                       -0.1113, -0.2084, -0.1320,  0.0827, -0.1184,  0.2246, -0.1253, -0.1249,\n",
       "                        0.0679, -0.0748,  0.2107, -0.0618,  0.1636, -0.0679,  0.2149,  0.2099,\n",
       "                        0.0115,  0.0496,  0.0706, -0.3074, -0.2298,  0.0283,  0.0127,  0.1589,\n",
       "                       -0.2379, -0.2705,  0.2376,  0.2604, -0.0497, -0.0179, -0.2691,  0.1497,\n",
       "                       -0.1412, -0.2045,  0.0138,  0.1561, -0.3750, -0.0078, -0.0096,  0.0949],\n",
       "                      [-0.0602,  0.0525,  0.2165, -0.1453,  0.3012, -0.1557, -0.3653,  0.2628,\n",
       "                        0.1915,  0.1490, -0.3946,  0.1906, -0.2971,  0.2049, -0.1053, -0.3744,\n",
       "                       -0.1966,  0.1035,  0.0717, -0.0662, -0.2614, -0.1483, -0.0075,  0.1372,\n",
       "                        0.0044,  0.0312, -0.0383, -0.1036,  0.0885,  0.0112,  0.2649, -0.2311,\n",
       "                        0.1696,  0.3009,  0.1278,  0.1560, -0.0867,  0.0307, -0.0594,  0.0283,\n",
       "                        0.0931, -0.1269, -0.0398, -0.2604,  0.0278, -0.3653, -0.4179, -0.0685,\n",
       "                        0.3841, -0.0610,  0.0313,  0.1032, -0.1516,  0.1842, -0.1349,  0.3153,\n",
       "                        0.2856,  0.2003, -0.0740,  0.0868,  0.0524, -0.1219,  0.3401, -0.1239,\n",
       "                       -0.0718, -0.0117, -0.0761,  0.1727, -0.2165,  0.1487, -0.1256,  0.2223,\n",
       "                       -0.4834,  0.1509,  0.0692, -0.2168,  0.0260, -0.1951,  0.0159, -0.0277,\n",
       "                        0.2185,  0.0123, -0.3077, -0.1020,  0.0806,  0.0810, -0.2418,  0.1405,\n",
       "                       -0.0129, -0.1561,  0.0507,  0.1424,  0.2476,  0.0997,  0.4138, -0.1381,\n",
       "                        0.1405, -0.0340,  0.2469, -0.0332,  0.0330, -0.1568,  0.0281,  0.0825,\n",
       "                        0.0878,  0.1827, -0.0135, -0.0469,  0.0493, -0.0616, -0.0066,  0.1342,\n",
       "                        0.2256,  0.1804,  0.3328,  0.0776, -0.0478,  0.0330,  0.1662,  0.0216,\n",
       "                       -0.0705,  0.1182, -0.3822,  0.1503, -0.0110, -0.0786,  0.0116,  0.0146]],\n",
       "                     device='cuda:0')),\n",
       "             ('interactNN.layer4.bias',\n",
       "              tensor([-0.0384,  0.0040], device='cuda:0')),\n",
       "             ('thetaDotNN.layer1.weight',\n",
       "              tensor([[-1.8681e-01, -1.3028e-01, -3.9259e-02,  1.8471e-01,  2.9701e-01,\n",
       "                        2.1371e-02],\n",
       "                      [ 4.1711e-01, -3.5386e-01,  6.8416e-03,  3.3089e-01,  3.2287e-02,\n",
       "                       -8.9898e-02],\n",
       "                      [ 2.3725e-01, -2.1601e-02,  2.0488e-02,  2.1467e-01, -1.6669e-01,\n",
       "                        1.6923e-01],\n",
       "                      [ 7.3318e-01, -1.6653e-01, -9.4698e-02,  4.7545e-01,  2.8704e-01,\n",
       "                       -2.5296e-01],\n",
       "                      [-3.0505e-01,  1.5881e-02,  2.4231e-02,  2.8492e-01, -1.6385e-01,\n",
       "                        3.7871e-01],\n",
       "                      [-7.7428e-02, -5.0631e-01,  1.7374e-01,  1.4279e-01,  2.0200e-01,\n",
       "                       -5.6921e-02],\n",
       "                      [ 3.7162e-01, -1.9801e-01, -1.1636e-01, -4.6606e-01, -3.0923e-01,\n",
       "                        3.1659e-01],\n",
       "                      [ 5.4149e-01, -1.9108e-01,  3.0354e-01,  2.8573e-01, -2.2179e-01,\n",
       "                       -2.3912e-01],\n",
       "                      [-4.7535e-02, -2.9146e-01,  7.0241e-02, -1.1072e-01,  6.4195e-02,\n",
       "                        2.2958e-02],\n",
       "                      [-3.4028e-02, -2.3522e-01,  3.1132e-01, -1.1498e-01,  3.4160e-01,\n",
       "                       -3.3451e-01],\n",
       "                      [ 5.3549e-01, -2.4423e-01, -4.9183e-02, -9.5463e-02,  1.9437e-01,\n",
       "                        6.7542e-02],\n",
       "                      [-6.7917e-01, -2.8614e-01,  1.3535e-01, -1.3964e-01,  2.1446e-01,\n",
       "                       -1.2787e-02],\n",
       "                      [-3.0554e-01,  1.7033e-01,  2.2215e-01,  2.6633e-01, -2.3046e-02,\n",
       "                        2.3001e-01],\n",
       "                      [ 5.9477e-02, -4.1988e-01, -2.3777e-01, -4.5132e-01,  3.0105e-01,\n",
       "                       -4.7623e-02],\n",
       "                      [-4.1034e-02, -3.0005e-01, -2.2392e-01,  1.2717e-01, -3.3941e-01,\n",
       "                       -2.1874e-01],\n",
       "                      [-2.5866e-01, -2.5023e-01, -1.4796e-01, -1.6671e-01, -2.7018e-01,\n",
       "                       -1.3606e-02],\n",
       "                      [ 7.9587e-02, -1.0902e-02,  2.6691e-01,  1.6882e-01, -9.8182e-03,\n",
       "                        3.4722e-01],\n",
       "                      [-2.7164e-01, -2.1744e-01, -2.2055e-01, -2.1337e-01, -2.1490e-01,\n",
       "                        2.2414e-01],\n",
       "                      [ 2.3919e-01, -4.3915e-01, -1.5500e-01,  1.7859e-02, -1.3522e-03,\n",
       "                       -1.3968e-01],\n",
       "                      [-2.2485e-01,  4.1472e-02, -1.4110e-01,  5.3266e-01,  2.9928e-01,\n",
       "                       -3.6887e-01],\n",
       "                      [-1.9945e-01, -1.3152e-01, -2.0239e-01,  1.4607e-01,  6.1236e-02,\n",
       "                       -1.2736e-01],\n",
       "                      [-8.0268e-02, -5.3383e-01, -2.7414e-01, -1.1992e-01, -1.6534e-01,\n",
       "                       -1.1201e-02],\n",
       "                      [-3.8160e-01,  2.7176e-01, -1.3797e-01,  3.5851e-01, -5.9070e-02,\n",
       "                        2.8726e-01],\n",
       "                      [-5.0048e-02,  4.5354e-01, -2.0156e-01, -1.6853e-01,  1.7471e-01,\n",
       "                       -7.1188e-02],\n",
       "                      [ 1.7841e-01,  2.7232e-01, -6.4587e-02, -1.5637e-02, -3.1130e-01,\n",
       "                        3.4959e-01],\n",
       "                      [ 2.2103e-01,  7.8684e-01,  1.7210e-01, -4.2079e-01, -2.1122e-01,\n",
       "                        2.0097e-01],\n",
       "                      [-3.5541e-01, -2.0287e-01, -4.2809e-01,  1.9080e-01, -3.6519e-01,\n",
       "                       -8.0883e-02],\n",
       "                      [-2.9115e-02, -5.3747e-01, -1.5362e-01, -8.6330e-02,  1.3823e-01,\n",
       "                       -2.1384e-01],\n",
       "                      [ 4.5279e-01,  1.8822e-01,  8.4899e-02,  7.6277e-02, -3.2780e-01,\n",
       "                       -3.2528e-02],\n",
       "                      [ 2.2649e-01, -1.8620e-02,  2.5497e-01,  3.9504e-01, -2.5227e-01,\n",
       "                        6.9249e-02],\n",
       "                      [-4.3467e-01,  2.0370e-01, -3.5340e-01, -1.2534e-01, -2.5216e-01,\n",
       "                       -3.3665e-01],\n",
       "                      [-2.5898e-01, -1.8425e-01, -4.4684e-02, -3.8786e-01, -2.7641e-01,\n",
       "                       -9.9273e-03],\n",
       "                      [-2.0595e-01,  1.9963e-01, -2.5565e-01, -2.5906e-01,  2.1265e-01,\n",
       "                        3.6014e-01],\n",
       "                      [-1.5381e-01, -3.6299e-02,  7.7201e-02,  2.3961e-01,  1.3870e-01,\n",
       "                       -6.0064e-02],\n",
       "                      [-1.5330e-01, -1.3769e-01, -3.0530e-01,  1.0084e-01,  2.6083e-01,\n",
       "                        2.6964e-01],\n",
       "                      [ 5.0581e-01, -2.4806e-02,  1.0902e-01, -1.9458e-01,  2.1996e-01,\n",
       "                        8.0709e-02],\n",
       "                      [-4.4490e-01,  8.5155e-01, -2.3168e-01, -2.8406e-01,  5.5951e-02,\n",
       "                       -6.3011e-02],\n",
       "                      [ 4.7440e-01, -3.3695e-01,  3.2640e-01,  3.1164e-01, -1.1724e-01,\n",
       "                        1.7134e-01],\n",
       "                      [ 2.3089e-01,  2.2609e-01, -1.7278e-01, -1.5435e-01, -9.5613e-02,\n",
       "                        9.4382e-02],\n",
       "                      [-4.0687e-01, -1.2127e-01, -1.3289e-01, -2.1963e-01,  2.7948e-01,\n",
       "                        1.8613e-01],\n",
       "                      [-2.9455e-01, -3.4556e-01,  7.2572e-02, -1.0605e-01,  2.3385e-01,\n",
       "                        2.3869e-01],\n",
       "                      [-2.6662e-01, -1.7332e-01,  4.3649e-02, -3.9431e-01, -3.8758e-01,\n",
       "                       -5.2364e-02],\n",
       "                      [-1.0488e-01, -1.1506e-01, -1.6522e-01,  5.0943e-02,  3.2305e-01,\n",
       "                        3.8103e-01],\n",
       "                      [-5.6173e-01, -2.7816e-01,  6.1515e-02, -2.1944e-01, -2.0414e-01,\n",
       "                        3.3276e-02],\n",
       "                      [-4.3823e-01, -5.8963e-01,  2.0326e-02, -1.4997e-01,  2.8265e-01,\n",
       "                       -5.1413e-02],\n",
       "                      [ 1.6285e-01,  7.0406e-02, -6.1689e-02, -4.6955e-01, -8.8198e-02,\n",
       "                       -3.1080e-01],\n",
       "                      [-8.7420e-02, -6.5176e-01, -2.2231e-01,  4.1939e-01,  1.0956e-01,\n",
       "                        2.4131e-01],\n",
       "                      [-2.6825e-01,  2.9293e-01,  3.7066e-01,  4.5439e-01, -2.0611e-02,\n",
       "                       -1.4937e-02],\n",
       "                      [ 3.7178e-01,  2.1967e-02,  1.9797e-02, -3.8244e-01,  1.4066e-01,\n",
       "                        1.2754e-01],\n",
       "                      [ 3.2232e-01,  2.7585e-01, -3.4141e-01, -3.2103e-01, -2.9848e-01,\n",
       "                       -3.3474e-02],\n",
       "                      [ 3.9700e-01,  4.1286e-01, -1.3350e-01, -2.1005e-01, -1.8711e-01,\n",
       "                       -9.5117e-03],\n",
       "                      [ 3.3221e-01, -1.4940e-01,  1.7966e-01,  2.1697e-01, -3.2145e-01,\n",
       "                       -1.5482e-01],\n",
       "                      [ 4.4488e-01, -3.5987e-01,  2.7324e-02, -1.9857e-01,  3.1935e-01,\n",
       "                        4.1895e-02],\n",
       "                      [-5.0266e-01, -9.9452e-02, -8.4518e-02, -6.0150e-02, -3.2998e-01,\n",
       "                        3.3623e-02],\n",
       "                      [ 4.0067e-01, -4.4803e-01, -3.3372e-01, -4.3238e-01, -1.9916e-01,\n",
       "                        2.3890e-01],\n",
       "                      [ 2.3013e-01, -3.1438e-01, -2.7116e-01, -2.7722e-01, -2.1572e-01,\n",
       "                        2.1822e-01],\n",
       "                      [ 1.6377e-01,  3.5585e-01,  4.0743e-01,  4.0637e-01,  5.8995e-02,\n",
       "                       -3.9329e-02],\n",
       "                      [-6.3340e-01,  1.8832e-03,  5.0577e-01,  3.9465e-02, -1.6223e-01,\n",
       "                        2.4204e-01],\n",
       "                      [-7.0016e-01,  7.4902e-02,  1.0004e-01, -1.4504e-02,  1.6865e-02,\n",
       "                        3.8424e-02],\n",
       "                      [ 3.5103e-01,  4.3306e-01,  1.4400e-01,  2.6083e-01, -2.8434e-01,\n",
       "                       -1.8732e-02],\n",
       "                      [-3.4982e-01,  4.6164e-01,  9.4398e-02, -6.3702e-01,  1.6693e-01,\n",
       "                        1.4164e-01],\n",
       "                      [-2.5259e-02,  2.1738e-02,  4.8653e-02,  2.5761e-01,  1.1587e-01,\n",
       "                        9.0600e-02],\n",
       "                      [ 1.4446e-01, -1.9739e-01,  1.0942e-01, -3.8866e-01,  1.7696e-01,\n",
       "                       -2.6542e-01],\n",
       "                      [ 8.9687e-02, -1.6302e-02, -2.7378e-01,  4.7497e-01, -3.8332e-01,\n",
       "                        1.9268e-02],\n",
       "                      [-2.6679e-01,  5.5294e-02, -1.2390e-01,  1.8871e-01, -2.3285e-01,\n",
       "                        1.6390e-01],\n",
       "                      [-2.7079e-01, -4.2159e-01,  9.1071e-02, -2.3547e-01,  2.2281e-01,\n",
       "                       -3.8440e-02],\n",
       "                      [-4.2825e-01, -3.9435e-02, -1.2255e-01,  3.2049e-01, -1.8788e-01,\n",
       "                       -1.5250e-01],\n",
       "                      [-1.5845e-01,  3.3586e-01, -3.6888e-01, -2.1998e-01, -6.5625e-02,\n",
       "                       -2.4054e-01],\n",
       "                      [-4.8007e-01,  2.2078e-01, -2.4960e-01,  4.0065e-01,  2.5147e-01,\n",
       "                       -1.0610e-01],\n",
       "                      [-6.8200e-04,  3.1147e-01, -1.4028e-01,  4.8439e-01,  3.6118e-01,\n",
       "                        1.6158e-01],\n",
       "                      [-6.9920e-02,  2.9237e-01, -1.4829e-01, -2.9194e-01, -1.1674e-01,\n",
       "                        2.1375e-01],\n",
       "                      [ 2.4541e-02, -1.6104e-02, -2.1220e-01,  2.0557e-01,  1.6375e-01,\n",
       "                        1.3127e-01],\n",
       "                      [ 1.1014e-01,  1.8949e-01,  1.6136e-01,  4.0716e-01,  3.3515e-01,\n",
       "                       -1.5514e-02],\n",
       "                      [-3.1890e-01, -3.8678e-02,  1.5420e-01,  5.4384e-02,  4.6106e-02,\n",
       "                        2.8309e-01],\n",
       "                      [-1.1187e-01,  1.3773e-01, -2.4582e-01, -2.4238e-01, -5.1893e-02,\n",
       "                        1.7128e-01],\n",
       "                      [-2.2760e-01, -2.4600e-01,  3.3993e-01,  3.8084e-01, -4.2562e-01,\n",
       "                        8.2552e-02],\n",
       "                      [-7.4430e-02, -3.3833e-01,  2.9130e-01,  2.7011e-01, -4.1135e-02,\n",
       "                        3.9120e-01],\n",
       "                      [ 1.7172e-01,  1.7666e-01, -1.1278e-01, -2.0890e-01, -2.3397e-01,\n",
       "                        2.2767e-02],\n",
       "                      [-2.5800e-01, -4.3199e-01,  2.1679e-01, -4.6288e-02,  4.0228e-02,\n",
       "                        1.7141e-01],\n",
       "                      [-9.6852e-02, -4.0141e-01, -1.6547e-01, -2.2064e-01,  1.7819e-01,\n",
       "                        4.2899e-01],\n",
       "                      [ 3.0172e-01,  6.8514e-01,  4.2843e-02, -4.3288e-01,  2.2528e-01,\n",
       "                        1.2798e-01],\n",
       "                      [ 4.0686e-01, -2.9512e-01,  2.0550e-01, -1.7920e-01, -1.7861e-01,\n",
       "                        1.9074e-01],\n",
       "                      [ 4.4323e-01, -3.4533e-01,  3.1457e-01,  1.0189e-01, -2.0093e-01,\n",
       "                        1.9657e-02],\n",
       "                      [-1.6864e-01,  1.5873e-01, -2.6863e-01,  4.5964e-01, -1.0059e-01,\n",
       "                       -3.3317e-01],\n",
       "                      [-4.7698e-01,  3.3468e-02,  1.0401e-01, -1.8826e-01,  2.7700e-01,\n",
       "                       -2.2316e-01],\n",
       "                      [ 1.0258e-01, -4.5742e-01, -4.1627e-01,  4.1672e-01,  5.5912e-02,\n",
       "                       -3.3061e-01],\n",
       "                      [-3.7026e-01, -1.6053e-01,  2.5266e-01,  2.3767e-01,  5.0318e-02,\n",
       "                       -1.5325e-01],\n",
       "                      [-2.2590e-01, -5.7364e-02, -4.0880e-01, -1.7564e-01, -3.2823e-01,\n",
       "                       -1.4245e-01],\n",
       "                      [ 4.4164e-01,  4.4592e-01, -1.8553e-01,  3.4396e-01, -2.1125e-02,\n",
       "                        2.9562e-01],\n",
       "                      [ 2.6234e-01,  6.3419e-01, -7.8717e-03,  4.1111e-01,  4.9226e-02,\n",
       "                        8.2242e-02],\n",
       "                      [ 7.7381e-02, -5.6281e-01,  1.2751e-01, -9.7964e-02, -2.3458e-02,\n",
       "                        1.0758e-01],\n",
       "                      [-4.3918e-01,  1.9076e-01, -2.5904e-01,  3.6612e-01,  2.6039e-01,\n",
       "                        2.2914e-01],\n",
       "                      [-2.6623e-01, -3.4993e-01,  3.9256e-01, -1.5757e-01, -3.1656e-01,\n",
       "                       -3.2139e-01],\n",
       "                      [ 5.9720e-01, -3.0831e-02, -9.2076e-02,  3.8218e-02,  2.0642e-01,\n",
       "                       -1.0818e-01],\n",
       "                      [-2.9010e-01, -3.4794e-01, -2.4687e-01,  3.2032e-01, -1.0594e-01,\n",
       "                        3.7372e-01],\n",
       "                      [-3.4775e-01, -4.7741e-01, -1.2461e-02,  5.6232e-01, -4.6239e-02,\n",
       "                       -7.6936e-02],\n",
       "                      [-2.3425e-01,  4.1339e-01,  1.3235e-01,  2.7202e-01,  2.8024e-03,\n",
       "                       -1.1188e-01],\n",
       "                      [ 3.7510e-01,  7.8113e-02,  1.7417e-01, -3.8148e-01, -1.5179e-02,\n",
       "                       -2.3286e-01],\n",
       "                      [-3.1674e-01, -5.0736e-01, -3.1549e-01, -3.3377e-01,  1.6353e-01,\n",
       "                        3.6153e-01],\n",
       "                      [-1.9084e-01,  8.4091e-02,  1.6187e-01, -2.8396e-01,  3.1120e-01,\n",
       "                       -4.0867e-01],\n",
       "                      [ 6.7071e-03,  1.5693e-01,  5.9558e-02, -5.0015e-01, -1.9517e-01,\n",
       "                        1.5243e-01],\n",
       "                      [ 4.6802e-01, -1.7383e-01, -3.5581e-01, -1.6008e-01,  2.7450e-01,\n",
       "                       -2.5376e-01],\n",
       "                      [ 2.8082e-01, -2.7465e-01, -2.5141e-01, -3.8223e-01,  6.5888e-02,\n",
       "                        1.0791e-01],\n",
       "                      [-5.1294e-01, -2.5684e-02,  4.1956e-01, -2.3805e-01,  2.0796e-01,\n",
       "                       -3.2651e-01],\n",
       "                      [ 3.8584e-01,  2.0899e-01, -8.2472e-02,  3.0672e-01,  3.8064e-01,\n",
       "                        1.6530e-02],\n",
       "                      [-6.3656e-03, -1.9925e-01,  9.8933e-02,  2.4294e-01,  3.8166e-01,\n",
       "                       -1.2482e-01],\n",
       "                      [-8.7248e-02, -4.9077e-01,  2.6538e-01,  8.6947e-02,  2.5040e-01,\n",
       "                       -2.2389e-01],\n",
       "                      [-3.1299e-01, -2.7171e-01, -3.0069e-01,  4.4530e-01,  1.0011e-02,\n",
       "                       -3.0142e-01],\n",
       "                      [-1.0677e-03,  4.0581e-02, -5.8463e-02,  4.7681e-02,  2.9261e-02,\n",
       "                       -4.0749e-04],\n",
       "                      [-1.0976e-01, -1.8295e-01, -4.0194e-01,  1.9406e-01, -5.2713e-02,\n",
       "                        1.5217e-01],\n",
       "                      [-3.1501e-01,  7.1313e-02,  1.6664e-02, -3.3439e-01, -1.8980e-01,\n",
       "                       -3.3915e-01],\n",
       "                      [ 1.4918e-01,  2.7618e-01,  5.8484e-02,  4.1207e-01,  2.2658e-01,\n",
       "                       -3.4797e-01],\n",
       "                      [-3.7767e-02, -1.9664e-01, -1.7136e-02, -4.3965e-02,  7.5595e-02,\n",
       "                       -3.0796e-01],\n",
       "                      [ 2.4138e-01, -3.0196e-01, -3.5547e-01, -3.2123e-01,  2.0902e-02,\n",
       "                       -2.4579e-01],\n",
       "                      [-6.7791e-02,  1.5101e-01, -1.3343e-01, -8.2600e-02, -6.8051e-02,\n",
       "                       -1.0842e-01],\n",
       "                      [-4.1497e-01,  2.2614e-01,  1.8552e-01, -2.7662e-01,  3.9954e-02,\n",
       "                       -4.5301e-02],\n",
       "                      [ 2.3227e-01, -4.0790e-01, -1.9655e-01, -2.5280e-01, -3.4026e-02,\n",
       "                       -3.9756e-01],\n",
       "                      [ 1.9596e-01, -2.4091e-01, -9.0348e-02, -4.0526e-01, -1.5975e-02,\n",
       "                       -1.6227e-01],\n",
       "                      [ 4.3978e-02, -5.0832e-02, -3.7822e-02, -3.6325e-01,  1.2124e-01,\n",
       "                        1.3836e-01],\n",
       "                      [-4.2441e-01,  1.0870e-01,  3.2058e-01, -2.7915e-01,  3.0791e-01,\n",
       "                       -2.9307e-01],\n",
       "                      [ 6.8921e-01, -3.6047e-03,  3.4404e-02, -2.7901e-01,  1.5990e-01,\n",
       "                        3.4799e-01],\n",
       "                      [ 3.6691e-01,  4.1474e-01,  2.3253e-01, -1.5024e-01, -2.2791e-01,\n",
       "                       -1.2832e-01],\n",
       "                      [-5.3619e-01, -5.7943e-02,  2.3141e-01,  6.3913e-02, -1.7904e-01,\n",
       "                       -2.0351e-01],\n",
       "                      [ 4.1065e-02, -2.7325e-01,  4.2986e-02,  2.8875e-02, -1.7921e-01,\n",
       "                        2.3496e-01],\n",
       "                      [-3.5920e-01, -2.6390e-01, -8.2108e-02, -1.9579e-01,  3.5676e-01,\n",
       "                       -1.0193e-01],\n",
       "                      [ 4.4043e-01, -8.7417e-02,  4.0216e-02,  3.2425e-01,  1.0815e-02,\n",
       "                        1.6636e-01],\n",
       "                      [ 2.0033e-01, -8.1139e-03, -3.0753e-01,  9.3928e-02,  9.2314e-02,\n",
       "                        2.4118e-01],\n",
       "                      [ 3.1209e-01, -9.8681e-02,  2.6777e-01,  1.8124e-01,  7.5944e-02,\n",
       "                       -2.8375e-02]], device='cuda:0')),\n",
       "             ('thetaDotNN.layer1.bias',\n",
       "              tensor([-0.1337,  0.2720, -0.0197,  0.3524, -0.3633, -0.1729, -0.0472,  0.2596,\n",
       "                      -0.0698, -0.3082,  0.0747, -0.3104, -0.0482,  0.2206,  0.2290,  0.0278,\n",
       "                      -0.2498,  0.1602,  0.2610, -0.0498, -0.2856,  0.2848, -0.3240,  0.2007,\n",
       "                      -0.3657, -0.1449, -0.0213, -0.0228,  0.3862, -0.0708,  0.3532,  0.3563,\n",
       "                      -0.3175, -0.3271,  0.1500,  0.0897,  0.2309, -0.0696, -0.2890, -0.0459,\n",
       "                      -0.2256,  0.3980, -0.3853, -0.0361, -0.3613,  0.3460,  0.3071, -0.1310,\n",
       "                      -0.0189,  0.1894,  0.2803, -0.0760, -0.3084,  0.3983, -0.3239,  0.0826,\n",
       "                      -0.3019, -0.2039, -0.1550, -0.3614,  0.2326, -0.0463, -0.0112,  0.0313,\n",
       "                       0.1983, -0.0908, -0.0309, -0.1119,  0.1750, -0.1581,  0.1420,  0.0527,\n",
       "                      -0.1619, -0.2563, -0.1035,  0.3634,  0.5588,  0.0364, -0.2349, -0.0591,\n",
       "                       0.5555, -0.1446, -0.0757,  0.0948, -0.2411,  0.4169, -0.3164,  0.3909,\n",
       "                       0.0240, -0.3821, -0.2104,  0.1391, -0.1990,  0.1309, -0.3070,  0.4885,\n",
       "                      -0.1077,  0.0733, -0.1065,  0.1882, -0.0562,  0.0403,  0.0034, -0.1666,\n",
       "                      -0.1606, -0.3539,  0.5017,  0.2359,  0.4095,  0.1153,  0.2772,  0.0026,\n",
       "                      -0.0674,  0.1242, -0.1892, -0.4049, -0.0469, -0.0696,  0.0174, -0.3860,\n",
       "                      -0.1076,  0.0997,  0.1515, -0.1788,  0.0824,  0.0452,  0.2995,  0.1211],\n",
       "                     device='cuda:0')),\n",
       "             ('thetaDotNN.layer2.weight',\n",
       "              tensor([[-0.0485,  0.0092,  0.0164,  ...,  0.0405, -0.0390, -0.0195],\n",
       "                      [ 0.0031,  0.0049,  0.0564,  ...,  0.0789,  0.0422,  0.0594],\n",
       "                      [ 0.0239, -0.0280, -0.0629,  ...,  0.0606,  0.0130, -0.0546],\n",
       "                      ...,\n",
       "                      [-0.0960,  0.0153, -0.0563,  ..., -0.0711, -0.0795,  0.0845],\n",
       "                      [ 0.0466, -0.0784, -0.0155,  ..., -0.0254, -0.0401,  0.0391],\n",
       "                      [-0.0703, -0.0057,  0.0329,  ..., -0.0628,  0.0407,  0.0612]],\n",
       "                     device='cuda:0')),\n",
       "             ('thetaDotNN.layer2.bias',\n",
       "              tensor([ 0.0096,  0.0500,  0.0662, -0.1759,  0.2223, -0.0034, -0.0219,  0.1507,\n",
       "                      -0.0332, -0.0310,  0.0031, -0.0647, -0.0077, -0.0293,  0.2685,  0.3039,\n",
       "                      -0.0783,  0.0129, -0.1025, -0.0121, -0.1195,  0.0010, -0.0087, -0.0258,\n",
       "                      -0.1049, -0.1114, -0.0555, -0.0988, -0.1497, -0.0537, -0.0668, -0.0219,\n",
       "                      -0.0405, -0.1086, -0.0394, -0.0699, -0.0409, -0.0528,  0.1349, -0.0777,\n",
       "                       0.0172, -0.0164, -0.2668, -0.0267, -0.1443,  0.0462, -0.0594, -0.0829,\n",
       "                      -0.0052,  0.0218, -0.0615, -0.0679, -0.1214,  0.0486,  0.2350,  0.0114,\n",
       "                       0.0039, -0.0629,  0.1382, -0.0850,  0.0806,  0.2010, -0.1578, -0.1687,\n",
       "                      -0.0520,  0.0708,  0.0639, -0.0930, -0.1431, -0.1881, -0.0341, -0.1068,\n",
       "                      -0.0275, -0.0020, -0.0467,  0.0359,  0.0976,  0.0239, -0.1456, -0.2304,\n",
       "                       0.1096, -0.0097, -0.1429, -0.0173, -0.0940, -0.0862, -0.1507, -0.0912,\n",
       "                       0.0256,  0.1318,  0.0561, -0.1580, -0.0626,  0.0360, -0.1245,  0.0194,\n",
       "                      -0.0883,  0.0134,  0.1551, -0.1191, -0.0063, -0.2044, -0.0255, -0.0900,\n",
       "                      -0.0664,  0.0229, -0.0511,  0.0127, -0.0137, -0.0298, -0.0323, -0.0682,\n",
       "                      -0.1781,  0.0642,  0.2625,  0.0283, -0.0279, -0.1689, -0.0480, -0.0766,\n",
       "                      -0.0926,  0.0754, -0.0922,  0.0526, -0.0177, -0.0621, -0.0769, -0.0256],\n",
       "                     device='cuda:0')),\n",
       "             ('thetaDotNN.layer3.weight',\n",
       "              tensor([[-0.0299,  0.0485,  0.0408,  ..., -0.0223, -0.0018,  0.0878],\n",
       "                      [-0.0283,  0.0852,  0.0026,  ...,  0.0700,  0.0837, -0.0103],\n",
       "                      [ 0.0667, -0.0670,  0.0550,  ...,  0.0510, -0.0365,  0.0615],\n",
       "                      ...,\n",
       "                      [-0.0732, -0.0582, -0.0422,  ..., -0.0334, -0.0235, -0.0396],\n",
       "                      [ 0.0666, -0.0534, -0.0707,  ..., -0.0707,  0.0482, -0.0855],\n",
       "                      [-0.0691,  0.0735, -0.0114,  ..., -0.0731, -0.0585, -0.0073]],\n",
       "                     device='cuda:0')),\n",
       "             ('thetaDotNN.layer3.bias',\n",
       "              tensor([ 0.3969, -0.1980, -0.1283, -0.0239,  0.0094, -0.0903, -0.1100,  0.1179,\n",
       "                       0.2853, -0.1220,  0.2445, -0.1103,  0.1791,  0.2601, -0.0346, -0.0659,\n",
       "                      -0.2907, -0.3798, -0.0596, -0.0589, -0.0734, -0.1799, -0.2697,  0.1766,\n",
       "                      -0.0456, -0.3408, -0.1208, -0.2701,  0.2252, -0.0286, -0.1176, -0.0967,\n",
       "                      -0.0096, -0.1109, -0.0906, -0.1969, -0.0185, -0.0464,  0.3891, -0.1742,\n",
       "                       0.0160,  0.2263, -0.0281, -0.0732, -0.0822, -0.0834, -0.0031,  0.0776,\n",
       "                      -0.3639,  0.0590, -0.2475, -0.1238, -0.0403, -0.0650, -0.1043, -0.0343,\n",
       "                      -0.2455, -0.0014, -0.0590,  0.0004, -0.0129,  0.1651,  0.3353, -0.0135,\n",
       "                       0.2893, -0.2096,  0.1408,  0.1974,  0.1639, -0.2463, -0.0904, -0.2356,\n",
       "                       0.2428, -0.0516,  0.0240, -0.1402,  0.0145, -0.0675, -0.0908, -0.0191,\n",
       "                      -0.3901, -0.0313,  0.0186, -0.2341, -0.0453,  0.2544,  0.3192, -0.3294,\n",
       "                       0.1619, -0.3752, -0.1943, -0.0266, -0.0732, -0.0198,  0.2822,  0.0398,\n",
       "                      -0.3358,  0.0248, -0.0198,  0.2555, -0.0717,  0.0858,  0.0090,  0.1065,\n",
       "                      -0.0773,  0.0121,  0.0117, -0.3417,  0.3158, -0.0633, -0.3757,  0.1796,\n",
       "                      -0.1018, -0.0238, -0.0939,  0.0906, -0.0433,  0.1423,  0.1332, -0.2826,\n",
       "                      -0.3429, -0.2567, -0.1202, -0.1773, -0.0332, -0.0252, -0.2198,  0.0276],\n",
       "                     device='cuda:0')),\n",
       "             ('thetaDotNN.layer4.weight',\n",
       "              tensor([[-0.2562,  0.1857,  0.0399,  0.0232,  0.0384, -0.0422,  0.1119,  0.0823,\n",
       "                       -0.3114,  0.0269,  0.2683, -0.1215,  0.2472, -0.2592, -0.0116, -0.1002,\n",
       "                        0.2632, -0.2933, -0.0870, -0.0756,  0.0773,  0.1119, -0.1519, -0.4697,\n",
       "                       -0.0986,  0.1149,  0.1365,  0.1119,  0.3028, -0.0573,  0.1106,  0.0737,\n",
       "                        0.0969,  0.1164, -0.0843, -0.1464,  0.0811,  0.0849, -0.2826,  0.1244,\n",
       "                        0.1153, -0.2777,  0.0043,  0.1005, -0.0716, -0.0110,  0.0579,  0.5446,\n",
       "                        0.3151,  0.0908,  0.1864,  0.0698, -0.1160, -0.0982, -0.0869, -0.0750,\n",
       "                       -0.2099, -0.1168,  0.0464, -0.0597,  0.0138,  0.2494, -0.2279, -0.0714,\n",
       "                        0.1850,  0.1358,  0.2282,  0.3231,  0.4600,  0.1620, -0.0809,  0.1246,\n",
       "                        0.2261,  0.0834, -0.1250,  0.0636, -0.0497, -0.0858,  0.0345,  0.0697,\n",
       "                       -0.2162, -0.0138, -0.1967,  0.2596, -0.0981,  0.3179, -0.1851,  0.1766,\n",
       "                        0.5105, -0.4057, -0.1287,  0.1461,  0.1209, -0.0363,  0.2420,  0.1160,\n",
       "                        0.2151,  0.1064, -0.1036,  0.2056,  0.0723,  0.2421,  0.0227, -0.3456,\n",
       "                       -0.0631, -0.1070, -0.1723, -0.2609, -0.2437,  0.0186, -0.2554, -0.1163,\n",
       "                       -0.0581,  0.0686, -0.0036, -0.1539,  0.0495,  0.2569, -0.2557,  0.2661,\n",
       "                        0.2789, -0.2343,  0.0925, -0.1081,  0.0131,  0.0501, -0.1888,  0.0315]],\n",
       "                     device='cuda:0')),\n",
       "             ('thetaDotNN.layer4.bias', tensor([-0.0192], device='cuda:0'))])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "44265599",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T11:25:29.871539Z",
     "start_time": "2023-03-02T11:22:59.218968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Loss: [3.4976, 0.2283]\n"
     ]
    }
   ],
   "source": [
    "# モデルを評価モードに設定\n",
    "stored_model.eval()\n",
    "\n",
    "# 推論\n",
    "test_lossv = 0\n",
    "test_losstheta = 0\n",
    "test_count = 0\n",
    "with torch.no_grad():\n",
    "    for batch_x, batch_y, batch_ct in test_data:\n",
    "        for ib in range(batch_x.size(0)):\n",
    "            model.load_celltypes(batch_ct[ib].to(device))\n",
    "            test_out = calc_multiSteps(batch_x[ib].to(device))\n",
    "            lv, ltheta = myLoss(test_out, batch_y[ib].to(device))\n",
    "            test_lossv = test_lossv + lv\n",
    "            test_losstheta = test_losstheta + ltheta\n",
    "        test_count = test_count + batch_x.size(0)\n",
    "test_lossv = test_lossv/test_count\n",
    "test_losstheta = test_losstheta/test_count\n",
    "print('test Loss: [%.4f, %.4f]' % (test_lossv.item(), test_losstheta.item()))\n",
    "test_loss = [test_lossv.item(), test_losstheta.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d0283033",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T11:25:29.885112Z",
     "start_time": "2023-03-02T11:25:29.876545Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import datetime\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "nowstr = now.strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "os.makedirs(savedirName + nowstr + '/', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "445915ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T11:25:29.897162Z",
     "start_time": "2023-03-02T11:25:29.891368Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0137, device='cuda:0')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stored_model.selfpropel.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "62154d31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-02T11:25:29.920988Z",
     "start_time": "2023-03-02T11:25:29.899489Z"
    }
   },
   "outputs": [],
   "source": [
    "stored_model = stored_model.to('cpu')\n",
    "\n",
    "filename1 = savedirName + nowstr + '/' + nowstr + '_Model.pkl'\n",
    "with open(filename1, \"wb\") as f:\n",
    "    pickle.dump(stored_model, f)\n",
    "\n",
    "filename1_2 = savedirName + nowstr + '/' + nowstr + '_Model.pt'\n",
    "torch.save(stored_model, filename1_2)\n",
    "\n",
    "filename2 = savedirName + nowstr + '/' + nowstr\n",
    "torch.save(stored_model.interactNN.state_dict(), filename2 + '_interactNN.pkl')\n",
    "torch.save(stored_model.thetaDotNN.state_dict(), filename2 + '_thetaDotNN.pkl')\n",
    "torch.save(stored_model.selfpropel.detach(), filename2 + '_selfpropel.pkl')\n",
    "\n",
    "filename3 = savedirName + nowstr + '/' + nowstr + '_Separation.npz'\n",
    "np.savez(filename3, dr_thresh=dr_thresh, T_pred=T_pred, batch_size=batch_size,\n",
    "         train_inds=train_inds, valid_inds=valid_inds, test_inds=test_inds, \n",
    "         val_loss_log=val_loss_log, test_loss=test_loss,\n",
    "         transfer_origin=model_dir)\n",
    "\n",
    "filename4 = savedirName + nowstr + '/' + nowstr + '_optimizer.pt'\n",
    "torch.save(optimizer, filename4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0bd69a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 249.41666600000002,
   "position": {
    "height": "40px",
    "left": "554px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
